03/06/2020 13:13:01.183 DEBUG [org.apache.calcite.sql2rel] Plan after converting SqlNode to RelNode
LogicalSort(sort0=[$2], dir0=[DESC-nulls-last], fetch=[10])
  LogicalProject(id=[$0], cf=[$1], degree=[$1.degree])
    LogicalTableScan(table=[[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]]])

03/06/2020 13:13:02.199 DEBUG [org.apache.flink.table.planner.plan.optimize.program.FlinkGroupProgram] iteration: 1
03/06/2020 13:13:02.259 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#0: Apply rule [TableScanRule] to [rel#0:LogicalTableScan.NONE.any.None: 0.false.UNKNOWN(table=[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]])]
03/06/2020 13:13:02.262 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#0: Rule TableScanRule arguments [rel#0:LogicalTableScan.NONE.any.None: 0.false.UNKNOWN(table=[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]])] produced LogicalTableScan#14
03/06/2020 13:13:02.279 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#12:LogicalSink.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#11,name=DataStreamTableSink,fields=id, cf)
03/06/2020 13:13:02.280 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#10:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#9,id=$0,cf=$1)
03/06/2020 13:13:02.280 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#8:LogicalSort.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#7,sort0=$2,dir0=DESC-nulls-last,fetch=10)
03/06/2020 13:13:02.280 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#6:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#5,id=$0,cf=$1,degree=$1.degree)
03/06/2020 13:13:02.280 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#0:LogicalTableScan.NONE.any.None: 0.false.UNKNOWN(table=[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]])
03/06/2020 13:13:02.322 DEBUG [org.apache.flink.table.planner.plan.optimize.program.FlinkGroupProgram] optimize convert table references before rewriting sub-queries to semi-join cost 81 ms.
optimize result:
 LogicalSink(name=[DataStreamTableSink], fields=[id, cf])
+- LogicalProject(id=[$0], cf=[$1])
   +- LogicalSort(sort0=[$2], dir0=[DESC-nulls-last], fetch=[10])
      +- LogicalProject(id=[$0], cf=[$1], degree=[$1.degree])
         +- LogicalTableScan(table=[[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]]])

03/06/2020 13:13:02.333 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#22:LogicalSink.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#21,name=DataStreamTableSink,fields=id, cf)
03/06/2020 13:13:02.333 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#20:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#19,id=$0,cf=$1)
03/06/2020 13:13:02.335 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#18:LogicalSort.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#17,sort0=$2,dir0=DESC-nulls-last,fetch=10)
03/06/2020 13:13:02.335 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#16:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#15,id=$0,cf=$1,degree=$1.degree)
03/06/2020 13:13:02.335 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#0:LogicalTableScan.NONE.any.None: 0.false.UNKNOWN(table=[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]])
03/06/2020 13:13:02.343 DEBUG [org.apache.flink.table.planner.plan.optimize.program.FlinkGroupProgram] optimize rewrite sub-queries to semi-join cost 13 ms.
optimize result:
 LogicalSink(name=[DataStreamTableSink], fields=[id, cf])
+- LogicalProject(id=[$0], cf=[$1])
   +- LogicalSort(sort0=[$2], dir0=[DESC-nulls-last], fetch=[10])
      +- LogicalProject(id=[$0], cf=[$1], degree=[$1.degree])
         +- LogicalTableScan(table=[[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]]])

03/06/2020 13:13:02.351 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#31:LogicalSink.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#30,name=DataStreamTableSink,fields=id, cf)
03/06/2020 13:13:02.351 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#29:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#28,id=$0,cf=$1)
03/06/2020 13:13:02.351 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#27:LogicalSort.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#26,sort0=$2,dir0=DESC-nulls-last,fetch=10)
03/06/2020 13:13:02.351 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#25:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#24,id=$0,cf=$1,degree=$1.degree)
03/06/2020 13:13:02.351 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#0:LogicalTableScan.NONE.any.None: 0.false.UNKNOWN(table=[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]])
03/06/2020 13:13:02.353 DEBUG [org.apache.flink.table.planner.plan.optimize.program.FlinkGroupProgram] optimize sub-queries remove cost 7 ms.
optimize result:
 LogicalSink(name=[DataStreamTableSink], fields=[id, cf])
+- LogicalProject(id=[$0], cf=[$1])
   +- LogicalSort(sort0=[$2], dir0=[DESC-nulls-last], fetch=[10])
      +- LogicalProject(id=[$0], cf=[$1], degree=[$1.degree])
         +- LogicalTableScan(table=[[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]]])

03/06/2020 13:13:02.354 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1: Apply rule [TableScanRule] to [rel#0:LogicalTableScan.NONE.any.None: 0.false.UNKNOWN(table=[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]])]
03/06/2020 13:13:02.355 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1: Rule TableScanRule arguments [rel#0:LogicalTableScan.NONE.any.None: 0.false.UNKNOWN(table=[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]])] produced LogicalTableScan#42
03/06/2020 13:13:02.356 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#40:LogicalSink.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#39,name=DataStreamTableSink,fields=id, cf)
03/06/2020 13:13:02.356 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#38:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#37,id=$0,cf=$1)
03/06/2020 13:13:02.357 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#36:LogicalSort.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#35,sort0=$2,dir0=DESC-nulls-last,fetch=10)
03/06/2020 13:13:02.357 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#34:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#33,id=$0,cf=$1,degree=$1.degree)
03/06/2020 13:13:02.358 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#0:LogicalTableScan.NONE.any.None: 0.false.UNKNOWN(table=[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]])
03/06/2020 13:13:02.360 DEBUG [org.apache.flink.table.planner.plan.optimize.program.FlinkGroupProgram] optimize convert table references after sub-queries removed cost 5 ms.
optimize result:
 LogicalSink(name=[DataStreamTableSink], fields=[id, cf])
+- LogicalProject(id=[$0], cf=[$1])
   +- LogicalSort(sort0=[$2], dir0=[DESC-nulls-last], fetch=[10])
      +- LogicalProject(id=[$0], cf=[$1], degree=[$1.degree])
         +- LogicalTableScan(table=[[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]]])

03/06/2020 13:13:02.365 DEBUG [org.apache.flink.table.planner.plan.optimize.program.FlinkChainedProgram] optimize subquery_rewrite cost 172 ms.
optimize result: 
LogicalSink(name=[DataStreamTableSink], fields=[id, cf])
+- LogicalProject(id=[$0], cf=[$1])
   +- LogicalSort(sort0=[$2], dir0=[DESC-nulls-last], fetch=[10])
      +- LogicalProject(id=[$0], cf=[$1], degree=[$1.degree])
         +- LogicalTableScan(table=[[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]]])

03/06/2020 13:13:02.366 DEBUG [org.apache.flink.table.planner.plan.optimize.program.FlinkGroupProgram] iteration: 1
03/06/2020 13:13:02.383 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#2: Apply rule [TableScanRule] to [rel#0:LogicalTableScan.NONE.any.None: 0.false.UNKNOWN(table=[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]])]
03/06/2020 13:13:02.383 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#2: Rule TableScanRule arguments [rel#0:LogicalTableScan.NONE.any.None: 0.false.UNKNOWN(table=[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]])] produced LogicalTableScan#52
03/06/2020 13:13:02.384 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#50:LogicalSink.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#49,name=DataStreamTableSink,fields=id, cf)
03/06/2020 13:13:02.384 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#48:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#47,id=$0,cf=$1)
03/06/2020 13:13:02.384 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#46:LogicalSort.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#45,sort0=$2,dir0=DESC-nulls-last,fetch=10)
03/06/2020 13:13:02.385 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#44:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#43,id=$0,cf=$1,degree=$1.degree)
03/06/2020 13:13:02.385 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#0:LogicalTableScan.NONE.any.None: 0.false.UNKNOWN(table=[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]])
03/06/2020 13:13:02.386 DEBUG [org.apache.flink.table.planner.plan.optimize.program.FlinkGroupProgram] optimize convert correlate to temporal table join cost 12 ms.
optimize result:
 LogicalSink(name=[DataStreamTableSink], fields=[id, cf])
+- LogicalProject(id=[$0], cf=[$1])
   +- LogicalSort(sort0=[$2], dir0=[DESC-nulls-last], fetch=[10])
      +- LogicalProject(id=[$0], cf=[$1], degree=[$1.degree])
         +- LogicalTableScan(table=[[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]]])

03/06/2020 13:13:02.388 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#60:LogicalSink.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#59,name=DataStreamTableSink,fields=id, cf)
03/06/2020 13:13:02.388 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#58:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#57,id=$0,cf=$1)
03/06/2020 13:13:02.388 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#56:LogicalSort.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#55,sort0=$2,dir0=DESC-nulls-last,fetch=10)
03/06/2020 13:13:02.389 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#54:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#53,id=$0,cf=$1,degree=$1.degree)
03/06/2020 13:13:02.389 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#0:LogicalTableScan.NONE.any.None: 0.false.UNKNOWN(table=[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]])
03/06/2020 13:13:02.391 DEBUG [org.apache.flink.table.planner.plan.optimize.program.FlinkGroupProgram] optimize convert enumerable table scan cost 3 ms.
optimize result:
 LogicalSink(name=[DataStreamTableSink], fields=[id, cf])
+- LogicalProject(id=[$0], cf=[$1])
   +- LogicalSort(sort0=[$2], dir0=[DESC-nulls-last], fetch=[10])
      +- LogicalProject(id=[$0], cf=[$1], degree=[$1.degree])
         +- LogicalTableScan(table=[[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]]])

03/06/2020 13:13:02.393 DEBUG [org.apache.flink.table.planner.plan.optimize.program.FlinkChainedProgram] optimize temporal_join_rewrite cost 26 ms.
optimize result: 
LogicalSink(name=[DataStreamTableSink], fields=[id, cf])
+- LogicalProject(id=[$0], cf=[$1])
   +- LogicalSort(sort0=[$2], dir0=[DESC-nulls-last], fetch=[10])
      +- LogicalProject(id=[$0], cf=[$1], degree=[$1.degree])
         +- LogicalTableScan(table=[[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]]])

03/06/2020 13:13:02.421 DEBUG [org.apache.flink.table.planner.plan.optimize.program.FlinkChainedProgram] optimize decorrelate cost 26 ms.
optimize result: 
LogicalSink(name=[DataStreamTableSink], fields=[id, cf])
+- LogicalProject(id=[$0], cf=[$1])
   +- LogicalSort(sort0=[$2], dir0=[DESC-nulls-last], fetch=[10])
      +- LogicalProject(id=[$0], cf=[$1], degree=[$1.degree])
         +- LogicalTableScan(table=[[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]]])

03/06/2020 13:13:02.444 DEBUG [org.apache.flink.table.planner.plan.optimize.program.FlinkChainedProgram] optimize time_indicator cost 18 ms.
optimize result: 
LogicalSink(name=[DataStreamTableSink], fields=[id, cf])
+- LogicalProject(id=[$0], cf=[$1])
   +- LogicalSort(sort0=[$2], dir0=[DESC-nulls-last], fetch=[10])
      +- LogicalProject(id=[$0], cf=[$1], degree=[$1.degree])
         +- LogicalTableScan(table=[[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]]])

03/06/2020 13:13:02.451 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#5: Apply rule [ReduceExpressionsRule(Project)] to [rel#67:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#66,id=$0,cf=$1,degree=$1.degree)]
03/06/2020 13:13:02.541 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#6: Apply rule [ReduceExpressionsRule(Project)] to [rel#71:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#70,id=$0,cf=$1)]
03/06/2020 13:13:02.548 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#73:LogicalSink.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#72,name=DataStreamTableSink,fields=id, cf)
03/06/2020 13:13:02.548 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#71:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#70,id=$0,cf=$1)
03/06/2020 13:13:02.549 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#69:LogicalSort.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#68,sort0=$2,dir0=DESC-nulls-last,fetch=10)
03/06/2020 13:13:02.549 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#67:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#66,id=$0,cf=$1,degree=$1.degree)
03/06/2020 13:13:02.550 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#0:LogicalTableScan.NONE.any.None: 0.false.UNKNOWN(table=[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]])
03/06/2020 13:13:02.551 DEBUG [org.apache.flink.table.planner.plan.optimize.program.FlinkChainedProgram] optimize default_rewrite cost 106 ms.
optimize result: 
LogicalSink(name=[DataStreamTableSink], fields=[id, cf])
+- LogicalProject(id=[$0], cf=[$1])
   +- LogicalSort(sort0=[$2], dir0=[DESC-nulls-last], fetch=[10])
      +- LogicalProject(id=[$0], cf=[$1], degree=[$1.degree])
         +- LogicalTableScan(table=[[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]]])

03/06/2020 13:13:02.551 DEBUG [org.apache.flink.table.planner.plan.optimize.program.FlinkGroupProgram] iteration: 1
03/06/2020 13:13:02.553 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#8: Apply rule [ReduceExpressionsRule(Project)] to [rel#76:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#75,id=$0,cf=$1,degree=$1.degree)]
03/06/2020 13:13:02.556 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#9: Apply rule [ReduceExpressionsRule(Project)] to [rel#80:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#79,id=$0,cf=$1)]
03/06/2020 13:13:02.557 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#82:LogicalSink.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#81,name=DataStreamTableSink,fields=id, cf)
03/06/2020 13:13:02.557 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#80:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#79,id=$0,cf=$1)
03/06/2020 13:13:02.557 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#78:LogicalSort.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#77,sort0=$2,dir0=DESC-nulls-last,fetch=10)
03/06/2020 13:13:02.557 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#76:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#75,id=$0,cf=$1,degree=$1.degree)
03/06/2020 13:13:02.558 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#0:LogicalTableScan.NONE.any.None: 0.false.UNKNOWN(table=[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]])
03/06/2020 13:13:02.559 DEBUG [org.apache.flink.table.planner.plan.optimize.program.FlinkGroupProgram] optimize filter rules cost 7 ms.
optimize result:
 LogicalSink(name=[DataStreamTableSink], fields=[id, cf])
+- LogicalProject(id=[$0], cf=[$1])
   +- LogicalSort(sort0=[$2], dir0=[DESC-nulls-last], fetch=[10])
      +- LogicalProject(id=[$0], cf=[$1], degree=[$1.degree])
         +- LogicalTableScan(table=[[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]]])

03/06/2020 13:13:02.561 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#91:LogicalSink.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#90,name=DataStreamTableSink,fields=id, cf)
03/06/2020 13:13:02.561 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#89:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#88,id=$0,cf=$1)
03/06/2020 13:13:02.561 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#87:LogicalSort.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#86,sort0=$2,dir0=DESC-nulls-last,fetch=10)
03/06/2020 13:13:02.561 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#85:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#84,id=$0,cf=$1,degree=$1.degree)
03/06/2020 13:13:02.561 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#0:LogicalTableScan.NONE.any.None: 0.false.UNKNOWN(table=[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]])
03/06/2020 13:13:02.564 DEBUG [org.apache.flink.table.planner.plan.optimize.program.FlinkGroupProgram] optimize push predicate into table scan cost 3 ms.
optimize result:
 LogicalSink(name=[DataStreamTableSink], fields=[id, cf])
+- LogicalProject(id=[$0], cf=[$1])
   +- LogicalSort(sort0=[$2], dir0=[DESC-nulls-last], fetch=[10])
      +- LogicalProject(id=[$0], cf=[$1], degree=[$1.degree])
         +- LogicalTableScan(table=[[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]]])

03/06/2020 13:13:02.569 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#100:LogicalSink.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#99,name=DataStreamTableSink,fields=id, cf)
03/06/2020 13:13:02.569 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#98:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#97,id=$0,cf=$1)
03/06/2020 13:13:02.570 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#96:LogicalSort.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#95,sort0=$2,dir0=DESC-nulls-last,fetch=10)
03/06/2020 13:13:02.570 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#94:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#93,id=$0,cf=$1,degree=$1.degree)
03/06/2020 13:13:02.571 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#0:LogicalTableScan.NONE.any.None: 0.false.UNKNOWN(table=[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]])
03/06/2020 13:13:02.573 DEBUG [org.apache.flink.table.planner.plan.optimize.program.FlinkGroupProgram] optimize prune empty after predicate push down cost 7 ms.
optimize result:
 LogicalSink(name=[DataStreamTableSink], fields=[id, cf])
+- LogicalProject(id=[$0], cf=[$1])
   +- LogicalSort(sort0=[$2], dir0=[DESC-nulls-last], fetch=[10])
      +- LogicalProject(id=[$0], cf=[$1], degree=[$1.degree])
         +- LogicalTableScan(table=[[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]]])

03/06/2020 13:13:02.574 DEBUG [org.apache.flink.table.planner.plan.optimize.program.FlinkChainedProgram] optimize predicate_pushdown cost 22 ms.
optimize result: 
LogicalSink(name=[DataStreamTableSink], fields=[id, cf])
+- LogicalProject(id=[$0], cf=[$1])
   +- LogicalSort(sort0=[$2], dir0=[DESC-nulls-last], fetch=[10])
      +- LogicalProject(id=[$0], cf=[$1], degree=[$1.degree])
         +- LogicalTableScan(table=[[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]]])

03/06/2020 13:13:02.778 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 1/1; PHASE = PRE_PROCESS_MDR; COST = {inf}
03/06/2020 13:13:02.778 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 2/1; PHASE = PRE_PROCESS; COST = {inf}
03/06/2020 13:13:02.779 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 3/1; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:02.780 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [FlinkLogicalSinkConverter(in:NONE,out:LOGICAL)] rels [rel#109:LogicalSink.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#108,name=DataStreamTableSink,fields=id, cf)]
03/06/2020 13:13:02.780 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#103: Apply rule [FlinkLogicalSinkConverter(in:NONE,out:LOGICAL)] to [rel#109:LogicalSink.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#108,name=DataStreamTableSink,fields=id, cf)]
03/06/2020 13:13:02.782 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#114 via FlinkLogicalSinkConverter(in:NONE,out:LOGICAL)
03/06/2020 13:13:02.832 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#103 generated 1 successors: [rel#114:FlinkLogicalSink.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#113,name=DataStreamTableSink,fields=id, cf)]
03/06/2020 13:13:02.833 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 4/2; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:02.833 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [ProjectToCalcRule] rels [rel#107:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#106,id=$0,cf=$1)]
03/06/2020 13:13:02.834 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#84: Apply rule [ProjectToCalcRule] to [rel#107:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#106,id=$0,cf=$1)]
03/06/2020 13:13:02.840 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#115 via ProjectToCalcRule
03/06/2020 13:13:02.841 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#84 generated 1 successors: [rel#115:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#106,expr#0..2={inputs},id=$t0,cf=$t1)]
03/06/2020 13:13:02.841 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 5/3; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:02.842 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [rel#115:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#106,expr#0..2={inputs},id=$t0,cf=$t1)]
03/06/2020 13:13:02.842 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#129: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#115:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#106,expr#0..2={inputs},id=$t0,cf=$t1)]
03/06/2020 13:13:02.844 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#117 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
03/06/2020 13:13:02.947 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#129 generated 1 successors: [rel#117:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#116,select=id, cf)]
03/06/2020 13:13:02.949 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 6/4; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:02.951 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [ProjectSortTransposeRule] rels [rel#107:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#106,id=$0,cf=$1), rel#105:LogicalSort.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#104,sort0=$2,dir0=DESC-nulls-last,fetch=10)]
03/06/2020 13:13:02.957 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#88: Apply rule [ProjectSortTransposeRule] to [rel#107:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#106,id=$0,cf=$1), rel#105:LogicalSort.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#104,sort0=$2,dir0=DESC-nulls-last,fetch=10)]
03/06/2020 13:13:02.957 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#88 generated 0 successors.
03/06/2020 13:13:02.958 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 7/5; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:02.958 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [FlinkLogicalSortStreamConverter(in:NONE,out:LOGICAL)] rels [rel#105:LogicalSort.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#104,sort0=$2,dir0=DESC-nulls-last,fetch=10)]
03/06/2020 13:13:02.958 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#58: Apply rule [FlinkLogicalSortStreamConverter(in:NONE,out:LOGICAL)] to [rel#105:LogicalSort.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#104,sort0=$2,dir0=DESC-nulls-last,fetch=10)]
03/06/2020 13:13:02.958 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#119 via FlinkLogicalSortStreamConverter(in:NONE,out:LOGICAL)
03/06/2020 13:13:03.025 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#58 generated 1 successors: [rel#119:FlinkLogicalSort.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#118,sort0=$2,dir0=DESC-nulls-last,fetch=10)]
03/06/2020 13:13:03.026 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 8/6; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:03.026 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [SortRemoveRule] rels [rel#119:FlinkLogicalSort.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#118,sort0=$2,dir0=DESC-nulls-last,fetch=10)]
03/06/2020 13:13:03.026 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#149: Apply rule [SortRemoveRule] to [rel#119:FlinkLogicalSort.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#118,sort0=$2,dir0=DESC-nulls-last,fetch=10)]
03/06/2020 13:13:03.026 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#149 generated 0 successors.
03/06/2020 13:13:03.026 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 9/7; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:03.026 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [SortRemoveRule] rels [rel#105:LogicalSort.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#104,sort0=$2,dir0=DESC-nulls-last,fetch=10)]
03/06/2020 13:13:03.026 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#63: Apply rule [SortRemoveRule] to [rel#105:LogicalSort.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#104,sort0=$2,dir0=DESC-nulls-last,fetch=10)]
03/06/2020 13:13:03.027 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#63 generated 0 successors.
03/06/2020 13:13:03.027 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 10/8; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:03.027 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [SortProjectTransposeRule] rels [rel#105:LogicalSort.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#104,sort0=$2,dir0=DESC-nulls-last,fetch=10), rel#103:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#102,id=$0,cf=$1,degree=$1.degree)]
03/06/2020 13:13:03.027 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#61: Apply rule [SortProjectTransposeRule] to [rel#105:LogicalSort.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#104,sort0=$2,dir0=DESC-nulls-last,fetch=10), rel#103:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#102,id=$0,cf=$1,degree=$1.degree)]
03/06/2020 13:13:03.027 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#61 generated 0 successors.
03/06/2020 13:13:03.027 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 11/9; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:03.028 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [PushProjectIntoTableSourceScanRule] rels [rel#103:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#102,id=$0,cf=$1,degree=$1.degree), rel#0:LogicalTableScan.NONE.any.None: 0.false.UNKNOWN(table=[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]])]
03/06/2020 13:13:03.028 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#35: Apply rule [PushProjectIntoTableSourceScanRule] to [rel#103:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#102,id=$0,cf=$1,degree=$1.degree), rel#0:LogicalTableScan.NONE.any.None: 0.false.UNKNOWN(table=[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]])]
03/06/2020 13:13:03.031 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#35 generated 0 successors.
03/06/2020 13:13:03.033 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 12/10; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:03.034 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [ProjectToCalcRule] rels [rel#103:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#102,id=$0,cf=$1,degree=$1.degree)]
03/06/2020 13:13:03.034 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#38: Apply rule [ProjectToCalcRule] to [rel#103:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#102,id=$0,cf=$1,degree=$1.degree)]
03/06/2020 13:13:03.034 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#120 via ProjectToCalcRule
03/06/2020 13:13:03.035 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#38 generated 1 successors: [rel#120:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#102,expr#0..1={inputs},expr#2=$t1.degree,id=$t0,cf=$t1,degree=$t2)]
03/06/2020 13:13:03.035 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 13/11; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:03.036 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [rel#120:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#102,expr#0..1={inputs},expr#2=$t1.degree,id=$t0,cf=$t1,degree=$t2)]
03/06/2020 13:13:03.036 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#159: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#120:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#102,expr#0..1={inputs},expr#2=$t1.degree,id=$t0,cf=$t1,degree=$t2)]
03/06/2020 13:13:03.037 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#122 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
03/06/2020 13:13:03.058 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#159 generated 1 successors: [rel#122:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#121,select=id, cf, cf.degree AS degree)]
03/06/2020 13:13:03.058 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 14/12; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:03.058 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [FlinkLogicalTableSourceScanConverter(in:NONE,out:LOGICAL)] rels [rel#0:LogicalTableScan.NONE.any.None: 0.false.UNKNOWN(table=[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]])]
03/06/2020 13:13:03.059 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#14: Apply rule [FlinkLogicalTableSourceScanConverter(in:NONE,out:LOGICAL)] to [rel#0:LogicalTableScan.NONE.any.None: 0.false.UNKNOWN(table=[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]])]
03/06/2020 13:13:03.060 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#123 via FlinkLogicalTableSourceScanConverter(in:NONE,out:LOGICAL)
03/06/2020 13:13:03.134 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#14 generated 1 successors: [rel#123:FlinkLogicalTableSourceScan.LOGICAL.any.None: 0.false.UNKNOWN(table=[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]],fields=id, cf)]
03/06/2020 13:13:03.136 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 15/13; PHASE = OPTIMIZE; COST = {2.0000003E8 rows, 2.0000002E8 cpu, 1.6E9 io, 0.0 network, 0.0 memory}
03/06/2020 13:13:03.137 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 16/1; PHASE = CLEANUP; COST = {2.0000003E8 rows, 2.0000002E8 cpu, 1.6E9 io, 0.0 network, 0.0 memory}
03/06/2020 13:13:03.223 DEBUG [org.apache.calcite.plan.RelOptPlanner] Cheapest plan:
FlinkLogicalSink(name=[DataStreamTableSink], fields=[id, cf]): rowcount = 10.0, cumulative cost = {2.0000003E8 rows, 2.0000002E8 cpu, 1.6E9 io, 0.0 network, 0.0 memory}, id = 127
  FlinkLogicalCalc(select=[id, cf]): rowcount = 10.0, cumulative cost = {2.0000002E8 rows, 2.0000001E8 cpu, 1.6E9 io, 0.0 network, 0.0 memory}, id = 126
    FlinkLogicalSort(sort0=[$2], dir0=[DESC-nulls-last], fetch=[10]): rowcount = 10.0, cumulative cost = {2.0000001E8 rows, 2.0000001E8 cpu, 1.6E9 io, 0.0 network, 0.0 memory}, id = 125
      FlinkLogicalCalc(select=[id, cf, cf.degree AS degree]): rowcount = 1.0E8, cumulative cost = {2.0E8 rows, 2.0E8 cpu, 1.6E9 io, 0.0 network, 0.0 memory}, id = 124
        FlinkLogicalTableSourceScan(table=[[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]]], fields=[id, cf]): rowcount = 1.0E8, cumulative cost = {1.0E8 rows, 1.0E8 cpu, 1.6E9 io, 0.0 network, 0.0 memory}, id = 123

03/06/2020 13:13:03.248 DEBUG [org.apache.calcite.plan.RelOptPlanner] Provenance:
FlinkLogicalSink#127
  direct
    rel#114:FlinkLogicalSink.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#113,name=DataStreamTableSink,fields=id, cf)
      call#103 rule [FlinkLogicalSinkConverter(in:NONE,out:LOGICAL)]
        rel#109:LogicalSink.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#108,name=DataStreamTableSink,fields=id, cf)
          no parent
FlinkLogicalCalc#126
  direct
    rel#117:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#116,select=id, cf)
      call#129 rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)]
        rel#115:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#106,expr#0..2={inputs},id=$t0,cf=$t1)
          call#84 rule [ProjectToCalcRule]
            rel#107:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#106,id=$0,cf=$1)
              no parent
FlinkLogicalSort#125
  direct
    rel#119:FlinkLogicalSort.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#118,sort0=$2,dir0=DESC-nulls-last,fetch=10)
      call#58 rule [FlinkLogicalSortStreamConverter(in:NONE,out:LOGICAL)]
        rel#105:LogicalSort.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#104,sort0=$2,dir0=DESC-nulls-last,fetch=10)
          no parent
FlinkLogicalCalc#124
  direct
    rel#122:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#121,select=id, cf, cf.degree AS degree)
      call#159 rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)]
        rel#120:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#102,expr#0..1={inputs},expr#2=$t1.degree,id=$t0,cf=$t1,degree=$t2)
          call#38 rule [ProjectToCalcRule]
            rel#103:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#102,id=$0,cf=$1,degree=$1.degree)
              no parent
rel#123:FlinkLogicalTableSourceScan.LOGICAL.any.None: 0.false.UNKNOWN(table=[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]],fields=id, cf)
  call#14 rule [FlinkLogicalTableSourceScanConverter(in:NONE,out:LOGICAL)]
    rel#0:LogicalTableScan.NONE.any.None: 0.false.UNKNOWN(table=[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]])
      no parent

03/06/2020 13:13:03.262 DEBUG [org.apache.flink.table.planner.plan.optimize.program.FlinkChainedProgram] optimize logical cost 675 ms.
optimize result: 
FlinkLogicalSink(name=[DataStreamTableSink], fields=[id, cf])
+- FlinkLogicalCalc(select=[id, cf])
   +- FlinkLogicalSort(sort0=[$2], dir0=[DESC-nulls-last], fetch=[10])
      +- FlinkLogicalCalc(select=[id, cf, cf.degree AS degree])
         +- FlinkLogicalTableSourceScan(table=[[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]]], fields=[id, cf])

03/06/2020 13:13:03.287 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#135:FlinkLogicalSink.LOGICAL.any.None: 0.false.UNKNOWN(input=HepRelVertex#134,name=DataStreamTableSink,fields=id, cf)
03/06/2020 13:13:03.290 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#133:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=HepRelVertex#132,select=id, cf)
03/06/2020 13:13:03.291 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#131:FlinkLogicalSort.LOGICAL.any.None: 0.false.UNKNOWN(input=HepRelVertex#130,sort0=$2,dir0=DESC-nulls-last,fetch=10)
03/06/2020 13:13:03.291 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#129:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=HepRelVertex#128,select=id, cf, cf.degree AS degree)
03/06/2020 13:13:03.292 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#123:FlinkLogicalTableSourceScan.LOGICAL.any.None: 0.false.UNKNOWN(table=[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]],fields=id, cf)
03/06/2020 13:13:03.301 DEBUG [org.apache.flink.table.planner.plan.optimize.program.FlinkChainedProgram] optimize logical_rewrite cost 32 ms.
optimize result: 
FlinkLogicalSink(name=[DataStreamTableSink], fields=[id, cf])
+- FlinkLogicalCalc(select=[id, cf])
   +- FlinkLogicalSort(sort0=[$2], dir0=[DESC-nulls-last], fetch=[10])
      +- FlinkLogicalCalc(select=[id, cf, cf.degree AS degree])
         +- FlinkLogicalTableSourceScan(table=[[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]]], fields=[id, cf])

03/06/2020 13:13:03.341 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 1/1; PHASE = PRE_PROCESS_MDR; COST = {inf}
03/06/2020 13:13:03.344 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 2/1; PHASE = PRE_PROCESS; COST = {inf}
03/06/2020 13:13:03.344 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 3/1; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:03.346 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [StreamExecSinkRule(in:LOGICAL,out:STREAM_PHYSICAL)] rels [rel#144:FlinkLogicalSink.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#143,name=DataStreamTableSink,fields=id, cf)]
03/06/2020 13:13:03.346 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#244: Apply rule [StreamExecSinkRule(in:LOGICAL,out:STREAM_PHYSICAL)] to [rel#144:FlinkLogicalSink.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#143,name=DataStreamTableSink,fields=id, cf)]
03/06/2020 13:13:03.355 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#149 via StreamExecSinkRule(in:LOGICAL,out:STREAM_PHYSICAL)
03/06/2020 13:13:03.406 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#244 generated 1 successors: [rel#149:StreamExecSink.STREAM_PHYSICAL.any.None: 0.false.UNKNOWN(input=RelSubset#148,name=DataStreamTableSink,fields=id, cf)]
03/06/2020 13:13:03.406 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 4/2; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:03.407 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)] rels [rel#142:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#141,select=id, cf)]
03/06/2020 13:13:03.407 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#226: Apply rule [StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)] to [rel#142:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#141,select=id, cf)]
03/06/2020 13:13:03.409 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#151 via StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)
03/06/2020 13:13:03.524 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#226 generated 1 successors: [rel#151:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.UNKNOWN(input=RelSubset#150,select=id, cf)]
03/06/2020 13:13:03.525 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 5/3; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:03.527 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [StreamExecSortLimitRule(in:LOGICAL,out:STREAM_PHYSICAL)] rels [rel#140:FlinkLogicalSort.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#139,sort0=$2,dir0=DESC-nulls-last,fetch=10)]
03/06/2020 13:13:03.527 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#215: Apply rule [StreamExecSortLimitRule(in:LOGICAL,out:STREAM_PHYSICAL)] to [rel#140:FlinkLogicalSort.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#139,sort0=$2,dir0=DESC-nulls-last,fetch=10)]
03/06/2020 13:13:03.539 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#153 via StreamExecSortLimitRule(in:LOGICAL,out:STREAM_PHYSICAL)
03/06/2020 13:13:03.634 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#215 generated 1 successors: [rel#153:StreamExecSortLimit.STREAM_PHYSICAL.single.None: 0.false.UNKNOWN(input=RelSubset#152,orderBy=degree DESC,offset=0,fetch=10)]
03/06/2020 13:13:03.634 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 6/4; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:03.635 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)] rels [rel#138:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#137,select=id, cf, cf.degree AS degree)]
03/06/2020 13:13:03.635 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#201: Apply rule [StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)] to [rel#138:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#137,select=id, cf, cf.degree AS degree)]
03/06/2020 13:13:03.637 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#157 via StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)
03/06/2020 13:13:03.650 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#201 generated 1 successors: [rel#157:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.UNKNOWN(input=RelSubset#156,select=id, cf, cf.degree AS degree)]
03/06/2020 13:13:03.652 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 7/5; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:03.653 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [StreamExecTableSourceScanRule(in:LOGICAL,out:STREAM_PHYSICAL)] rels [rel#123:FlinkLogicalTableSourceScan.LOGICAL.any.None: 0.false.UNKNOWN(table=[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]],fields=id, cf)]
03/06/2020 13:13:03.658 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#189: Apply rule [StreamExecTableSourceScanRule(in:LOGICAL,out:STREAM_PHYSICAL)] to [rel#123:FlinkLogicalTableSourceScan.LOGICAL.any.None: 0.false.UNKNOWN(table=[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]],fields=id, cf)]
03/06/2020 13:13:03.661 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#160 via StreamExecTableSourceScanRule(in:LOGICAL,out:STREAM_PHYSICAL)
03/06/2020 13:13:03.784 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#189 generated 1 successors: [rel#160:StreamExecTableSourceScan.STREAM_PHYSICAL.any.None: 0.false.UNKNOWN(table=[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]],fields=id, cf)]
03/06/2020 13:13:03.785 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 8/6; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:03.787 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [FlinkExpandConversionRule] rels [rel#159:AbstractConverter.STREAM_PHYSICAL.single.None: 0.false.UNKNOWN(input=RelSubset#158,convention=STREAM_PHYSICAL,FlinkRelDistributionTraitDef=single,MiniBatchIntervalTraitDef=None: 0,UpdateAsRetractionTraitDef=false,AccModeTraitDef=UNKNOWN), rel#157:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.UNKNOWN(input=RelSubset#156,select=id, cf, cf.degree AS degree)]
03/06/2020 13:13:03.787 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#257: Apply rule [FlinkExpandConversionRule] to [rel#159:AbstractConverter.STREAM_PHYSICAL.single.None: 0.false.UNKNOWN(input=RelSubset#158,convention=STREAM_PHYSICAL,FlinkRelDistributionTraitDef=single,MiniBatchIntervalTraitDef=None: 0,UpdateAsRetractionTraitDef=false,AccModeTraitDef=UNKNOWN), rel#157:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.UNKNOWN(input=RelSubset#156,select=id, cf, cf.degree AS degree)]
03/06/2020 13:13:03.795 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#161 via FlinkExpandConversionRule
03/06/2020 13:13:03.876 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#257 generated 1 successors: [StreamExecExchange#161]
03/06/2020 13:13:03.877 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 9/7; PHASE = OPTIMIZE; COST = {3.0000003E8 rows, 1.6300000286310211E10 cpu, 1.6E9 io, 2.0E9 network, 0.0 memory}
03/06/2020 13:13:03.878 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 10/1; PHASE = CLEANUP; COST = {3.0000003E8 rows, 1.6300000286310211E10 cpu, 1.6E9 io, 2.0E9 network, 0.0 memory}
03/06/2020 13:13:03.908 DEBUG [org.apache.calcite.plan.RelOptPlanner] Cheapest plan:
StreamExecSink(name=[DataStreamTableSink], fields=[id, cf]): rowcount = 10.0, cumulative cost = {3.0000003E8 rows, 1.6300000286310211E10 cpu, 1.6E9 io, 2.0E9 network, 0.0 memory}, id = 167
  StreamExecCalc(select=[id, cf]): rowcount = 10.0, cumulative cost = {3.0000002E8 rows, 1.6300000276310211E10 cpu, 1.6E9 io, 2.0E9 network, 0.0 memory}, id = 166
    StreamExecSortLimit(orderBy=[degree DESC], offset=[0], fetch=[10]): rowcount = 10.0, cumulative cost = {3.0000001E8 rows, 1.6300000276310211E10 cpu, 1.6E9 io, 2.0E9 network, 0.0 memory}, id = 165
      StreamExecExchange(distribution=[single]): rowcount = 1.0E8, cumulative cost = {3.0E8 rows, 1.63E10 cpu, 1.6E9 io, 2.0E9 network, 0.0 memory}, id = 164
        StreamExecCalc(select=[id, cf, cf.degree AS degree]): rowcount = 1.0E8, cumulative cost = {2.0E8 rows, 2.0E8 cpu, 1.6E9 io, 0.0 network, 0.0 memory}, id = 163
          StreamExecTableSourceScan(table=[[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]]], fields=[id, cf]): rowcount = 1.0E8, cumulative cost = {1.0E8 rows, 1.0E8 cpu, 1.6E9 io, 0.0 network, 0.0 memory}, id = 160

03/06/2020 13:13:03.912 DEBUG [org.apache.calcite.plan.RelOptPlanner] Provenance:
StreamExecSink#167
  direct
    rel#149:StreamExecSink.STREAM_PHYSICAL.any.None: 0.false.UNKNOWN(input=RelSubset#148,name=DataStreamTableSink,fields=id, cf)
      call#244 rule [StreamExecSinkRule(in:LOGICAL,out:STREAM_PHYSICAL)]
        rel#144:FlinkLogicalSink.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#143,name=DataStreamTableSink,fields=id, cf)
          no parent
StreamExecCalc#166
  direct
    rel#151:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.UNKNOWN(input=RelSubset#150,select=id, cf)
      call#226 rule [StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)]
        rel#142:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#141,select=id, cf)
          no parent
StreamExecSortLimit#165
  direct
    rel#153:StreamExecSortLimit.STREAM_PHYSICAL.single.None: 0.false.UNKNOWN(input=RelSubset#152,orderBy=degree DESC,offset=0,fetch=10)
      call#215 rule [StreamExecSortLimitRule(in:LOGICAL,out:STREAM_PHYSICAL)]
        rel#140:FlinkLogicalSort.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#139,sort0=$2,dir0=DESC-nulls-last,fetch=10)
          no parent
StreamExecExchange#164
  direct
    rel#162:StreamExecExchange.STREAM_PHYSICAL.single.None: 0.false.UNKNOWN(input=RelSubset#158,distribution=single)
      call#257 rule [FlinkExpandConversionRule]
        rel#159:AbstractConverter.STREAM_PHYSICAL.single.None: 0.false.UNKNOWN(input=RelSubset#158,convention=STREAM_PHYSICAL,FlinkRelDistributionTraitDef=single,MiniBatchIntervalTraitDef=None: 0,UpdateAsRetractionTraitDef=false,AccModeTraitDef=UNKNOWN)
          call#201 rule [StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)]
            rel#138:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#137,select=id, cf, cf.degree AS degree)
              no parent
        rel#157:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.UNKNOWN(input=RelSubset#156,select=id, cf, cf.degree AS degree)
          call#201 rule [StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)]
            rel#138 (see above)
StreamExecCalc#163
  direct
    rel#157 (see above)
rel#160:StreamExecTableSourceScan.STREAM_PHYSICAL.any.None: 0.false.UNKNOWN(table=[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]],fields=id, cf)
  call#189 rule [StreamExecTableSourceScanRule(in:LOGICAL,out:STREAM_PHYSICAL)]
    rel#123:FlinkLogicalTableSourceScan.LOGICAL.any.None: 0.false.UNKNOWN(table=[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]],fields=id, cf)
      no parent

03/06/2020 13:13:03.914 DEBUG [org.apache.flink.table.planner.plan.optimize.program.FlinkChainedProgram] optimize physical cost 611 ms.
optimize result: 
Sink(name=[DataStreamTableSink], fields=[id, cf])
+- Calc(select=[id, cf])
   +- SortLimit(orderBy=[degree DESC], offset=[0], fetch=[10])
      +- Exchange(distribution=[single])
         +- Calc(select=[id, cf, cf.degree AS degree])
            +- TableSourceScan(table=[[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]]], fields=[id, cf])

03/06/2020 13:13:03.916 DEBUG [org.apache.flink.table.planner.plan.optimize.program.FlinkGroupProgram] iteration: 1
03/06/2020 13:13:03.933 DEBUG [org.apache.flink.table.planner.plan.optimize.program.FlinkGroupProgram] optimize init for retraction cost 5 ms.
optimize result:
 Sink(name=[DataStreamTableSink], fields=[id, cf])
+- Calc(select=[id, cf])
   +- SortLimit(orderBy=[degree DESC], offset=[0], fetch=[10])
      +- Exchange(distribution=[single])
         +- Calc(select=[id, cf, cf.degree AS degree])
            +- TableSourceScan(table=[[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]]], fields=[id, cf])

03/06/2020 13:13:03.955 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#263: Apply rule [AssignDefaultRetractionRule] to [rel#160:StreamExecTableSourceScan.STREAM_PHYSICAL.any.None: 0.false.UNKNOWN(table=[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]],fields=id, cf)]
03/06/2020 13:13:03.958 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#263: Rule AssignDefaultRetractionRule arguments [rel#160:StreamExecTableSourceScan.STREAM_PHYSICAL.any.None: 0.false.UNKNOWN(table=[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]],fields=id, cf)] produced StreamExecTableSourceScan#180
03/06/2020 13:13:03.961 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#264: Apply rule [AssignDefaultRetractionRule] to [rel#180:StreamExecTableSourceScan.STREAM_PHYSICAL.any.None: 0.false.Acc(table=[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]],fields=id, cf)]
03/06/2020 13:13:03.962 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#265: Apply rule [AssignDefaultRetractionRule] to [rel#170:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.UNKNOWN(input=HepRelVertex#169,select=id, cf, cf.degree AS degree)]
03/06/2020 13:13:03.962 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#265: Rule AssignDefaultRetractionRule arguments [rel#170:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.UNKNOWN(input=HepRelVertex#169,select=id, cf, cf.degree AS degree)] produced StreamExecCalc#182
03/06/2020 13:13:03.967 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#266: Apply rule [AssignDefaultRetractionRule] to [rel#180:StreamExecTableSourceScan.STREAM_PHYSICAL.any.None: 0.false.Acc(table=[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]],fields=id, cf)]
03/06/2020 13:13:03.969 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#267: Apply rule [AssignDefaultRetractionRule] to [rel#182:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#181,select=id, cf, cf.degree AS degree)]
03/06/2020 13:13:03.970 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#268: Apply rule [AssignDefaultRetractionRule] to [rel#172:StreamExecExchange.STREAM_PHYSICAL.single.None: 0.false.UNKNOWN(input=HepRelVertex#171,distribution=single)]
03/06/2020 13:13:03.975 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#268: Rule AssignDefaultRetractionRule arguments [rel#172:StreamExecExchange.STREAM_PHYSICAL.single.None: 0.false.UNKNOWN(input=HepRelVertex#171,distribution=single)] produced StreamExecExchange#184
03/06/2020 13:13:03.976 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#269: Apply rule [AssignDefaultRetractionRule] to [rel#180:StreamExecTableSourceScan.STREAM_PHYSICAL.any.None: 0.false.Acc(table=[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]],fields=id, cf)]
03/06/2020 13:13:03.976 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#270: Apply rule [AssignDefaultRetractionRule] to [rel#182:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#181,select=id, cf, cf.degree AS degree)]
03/06/2020 13:13:03.977 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#271: Apply rule [AssignDefaultRetractionRule] to [rel#184:StreamExecExchange.STREAM_PHYSICAL.single.None: 0.false.Acc(input=HepRelVertex#183,distribution=single)]
03/06/2020 13:13:03.977 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#272: Apply rule [AssignDefaultRetractionRule] to [rel#174:StreamExecSortLimit.STREAM_PHYSICAL.single.None: 0.false.UNKNOWN(input=HepRelVertex#173,orderBy=degree DESC,offset=0,fetch=10)]
03/06/2020 13:13:03.977 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#272: Rule AssignDefaultRetractionRule arguments [rel#174:StreamExecSortLimit.STREAM_PHYSICAL.single.None: 0.false.UNKNOWN(input=HepRelVertex#173,orderBy=degree DESC,offset=0,fetch=10)] produced StreamExecSortLimit#186
03/06/2020 13:13:03.978 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#273: Apply rule [AssignDefaultRetractionRule] to [rel#180:StreamExecTableSourceScan.STREAM_PHYSICAL.any.None: 0.false.Acc(table=[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]],fields=id, cf)]
03/06/2020 13:13:03.978 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#274: Apply rule [AssignDefaultRetractionRule] to [rel#182:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#181,select=id, cf, cf.degree AS degree)]
03/06/2020 13:13:03.978 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#275: Apply rule [AssignDefaultRetractionRule] to [rel#184:StreamExecExchange.STREAM_PHYSICAL.single.None: 0.false.Acc(input=HepRelVertex#183,distribution=single)]
03/06/2020 13:13:03.978 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#276: Apply rule [AssignDefaultRetractionRule] to [rel#186:StreamExecSortLimit.STREAM_PHYSICAL.single.None: 0.false.Acc(input=HepRelVertex#185,orderBy=degree DESC,offset=0,fetch=10)]
03/06/2020 13:13:03.979 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#277: Apply rule [AssignDefaultRetractionRule] to [rel#176:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.UNKNOWN(input=HepRelVertex#175,select=id, cf)]
03/06/2020 13:13:03.979 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#277: Rule AssignDefaultRetractionRule arguments [rel#176:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.UNKNOWN(input=HepRelVertex#175,select=id, cf)] produced StreamExecCalc#188
03/06/2020 13:13:03.980 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#278: Apply rule [AssignDefaultRetractionRule] to [rel#180:StreamExecTableSourceScan.STREAM_PHYSICAL.any.None: 0.false.Acc(table=[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]],fields=id, cf)]
03/06/2020 13:13:03.980 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#279: Apply rule [AssignDefaultRetractionRule] to [rel#182:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#181,select=id, cf, cf.degree AS degree)]
03/06/2020 13:13:03.980 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#280: Apply rule [AssignDefaultRetractionRule] to [rel#184:StreamExecExchange.STREAM_PHYSICAL.single.None: 0.false.Acc(input=HepRelVertex#183,distribution=single)]
03/06/2020 13:13:03.981 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#281: Apply rule [AssignDefaultRetractionRule] to [rel#186:StreamExecSortLimit.STREAM_PHYSICAL.single.None: 0.false.Acc(input=HepRelVertex#185,orderBy=degree DESC,offset=0,fetch=10)]
03/06/2020 13:13:03.981 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#282: Apply rule [AssignDefaultRetractionRule] to [rel#188:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#187,select=id, cf)]
03/06/2020 13:13:03.982 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#283: Apply rule [AssignDefaultRetractionRule] to [rel#178:StreamExecSink.STREAM_PHYSICAL.any.None: 0.true.UNKNOWN(input=HepRelVertex#177,name=DataStreamTableSink,fields=id, cf)]
03/06/2020 13:13:03.986 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#283: Rule AssignDefaultRetractionRule arguments [rel#178:StreamExecSink.STREAM_PHYSICAL.any.None: 0.true.UNKNOWN(input=HepRelVertex#177,name=DataStreamTableSink,fields=id, cf)] produced StreamExecSink#190
03/06/2020 13:13:03.988 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#284: Apply rule [AssignDefaultRetractionRule] to [rel#180:StreamExecTableSourceScan.STREAM_PHYSICAL.any.None: 0.false.Acc(table=[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]],fields=id, cf)]
03/06/2020 13:13:03.988 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#285: Apply rule [AssignDefaultRetractionRule] to [rel#182:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#181,select=id, cf, cf.degree AS degree)]
03/06/2020 13:13:03.989 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#286: Apply rule [AssignDefaultRetractionRule] to [rel#184:StreamExecExchange.STREAM_PHYSICAL.single.None: 0.false.Acc(input=HepRelVertex#183,distribution=single)]
03/06/2020 13:13:03.989 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#287: Apply rule [AssignDefaultRetractionRule] to [rel#186:StreamExecSortLimit.STREAM_PHYSICAL.single.None: 0.false.Acc(input=HepRelVertex#185,orderBy=degree DESC,offset=0,fetch=10)]
03/06/2020 13:13:03.989 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#288: Apply rule [AssignDefaultRetractionRule] to [rel#188:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#187,select=id, cf)]
03/06/2020 13:13:03.989 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#289: Apply rule [AssignDefaultRetractionRule] to [rel#190:StreamExecSink.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#189,name=DataStreamTableSink,fields=id, cf)]
03/06/2020 13:13:03.989 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#290: Apply rule [SetUpdatesAsRetractionRule] to [rel#180:StreamExecTableSourceScan.STREAM_PHYSICAL.any.None: 0.false.Acc(table=[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]],fields=id, cf)]
03/06/2020 13:13:03.991 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#291: Apply rule [SetUpdatesAsRetractionRule] to [rel#182:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#181,select=id, cf, cf.degree AS degree)]
03/06/2020 13:13:03.992 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#292: Apply rule [SetUpdatesAsRetractionRule] to [rel#184:StreamExecExchange.STREAM_PHYSICAL.single.None: 0.false.Acc(input=HepRelVertex#183,distribution=single)]
03/06/2020 13:13:03.993 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#293: Apply rule [SetUpdatesAsRetractionRule] to [rel#186:StreamExecSortLimit.STREAM_PHYSICAL.single.None: 0.false.Acc(input=HepRelVertex#185,orderBy=degree DESC,offset=0,fetch=10)]
03/06/2020 13:13:03.996 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#294: Apply rule [SetUpdatesAsRetractionRule] to [rel#188:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#187,select=id, cf)]
03/06/2020 13:13:03.996 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#295: Apply rule [SetUpdatesAsRetractionRule] to [rel#190:StreamExecSink.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#189,name=DataStreamTableSink,fields=id, cf)]
03/06/2020 13:13:03.998 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#295: Rule SetUpdatesAsRetractionRule arguments [rel#190:StreamExecSink.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#189,name=DataStreamTableSink,fields=id, cf)] produced StreamExecSink#193
03/06/2020 13:13:04.008 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#296: Apply rule [SetUpdatesAsRetractionRule] to [rel#180:StreamExecTableSourceScan.STREAM_PHYSICAL.any.None: 0.false.Acc(table=[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]],fields=id, cf)]
03/06/2020 13:13:04.008 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#297: Apply rule [SetUpdatesAsRetractionRule] to [rel#182:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#181,select=id, cf, cf.degree AS degree)]
03/06/2020 13:13:04.009 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#298: Apply rule [SetUpdatesAsRetractionRule] to [rel#184:StreamExecExchange.STREAM_PHYSICAL.single.None: 0.false.Acc(input=HepRelVertex#183,distribution=single)]
03/06/2020 13:13:04.015 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#299: Apply rule [SetUpdatesAsRetractionRule] to [rel#186:StreamExecSortLimit.STREAM_PHYSICAL.single.None: 0.false.Acc(input=HepRelVertex#185,orderBy=degree DESC,offset=0,fetch=10)]
03/06/2020 13:13:04.015 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#300: Apply rule [SetUpdatesAsRetractionRule] to [rel#192:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#187,select=id, cf)]
03/06/2020 13:13:04.016 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#300: Rule SetUpdatesAsRetractionRule arguments [rel#192:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#187,select=id, cf)] produced StreamExecCalc#198
03/06/2020 13:13:04.019 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#301: Apply rule [SetUpdatesAsRetractionRule] to [rel#180:StreamExecTableSourceScan.STREAM_PHYSICAL.any.None: 0.false.Acc(table=[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]],fields=id, cf)]
03/06/2020 13:13:04.020 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#302: Apply rule [SetUpdatesAsRetractionRule] to [rel#182:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#181,select=id, cf, cf.degree AS degree)]
03/06/2020 13:13:04.021 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#303: Apply rule [SetUpdatesAsRetractionRule] to [rel#184:StreamExecExchange.STREAM_PHYSICAL.single.None: 0.false.Acc(input=HepRelVertex#183,distribution=single)]
03/06/2020 13:13:04.022 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#304: Apply rule [SetUpdatesAsRetractionRule] to [rel#197:StreamExecSortLimit.STREAM_PHYSICAL.single.None: 0.true.Acc(input=HepRelVertex#185,orderBy=degree DESC,offset=0,fetch=10)]
03/06/2020 13:13:04.023 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#305: Apply rule [SetUpdatesAsRetractionRule] to [rel#200:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#199,select=id, cf)]
03/06/2020 13:13:04.023 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#306: Apply rule [SetUpdatesAsRetractionRule] to [rel#195:StreamExecSink.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#194,name=DataStreamTableSink,fields=id, cf)]
03/06/2020 13:13:04.023 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#307: Apply rule [SetAccModeRule] to [rel#180:StreamExecTableSourceScan.STREAM_PHYSICAL.any.None: 0.false.Acc(table=[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]],fields=id, cf)]
03/06/2020 13:13:04.024 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#308: Apply rule [SetAccModeRule] to [rel#182:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#181,select=id, cf, cf.degree AS degree)]
03/06/2020 13:13:04.024 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#309: Apply rule [SetAccModeRule] to [rel#184:StreamExecExchange.STREAM_PHYSICAL.single.None: 0.false.Acc(input=HepRelVertex#183,distribution=single)]
03/06/2020 13:13:04.024 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#310: Apply rule [SetAccModeRule] to [rel#197:StreamExecSortLimit.STREAM_PHYSICAL.single.None: 0.true.Acc(input=HepRelVertex#185,orderBy=degree DESC,offset=0,fetch=10)]
03/06/2020 13:13:04.026 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#310: Rule SetAccModeRule arguments [rel#197:StreamExecSortLimit.STREAM_PHYSICAL.single.None: 0.true.Acc(input=HepRelVertex#185,orderBy=degree DESC,offset=0,fetch=10)] produced StreamExecSortLimit#202
03/06/2020 13:13:04.028 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#311: Apply rule [SetAccModeRule] to [rel#180:StreamExecTableSourceScan.STREAM_PHYSICAL.any.None: 0.false.Acc(table=[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]],fields=id, cf)]
03/06/2020 13:13:04.029 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#312: Apply rule [SetAccModeRule] to [rel#182:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#181,select=id, cf, cf.degree AS degree)]
03/06/2020 13:13:04.029 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#313: Apply rule [SetAccModeRule] to [rel#184:StreamExecExchange.STREAM_PHYSICAL.single.None: 0.false.Acc(input=HepRelVertex#183,distribution=single)]
03/06/2020 13:13:04.029 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#314: Apply rule [SetAccModeRule] to [rel#202:StreamExecSortLimit.STREAM_PHYSICAL.single.None: 0.true.AccRetract(input=HepRelVertex#185,orderBy=degree DESC,offset=0,fetch=10)]
03/06/2020 13:13:04.029 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#315: Apply rule [SetAccModeRule] to [rel#200:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#199,select=id, cf)]
03/06/2020 13:13:04.030 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#315: Rule SetAccModeRule arguments [rel#200:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#199,select=id, cf)] produced StreamExecCalc#204
03/06/2020 13:13:04.030 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#316: Apply rule [SetAccModeRule] to [rel#180:StreamExecTableSourceScan.STREAM_PHYSICAL.any.None: 0.false.Acc(table=[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]],fields=id, cf)]
03/06/2020 13:13:04.031 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#317: Apply rule [SetAccModeRule] to [rel#182:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#181,select=id, cf, cf.degree AS degree)]
03/06/2020 13:13:04.031 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#318: Apply rule [SetAccModeRule] to [rel#184:StreamExecExchange.STREAM_PHYSICAL.single.None: 0.false.Acc(input=HepRelVertex#183,distribution=single)]
03/06/2020 13:13:04.031 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#319: Apply rule [SetAccModeRule] to [rel#202:StreamExecSortLimit.STREAM_PHYSICAL.single.None: 0.true.AccRetract(input=HepRelVertex#185,orderBy=degree DESC,offset=0,fetch=10)]
03/06/2020 13:13:04.031 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#320: Apply rule [SetAccModeRule] to [rel#204:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.AccRetract(input=HepRelVertex#203,select=id, cf)]
03/06/2020 13:13:04.031 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#321: Apply rule [SetAccModeRule] to [rel#195:StreamExecSink.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#194,name=DataStreamTableSink,fields=id, cf)]
03/06/2020 13:13:04.035 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#321: Rule SetAccModeRule arguments [rel#195:StreamExecSink.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#194,name=DataStreamTableSink,fields=id, cf)] produced StreamExecSink#206
03/06/2020 13:13:04.042 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#322: Apply rule [SetAccModeRule] to [rel#180:StreamExecTableSourceScan.STREAM_PHYSICAL.any.None: 0.false.Acc(table=[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]],fields=id, cf)]
03/06/2020 13:13:04.043 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#323: Apply rule [SetAccModeRule] to [rel#182:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#181,select=id, cf, cf.degree AS degree)]
03/06/2020 13:13:04.043 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#324: Apply rule [SetAccModeRule] to [rel#184:StreamExecExchange.STREAM_PHYSICAL.single.None: 0.false.Acc(input=HepRelVertex#183,distribution=single)]
03/06/2020 13:13:04.043 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#325: Apply rule [SetAccModeRule] to [rel#202:StreamExecSortLimit.STREAM_PHYSICAL.single.None: 0.true.AccRetract(input=HepRelVertex#185,orderBy=degree DESC,offset=0,fetch=10)]
03/06/2020 13:13:04.044 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#326: Apply rule [SetAccModeRule] to [rel#204:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.AccRetract(input=HepRelVertex#203,select=id, cf)]
03/06/2020 13:13:04.044 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#327: Apply rule [SetAccModeRule] to [rel#206:StreamExecSink.STREAM_PHYSICAL.any.None: 0.true.AccRetract(input=HepRelVertex#205,name=DataStreamTableSink,fields=id, cf)]
03/06/2020 13:13:04.044 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#206:StreamExecSink.STREAM_PHYSICAL.any.None: 0.true.AccRetract(input=HepRelVertex#205,name=DataStreamTableSink,fields=id, cf)
03/06/2020 13:13:04.044 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#204:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.AccRetract(input=HepRelVertex#203,select=id, cf)
03/06/2020 13:13:04.044 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#202:StreamExecSortLimit.STREAM_PHYSICAL.single.None: 0.true.AccRetract(input=HepRelVertex#185,orderBy=degree DESC,offset=0,fetch=10)
03/06/2020 13:13:04.044 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#184:StreamExecExchange.STREAM_PHYSICAL.single.None: 0.false.Acc(input=HepRelVertex#183,distribution=single)
03/06/2020 13:13:04.044 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#182:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#181,select=id, cf, cf.degree AS degree)
03/06/2020 13:13:04.044 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#180:StreamExecTableSourceScan.STREAM_PHYSICAL.any.None: 0.false.Acc(table=[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]],fields=id, cf)
03/06/2020 13:13:04.046 DEBUG [org.apache.flink.table.planner.plan.optimize.program.FlinkGroupProgram] optimize retraction rules cost 111 ms.
optimize result:
 Sink(name=[DataStreamTableSink], fields=[id, cf])
+- Calc(select=[id, cf])
   +- SortLimit(orderBy=[degree DESC], offset=[0], fetch=[10])
      +- Exchange(distribution=[single])
         +- Calc(select=[id, cf, cf.degree AS degree])
            +- TableSourceScan(table=[[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]]], fields=[id, cf])

03/06/2020 13:13:04.057 DEBUG [org.apache.flink.table.planner.plan.optimize.program.FlinkGroupProgram] optimize Initialization for mini-batch interval inference cost 0 ms.
optimize result:
 Sink(name=[DataStreamTableSink], fields=[id, cf])
+- Calc(select=[id, cf])
   +- SortLimit(orderBy=[degree DESC], offset=[0], fetch=[10])
      +- Exchange(distribution=[single])
         +- Calc(select=[id, cf, cf.degree AS degree])
            +- TableSourceScan(table=[[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]]], fields=[id, cf])

03/06/2020 13:13:04.072 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#328: Apply rule [MiniBatchIntervalInferRule] to [rel#218:StreamExecSink.STREAM_PHYSICAL.any.None: 0.true.AccRetract(input=HepRelVertex#217,name=DataStreamTableSink,fields=id, cf)]
03/06/2020 13:13:04.074 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#329: Apply rule [MiniBatchIntervalInferRule] to [rel#216:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.AccRetract(input=HepRelVertex#215,select=id, cf)]
03/06/2020 13:13:04.075 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#330: Apply rule [MiniBatchIntervalInferRule] to [rel#214:StreamExecSortLimit.STREAM_PHYSICAL.single.None: 0.true.AccRetract(input=HepRelVertex#213,orderBy=degree DESC,offset=0,fetch=10)]
03/06/2020 13:13:04.076 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#331: Apply rule [MiniBatchIntervalInferRule] to [rel#212:StreamExecExchange.STREAM_PHYSICAL.single.None: 0.false.Acc(input=HepRelVertex#211,distribution=single)]
03/06/2020 13:13:04.076 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#332: Apply rule [MiniBatchIntervalInferRule] to [rel#210:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#209,select=id, cf, cf.degree AS degree)]
03/06/2020 13:13:04.078 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#333: Apply rule [MiniBatchIntervalInferRule] to [rel#180:StreamExecTableSourceScan.STREAM_PHYSICAL.any.None: 0.false.Acc(table=[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]],fields=id, cf)]
03/06/2020 13:13:04.079 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#218:StreamExecSink.STREAM_PHYSICAL.any.None: 0.true.AccRetract(input=HepRelVertex#217,name=DataStreamTableSink,fields=id, cf)
03/06/2020 13:13:04.079 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#216:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.AccRetract(input=HepRelVertex#215,select=id, cf)
03/06/2020 13:13:04.080 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#214:StreamExecSortLimit.STREAM_PHYSICAL.single.None: 0.true.AccRetract(input=HepRelVertex#213,orderBy=degree DESC,offset=0,fetch=10)
03/06/2020 13:13:04.080 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#212:StreamExecExchange.STREAM_PHYSICAL.single.None: 0.false.Acc(input=HepRelVertex#211,distribution=single)
03/06/2020 13:13:04.081 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#210:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#209,select=id, cf, cf.degree AS degree)
03/06/2020 13:13:04.084 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#180:StreamExecTableSourceScan.STREAM_PHYSICAL.any.None: 0.false.Acc(table=[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]],fields=id, cf)
03/06/2020 13:13:04.091 DEBUG [org.apache.flink.table.planner.plan.optimize.program.FlinkGroupProgram] optimize mini-batch interval rules cost 29 ms.
optimize result:
 Sink(name=[DataStreamTableSink], fields=[id, cf])
+- Calc(select=[id, cf])
   +- SortLimit(orderBy=[degree DESC], offset=[0], fetch=[10])
      +- Exchange(distribution=[single])
         +- Calc(select=[id, cf, cf.degree AS degree])
            +- TableSourceScan(table=[[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]]], fields=[id, cf])

03/06/2020 13:13:04.098 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#229:StreamExecSink.STREAM_PHYSICAL.any.None: 0.true.AccRetract(input=HepRelVertex#228,name=DataStreamTableSink,fields=id, cf)
03/06/2020 13:13:04.099 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#227:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.AccRetract(input=HepRelVertex#226,select=id, cf)
03/06/2020 13:13:04.099 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#225:StreamExecSortLimit.STREAM_PHYSICAL.single.None: 0.true.AccRetract(input=HepRelVertex#224,orderBy=degree DESC,offset=0,fetch=10)
03/06/2020 13:13:04.099 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#223:StreamExecExchange.STREAM_PHYSICAL.single.None: 0.false.Acc(input=HepRelVertex#222,distribution=single)
03/06/2020 13:13:04.099 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#221:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#220,select=id, cf, cf.degree AS degree)
03/06/2020 13:13:04.099 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#180:StreamExecTableSourceScan.STREAM_PHYSICAL.any.None: 0.false.Acc(table=[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]],fields=id, cf)
03/06/2020 13:13:04.102 DEBUG [org.apache.flink.table.planner.plan.optimize.program.FlinkGroupProgram] optimize physical rewrite cost 9 ms.
optimize result:
 Sink(name=[DataStreamTableSink], fields=[id, cf])
+- Calc(select=[id, cf])
   +- SortLimit(orderBy=[degree DESC], offset=[0], fetch=[10])
      +- Exchange(distribution=[single])
         +- Calc(select=[id, cf, cf.degree AS degree])
            +- TableSourceScan(table=[[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]]], fields=[id, cf])

03/06/2020 13:13:04.105 DEBUG [org.apache.flink.table.planner.plan.optimize.program.FlinkChainedProgram] optimize physical_rewrite cost 186 ms.
optimize result: 
Sink(name=[DataStreamTableSink], fields=[id, cf])
+- Calc(select=[id, cf])
   +- SortLimit(orderBy=[degree DESC], offset=[0], fetch=[10])
      +- Exchange(distribution=[single])
         +- Calc(select=[id, cf, cf.degree AS degree])
            +- TableSourceScan(table=[[default_catalog, default_database, loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]]], fields=[id, cf])

03/06/2020 13:13:04.157 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the org.apache.flink.api.java.typeutils.RowTypeInfo
03/06/2020 13:13:04.159 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the [Ljava.lang.String;
03/06/2020 13:13:04.237 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the org.apache.flink.addons.hbase.HBaseRowInputFormat
03/06/2020 13:13:04.251 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the java.lang.String
03/06/2020 13:13:04.251 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the [C
03/06/2020 13:13:04.255 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the java.lang.Integer
03/06/2020 13:13:04.255 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the org.apache.flink.addons.hbase.HBaseTableSchema
03/06/2020 13:13:04.259 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the java.util.LinkedHashMap
03/06/2020 13:13:04.261 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the java.lang.Boolean
03/06/2020 13:13:04.272 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the org.apache.flink.addons.hbase.HBaseTableSchema$RowKeyInfo
03/06/2020 13:13:04.272 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the java.lang.String
03/06/2020 13:13:04.272 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the [C
03/06/2020 13:13:04.272 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the java.lang.Integer
03/06/2020 13:13:04.272 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the org.apache.flink.api.common.typeinfo.BasicTypeInfo
03/06/2020 13:13:04.273 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the java.lang.Class
03/06/2020 13:13:04.277 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the org.apache.flink.api.common.typeutils.base.StringSerializer
03/06/2020 13:13:04.278 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the [Ljava.lang.Class;
03/06/2020 13:13:04.278 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the java.lang.Class
03/06/2020 13:13:04.280 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the java.lang.Integer
03/06/2020 13:13:04.282 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the java.lang.String
03/06/2020 13:13:04.283 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the [C
03/06/2020 13:13:04.284 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the java.lang.Integer
03/06/2020 13:13:04.309 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the java.lang.Boolean
03/06/2020 13:13:04.537 DEBUG [org.apache.flink.table.planner.codegen.OperatorCodeGenerator$] Compiling OneInputStreamOperator Code:
SourceConversion
03/06/2020 13:13:04.684 DEBUG [org.apache.flink.table.planner.codegen.OperatorCodeGenerator$] Compiling OneInputStreamOperator Code:
StreamExecCalc
03/06/2020 13:13:04.768 DEBUG [org.apache.flink.table.planner.codegen.OperatorCodeGenerator$] Compiling OneInputStreamOperator Code:
StreamExecCalc
03/06/2020 13:13:04.788 DEBUG [org.apache.flink.table.planner.codegen.OperatorCodeGenerator$] Compiling OneInputStreamOperator Code:
SinkConversion
03/06/2020 13:13:04.827 DEBUG [org.apache.hadoop.security.Groups]  Creating new Groups object
03/06/2020 13:13:04.880 DEBUG [org.apache.hadoop.util.NativeCodeLoader] Trying to load the custom-built native-hadoop library...
03/06/2020 13:13:04.881 DEBUG [org.apache.hadoop.util.NativeCodeLoader] Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
03/06/2020 13:13:04.881 DEBUG [org.apache.hadoop.util.NativeCodeLoader] java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
03/06/2020 13:13:04.881  WARN [org.apache.hadoop.util.NativeCodeLoader] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
03/06/2020 13:13:04.881 DEBUG [org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback] Falling back to shell based
03/06/2020 13:13:04.882 DEBUG [org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback] Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
03/06/2020 13:13:05.047 DEBUG [org.apache.hadoop.util.Shell] setsid exited with exit code 0
03/06/2020 13:13:05.047 DEBUG [org.apache.hadoop.security.Groups] Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
03/06/2020 13:13:05.213 DEBUG [org.apache.hadoop.metrics2.lib.MutableMetricsFactory] field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
03/06/2020 13:13:05.222 DEBUG [org.apache.hadoop.metrics2.lib.MutableMetricsFactory] field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
03/06/2020 13:13:05.222 DEBUG [org.apache.hadoop.metrics2.lib.MutableMetricsFactory] field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
03/06/2020 13:13:05.224 DEBUG [org.apache.hadoop.metrics2.impl.MetricsSystemImpl] UgiMetrics, User and group related metrics
03/06/2020 13:13:05.286 DEBUG [org.apache.hadoop.security.authentication.util.KerberosName] Kerberos krb5 configuration not found, setting default realm to empty
03/06/2020 13:13:05.299 DEBUG [org.apache.hadoop.security.UserGroupInformation] hadoop login
03/06/2020 13:13:05.303 DEBUG [org.apache.hadoop.security.UserGroupInformation] hadoop login commit
03/06/2020 13:13:05.308 DEBUG [org.apache.hadoop.security.UserGroupInformation] using local user:UnixPrincipal: aljoscha
03/06/2020 13:13:05.310 DEBUG [org.apache.hadoop.security.UserGroupInformation] UGI loginUser:aljoscha (auth:SIMPLE)
03/06/2020 13:13:05.476  INFO [org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper] Process identifier=hconnection-0x642ee49c connecting to ZooKeeper ensemble=localhost:2181
03/06/2020 13:13:05.487  INFO [org.apache.zookeeper.ZooKeeper] Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT
03/06/2020 13:13:05.487  INFO [org.apache.zookeeper.ZooKeeper] Client environment:host.name=ubuntu
03/06/2020 13:13:05.487  INFO [org.apache.zookeeper.ZooKeeper] Client environment:java.version=1.8.0_252
03/06/2020 13:13:05.487  INFO [org.apache.zookeeper.ZooKeeper] Client environment:java.vendor=Private Build
03/06/2020 13:13:05.487  INFO [org.apache.zookeeper.ZooKeeper] Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre
03/06/2020 13:13:05.487  INFO [org.apache.zookeeper.ZooKeeper] Client environment:java.class.path=/home/aljoscha/eclipse-workspace/Gradoop_Flink_Prototype/target/classes:/home/aljoscha/.m2/repository/org/apache/flink/flink-java/1.10.0/flink-java-1.10.0.jar:/home/aljoscha/.m2/repository/org/apache/flink/flink-core/1.10.0/flink-core-1.10.0.jar:/home/aljoscha/.m2/repository/org/apache/flink/flink-annotations/1.10.0/flink-annotations-1.10.0.jar:/home/aljoscha/.m2/repository/org/apache/flink/flink-metrics-core/1.10.0/flink-metrics-core-1.10.0.jar:/home/aljoscha/.m2/repository/com/esotericsoftware/kryo/kryo/2.24.0/kryo-2.24.0.jar:/home/aljoscha/.m2/repository/com/esotericsoftware/minlog/minlog/1.2/minlog-1.2.jar:/home/aljoscha/.m2/repository/org/objenesis/objenesis/2.1/objenesis-2.1.jar:/home/aljoscha/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/aljoscha/.m2/repository/org/apache/commons/commons-compress/1.18/commons-compress-1.18.jar:/home/aljoscha/.m2/repository/org/apache/flink/flink-shaded-asm-7/7.1-9.0/flink-shaded-asm-7-7.1-9.0.jar:/home/aljoscha/.m2/repository/org/apache/commons/commons-lang3/3.3.2/commons-lang3-3.3.2.jar:/home/aljoscha/.m2/repository/org/apache/commons/commons-math3/3.5/commons-math3-3.5.jar:/home/aljoscha/.m2/repository/org/slf4j/slf4j-api/1.7.15/slf4j-api-1.7.15.jar:/home/aljoscha/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/home/aljoscha/.m2/repository/org/apache/flink/force-shading/1.10.0/force-shading-1.10.0.jar:/home/aljoscha/.m2/repository/org/apache/flink/flink-clients_2.11/1.10.0/flink-clients_2.11-1.10.0.jar:/home/aljoscha/.m2/repository/org/apache/flink/flink-runtime_2.11/1.10.0/flink-runtime_2.11-1.10.0.jar:/home/aljoscha/.m2/repository/org/apache/flink/flink-queryable-state-client-java/1.10.0/flink-queryable-state-client-java-1.10.0.jar:/home/aljoscha/.m2/repository/org/apache/flink/flink-hadoop-fs/1.10.0/flink-hadoop-fs-1.10.0.jar:/home/aljoscha/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/aljoscha/.m2/repository/org/apache/flink/flink-shaded-netty/4.1.39.Final-9.0/flink-shaded-netty-4.1.39.Final-9.0.jar:/home/aljoscha/.m2/repository/org/javassist/javassist/3.24.0-GA/javassist-3.24.0-GA.jar:/home/aljoscha/.m2/repository/com/typesafe/akka/akka-actor_2.11/2.5.21/akka-actor_2.11-2.5.21.jar:/home/aljoscha/.m2/repository/com/typesafe/config/1.3.3/config-1.3.3.jar:/home/aljoscha/.m2/repository/org/scala-lang/modules/scala-java8-compat_2.11/0.7.0/scala-java8-compat_2.11-0.7.0.jar:/home/aljoscha/.m2/repository/com/typesafe/akka/akka-stream_2.11/2.5.21/akka-stream_2.11-2.5.21.jar:/home/aljoscha/.m2/repository/org/reactivestreams/reactive-streams/1.0.2/reactive-streams-1.0.2.jar:/home/aljoscha/.m2/repository/com/typesafe/ssl-config-core_2.11/0.3.7/ssl-config-core_2.11-0.3.7.jar:/home/aljoscha/.m2/repository/com/typesafe/akka/akka-protobuf_2.11/2.5.21/akka-protobuf_2.11-2.5.21.jar:/home/aljoscha/.m2/repository/com/typesafe/akka/akka-slf4j_2.11/2.5.21/akka-slf4j_2.11-2.5.21.jar:/home/aljoscha/.m2/repository/org/clapper/grizzled-slf4j_2.11/1.3.2/grizzled-slf4j_2.11-1.3.2.jar:/home/aljoscha/.m2/repository/com/github/scopt/scopt_2.11/3.5.0/scopt_2.11-3.5.0.jar:/home/aljoscha/.m2/repository/org/xerial/snappy/snappy-java/1.1.4/snappy-java-1.1.4.jar:/home/aljoscha/.m2/repository/com/twitter/chill_2.11/0.7.6/chill_2.11-0.7.6.jar:/home/aljoscha/.m2/repository/com/twitter/chill-java/0.7.6/chill-java-0.7.6.jar:/home/aljoscha/.m2/repository/org/lz4/lz4-java/1.5.0/lz4-java-1.5.0.jar:/home/aljoscha/.m2/repository/commons-cli/commons-cli/1.3.1/commons-cli-1.3.1.jar:/home/aljoscha/.m2/repository/org/apache/flink/flink-table-api-java-bridge_2.11/1.10.0/flink-table-api-java-bridge_2.11-1.10.0.jar:/home/aljoscha/.m2/repository/org/apache/flink/flink-table-api-java/1.10.0/flink-table-api-java-1.10.0.jar:/home/aljoscha/.m2/repository/org/apache/flink/flink-streaming-java_2.11/1.10.0/flink-streaming-java_2.11-1.10.0.jar:/home/aljoscha/.m2/repository/org/apache/flink/flink-table-planner_2.11/1.10.0/flink-table-planner_2.11-1.10.0.jar:/home/aljoscha/.m2/repository/org/apache/flink/flink-table-common/1.10.0/flink-table-common-1.10.0.jar:/home/aljoscha/.m2/repository/org/apache/flink/flink-table-api-scala-bridge_2.11/1.10.0/flink-table-api-scala-bridge_2.11-1.10.0.jar:/home/aljoscha/.m2/repository/org/apache/flink/flink-streaming-scala_2.11/1.10.0/flink-streaming-scala_2.11-1.10.0.jar:/home/aljoscha/.m2/repository/org/apache/flink/flink-scala_2.11/1.10.0/flink-scala_2.11-1.10.0.jar:/home/aljoscha/.m2/repository/org/scala-lang/scala-reflect/2.11.12/scala-reflect-2.11.12.jar:/home/aljoscha/.m2/repository/org/scala-lang/scala-library/2.11.12/scala-library-2.11.12.jar:/home/aljoscha/.m2/repository/org/scala-lang/scala-compiler/2.11.12/scala-compiler-2.11.12.jar:/home/aljoscha/.m2/repository/org/scala-lang/modules/scala-xml_2.11/1.0.5/scala-xml_2.11-1.0.5.jar:/home/aljoscha/.m2/repository/org/scala-lang/modules/scala-parser-combinators_2.11/1.0.4/scala-parser-combinators_2.11-1.0.4.jar:/home/aljoscha/.m2/repository/org/apache/flink/flink-table-uber_2.11/1.10.0/flink-table-uber_2.11-1.10.0.jar:/home/aljoscha/.m2/repository/org/apache/flink/flink-sql-parser/1.10.0/flink-sql-parser-1.10.0.jar:/home/aljoscha/.m2/repository/org/apache/calcite/calcite-core/1.21.0/calcite-core-1.21.0.jar:/home/aljoscha/.m2/repository/org/apache/flink/flink-table-planner-blink_2.11/1.10.0/flink-table-planner-blink_2.11-1.10.0.jar:/home/aljoscha/.m2/repository/org/apache/flink/flink-table-api-scala_2.11/1.10.0/flink-table-api-scala_2.11-1.10.0.jar:/home/aljoscha/.m2/repository/org/reflections/reflections/0.9.10/reflections-0.9.10.jar:/home/aljoscha/.m2/repository/org/apache/flink/flink-table-runtime-blink_2.11/1.10.0/flink-table-runtime-blink_2.11-1.10.0.jar:/home/aljoscha/.m2/repository/org/codehaus/janino/janino/3.0.9/janino-3.0.9.jar:/home/aljoscha/.m2/repository/org/codehaus/janino/commons-compiler/3.0.9/commons-compiler-3.0.9.jar:/home/aljoscha/.m2/repository/org/apache/calcite/avatica/avatica-core/1.15.0/avatica-core-1.15.0.jar:/home/aljoscha/.m2/repository/org/apache/flink/flink-table-uber-blink_2.11/1.10.0/flink-table-uber-blink_2.11-1.10.0.jar:/home/aljoscha/.m2/repository/org/apache/flink/flink-hbase_2.11/1.10.0/flink-hbase_2.11-1.10.0.jar:/home/aljoscha/.m2/repository/org/apache/hbase/hbase-server/1.4.3/hbase-server-1.4.3.jar:/home/aljoscha/.m2/repository/org/apache/hbase/hbase-protocol/1.4.3/hbase-protocol-1.4.3.jar:/home/aljoscha/.m2/repository/org/apache/hbase/hbase-procedure/1.4.3/hbase-procedure-1.4.3.jar:/home/aljoscha/.m2/repository/org/apache/hbase/hbase-common/1.4.3/hbase-common-1.4.3-tests.jar:/home/aljoscha/.m2/repository/org/apache/hbase/hbase-client/1.4.3/hbase-client-1.4.3.jar:/home/aljoscha/.m2/repository/org/apache/hbase/hbase-prefix-tree/1.4.3/hbase-prefix-tree-1.4.3.jar:/home/aljoscha/.m2/repository/org/apache/hbase/hbase-metrics-api/1.4.3/hbase-metrics-api-1.4.3.jar:/home/aljoscha/.m2/repository/org/apache/hbase/hbase-metrics/1.4.3/hbase-metrics-1.4.3.jar:/home/aljoscha/.m2/repository/io/dropwizard/metrics/metrics-core/3.1.2/metrics-core-3.1.2.jar:/home/aljoscha/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/aljoscha/.m2/repository/commons-codec/commons-codec/1.9/commons-codec-1.9.jar:/home/aljoscha/.m2/repository/org/apache/hbase/hbase-hadoop2-compat/1.4.3/hbase-hadoop2-compat-1.4.3.jar:/home/aljoscha/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/aljoscha/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar:/home/aljoscha/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/aljoscha/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/aljoscha/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/aljoscha/.m2/repository/org/apache/commons/commons-math/2.2/commons-math-2.2.jar:/home/aljoscha/.m2/repository/org/apache/zookeeper/zookeeper/3.4.10/zookeeper-3.4.10.jar:/home/aljoscha/.m2/repository/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar:/home/aljoscha/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/aljoscha/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/aljoscha/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/home/aljoscha/.m2/repository/io/netty/netty-all/4.1.8.Final/netty-all-4.1.8.Final.jar:/home/aljoscha/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/aljoscha/.m2/repository/com/lmax/disruptor/3.3.0/disruptor-3.3.0.jar:/home/aljoscha/.m2/repository/org/apache/httpcomponents/httpclient/4.5.2/httpclient-4.5.2.jar:/home/aljoscha/.m2/repository/org/apache/httpcomponents/httpcore/4.4.4/httpcore-4.4.4.jar:/home/aljoscha/.m2/repository/org/apache/flink/flink-optimizer_2.11/1.10.0/flink-optimizer_2.11-1.10.0.jar:/home/aljoscha/.m2/repository/org/apache/flink/flink-shaded-guava/18.0-9.0/flink-shaded-guava-18.0-9.0.jar:/home/aljoscha/.m2/repository/org/apache/flink/flink-shaded-jackson/2.10.1-9.0/flink-shaded-jackson-2.10.1-9.0.jar:/home/aljoscha/.m2/repository/org/gradoop/gradoop-flink/0.6.0-SNAPSHOT/gradoop-flink-0.6.0-SNAPSHOT.jar:/home/aljoscha/.m2/repository/org/gradoop/gradoop-common/0.6.0-SNAPSHOT/gradoop-common-0.6.0-SNAPSHOT.jar:/home/aljoscha/.m2/repository/org/apache/flink/flink-gelly_2.11/1.7.2/flink-gelly_2.11-1.7.2.jar:/home/aljoscha/.m2/repository/me/lemire/integercompression/JavaFastPFOR/0.1.10/JavaFastPFOR-0.1.10.jar:/home/aljoscha/.m2/repository/org/apache/flink/flink-hadoop-compatibility_2.11/1.7.2/flink-hadoop-compatibility_2.11-1.7.2.jar:/home/aljoscha/.m2/repository/org/apache/flink/flink-shaded-hadoop2/1.7.2/flink-shaded-hadoop2-1.7.2.jar:/home/aljoscha/.m2/repository/org/apache/avro/avro/1.8.2/avro-1.8.2.jar:/home/aljoscha/.m2/repository/com/thoughtworks/paranamer/paranamer/2.7/paranamer-2.7.jar:/home/aljoscha/.m2/repository/org/tukaani/xz/1.5/xz-1.5.jar:/home/aljoscha/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/aljoscha/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/aljoscha/.m2/repository/javax/servlet/servlet-api/2.5/servlet-api-2.5.jar:/home/aljoscha/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/aljoscha/.m2/repository/com/jamesmurty/utils/java-xmlbuilder/0.4/java-xmlbuilder-0.4.jar:/home/aljoscha/.m2/repository/commons-configuration/commons-configuration/1.7/commons-configuration-1.7.jar:/home/aljoscha/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/aljoscha/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/home/aljoscha/.m2/repository/commons-beanutils/commons-beanutils/1.9.3/commons-beanutils-1.9.3.jar:/home/aljoscha/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/aljoscha/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/aljoscha/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/aljoscha/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/aljoscha/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/aljoscha/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/aljoscha/.m2/repository/org/gradoop/gradoop-hbase/0.6.0-SNAPSHOT/gradoop-hbase-0.6.0-SNAPSHOT.jar:/home/aljoscha/.m2/repository/org/gradoop/gradoop-store-api/0.6.0-SNAPSHOT/gradoop-store-api-0.6.0-SNAPSHOT.jar:/home/aljoscha/.m2/repository/org/apache/hbase/hbase-common/1.4.3/hbase-common-1.4.3.jar:/home/aljoscha/.m2/repository/org/apache/hbase/hbase-annotations/1.4.3/hbase-annotations-1.4.3.jar:/home/aljoscha/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/aljoscha/.m2/repository/org/apache/hadoop/hadoop-common/2.7.4/hadoop-common-2.7.4.jar:/home/aljoscha/.m2/repository/org/apache/hadoop/hadoop-annotations/2.7.4/hadoop-annotations-2.7.4.jar:/home/aljoscha/.m2/repository/org/mortbay/jetty/jetty-sslengine/6.1.26/jetty-sslengine-6.1.26.jar:/home/aljoscha/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/aljoscha/.m2/repository/org/apache/hadoop/hadoop-auth/2.7.4/hadoop-auth-2.7.4.jar:/home/aljoscha/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/aljoscha/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/aljoscha/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/aljoscha/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/aljoscha/.m2/repository/org/apache/curator/curator-framework/2.7.1/curator-framework-2.7.1.jar:/home/aljoscha/.m2/repository/org/apache/curator/curator-client/2.7.1/curator-client-2.7.1.jar:/home/aljoscha/.m2/repository/org/apache/curator/curator-recipes/2.7.1/curator-recipes-2.7.1.jar:/home/aljoscha/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.7.4/hadoop-mapreduce-client-core-2.7.4.jar:/home/aljoscha/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.7.4/hadoop-yarn-common-2.7.4.jar:/home/aljoscha/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.7.4/hadoop-yarn-api-2.7.4.jar:/home/aljoscha/.m2/repository/io/netty/netty/3.6.2.Final/netty-3.6.2.Final.jar:/home/aljoscha/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/aljoscha/.m2/repository/org/apache/hbase/hbase-hadoop-compat/1.4.3/hbase-hadoop-compat-1.4.3.jar:/home/aljoscha/.m2/repository/com/github/s1ck/gdl/0.3.2/gdl-0.3.2.jar:/home/aljoscha/.m2/repository/org/antlr/antlr4-runtime/4.5/antlr4-runtime-4.5.jar:/home/aljoscha/.m2/repository/org/abego/treelayout/org.abego.treelayout.core/1.0.1/org.abego.treelayout.core-1.0.1.jar:/home/aljoscha/.m2/repository/org/codehaus/jettison/jettison/1.3.7/jettison-1.3.7.jar:/home/aljoscha/.m2/repository/stax/stax-api/1.0.1/stax-api-1.0.1.jar:/usr/lib/jvm/java-1.8.0-openjdk-amd64/lib/tools.jar
03/06/2020 13:13:05.488  INFO [org.apache.zookeeper.ZooKeeper] Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
03/06/2020 13:13:05.488  INFO [org.apache.zookeeper.ZooKeeper] Client environment:java.io.tmpdir=/tmp
03/06/2020 13:13:05.488  INFO [org.apache.zookeeper.ZooKeeper] Client environment:java.compiler=<NA>
03/06/2020 13:13:05.488  INFO [org.apache.zookeeper.ZooKeeper] Client environment:os.name=Linux
03/06/2020 13:13:05.488  INFO [org.apache.zookeeper.ZooKeeper] Client environment:os.arch=amd64
03/06/2020 13:13:05.488  INFO [org.apache.zookeeper.ZooKeeper] Client environment:os.version=5.3.0-51-generic
03/06/2020 13:13:05.488  INFO [org.apache.zookeeper.ZooKeeper] Client environment:user.name=aljoscha
03/06/2020 13:13:05.488  INFO [org.apache.zookeeper.ZooKeeper] Client environment:user.home=/home/aljoscha
03/06/2020 13:13:05.489  INFO [org.apache.zookeeper.ZooKeeper] Client environment:user.dir=/home/aljoscha/eclipse-workspace/Gradoop_Flink_Prototype
03/06/2020 13:13:05.490  INFO [org.apache.zookeeper.ZooKeeper] Initiating client connection, connectString=localhost:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.PendingWatcher@3d9f5016
03/06/2020 13:13:05.493 DEBUG [org.apache.zookeeper.ClientCnxn] zookeeper.disableAutoWatchReset is false
03/06/2020 13:13:05.527  INFO [org.apache.zookeeper.ClientCnxn] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
03/06/2020 13:13:05.552  INFO [org.apache.zookeeper.ClientCnxn] Socket connection established to localhost/127.0.0.1:2181, initiating session
03/06/2020 13:13:05.556 DEBUG [org.apache.zookeeper.ClientCnxn] Session establishment request sent on localhost/127.0.0.1:2181
03/06/2020 13:13:05.568  INFO [org.apache.zookeeper.ClientCnxn] Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x172799b82f2002e, negotiated timeout = 90000
03/06/2020 13:13:05.572 DEBUG [org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher] hconnection-0x642ee49c0x0, quorum=localhost:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
03/06/2020 13:13:05.574 DEBUG [org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher] hconnection-0x642ee49c-0x172799b82f2002e connected
03/06/2020 13:13:05.587 DEBUG [org.apache.zookeeper.ClientCnxn] Reading reply sessionid:0x172799b82f2002e, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,1040,0  request:: '/hbase/hbaseid,F  response:: s{36,897,1589975516652,1591178147927,3,0,0,0,67,0,36} 
03/06/2020 13:13:05.590 DEBUG [org.apache.zookeeper.ClientCnxn] Reading reply sessionid:0x172799b82f2002e, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,1040,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a31363030302affffff9f4357ffffffbf5875150425546a2434306339306330662d663833372d343664652d626233622d363436353332383637336261,s{36,897,1589975516652,1591178147927,3,0,0,0,67,0,36} 
03/06/2020 13:13:05.892 DEBUG [io.netty.util.internal.logging.InternalLoggerFactory] Using SLF4J as the default logging framework
03/06/2020 13:13:05.898 DEBUG [io.netty.util.ResourceLeakDetector] -Dio.netty.leakDetection.level: simple
03/06/2020 13:13:05.898 DEBUG [io.netty.util.ResourceLeakDetector] -Dio.netty.leakDetection.maxRecords: 4
03/06/2020 13:13:05.916 DEBUG [io.netty.util.internal.PlatformDependent] -Dio.netty.noUnsafe: false
03/06/2020 13:13:05.919 DEBUG [io.netty.util.internal.PlatformDependent0] java.nio.Buffer.address: available
03/06/2020 13:13:05.920 DEBUG [io.netty.util.internal.PlatformDependent0] sun.misc.Unsafe.theUnsafe: available
03/06/2020 13:13:05.921 DEBUG [io.netty.util.internal.PlatformDependent0] sun.misc.Unsafe.copyMemory: available
03/06/2020 13:13:05.922 DEBUG [io.netty.util.internal.PlatformDependent0] direct buffer constructor: available
03/06/2020 13:13:05.923 DEBUG [io.netty.util.internal.PlatformDependent0] java.nio.Bits.unaligned: available, true
03/06/2020 13:13:05.924 DEBUG [io.netty.util.internal.PlatformDependent0] java.nio.DirectByteBuffer.<init>(long, int): available
03/06/2020 13:13:05.925 DEBUG [io.netty.util.internal.Cleaner0] java.nio.ByteBuffer.cleaner(): available
03/06/2020 13:13:05.926 DEBUG [io.netty.util.internal.PlatformDependent] Java version: 8
03/06/2020 13:13:05.926 DEBUG [io.netty.util.internal.PlatformDependent] sun.misc.Unsafe: available
03/06/2020 13:13:05.927 DEBUG [io.netty.util.internal.PlatformDependent] -Dio.netty.noJavassist: false
03/06/2020 13:13:06.015 DEBUG [io.netty.util.internal.PlatformDependent] Javassist: available
03/06/2020 13:13:06.015 DEBUG [io.netty.util.internal.PlatformDependent] -Dio.netty.tmpdir: /tmp (java.io.tmpdir)
03/06/2020 13:13:06.015 DEBUG [io.netty.util.internal.PlatformDependent] -Dio.netty.bitMode: 64 (sun.arch.data.model)
03/06/2020 13:13:06.015 DEBUG [io.netty.util.internal.PlatformDependent] -Dio.netty.noPreferDirect: false
03/06/2020 13:13:06.016 DEBUG [io.netty.util.internal.PlatformDependent] io.netty.maxDirectMemory: 911736832 bytes
03/06/2020 13:13:06.016 DEBUG [io.netty.util.ResourceLeakDetectorFactory] Loaded default ResourceLeakDetector: io.netty.util.ResourceLeakDetector@6be6931f
03/06/2020 13:13:06.025 DEBUG [io.netty.util.internal.PlatformDependent] org.jctools-core.MpscChunkedArrayQueue: available
03/06/2020 13:13:06.041 DEBUG [io.netty.util.internal.ThreadLocalRandom] -Dio.netty.initialSeedUniquifier: 0x039a6d2e2e4c1fa8
03/06/2020 13:13:06.064 DEBUG [org.apache.hadoop.hbase.util.ClassSize] Using Unsafe to estimate memory layout
03/06/2020 13:13:06.086 DEBUG [org.apache.hadoop.hbase.ipc.AbstractRpcClient] Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@23c767e6, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
03/06/2020 13:13:06.216 DEBUG [org.apache.zookeeper.ClientCnxn] Reading reply sessionid:0x172799b82f2002e, packet:: clientPath:null serverPath:null finished:false header:: 3,4  replyHeader:: 3,1041,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a31363230317245ffffff8ffffffff46c10ffffffddffffffc050425546a12a67562756e747510ffffffc97e18ffffffa8ffffffa8ffffffeeffffffccffffffa72e100183,s{911,911,1591178156577,1591178156577,0,0,0,0,59,0,911} 
03/06/2020 13:13:06.228 DEBUG [org.apache.zookeeper.ClientCnxn] Reading reply sessionid:0x172799b82f2002e, packet:: clientPath:null serverPath:null finished:false header:: 4,8  replyHeader:: 4,1041,0  request:: '/hbase,F  response:: v{'replication,'meta-region-server,'rs,'splitWAL,'backup-masters,'table-lock,'flush-table-proc,'master-maintenance,'region-in-transition,'online-snapshot,'switch,'master,'running,'recovering-regions,'draining,'namespace,'hbaseid,'table} 
03/06/2020 13:13:06.502 DEBUG [org.apache.hadoop.hbase.ipc.RpcConnection] Use SIMPLE authentication for service ClientService, sasl=false
03/06/2020 13:13:06.532 DEBUG [org.apache.hadoop.hbase.ipc.BlockingRpcConnection] Connecting to ubuntu/127.0.1.1:16201
03/06/2020 13:13:06.804 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the org.gradoop.common.model.impl.id.GradoopId
03/06/2020 13:13:06.805 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the [B
03/06/2020 13:13:06.815 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the org.gradoop.common.model.impl.id.GradoopId
03/06/2020 13:13:06.815 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the [B
03/06/2020 13:13:06.816 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the org.gradoop.common.model.impl.id.GradoopId
03/06/2020 13:13:06.816 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the [B
03/06/2020 13:13:07.429  INFO [org.apache.flink.table.module.ModuleManager] Got FunctionDefinition as from module core
03/06/2020 13:13:07.437  INFO [org.apache.flink.table.module.ModuleManager] Got FunctionDefinition as from module core
03/06/2020 13:13:07.438  INFO [org.apache.flink.table.module.ModuleManager] Got FunctionDefinition as from module core
03/06/2020 13:13:07.473  INFO [org.apache.flink.api.java.typeutils.TypeExtractor] class aljoschaRydzyk.Gradoop_Flink_Prototype.MatchDegreeChoice$VertexAccum does not contain a getter for field bool
03/06/2020 13:13:07.473  INFO [org.apache.flink.api.java.typeutils.TypeExtractor] class aljoschaRydzyk.Gradoop_Flink_Prototype.MatchDegreeChoice$VertexAccum does not contain a setter for field bool
03/06/2020 13:13:07.473  INFO [org.apache.flink.api.java.typeutils.TypeExtractor] Class class aljoschaRydzyk.Gradoop_Flink_Prototype.MatchDegreeChoice$VertexAccum cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
03/06/2020 13:13:07.600  INFO [org.apache.flink.api.java.typeutils.TypeExtractor] class aljoschaRydzyk.Gradoop_Flink_Prototype.MatchDegreeChoice$VertexAccum does not contain a getter for field bool
03/06/2020 13:13:07.600  INFO [org.apache.flink.api.java.typeutils.TypeExtractor] class aljoschaRydzyk.Gradoop_Flink_Prototype.MatchDegreeChoice$VertexAccum does not contain a setter for field bool
03/06/2020 13:13:07.600  INFO [org.apache.flink.api.java.typeutils.TypeExtractor] Class class aljoschaRydzyk.Gradoop_Flink_Prototype.MatchDegreeChoice$VertexAccum cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
03/06/2020 13:13:07.622  INFO [org.apache.flink.table.module.ModuleManager] Got FunctionDefinition as from module core
03/06/2020 13:13:07.623  INFO [org.apache.flink.api.java.typeutils.TypeExtractor] class aljoschaRydzyk.Gradoop_Flink_Prototype.MatchDegreeChoice$VertexAccum does not contain a getter for field bool
03/06/2020 13:13:07.623  INFO [org.apache.flink.api.java.typeutils.TypeExtractor] class aljoschaRydzyk.Gradoop_Flink_Prototype.MatchDegreeChoice$VertexAccum does not contain a setter for field bool
03/06/2020 13:13:07.623  INFO [org.apache.flink.api.java.typeutils.TypeExtractor] Class class aljoschaRydzyk.Gradoop_Flink_Prototype.MatchDegreeChoice$VertexAccum cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
03/06/2020 13:13:07.625  INFO [org.apache.flink.api.java.typeutils.TypeExtractor] class aljoschaRydzyk.Gradoop_Flink_Prototype.MatchDegreeChoice$VertexAccum does not contain a getter for field bool
03/06/2020 13:13:07.625  INFO [org.apache.flink.api.java.typeutils.TypeExtractor] class aljoschaRydzyk.Gradoop_Flink_Prototype.MatchDegreeChoice$VertexAccum does not contain a setter for field bool
03/06/2020 13:13:07.625  INFO [org.apache.flink.api.java.typeutils.TypeExtractor] Class class aljoschaRydzyk.Gradoop_Flink_Prototype.MatchDegreeChoice$VertexAccum cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
03/06/2020 13:13:07.636  INFO [org.apache.flink.table.module.ModuleManager] Got FunctionDefinition flatten from module core
03/06/2020 13:13:07.638  INFO [org.apache.flink.table.module.ModuleManager] Got FunctionDefinition get from module core
03/06/2020 13:13:07.639  INFO [org.apache.flink.table.module.ModuleManager] Got FunctionDefinition get from module core
03/06/2020 13:13:07.641  INFO [org.apache.flink.table.module.ModuleManager] Got FunctionDefinition as from module core
03/06/2020 13:13:07.642  INFO [org.apache.flink.table.module.ModuleManager] Got FunctionDefinition as from module core
03/06/2020 13:13:07.645  INFO [org.apache.flink.table.module.ModuleManager] Got FunctionDefinition as from module core
03/06/2020 13:13:07.646  INFO [org.apache.flink.table.module.ModuleManager] Got FunctionDefinition as from module core
03/06/2020 13:13:07.646  INFO [org.apache.flink.table.module.ModuleManager] Got FunctionDefinition as from module core
03/06/2020 13:13:07.659  INFO [org.apache.flink.table.module.ModuleManager] Got FunctionDefinition equals from module core
03/06/2020 13:13:07.711  INFO [org.apache.flink.api.java.ExecutionEnvironment] The job has 0 registered types and 0 default Kryo serializers
03/06/2020 13:13:07.711 DEBUG [org.apache.flink.api.java.ExecutionEnvironment] Registered Kryo types: []
03/06/2020 13:13:07.712 DEBUG [org.apache.flink.api.java.ExecutionEnvironment] Registered Kryo with Serializers types: []
03/06/2020 13:13:07.712 DEBUG [org.apache.flink.api.java.ExecutionEnvironment] Registered Kryo with Serializer Classes types: []
03/06/2020 13:13:07.712 DEBUG [org.apache.flink.api.java.ExecutionEnvironment] Registered Kryo default Serializers: []
03/06/2020 13:13:07.712 DEBUG [org.apache.flink.api.java.ExecutionEnvironment] Registered Kryo default Serializers Classes []
03/06/2020 13:13:07.712 DEBUG [org.apache.flink.api.java.ExecutionEnvironment] Registered POJO types: []
03/06/2020 13:13:07.712 DEBUG [org.apache.flink.api.java.ExecutionEnvironment] Static code analysis mode: DISABLE
03/06/2020 13:13:07.722 DEBUG [org.apache.flink.client.PlanTranslator] Set parallelism 1, plan default parallelism 2
03/06/2020 13:13:07.737 DEBUG [org.apache.flink.optimizer.Optimizer] Beginning compilation of program 'Flink Java Job at Wed Jun 03 13:13:07 CEST 2020'
03/06/2020 13:13:07.737 DEBUG [org.apache.flink.optimizer.Optimizer] Using a default parallelism of 2
03/06/2020 13:13:07.737 DEBUG [org.apache.flink.optimizer.Optimizer] Using default data exchange mode PIPELINED
03/06/2020 13:13:07.790  INFO [org.apache.flink.addons.hbase.AbstractTableInputFormat] Initializing HBaseConfiguration
03/06/2020 13:13:07.832  INFO [org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper] Process identifier=hconnection-0x7c9beb51 connecting to ZooKeeper ensemble=localhost:2181
03/06/2020 13:13:07.832  INFO [org.apache.zookeeper.ZooKeeper] Initiating client connection, connectString=localhost:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.PendingWatcher@133aacbe
03/06/2020 13:13:07.842  INFO [org.apache.zookeeper.ClientCnxn] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
03/06/2020 13:13:07.844  INFO [org.apache.zookeeper.ClientCnxn] Socket connection established to localhost/127.0.0.1:2181, initiating session
03/06/2020 13:13:07.844 DEBUG [org.apache.zookeeper.ClientCnxn] Session establishment request sent on localhost/127.0.0.1:2181
03/06/2020 13:13:07.848  INFO [org.apache.zookeeper.ClientCnxn] Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x172799b82f2002f, negotiated timeout = 90000
03/06/2020 13:13:07.849 DEBUG [org.apache.zookeeper.ClientCnxn] Reading reply sessionid:0x172799b82f2002f, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,1042,0  request:: '/hbase/hbaseid,F  response:: s{36,897,1589975516652,1591178147927,3,0,0,0,67,0,36} 
03/06/2020 13:13:07.853 DEBUG [org.apache.zookeeper.ClientCnxn] Reading reply sessionid:0x172799b82f2002f, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,1042,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a31363030302affffff9f4357ffffffbf5875150425546a2434306339306330662d663833372d343664652d626233622d363436353332383637336261,s{36,897,1589975516652,1591178147927,3,0,0,0,67,0,36} 
03/06/2020 13:13:07.853 DEBUG [org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher] hconnection-0x7c9beb510x0, quorum=localhost:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
03/06/2020 13:13:07.854 DEBUG [org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher] hconnection-0x7c9beb51-0x172799b82f2002f connected
03/06/2020 13:13:07.856 DEBUG [org.apache.hadoop.hbase.ipc.AbstractRpcClient] Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@2aa5bd48, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
03/06/2020 13:13:08.128  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils] The configuration option Key: 'taskmanager.cpu.cores' , default: null (fallback keys: []) required for local execution is not set, setting it to its default value 1.7976931348623157E308
03/06/2020 13:13:08.130  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils] The configuration option Key: 'taskmanager.memory.task.heap.size' , default: null (fallback keys: []) required for local execution is not set, setting it to its default value 9223372036854775807 bytes
03/06/2020 13:13:08.130  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils] The configuration option Key: 'taskmanager.memory.task.off-heap.size' , default: 0 bytes (fallback keys: []) required for local execution is not set, setting it to its default value 9223372036854775807 bytes
03/06/2020 13:13:08.130  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils] The configuration option Key: 'taskmanager.memory.network.min' , default: 64 mb (fallback keys: [{key=taskmanager.network.memory.min, isDeprecated=true}]) required for local execution is not set, setting it to its default value 64 mb
03/06/2020 13:13:08.131  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils] The configuration option Key: 'taskmanager.memory.network.max' , default: 1 gb (fallback keys: [{key=taskmanager.network.memory.max, isDeprecated=true}]) required for local execution is not set, setting it to its default value 64 mb
03/06/2020 13:13:08.131  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils] The configuration option Key: 'taskmanager.memory.managed.size' , default: null (fallback keys: [{key=taskmanager.memory.size, isDeprecated=true}]) required for local execution is not set, setting it to its default value 128 mb
03/06/2020 13:13:08.171  INFO [org.apache.flink.runtime.minicluster.MiniCluster] Starting Flink Mini Cluster
03/06/2020 13:13:08.171 DEBUG [org.apache.flink.runtime.minicluster.MiniCluster] Using configuration MiniClusterConfiguration {singleRpcService=SHARED, numTaskManagers=1, commonBindAddress='null', config={taskmanager.memory.network.min=64 mb, taskmanager.cpu.cores=1.7976931348623157E308, taskmanager.memory.task.off-heap.size=9223372036854775807 bytes, execution.target=local, rest.bind-port=0, taskmanager.memory.network.max=64 mb, execution.attached=true, jobmanager.scheduler=ng, taskmanager.memory.managed.size=128 mb, taskmanager.numberOfTaskSlots=2, taskmanager.memory.task.heap.size=9223372036854775807 bytes, rest.address=localhost}}
03/06/2020 13:13:08.175  INFO [org.apache.flink.runtime.minicluster.MiniCluster] Starting Metrics Registry
03/06/2020 13:13:08.286  INFO [org.apache.flink.runtime.metrics.MetricRegistryImpl] No metrics reporter configured, no metrics will be exposed/reported.
03/06/2020 13:13:08.286  INFO [org.apache.flink.runtime.minicluster.MiniCluster] Starting RPC Service(s)
03/06/2020 13:13:09.121  INFO [akka.event.slf4j.Slf4jLogger] Slf4jLogger started
03/06/2020 13:13:09.162 DEBUG [akka.event.EventStream] logger log1-Slf4jLogger started
03/06/2020 13:13:09.166 DEBUG [akka.event.EventStream] Default Loggers started
03/06/2020 13:13:09.639  INFO [org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils] Trying to start actor system at :0
03/06/2020 13:13:09.652 DEBUG [org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils] Using akka configuration
 Config(SimpleConfigObject({"akka":{"actor":{"default-dispatcher":{"executor":"thread-pool-executor","thread-pool-executor":{"core-pool-size-max":1,"core-pool-size-min":1},"thread-priority":1,"throughput":15,"type":"akka.dispatch.PriorityThreadsDispatcher"},"guardian-supervisor-strategy":"org.apache.flink.runtime.akka.StoppingSupervisorWithoutLoggingActorKilledExceptionStrategy","provider":"akka.remote.RemoteActorRefProvider","warn-about-java-serializer-usage":"off"},"daemonic":"off","jvm-exit-on-fatal-error":"on","log-config-on-start":"off","log-dead-letters":"off","log-dead-letters-during-shutdown":"off","loggers":["akka.event.slf4j.Slf4jLogger"],"logging-filter":"akka.event.slf4j.Slf4jLoggingFilter","loglevel":"DEBUG","remote":{"log-remote-lifecycle-events":"off","netty":{"tcp":{"bind-hostname":"0.0.0.0","bind-port":0,"client-socket-worker-pool":{"pool-size-factor":1,"pool-size-max":2,"pool-size-min":1},"connection-timeout":"20000ms","hostname":"","maximum-frame-size":"10485760b","port":0,"server-socket-worker-pool":{"pool-size-factor":1,"pool-size-max":2,"pool-size-min":1},"tcp-nodelay":"on","transport-class":"akka.remote.transport.netty.NettyTransport"}},"retry-gate-closed-for":"50 ms","startup-timeout":"100000ms","transport-failure-detector":{"acceptable-heartbeat-pause":"6000000ms","heartbeat-interval":"1000000ms","threshold":300}},"serialize-messages":"off","stdout-loglevel":"OFF"}}))
03/06/2020 13:13:09.722  INFO [akka.event.slf4j.Slf4jLogger] Slf4jLogger started
03/06/2020 13:13:09.724 DEBUG [akka.event.EventStream] logger log1-Slf4jLogger started
03/06/2020 13:13:09.725 DEBUG [akka.event.EventStream] Default Loggers started
03/06/2020 13:13:09.751  INFO [akka.remote.Remoting] Starting remoting
03/06/2020 13:13:09.836 DEBUG [org.apache.flink.shaded.akka.org.jboss.netty.channel.socket.nio.SelectorUtil] Using select timeout of 500
03/06/2020 13:13:09.836 DEBUG [org.apache.flink.shaded.akka.org.jboss.netty.channel.socket.nio.SelectorUtil] Epoll-bug workaround enabled = false
03/06/2020 13:13:10.028  INFO [akka.remote.Remoting] Remoting started; listening on addresses :[akka.tcp://flink-metrics@127.0.1.1:43257]
03/06/2020 13:13:10.110  INFO [org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils] Actor system started at akka.tcp://flink-metrics@127.0.1.1:43257
03/06/2020 13:13:10.127  INFO [org.apache.flink.runtime.rpc.akka.AkkaRpcService] Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/MetricQueryService .
03/06/2020 13:13:10.279  INFO [org.apache.flink.runtime.minicluster.MiniCluster] Starting high-availability services
03/06/2020 13:13:10.298  INFO [org.apache.flink.runtime.blob.BlobServer] Created BLOB server storage directory /tmp/blobStore-fcbeea00-dd1e-462b-805f-454a4f8b04b4
03/06/2020 13:13:10.303 DEBUG [org.apache.flink.util.NetUtils] Trying to open socket on port 0
03/06/2020 13:13:10.304  INFO [org.apache.flink.runtime.blob.BlobServer] Started BLOB server at 0.0.0.0:39029 - max concurrent requests: 50 - max backlog: 1000
03/06/2020 13:13:10.309  INFO [org.apache.flink.runtime.blob.PermanentBlobCache] Created BLOB cache storage directory /tmp/blobStore-e55efce1-88c5-4fb3-b494-a7d8b0453752
03/06/2020 13:13:10.311  INFO [org.apache.flink.runtime.blob.TransientBlobCache] Created BLOB cache storage directory /tmp/blobStore-3dbe0d38-0ed6-4029-afd3-16467313fc94
03/06/2020 13:13:10.314  INFO [org.apache.flink.runtime.minicluster.MiniCluster] Starting 1 TaskManger(s)
03/06/2020 13:13:10.320  INFO [org.apache.flink.runtime.taskexecutor.TaskManagerRunner] Starting TaskManager with ResourceID: 860855ef-8204-47f1-97b9-688ca96b77ac
03/06/2020 13:13:10.353  INFO [org.apache.flink.runtime.taskexecutor.TaskManagerServices] Temporary file directory '/tmp': total 39 GB, usable 23 GB (58,97% usable)
03/06/2020 13:13:10.360  INFO [org.apache.flink.runtime.io.disk.FileChannelManagerImpl] FileChannelManager uses directory /tmp/flink-io-da99f944-7252-436a-9d83-e42d8385a726 for spill files.
03/06/2020 13:13:10.389  INFO [org.apache.flink.runtime.io.disk.FileChannelManagerImpl] FileChannelManager uses directory /tmp/flink-netty-shuffle-bcd7517c-3d0e-4036-9a10-fb94db71e494 for spill files.
03/06/2020 13:13:10.560  INFO [org.apache.flink.runtime.io.network.buffer.NetworkBufferPool] Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
03/06/2020 13:13:10.588  INFO [org.apache.flink.runtime.io.network.NettyShuffleEnvironment] Starting the network environment and its components.
03/06/2020 13:13:10.588 DEBUG [org.apache.flink.runtime.io.network.NettyShuffleEnvironment] Starting network connection manager
03/06/2020 13:13:10.593  INFO [org.apache.flink.runtime.taskexecutor.KvStateService] Starting the kvState service and its components.
03/06/2020 13:13:10.638  INFO [org.apache.flink.runtime.taskexecutor.TaskManagerConfiguration] Messages have a max timeout of 10000 ms
03/06/2020 13:13:10.763  INFO [org.apache.flink.runtime.rpc.akka.AkkaRpcService] Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/taskmanager_0 .
03/06/2020 13:13:10.810  INFO [org.apache.flink.runtime.taskexecutor.JobLeaderService] Start job leader service.
03/06/2020 13:13:10.813  INFO [org.apache.flink.runtime.filecache.FileCache] User file cache uses directory /tmp/flink-dist-cache-11a3ee57-b067-4783-8d4a-c653797ca52b
03/06/2020 13:13:10.920 DEBUG [org.apache.flink.runtime.entrypoint.component.DefaultDispatcherResourceManagerComponentFactory] Starting Dispatcher REST endpoint.
03/06/2020 13:13:10.920  INFO [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Starting rest endpoint.
03/06/2020 13:13:11.231 DEBUG [org.apache.flink.shaded.netty4.io.netty.util.internal.logging.InternalLoggerFactory] Using SLF4J as the default logging framework
03/06/2020 13:13:11.234 DEBUG [org.apache.flink.shaded.netty4.io.netty.util.internal.InternalThreadLocalMap] -Dio.netty.threadLocalMap.stringBuilder.initialSize: 1024
03/06/2020 13:13:11.234 DEBUG [org.apache.flink.shaded.netty4.io.netty.util.internal.InternalThreadLocalMap] -Dio.netty.threadLocalMap.stringBuilder.maxSize: 4096
03/06/2020 13:13:11.339  WARN [org.apache.flink.runtime.webmonitor.WebMonitorUtils] Log file environment variable 'log.file' is not set.
03/06/2020 13:13:11.339  WARN [org.apache.flink.runtime.webmonitor.WebMonitorUtils] JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'Key: 'web.log.path' , default: null (fallback keys: [{key=jobmanager.web.log.path, isDeprecated=true}])'.
03/06/2020 13:13:11.365 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Failed to load web based job submission extension.
org.apache.flink.util.FlinkException: The module flink-runtime-web could not be found in the class path. Please add this jar in order to enable web based job submission.
	at org.apache.flink.runtime.webmonitor.WebMonitorUtils.loadWebSubmissionExtension(WebMonitorUtils.java:192)
	at org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint.initializeHandlers(DispatcherRestEndpoint.java:98)
	at org.apache.flink.runtime.rest.RestServerEndpoint.start(RestServerEndpoint.java:141)
	at org.apache.flink.runtime.entrypoint.component.DefaultDispatcherResourceManagerComponentFactory.create(DefaultDispatcherResourceManagerComponentFactory.java:165)
	at org.apache.flink.runtime.minicluster.MiniCluster.createDispatcherResourceManagerComponents(MiniCluster.java:394)
	at org.apache.flink.runtime.minicluster.MiniCluster.setupDispatcherResourceManagerComponents(MiniCluster.java:360)
	at org.apache.flink.runtime.minicluster.MiniCluster.start(MiniCluster.java:314)
	at org.apache.flink.client.deployment.executors.LocalExecutor.startMiniCluster(LocalExecutor.java:117)
	at org.apache.flink.client.deployment.executors.LocalExecutor.execute(LocalExecutor.java:63)
	at org.apache.flink.api.java.ExecutionEnvironment.executeAsync(ExecutionEnvironment.java:944)
	at org.apache.flink.api.java.ExecutionEnvironment.execute(ExecutionEnvironment.java:860)
	at org.apache.flink.api.java.ExecutionEnvironment.execute(ExecutionEnvironment.java:844)
	at org.apache.flink.api.java.DataSet.collect(DataSet.java:413)
	at aljoschaRydzyk.Gradoop_Flink_Prototype.MatchDegreeChoice.match(MatchDegreeChoice.java:111)
	at aljoschaRydzyk.Gradoop_Flink_Prototype.Execution_Prototype.main(Execution_Prototype.java:154)
03/06/2020 13:13:11.442 DEBUG [org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent0] -Dio.netty.noUnsafe: false
03/06/2020 13:13:11.444 DEBUG [org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent0] Java version: 8
03/06/2020 13:13:11.454 DEBUG [org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent0] sun.misc.Unsafe.theUnsafe: available
03/06/2020 13:13:11.454 DEBUG [org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent0] sun.misc.Unsafe.copyMemory: available
03/06/2020 13:13:11.457 DEBUG [org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent0] java.nio.Buffer.address: available
03/06/2020 13:13:11.457 DEBUG [org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent0] direct buffer constructor: available
03/06/2020 13:13:11.460 DEBUG [org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent0] java.nio.Bits.unaligned: available, true
03/06/2020 13:13:11.460 DEBUG [org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent0] jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable prior to Java9
03/06/2020 13:13:11.460 DEBUG [org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent0] java.nio.DirectByteBuffer.<init>(long, int): available
03/06/2020 13:13:11.460 DEBUG [org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent] sun.misc.Unsafe: available
03/06/2020 13:13:11.460 DEBUG [org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent] -Dio.netty.tmpdir: /tmp (java.io.tmpdir)
03/06/2020 13:13:11.460 DEBUG [org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent] -Dio.netty.bitMode: 64 (sun.arch.data.model)
03/06/2020 13:13:11.464 DEBUG [org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent] -Dio.netty.maxDirectMemory: 911736832 bytes
03/06/2020 13:13:11.464 DEBUG [org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent] -Dio.netty.uninitializedArrayAllocationThreshold: -1
03/06/2020 13:13:11.466 DEBUG [org.apache.flink.shaded.netty4.io.netty.util.internal.CleanerJava6] java.nio.ByteBuffer.cleaner(): available
03/06/2020 13:13:11.466 DEBUG [org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent] -Dio.netty.noPreferDirect: false
03/06/2020 13:13:11.488 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.cluster.ShutdownHandler@756200d1 under DELETE@/v1/cluster.
03/06/2020 13:13:11.490 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.cluster.ShutdownHandler@756200d1 under DELETE@/cluster.
03/06/2020 13:13:11.490 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.cluster.DashboardConfigHandler@5b74902c under GET@/v1/config.
03/06/2020 13:13:11.490 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.cluster.DashboardConfigHandler@5b74902c under GET@/config.
03/06/2020 13:13:11.490 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.cluster.ClusterConfigHandler@4e4bfd9c under GET@/v1/jobmanager/config.
03/06/2020 13:13:11.490 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.cluster.ClusterConfigHandler@4e4bfd9c under GET@/jobmanager/config.
03/06/2020 13:13:11.490 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.legacy.ConstantTextHandler@43ee1cf7 under GET@/v1/jobmanager/log.
03/06/2020 13:13:11.490 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.legacy.ConstantTextHandler@43ee1cf7 under GET@/jobmanager/log.
03/06/2020 13:13:11.490 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobManagerMetricsHandler@24954e82 under GET@/v1/jobmanager/metrics.
03/06/2020 13:13:11.491 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobManagerMetricsHandler@24954e82 under GET@/jobmanager/metrics.
03/06/2020 13:13:11.491 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.legacy.ConstantTextHandler@5b1f5fcc under GET@/v1/jobmanager/stdout.
03/06/2020 13:13:11.491 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.legacy.ConstantTextHandler@5b1f5fcc under GET@/jobmanager/stdout.
03/06/2020 13:13:11.491 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.JobIdsHandler@4a29fe2e under GET@/v1/jobs.
03/06/2020 13:13:11.491 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.JobIdsHandler@4a29fe2e under GET@/jobs.
03/06/2020 13:13:11.491 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.JobSubmitHandler@79135a38 under POST@/v1/jobs.
03/06/2020 13:13:11.491 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.JobSubmitHandler@79135a38 under POST@/jobs.
03/06/2020 13:13:11.491 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingJobsMetricsHandler@77fceac6 under GET@/v1/jobs/metrics.
03/06/2020 13:13:11.495 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingJobsMetricsHandler@77fceac6 under GET@/jobs/metrics.
03/06/2020 13:13:11.495 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.JobsOverviewHandler@563c3aca under GET@/v1/jobs/overview.
03/06/2020 13:13:11.495 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.JobsOverviewHandler@563c3aca under GET@/jobs/overview.
03/06/2020 13:13:11.495 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.JobDetailsHandler@53e166ad under GET@/v1/jobs/:jobid.
03/06/2020 13:13:11.495 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.JobDetailsHandler@53e166ad under GET@/jobs/:jobid.
03/06/2020 13:13:11.495 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@30c03473 under PATCH@/v1/jobs/:jobid.
03/06/2020 13:13:11.495 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@30c03473 under PATCH@/jobs/:jobid.
03/06/2020 13:13:11.497 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.JobAccumulatorsHandler@20fa5277 under GET@/v1/jobs/:jobid/accumulators.
03/06/2020 13:13:11.497 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.JobAccumulatorsHandler@20fa5277 under GET@/jobs/:jobid/accumulators.
03/06/2020 13:13:11.497 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointingStatisticsHandler@17a7d6c8 under GET@/v1/jobs/:jobid/checkpoints.
03/06/2020 13:13:11.497 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointingStatisticsHandler@17a7d6c8 under GET@/jobs/:jobid/checkpoints.
03/06/2020 13:13:11.497 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointConfigHandler@4f2b1e9f under GET@/v1/jobs/:jobid/checkpoints/config.
03/06/2020 13:13:11.497 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointConfigHandler@4f2b1e9f under GET@/jobs/:jobid/checkpoints/config.
03/06/2020 13:13:11.498 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointStatisticDetailsHandler@7ef9c8a5 under GET@/v1/jobs/:jobid/checkpoints/details/:checkpointid.
03/06/2020 13:13:11.498 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointStatisticDetailsHandler@7ef9c8a5 under GET@/jobs/:jobid/checkpoints/details/:checkpointid.
03/06/2020 13:13:11.498 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.TaskCheckpointStatisticDetailsHandler@c6244e7 under GET@/v1/jobs/:jobid/checkpoints/details/:checkpointid/subtasks/:vertexid.
03/06/2020 13:13:11.498 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.TaskCheckpointStatisticDetailsHandler@c6244e7 under GET@/jobs/:jobid/checkpoints/details/:checkpointid/subtasks/:vertexid.
03/06/2020 13:13:11.509 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.JobConfigHandler@25dad235 under GET@/v1/jobs/:jobid/config.
03/06/2020 13:13:11.509 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.JobConfigHandler@25dad235 under GET@/jobs/:jobid/config.
03/06/2020 13:13:11.510 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.JobExceptionsHandler@3292eff7 under GET@/v1/jobs/:jobid/exceptions.
03/06/2020 13:13:11.510 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.JobExceptionsHandler@3292eff7 under GET@/jobs/:jobid/exceptions.
03/06/2020 13:13:11.510 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.JobExecutionResultHandler@29ea5e0 under GET@/v1/jobs/:jobid/execution-result.
03/06/2020 13:13:11.510 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.JobExecutionResultHandler@29ea5e0 under GET@/jobs/:jobid/execution-result.
03/06/2020 13:13:11.510 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobMetricsHandler@1c459c28 under GET@/v1/jobs/:jobid/metrics.
03/06/2020 13:13:11.510 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobMetricsHandler@1c459c28 under GET@/jobs/:jobid/metrics.
03/06/2020 13:13:11.510 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.JobPlanHandler@6ffdbeef under GET@/v1/jobs/:jobid/plan.
03/06/2020 13:13:11.510 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.JobPlanHandler@6ffdbeef under GET@/jobs/:jobid/plan.
03/06/2020 13:13:11.510 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.rescaling.RescalingHandlers$RescalingTriggerHandler@4a3509b0 under PATCH@/v1/jobs/:jobid/rescaling.
03/06/2020 13:13:11.510 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.rescaling.RescalingHandlers$RescalingTriggerHandler@4a3509b0 under PATCH@/jobs/:jobid/rescaling.
03/06/2020 13:13:11.510 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.rescaling.RescalingHandlers$RescalingStatusHandler@3d7314b3 under GET@/v1/jobs/:jobid/rescaling/:triggerid.
03/06/2020 13:13:11.511 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.rescaling.RescalingHandlers$RescalingStatusHandler@3d7314b3 under GET@/jobs/:jobid/rescaling/:triggerid.
03/06/2020 13:13:11.511 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$SavepointTriggerHandler@d677be9 under POST@/v1/jobs/:jobid/savepoints.
03/06/2020 13:13:11.512 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$SavepointTriggerHandler@d677be9 under POST@/jobs/:jobid/savepoints.
03/06/2020 13:13:11.512 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$SavepointStatusHandler@fefb66c under GET@/v1/jobs/:jobid/savepoints/:triggerid.
03/06/2020 13:13:11.512 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$SavepointStatusHandler@fefb66c under GET@/jobs/:jobid/savepoints/:triggerid.
03/06/2020 13:13:11.512 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$StopWithSavepointHandler@6d7556a8 under POST@/v1/jobs/:jobid/stop.
03/06/2020 13:13:11.512 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$StopWithSavepointHandler@6d7556a8 under POST@/jobs/:jobid/stop.
03/06/2020 13:13:11.512 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.JobVertexDetailsHandler@48860139 under GET@/v1/jobs/:jobid/vertices/:vertexid.
03/06/2020 13:13:11.512 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.JobVertexDetailsHandler@48860139 under GET@/jobs/:jobid/vertices/:vertexid.
03/06/2020 13:13:11.512 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.JobVertexAccumulatorsHandler@7e0883f3 under GET@/v1/jobs/:jobid/vertices/:vertexid/accumulators.
03/06/2020 13:13:11.512 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.JobVertexAccumulatorsHandler@7e0883f3 under GET@/jobs/:jobid/vertices/:vertexid/accumulators.
03/06/2020 13:13:11.512 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.JobVertexBackPressureHandler@ca60688 under GET@/v1/jobs/:jobid/vertices/:vertexid/backpressure.
03/06/2020 13:13:11.512 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.JobVertexBackPressureHandler@ca60688 under GET@/jobs/:jobid/vertices/:vertexid/backpressure.
03/06/2020 13:13:11.513 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobVertexMetricsHandler@4ba1c1a2 under GET@/v1/jobs/:jobid/vertices/:vertexid/metrics.
03/06/2020 13:13:11.513 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobVertexMetricsHandler@4ba1c1a2 under GET@/jobs/:jobid/vertices/:vertexid/metrics.
03/06/2020 13:13:11.513 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.SubtasksAllAccumulatorsHandler@33568e26 under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/accumulators.
03/06/2020 13:13:11.513 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.SubtasksAllAccumulatorsHandler@33568e26 under GET@/jobs/:jobid/vertices/:vertexid/subtasks/accumulators.
03/06/2020 13:13:11.513 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingSubtasksMetricsHandler@97b84a4 under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/metrics.
03/06/2020 13:13:11.513 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingSubtasksMetricsHandler@97b84a4 under GET@/jobs/:jobid/vertices/:vertexid/subtasks/metrics.
03/06/2020 13:13:11.513 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.SubtaskCurrentAttemptDetailsHandler@35555145 under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex.
03/06/2020 13:13:11.513 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.SubtaskCurrentAttemptDetailsHandler@35555145 under GET@/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex.
03/06/2020 13:13:11.513 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.SubtaskExecutionAttemptDetailsHandler@70bc3a9c under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/attempts/:attempt.
03/06/2020 13:13:11.513 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.SubtaskExecutionAttemptDetailsHandler@70bc3a9c under GET@/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/attempts/:attempt.
03/06/2020 13:13:11.514 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.SubtaskExecutionAttemptAccumulatorsHandler@771cbd13 under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/attempts/:attempt/accumulators.
03/06/2020 13:13:11.514 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.SubtaskExecutionAttemptAccumulatorsHandler@771cbd13 under GET@/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/attempts/:attempt/accumulators.
03/06/2020 13:13:11.514 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.metrics.SubtaskMetricsHandler@229749f0 under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/metrics.
03/06/2020 13:13:11.514 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.metrics.SubtaskMetricsHandler@229749f0 under GET@/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/metrics.
03/06/2020 13:13:11.514 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.SubtasksTimesHandler@3d57fb9e under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasktimes.
03/06/2020 13:13:11.514 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.SubtasksTimesHandler@3d57fb9e under GET@/jobs/:jobid/vertices/:vertexid/subtasktimes.
03/06/2020 13:13:11.514 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.JobVertexTaskManagersHandler@2c2e5e72 under GET@/v1/jobs/:jobid/vertices/:vertexid/taskmanagers.
03/06/2020 13:13:11.514 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.JobVertexTaskManagersHandler@2c2e5e72 under GET@/jobs/:jobid/vertices/:vertexid/taskmanagers.
03/06/2020 13:13:11.515 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobVertexWatermarksHandler@3e489ac1 under GET@/v1/jobs/:jobid/vertices/:vertexid/watermarks.
03/06/2020 13:13:11.515 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobVertexWatermarksHandler@3e489ac1 under GET@/jobs/:jobid/vertices/:vertexid/watermarks.
03/06/2020 13:13:11.515 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@30c03473 under GET@/v1/jobs/:jobid/yarn-cancel.
03/06/2020 13:13:11.515 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@30c03473 under GET@/jobs/:jobid/yarn-cancel.
03/06/2020 13:13:11.515 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@26888c31 under GET@/v1/jobs/:jobid/yarn-stop.
03/06/2020 13:13:11.515 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@26888c31 under GET@/jobs/:jobid/yarn-stop.
03/06/2020 13:13:11.515 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.cluster.ClusterOverviewHandler@24010875 under GET@/v1/overview.
03/06/2020 13:13:11.515 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.cluster.ClusterOverviewHandler@24010875 under GET@/overview.
03/06/2020 13:13:11.515 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointDisposalHandlers$SavepointDisposalTriggerHandler@7a021f49 under POST@/v1/savepoint-disposal.
03/06/2020 13:13:11.524 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointDisposalHandlers$SavepointDisposalTriggerHandler@7a021f49 under POST@/savepoint-disposal.
03/06/2020 13:13:11.524 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointDisposalHandlers$SavepointDisposalStatusHandler@e60c5a under GET@/v1/savepoint-disposal/:triggerid.
03/06/2020 13:13:11.525 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointDisposalHandlers$SavepointDisposalStatusHandler@e60c5a under GET@/savepoint-disposal/:triggerid.
03/06/2020 13:13:11.525 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagersHandler@626df173 under GET@/v1/taskmanagers.
03/06/2020 13:13:11.525 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagersHandler@626df173 under GET@/taskmanagers.
03/06/2020 13:13:11.525 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingTaskManagersMetricsHandler@4e030feb under GET@/v1/taskmanagers/metrics.
03/06/2020 13:13:11.525 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingTaskManagersMetricsHandler@4e030feb under GET@/taskmanagers/metrics.
03/06/2020 13:13:11.525 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerDetailsHandler@2411b935 under GET@/v1/taskmanagers/:taskmanagerid.
03/06/2020 13:13:11.526 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerDetailsHandler@2411b935 under GET@/taskmanagers/:taskmanagerid.
03/06/2020 13:13:11.526 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerLogFileHandler@1425e531 under GET@/v1/taskmanagers/:taskmanagerid/log.
03/06/2020 13:13:11.526 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerLogFileHandler@1425e531 under GET@/taskmanagers/:taskmanagerid/log.
03/06/2020 13:13:11.526 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.metrics.TaskManagerMetricsHandler@194e78af under GET@/v1/taskmanagers/:taskmanagerid/metrics.
03/06/2020 13:13:11.526 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.metrics.TaskManagerMetricsHandler@194e78af under GET@/taskmanagers/:taskmanagerid/metrics.
03/06/2020 13:13:11.526 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerStdoutFileHandler@4fe4503a under GET@/v1/taskmanagers/:taskmanagerid/stdout.
03/06/2020 13:13:11.526 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerStdoutFileHandler@4fe4503a under GET@/taskmanagers/:taskmanagerid/stdout.
03/06/2020 13:13:11.540 DEBUG [org.apache.flink.shaded.netty4.io.netty.channel.MultithreadEventLoopGroup] -Dio.netty.eventLoopThreads: 4
03/06/2020 13:13:11.599 DEBUG [org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop] -Dio.netty.noKeySetOptimization: false
03/06/2020 13:13:11.600 DEBUG [org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop] -Dio.netty.selectorAutoRebuildThreshold: 512
03/06/2020 13:13:11.637 DEBUG [org.apache.flink.shaded.netty4.io.netty.util.internal.PlatformDependent] org.jctools-core.MpscChunkedArrayQueue: available
03/06/2020 13:13:11.689 DEBUG [org.apache.flink.shaded.netty4.io.netty.channel.DefaultChannelId] -Dio.netty.processId: 59964 (auto-detected)
03/06/2020 13:13:11.692 DEBUG [org.apache.flink.shaded.netty4.io.netty.util.NetUtil] -Djava.net.preferIPv4Stack: false
03/06/2020 13:13:11.692 DEBUG [org.apache.flink.shaded.netty4.io.netty.util.NetUtil] -Djava.net.preferIPv6Addresses: false
03/06/2020 13:13:11.694 DEBUG [org.apache.flink.shaded.netty4.io.netty.util.NetUtil] Loopback interface: lo (lo, 0:0:0:0:0:0:0:1%lo)
03/06/2020 13:13:11.695 DEBUG [org.apache.flink.shaded.netty4.io.netty.util.NetUtil] /proc/sys/net/core/somaxconn: 128
03/06/2020 13:13:11.697 DEBUG [org.apache.flink.shaded.netty4.io.netty.channel.DefaultChannelId] -Dio.netty.machineId: 00:0c:29:ff:fe:89:f7:ef (auto-detected)
03/06/2020 13:13:11.713 DEBUG [org.apache.flink.shaded.netty4.io.netty.util.ResourceLeakDetector] -Dorg.apache.flink.shaded.netty4.io.netty.leakDetection.level: simple
03/06/2020 13:13:11.713 DEBUG [org.apache.flink.shaded.netty4.io.netty.util.ResourceLeakDetector] -Dorg.apache.flink.shaded.netty4.io.netty.leakDetection.targetRecords: 4
03/06/2020 13:13:11.835 DEBUG [org.apache.flink.shaded.netty4.io.netty.buffer.PooledByteBufAllocator] -Dio.netty.allocator.numHeapArenas: 4
03/06/2020 13:13:11.835 DEBUG [org.apache.flink.shaded.netty4.io.netty.buffer.PooledByteBufAllocator] -Dio.netty.allocator.numDirectArenas: 4
03/06/2020 13:13:11.835 DEBUG [org.apache.flink.shaded.netty4.io.netty.buffer.PooledByteBufAllocator] -Dio.netty.allocator.pageSize: 8192
03/06/2020 13:13:11.835 DEBUG [org.apache.flink.shaded.netty4.io.netty.buffer.PooledByteBufAllocator] -Dio.netty.allocator.maxOrder: 11
03/06/2020 13:13:11.837 DEBUG [org.apache.flink.shaded.netty4.io.netty.buffer.PooledByteBufAllocator] -Dio.netty.allocator.chunkSize: 16777216
03/06/2020 13:13:11.837 DEBUG [org.apache.flink.shaded.netty4.io.netty.buffer.PooledByteBufAllocator] -Dio.netty.allocator.tinyCacheSize: 512
03/06/2020 13:13:11.837 DEBUG [org.apache.flink.shaded.netty4.io.netty.buffer.PooledByteBufAllocator] -Dio.netty.allocator.smallCacheSize: 256
03/06/2020 13:13:11.837 DEBUG [org.apache.flink.shaded.netty4.io.netty.buffer.PooledByteBufAllocator] -Dio.netty.allocator.normalCacheSize: 64
03/06/2020 13:13:11.837 DEBUG [org.apache.flink.shaded.netty4.io.netty.buffer.PooledByteBufAllocator] -Dio.netty.allocator.maxCachedBufferCapacity: 32768
03/06/2020 13:13:11.838 DEBUG [org.apache.flink.shaded.netty4.io.netty.buffer.PooledByteBufAllocator] -Dio.netty.allocator.cacheTrimInterval: 8192
03/06/2020 13:13:11.838 DEBUG [org.apache.flink.shaded.netty4.io.netty.buffer.PooledByteBufAllocator] -Dio.netty.allocator.cacheTrimIntervalMillis: 0
03/06/2020 13:13:11.838 DEBUG [org.apache.flink.shaded.netty4.io.netty.buffer.PooledByteBufAllocator] -Dio.netty.allocator.useCacheForAllThreads: true
03/06/2020 13:13:11.838 DEBUG [org.apache.flink.shaded.netty4.io.netty.buffer.PooledByteBufAllocator] -Dio.netty.allocator.maxCachedByteBuffersPerChunk: 1023
03/06/2020 13:13:11.860 DEBUG [org.apache.flink.shaded.netty4.io.netty.buffer.ByteBufUtil] -Dio.netty.allocator.type: pooled
03/06/2020 13:13:11.861 DEBUG [org.apache.flink.shaded.netty4.io.netty.buffer.ByteBufUtil] -Dio.netty.threadLocalDirectBufferSize: 0
03/06/2020 13:13:11.861 DEBUG [org.apache.flink.shaded.netty4.io.netty.buffer.ByteBufUtil] -Dio.netty.maxThreadLocalCharBufferSize: 16384
03/06/2020 13:13:11.913 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Binding rest endpoint to null:0.
03/06/2020 13:13:11.913  INFO [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Rest endpoint listening at localhost:45701
03/06/2020 13:13:11.916  INFO [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] Proposing leadership to contender http://localhost:45701
03/06/2020 13:13:11.934  INFO [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] http://localhost:45701 was granted leadership with leaderSessionID=bdb9e5d6-d7b8-4641-804d-690b80464201
03/06/2020 13:13:11.938  INFO [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] Received confirmation of leadership for leader http://localhost:45701 , session=bdb9e5d6-d7b8-4641-804d-690b80464201
03/06/2020 13:13:11.961  INFO [org.apache.flink.runtime.rpc.akka.AkkaRpcService] Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/resourcemanager .
03/06/2020 13:13:12.004 DEBUG [org.apache.flink.runtime.entrypoint.component.DefaultDispatcherResourceManagerComponentFactory] Starting Dispatcher.
03/06/2020 13:13:12.024  INFO [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] Proposing leadership to contender LeaderContender: DefaultDispatcherRunner
03/06/2020 13:13:12.038 DEBUG [org.apache.flink.runtime.entrypoint.component.DefaultDispatcherResourceManagerComponentFactory] Starting ResourceManager.
03/06/2020 13:13:12.039 DEBUG [org.apache.flink.runtime.dispatcher.runner.DefaultDispatcherRunner] Create new DispatcherLeaderProcess with leader session id 8a3c97cc-00c3-43f5-b176-0c11684f5958.
03/06/2020 13:13:12.041  INFO [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] Proposing leadership to contender LeaderContender: StandaloneResourceManager
03/06/2020 13:13:12.043  INFO [org.apache.flink.runtime.minicluster.MiniCluster] Flink Mini Cluster started successfully
03/06/2020 13:13:12.047  INFO [org.apache.flink.runtime.resourcemanager.StandaloneResourceManager] ResourceManager akka://flink/user/resourcemanager was granted leadership with fencing token 8639690d5ef45e2fe0068f8380094a38
03/06/2020 13:13:12.057  INFO [org.apache.flink.runtime.resourcemanager.slotmanager.SlotManagerImpl] Starting the SlotManager.
03/06/2020 13:13:12.064  INFO [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] Received confirmation of leadership for leader akka://flink/user/resourcemanager , session=e0068f83-8009-4a38-8639-690d5ef45e2f
03/06/2020 13:13:12.067 DEBUG [org.apache.flink.runtime.rpc.akka.AkkaRpcService] Try to connect to remote RPC endpoint with address akka://flink/user/resourcemanager. Returning a org.apache.flink.runtime.resourcemanager.ResourceManagerGateway gateway.
03/06/2020 13:13:12.078 DEBUG [org.apache.flink.runtime.resourcemanager.StandaloneResourceManager] Trigger heartbeat request.
03/06/2020 13:13:12.079 DEBUG [org.apache.flink.runtime.resourcemanager.StandaloneResourceManager] Trigger heartbeat request.
03/06/2020 13:13:12.083  INFO [org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess] Start SessionDispatcherLeaderProcess.
03/06/2020 13:13:12.101 DEBUG [org.apache.flink.runtime.rpc.akka.AkkaRpcService] Try to connect to remote RPC endpoint with address akka://flink/user/resourcemanager. Returning a org.apache.flink.runtime.resourcemanager.ResourceManagerGateway gateway.
03/06/2020 13:13:12.103  INFO [org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess] Recover all persisted job graphs.
03/06/2020 13:13:12.104  INFO [org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess] Successfully recovered 0 persisted job graphs.
03/06/2020 13:13:12.107  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutor] Connecting to ResourceManager akka://flink/user/resourcemanager(8639690d5ef45e2fe0068f8380094a38).
03/06/2020 13:13:12.115 DEBUG [org.apache.flink.runtime.rpc.akka.AkkaRpcService] Try to connect to remote RPC endpoint with address akka://flink/user/resourcemanager. Returning a org.apache.flink.runtime.resourcemanager.ResourceManagerGateway gateway.
03/06/2020 13:13:12.121  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutor] Resolved ResourceManager address, beginning registration
03/06/2020 13:13:12.122  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutor] Registration at ResourceManager attempt 1 (timeout=100ms)
03/06/2020 13:13:12.130 DEBUG [org.apache.flink.runtime.rpc.akka.AkkaRpcService] Try to connect to remote RPC endpoint with address akka://flink/user/taskmanager_0. Returning a org.apache.flink.runtime.taskexecutor.TaskExecutorGateway gateway.
03/06/2020 13:13:12.139  INFO [org.apache.flink.runtime.rpc.akka.AkkaRpcService] Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/dispatcher .
03/06/2020 13:13:12.148  INFO [org.apache.flink.runtime.resourcemanager.StandaloneResourceManager] Registering TaskManager with ResourceID 860855ef-8204-47f1-97b9-688ca96b77ac (akka://flink/user/taskmanager_0) at ResourceManager
03/06/2020 13:13:12.172  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutor] Successful registration at resource manager akka://flink/user/resourcemanager under registration id e4211fd15853f4a2b71a32cc83830ff7.
03/06/2020 13:13:12.182 DEBUG [org.apache.flink.runtime.resourcemanager.slotmanager.SlotManagerImpl] Registering TaskManager 860855ef-8204-47f1-97b9-688ca96b77ac under e4211fd15853f4a2b71a32cc83830ff7 at the SlotManager.
03/06/2020 13:13:12.204  INFO [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] Received confirmation of leadership for leader akka://flink/user/dispatcher , session=8a3c97cc-00c3-43f5-b176-0c11684f5958
03/06/2020 13:13:12.207 DEBUG [org.apache.flink.runtime.rpc.akka.AkkaRpcService] Try to connect to remote RPC endpoint with address akka://flink/user/dispatcher. Returning a org.apache.flink.runtime.dispatcher.DispatcherGateway gateway.
03/06/2020 13:13:12.208 DEBUG [org.apache.flink.runtime.rpc.akka.AkkaRpcService] Try to connect to remote RPC endpoint with address akka://flink/user/dispatcher. Returning a org.apache.flink.runtime.dispatcher.DispatcherGateway gateway.
03/06/2020 13:13:12.223  INFO [org.apache.flink.runtime.dispatcher.StandaloneDispatcher] Received JobGraph submission 27a49aaf7533a153067b6fcce6e8f170 (Flink Java Job at Wed Jun 03 13:13:07 CEST 2020).
03/06/2020 13:13:12.224  INFO [org.apache.flink.runtime.dispatcher.StandaloneDispatcher] Submitting job 27a49aaf7533a153067b6fcce6e8f170 (Flink Java Job at Wed Jun 03 13:13:07 CEST 2020).
03/06/2020 13:13:12.316  INFO [org.apache.flink.runtime.rpc.akka.AkkaRpcService] Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/jobmanager_1 .
03/06/2020 13:13:12.357  INFO [org.apache.flink.runtime.jobmaster.JobMaster] Initializing job Flink Java Job at Wed Jun 03 13:13:07 CEST 2020 (27a49aaf7533a153067b6fcce6e8f170).
03/06/2020 13:13:12.404  INFO [org.apache.flink.runtime.jobmaster.JobMaster] Using restart back off time strategy NoRestartBackoffTimeStrategy for Flink Java Job at Wed Jun 03 13:13:07 CEST 2020 (27a49aaf7533a153067b6fcce6e8f170).
03/06/2020 13:13:12.478  INFO [org.apache.flink.runtime.jobmaster.JobMaster] Running initialization on master for job Flink Java Job at Wed Jun 03 13:13:07 CEST 2020 (27a49aaf7533a153067b6fcce6e8f170).
03/06/2020 13:13:12.480  INFO [org.apache.flink.addons.hbase.AbstractTableInputFormat] Initializing HBaseConfiguration
03/06/2020 13:13:12.576  INFO [org.apache.flink.runtime.jobmaster.JobMaster] Successfully ran initialization on master in 97 ms.
03/06/2020 13:13:12.576 DEBUG [org.apache.flink.runtime.jobmaster.JobMaster] Adding 2 vertices from job graph Flink Java Job at Wed Jun 03 13:13:07 CEST 2020 (27a49aaf7533a153067b6fcce6e8f170).
03/06/2020 13:13:12.579 DEBUG [org.apache.flink.runtime.executiongraph.ExecutionGraph] Attaching 2 topologically sorted vertices to existing job graph with 0 vertices and 0 intermediate results.
03/06/2020 13:13:12.611 DEBUG [org.apache.zookeeper.ClientCnxn] Reading reply sessionid:0x172799b82f2002f, packet:: clientPath:null serverPath:null finished:false header:: 3,4  replyHeader:: 3,1044,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a31363230317245ffffff8ffffffff46c10ffffffddffffffc050425546a12a67562756e747510ffffffc97e18ffffffa8ffffffa8ffffffeeffffffccffffffa72e100183,s{911,911,1591178156577,1591178156577,0,0,0,0,59,0,911} 
03/06/2020 13:13:12.614 DEBUG [org.apache.zookeeper.ClientCnxn] Reading reply sessionid:0x172799b82f2002f, packet:: clientPath:null serverPath:null finished:false header:: 4,8  replyHeader:: 4,1044,0  request:: '/hbase,F  response:: v{'replication,'meta-region-server,'rs,'splitWAL,'backup-masters,'table-lock,'flush-table-proc,'master-maintenance,'region-in-transition,'online-snapshot,'switch,'master,'running,'recovering-regions,'draining,'namespace,'hbaseid,'table} 
03/06/2020 13:13:12.618 DEBUG [org.apache.hadoop.hbase.ipc.RpcConnection] Use SIMPLE authentication for service ClientService, sasl=false
03/06/2020 13:13:12.620 DEBUG [org.apache.hadoop.hbase.ipc.BlockingRpcConnection] Connecting to ubuntu/127.0.1.1:16201
03/06/2020 13:13:12.720  INFO [org.apache.flink.addons.hbase.AbstractTableInputFormat] Created 1 splits
03/06/2020 13:13:12.720  INFO [org.apache.flink.addons.hbase.AbstractTableInputFormat] created split (this=org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat@2e2de0ba)[0|[ubuntu:16201]|-|-]
03/06/2020 13:13:12.725 DEBUG [org.apache.flink.runtime.executiongraph.ExecutionGraph] Connecting ExecutionJobVertex 7d8dd6295572d72e69c940d520d84705 (CHAIN DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) -> Map (Map at getGraphCollection(HBaseDataSource.java:125)) -> Filter (Filter at getGraph(BaseGraphCollection.java:82))) to 0 predecessors.
03/06/2020 13:13:12.726 DEBUG [org.apache.flink.runtime.executiongraph.ExecutionGraph] Connecting ExecutionJobVertex 3cd62e156787952e99db0c94cf0769f0 (DataSink (collect())) to 1 predecessors.
03/06/2020 13:13:12.727 DEBUG [org.apache.flink.runtime.executiongraph.ExecutionGraph] Connecting input 0 of vertex 3cd62e156787952e99db0c94cf0769f0 (DataSink (collect())) to intermediate result referenced via predecessor 7d8dd6295572d72e69c940d520d84705 (CHAIN DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) -> Map (Map at getGraphCollection(HBaseDataSource.java:125)) -> Filter (Filter at getGraph(BaseGraphCollection.java:82))).
03/06/2020 13:13:12.769 DEBUG [org.apache.flink.runtime.jobmaster.JobMaster] Successfully created execution graph from job graph Flink Java Job at Wed Jun 03 13:13:07 CEST 2020 (27a49aaf7533a153067b6fcce6e8f170).
03/06/2020 13:13:12.775  INFO [org.apache.flink.runtime.executiongraph.failover.flip1.RestartPipelinedRegionStrategy] Start building failover regions.
03/06/2020 13:13:12.776 DEBUG [org.apache.flink.runtime.executiongraph.failover.flip1.RestartPipelinedRegionStrategy] Creating a failover region with 2 vertices.
03/06/2020 13:13:12.777 DEBUG [org.apache.flink.runtime.executiongraph.failover.flip1.RestartPipelinedRegionStrategy] Creating a failover region with 2 vertices.
03/06/2020 13:13:12.777  INFO [org.apache.flink.runtime.executiongraph.failover.flip1.RestartPipelinedRegionStrategy] Created 2 failover regions.
03/06/2020 13:13:12.777  INFO [org.apache.flink.runtime.jobmaster.JobMaster] Using failover strategy org.apache.flink.runtime.executiongraph.failover.flip1.RestartPipelinedRegionStrategy@3ff77bb6 for Flink Java Job at Wed Jun 03 13:13:07 CEST 2020 (27a49aaf7533a153067b6fcce6e8f170).
03/06/2020 13:13:12.786  INFO [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] Proposing leadership to contender akka://flink/user/jobmanager_1
03/06/2020 13:13:12.790  INFO [org.apache.flink.runtime.jobmaster.JobManagerRunnerImpl] JobManager runner for job Flink Java Job at Wed Jun 03 13:13:07 CEST 2020 (27a49aaf7533a153067b6fcce6e8f170) was granted leadership with session id 29d2309e-1fa2-474c-a234-94c3a73eb1ac at akka://flink/user/jobmanager_1.
03/06/2020 13:13:12.845  INFO [org.apache.flink.runtime.jobmaster.JobMaster] Starting execution of job Flink Java Job at Wed Jun 03 13:13:07 CEST 2020 (27a49aaf7533a153067b6fcce6e8f170) under job master id a23494c3a73eb1ac29d2309e1fa2474c.
03/06/2020 13:13:12.875  INFO [org.apache.flink.runtime.jobmaster.JobMaster] Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.LazyFromSourcesSchedulingStrategy]
03/06/2020 13:13:12.891  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] Job Flink Java Job at Wed Jun 03 13:13:07 CEST 2020 (27a49aaf7533a153067b6fcce6e8f170) switched from state CREATED to RUNNING.
03/06/2020 13:13:13.038  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] CHAIN DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) -> Map (Map at getGraphCollection(HBaseDataSource.java:125)) -> Filter (Filter at getGraph(BaseGraphCollection.java:82)) (1/2) (77393775f2f5e4ee3df790c3b98fa8c4) switched from CREATED to SCHEDULED.
03/06/2020 13:13:13.049  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] CHAIN DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) -> Map (Map at getGraphCollection(HBaseDataSource.java:125)) -> Filter (Filter at getGraph(BaseGraphCollection.java:82)) (2/2) (c0bee93248ded4bbff5301f05863bb2d) switched from CREATED to SCHEDULED.
03/06/2020 13:13:13.106 DEBUG [org.apache.flink.runtime.scheduler.DefaultExecutionSlotAllocator] Allocate slot with id SlotRequestId{c78d99727be8f0c7b80724ee1f2ccd84} for execution 7d8dd6295572d72e69c940d520d84705_0
03/06/2020 13:13:13.118 DEBUG [org.apache.flink.runtime.jobmaster.slotpool.SchedulerImpl] Received slot request [SlotRequestId{c78d99727be8f0c7b80724ee1f2ccd84}] for task: null
03/06/2020 13:13:13.278  INFO [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{20e7926a2367fcf5ae6b16b7dd8a8eca}]
03/06/2020 13:13:13.286 DEBUG [org.apache.flink.runtime.jobmaster.slotpool.SlotSharingManager] Create multi task slot [SlotRequestId{c2d9090807187f747ef6e9eac628f692}] in slot [SlotRequestId{20e7926a2367fcf5ae6b16b7dd8a8eca}].
03/06/2020 13:13:13.296 DEBUG [org.apache.flink.runtime.jobmaster.slotpool.SlotSharingManager] Create single task slot [SlotRequestId{c78d99727be8f0c7b80724ee1f2ccd84}] in multi task slot [SlotRequestId{c2d9090807187f747ef6e9eac628f692}] for group 7d8dd6295572d72e69c940d520d84705.
03/06/2020 13:13:13.311 DEBUG [org.apache.flink.runtime.scheduler.DefaultExecutionSlotAllocator] Allocate slot with id SlotRequestId{6b389c215c931a8acedb8f89c580d596} for execution 7d8dd6295572d72e69c940d520d84705_1
03/06/2020 13:13:13.313 DEBUG [org.apache.flink.runtime.jobmaster.slotpool.SchedulerImpl] Received slot request [SlotRequestId{6b389c215c931a8acedb8f89c580d596}] for task: null
03/06/2020 13:13:13.314  INFO [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{2d34d8eae62035d32d8295684ad0410a}]
03/06/2020 13:13:13.317 DEBUG [org.apache.flink.runtime.jobmaster.slotpool.SlotSharingManager] Create multi task slot [SlotRequestId{ccec96e44355f6545f22bea59c161ac9}] in slot [SlotRequestId{2d34d8eae62035d32d8295684ad0410a}].
03/06/2020 13:13:13.318 DEBUG [org.apache.flink.runtime.jobmaster.slotpool.SlotSharingManager] Create single task slot [SlotRequestId{6b389c215c931a8acedb8f89c580d596}] in multi task slot [SlotRequestId{ccec96e44355f6545f22bea59c161ac9}] for group 7d8dd6295572d72e69c940d520d84705.
03/06/2020 13:13:13.332  INFO [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] Received confirmation of leadership for leader akka://flink/user/jobmanager_1 , session=29d2309e-1fa2-474c-a234-94c3a73eb1ac
03/06/2020 13:13:13.336 DEBUG [org.apache.flink.runtime.jobmaster.JobMaster] Trigger heartbeat request.
03/06/2020 13:13:13.542  INFO [org.apache.flink.runtime.jobmaster.JobMaster] Connecting to ResourceManager akka://flink/user/resourcemanager(8639690d5ef45e2fe0068f8380094a38)
03/06/2020 13:13:13.579 DEBUG [org.apache.flink.runtime.rpc.akka.AkkaRpcService] Try to connect to remote RPC endpoint with address akka://flink/user/resourcemanager. Returning a org.apache.flink.runtime.resourcemanager.ResourceManagerGateway gateway.
03/06/2020 13:13:13.582  INFO [org.apache.flink.runtime.jobmaster.JobMaster] Resolved ResourceManager address, beginning registration
03/06/2020 13:13:13.582  INFO [org.apache.flink.runtime.jobmaster.JobMaster] Registration at ResourceManager attempt 1 (timeout=100ms)
03/06/2020 13:13:13.583 DEBUG [org.apache.flink.runtime.resourcemanager.JobLeaderIdService] Add job 27a49aaf7533a153067b6fcce6e8f170 to job leader id monitoring.
03/06/2020 13:13:13.586  INFO [org.apache.flink.runtime.resourcemanager.StandaloneResourceManager] Registering job manager a23494c3a73eb1ac29d2309e1fa2474c@akka://flink/user/jobmanager_1 for job 27a49aaf7533a153067b6fcce6e8f170.
03/06/2020 13:13:13.587 DEBUG [org.apache.flink.runtime.rpc.akka.AkkaRpcService] Try to connect to remote RPC endpoint with address akka://flink/user/jobmanager_1. Returning a org.apache.flink.runtime.jobmaster.JobMasterGateway gateway.
03/06/2020 13:13:13.587 DEBUG [org.apache.flink.runtime.resourcemanager.JobLeaderIdService] Found a new job leader 29d2309e-1fa2-474c-a234-94c3a73eb1ac@akka://flink/user/jobmanager_1.
03/06/2020 13:13:13.604  INFO [org.apache.flink.runtime.resourcemanager.StandaloneResourceManager] Registered job manager a23494c3a73eb1ac29d2309e1fa2474c@akka://flink/user/jobmanager_1 for job 27a49aaf7533a153067b6fcce6e8f170.
03/06/2020 13:13:13.608  INFO [org.apache.flink.runtime.jobmaster.JobMaster] JobManager successfully registered at ResourceManager, leader id: 8639690d5ef45e2fe0068f8380094a38.
03/06/2020 13:13:13.613  INFO [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] Requesting new slot [SlotRequestId{20e7926a2367fcf5ae6b16b7dd8a8eca}] and profile ResourceProfile{UNKNOWN} from resource manager.
03/06/2020 13:13:13.619  INFO [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] Requesting new slot [SlotRequestId{2d34d8eae62035d32d8295684ad0410a}] and profile ResourceProfile{UNKNOWN} from resource manager.
03/06/2020 13:13:13.619  INFO [org.apache.flink.runtime.resourcemanager.StandaloneResourceManager] Request slot with profile ResourceProfile{UNKNOWN} for job 27a49aaf7533a153067b6fcce6e8f170 with allocation id 25d6adf2da1523d007e7207a564168d1.
03/06/2020 13:13:13.651  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutor] Receive slot request 25d6adf2da1523d007e7207a564168d1 for job 27a49aaf7533a153067b6fcce6e8f170 from resource manager with leader id 8639690d5ef45e2fe0068f8380094a38.
03/06/2020 13:13:13.671  INFO [org.apache.flink.runtime.resourcemanager.StandaloneResourceManager] Request slot with profile ResourceProfile{UNKNOWN} for job 27a49aaf7533a153067b6fcce6e8f170 with allocation id 7e6c6acb9ede8f5a9ae4c73175ba2ff1.
03/06/2020 13:13:13.688 DEBUG [org.apache.flink.runtime.memory.MemoryManager] Initialized MemoryManager with total memory size 67108864 ({OFF_HEAP=67108864}), page size 32768.
03/06/2020 13:13:13.698  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutor] Allocated slot for 25d6adf2da1523d007e7207a564168d1.
03/06/2020 13:13:13.699  INFO [org.apache.flink.runtime.taskexecutor.JobLeaderService] Add job 27a49aaf7533a153067b6fcce6e8f170 for job leader monitoring.
03/06/2020 13:13:13.701 DEBUG [org.apache.flink.runtime.taskexecutor.JobLeaderService] New leader information for job 27a49aaf7533a153067b6fcce6e8f170. Address: akka://flink/user/jobmanager_1, leader id: a23494c3a73eb1ac29d2309e1fa2474c.
03/06/2020 13:13:13.704  INFO [org.apache.flink.runtime.taskexecutor.JobLeaderService] Try to register at job manager akka://flink/user/jobmanager_1 with leader id 29d2309e-1fa2-474c-a234-94c3a73eb1ac.
03/06/2020 13:13:13.704  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutor] Receive slot request 7e6c6acb9ede8f5a9ae4c73175ba2ff1 for job 27a49aaf7533a153067b6fcce6e8f170 from resource manager with leader id 8639690d5ef45e2fe0068f8380094a38.
03/06/2020 13:13:13.704 DEBUG [org.apache.flink.runtime.rpc.akka.AkkaRpcService] Try to connect to remote RPC endpoint with address akka://flink/user/jobmanager_1. Returning a org.apache.flink.runtime.jobmaster.JobMasterGateway gateway.
03/06/2020 13:13:13.706 DEBUG [org.apache.flink.runtime.memory.MemoryManager] Initialized MemoryManager with total memory size 67108864 ({OFF_HEAP=67108864}), page size 32768.
03/06/2020 13:13:13.707  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutor] Allocated slot for 7e6c6acb9ede8f5a9ae4c73175ba2ff1.
03/06/2020 13:13:13.707  INFO [org.apache.flink.runtime.taskexecutor.JobLeaderService] Add job 27a49aaf7533a153067b6fcce6e8f170 for job leader monitoring.
03/06/2020 13:13:13.709 DEBUG [org.apache.flink.runtime.taskexecutor.JobLeaderService] Retrying registration towards akka://flink/user/jobmanager_1 was cancelled.
03/06/2020 13:13:13.711  INFO [org.apache.flink.runtime.taskexecutor.JobLeaderService] Resolved JobManager address, beginning registration
03/06/2020 13:13:13.711 DEBUG [org.apache.flink.runtime.taskexecutor.JobLeaderService] New leader information for job 27a49aaf7533a153067b6fcce6e8f170. Address: akka://flink/user/jobmanager_1, leader id: a23494c3a73eb1ac29d2309e1fa2474c.
03/06/2020 13:13:13.711  INFO [org.apache.flink.runtime.taskexecutor.JobLeaderService] Try to register at job manager akka://flink/user/jobmanager_1 with leader id 29d2309e-1fa2-474c-a234-94c3a73eb1ac.
03/06/2020 13:13:13.711 DEBUG [org.apache.flink.runtime.rpc.akka.AkkaRpcService] Try to connect to remote RPC endpoint with address akka://flink/user/jobmanager_1. Returning a org.apache.flink.runtime.jobmaster.JobMasterGateway gateway.
03/06/2020 13:13:13.712  INFO [org.apache.flink.runtime.taskexecutor.JobLeaderService] Resolved JobManager address, beginning registration
03/06/2020 13:13:13.713  INFO [org.apache.flink.runtime.taskexecutor.JobLeaderService] Registration at JobManager attempt 1 (timeout=100ms)
03/06/2020 13:13:13.714 DEBUG [org.apache.flink.runtime.rpc.akka.AkkaRpcService] Try to connect to remote RPC endpoint with address akka://flink/user/taskmanager_0. Returning a org.apache.flink.runtime.taskexecutor.TaskExecutorGateway gateway.
03/06/2020 13:13:13.716 DEBUG [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] Register new TaskExecutor 860855ef-8204-47f1-97b9-688ca96b77ac.
03/06/2020 13:13:13.726  INFO [org.apache.flink.runtime.taskexecutor.JobLeaderService] Successful registration at job manager akka://flink/user/jobmanager_1 for job 27a49aaf7533a153067b6fcce6e8f170.
03/06/2020 13:13:13.726  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutor] Establish JobManager connection for job 27a49aaf7533a153067b6fcce6e8f170.
03/06/2020 13:13:13.739  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutor] Offer reserved slots to the leader of job 27a49aaf7533a153067b6fcce6e8f170.
03/06/2020 13:13:13.816  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] CHAIN DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) -> Map (Map at getGraphCollection(HBaseDataSource.java:125)) -> Filter (Filter at getGraph(BaseGraphCollection.java:82)) (1/2) (77393775f2f5e4ee3df790c3b98fa8c4) switched from SCHEDULED to DEPLOYING.
03/06/2020 13:13:13.821  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] Deploying CHAIN DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) -> Map (Map at getGraphCollection(HBaseDataSource.java:125)) -> Filter (Filter at getGraph(BaseGraphCollection.java:82)) (1/2) (attempt #0) to 860855ef-8204-47f1-97b9-688ca96b77ac @ localhost (dataPort=-1)
03/06/2020 13:13:13.870 DEBUG [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] Fulfilled slot request [SlotRequestId{20e7926a2367fcf5ae6b16b7dd8a8eca}] with allocated slot [25d6adf2da1523d007e7207a564168d1].
03/06/2020 13:13:13.870  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] CHAIN DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) -> Map (Map at getGraphCollection(HBaseDataSource.java:125)) -> Filter (Filter at getGraph(BaseGraphCollection.java:82)) (2/2) (c0bee93248ded4bbff5301f05863bb2d) switched from SCHEDULED to DEPLOYING.
03/06/2020 13:13:13.876  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] Deploying CHAIN DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) -> Map (Map at getGraphCollection(HBaseDataSource.java:125)) -> Filter (Filter at getGraph(BaseGraphCollection.java:82)) (2/2) (attempt #0) to 860855ef-8204-47f1-97b9-688ca96b77ac @ localhost (dataPort=-1)
03/06/2020 13:13:13.881 DEBUG [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] Fulfilled slot request [SlotRequestId{2d34d8eae62035d32d8295684ad0410a}] with allocated slot [7e6c6acb9ede8f5a9ae4c73175ba2ff1].
03/06/2020 13:13:13.907 DEBUG [org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager] Registered new allocation id 25d6adf2da1523d007e7207a564168d1 for local state stores for job 27a49aaf7533a153067b6fcce6e8f170.
03/06/2020 13:13:13.917 DEBUG [org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager] Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[/tmp/localState/aid_25d6adf2da1523d007e7207a564168d1], jobID=27a49aaf7533a153067b6fcce6e8f170, jobVertexID=7d8dd6295572d72e69c940d520d84705, subtaskIndex=0}} for 27a49aaf7533a153067b6fcce6e8f170 - 7d8dd6295572d72e69c940d520d84705 - 0 under allocation id 25d6adf2da1523d007e7207a564168d1.
03/06/2020 13:13:13.966 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionFactory] CHAIN DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) -> Map (Map at getGraphCollection(HBaseDataSource.java:125)) -> Filter (Filter at getGraph(BaseGraphCollection.java:82)) (1/2) (77393775f2f5e4ee3df790c3b98fa8c4): Initialized org.apache.flink.runtime.io.network.partition.ResultPartitionFactory@113fc38b
03/06/2020 13:13:13.992  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutor] Received task CHAIN DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) -> Map (Map at getGraphCollection(HBaseDataSource.java:125)) -> Filter (Filter at getGraph(BaseGraphCollection.java:82)) (1/2).
03/06/2020 13:13:14.023  INFO [org.apache.flink.runtime.taskmanager.Task] CHAIN DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) -> Map (Map at getGraphCollection(HBaseDataSource.java:125)) -> Filter (Filter at getGraph(BaseGraphCollection.java:82)) (1/2) (77393775f2f5e4ee3df790c3b98fa8c4) switched from CREATED to DEPLOYING.
03/06/2020 13:13:14.106  INFO [org.apache.flink.runtime.taskmanager.Task] Creating FileSystem stream leak safety net for task CHAIN DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) -> Map (Map at getGraphCollection(HBaseDataSource.java:125)) -> Filter (Filter at getGraph(BaseGraphCollection.java:82)) (1/2) (77393775f2f5e4ee3df790c3b98fa8c4) [DEPLOYING]
03/06/2020 13:13:14.129 DEBUG [org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager] Registered new allocation id 7e6c6acb9ede8f5a9ae4c73175ba2ff1 for local state stores for job 27a49aaf7533a153067b6fcce6e8f170.
03/06/2020 13:13:14.136 DEBUG [org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager] Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[/tmp/localState/aid_7e6c6acb9ede8f5a9ae4c73175ba2ff1], jobID=27a49aaf7533a153067b6fcce6e8f170, jobVertexID=7d8dd6295572d72e69c940d520d84705, subtaskIndex=1}} for 27a49aaf7533a153067b6fcce6e8f170 - 7d8dd6295572d72e69c940d520d84705 - 1 under allocation id 7e6c6acb9ede8f5a9ae4c73175ba2ff1.
03/06/2020 13:13:14.136 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionFactory] CHAIN DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) -> Map (Map at getGraphCollection(HBaseDataSource.java:125)) -> Filter (Filter at getGraph(BaseGraphCollection.java:82)) (2/2) (c0bee93248ded4bbff5301f05863bb2d): Initialized org.apache.flink.runtime.io.network.partition.ResultPartitionFactory@113fc38b
03/06/2020 13:13:14.155  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutor] Received task CHAIN DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) -> Map (Map at getGraphCollection(HBaseDataSource.java:125)) -> Filter (Filter at getGraph(BaseGraphCollection.java:82)) (2/2).
03/06/2020 13:13:14.171  INFO [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl] Activate slot 25d6adf2da1523d007e7207a564168d1.
03/06/2020 13:13:14.171  INFO [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl] Activate slot 7e6c6acb9ede8f5a9ae4c73175ba2ff1.
03/06/2020 13:13:14.174  INFO [org.apache.flink.runtime.taskmanager.Task] CHAIN DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) -> Map (Map at getGraphCollection(HBaseDataSource.java:125)) -> Filter (Filter at getGraph(BaseGraphCollection.java:82)) (2/2) (c0bee93248ded4bbff5301f05863bb2d) switched from CREATED to DEPLOYING.
03/06/2020 13:13:14.190  INFO [org.apache.flink.runtime.taskmanager.Task] Creating FileSystem stream leak safety net for task CHAIN DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) -> Map (Map at getGraphCollection(HBaseDataSource.java:125)) -> Filter (Filter at getGraph(BaseGraphCollection.java:82)) (2/2) (c0bee93248ded4bbff5301f05863bb2d) [DEPLOYING]
03/06/2020 13:13:14.209  INFO [org.apache.flink.runtime.taskmanager.Task] Loading JAR files for task CHAIN DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) -> Map (Map at getGraphCollection(HBaseDataSource.java:125)) -> Filter (Filter at getGraph(BaseGraphCollection.java:82)) (2/2) (c0bee93248ded4bbff5301f05863bb2d) [DEPLOYING].
03/06/2020 13:13:14.210 DEBUG [org.apache.flink.runtime.taskmanager.Task] Getting user code class loader for task c0bee93248ded4bbff5301f05863bb2d at library cache manager took 1 milliseconds
03/06/2020 13:13:14.210  INFO [org.apache.flink.runtime.taskmanager.Task] Loading JAR files for task CHAIN DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) -> Map (Map at getGraphCollection(HBaseDataSource.java:125)) -> Filter (Filter at getGraph(BaseGraphCollection.java:82)) (1/2) (77393775f2f5e4ee3df790c3b98fa8c4) [DEPLOYING].
03/06/2020 13:13:14.219  INFO [org.apache.flink.runtime.taskmanager.Task] Registering task at network: CHAIN DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) -> Map (Map at getGraphCollection(HBaseDataSource.java:125)) -> Filter (Filter at getGraph(BaseGraphCollection.java:82)) (2/2) (c0bee93248ded4bbff5301f05863bb2d) [DEPLOYING].
03/06/2020 13:13:14.220 DEBUG [org.apache.flink.runtime.taskmanager.Task] Getting user code class loader for task 77393775f2f5e4ee3df790c3b98fa8c4 at library cache manager took 10 milliseconds
03/06/2020 13:13:14.224  INFO [org.apache.flink.runtime.taskmanager.Task] Registering task at network: CHAIN DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) -> Map (Map at getGraphCollection(HBaseDataSource.java:125)) -> Filter (Filter at getGraph(BaseGraphCollection.java:82)) (1/2) (77393775f2f5e4ee3df790c3b98fa8c4) [DEPLOYING].
03/06/2020 13:13:14.231 DEBUG [org.apache.flink.runtime.io.network.buffer.LocalBufferPool] Using a local buffer pool with 2-2147483647 buffers
03/06/2020 13:13:14.232 DEBUG [org.apache.flink.runtime.io.network.buffer.LocalBufferPool] Using a local buffer pool with 2-2147483647 buffers
03/06/2020 13:13:14.243 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionManager] Registered ReleaseOnConsumptionResultPartition 7483b008bac320fb0b462f7d262e6cda@c0bee93248ded4bbff5301f05863bb2d [PIPELINED, 1 subpartitions, 1 pending consumptions].
03/06/2020 13:13:14.243 DEBUG [org.apache.flink.runtime.io.network.TaskEventDispatcher] registering 7483b008bac320fb0b462f7d262e6cda@c0bee93248ded4bbff5301f05863bb2d
03/06/2020 13:13:14.243 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionManager] Registered ReleaseOnConsumptionResultPartition 0fa8733ed407d2a8faf354b6a49dcab8@77393775f2f5e4ee3df790c3b98fa8c4 [PIPELINED, 1 subpartitions, 1 pending consumptions].
03/06/2020 13:13:14.346 DEBUG [org.apache.flink.runtime.io.network.TaskEventDispatcher] registering 0fa8733ed407d2a8faf354b6a49dcab8@77393775f2f5e4ee3df790c3b98fa8c4
03/06/2020 13:13:14.379  INFO [org.apache.flink.runtime.taskmanager.Task] CHAIN DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) -> Map (Map at getGraphCollection(HBaseDataSource.java:125)) -> Filter (Filter at getGraph(BaseGraphCollection.java:82)) (1/2) (77393775f2f5e4ee3df790c3b98fa8c4) switched from DEPLOYING to RUNNING.
03/06/2020 13:13:14.387  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] CHAIN DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) -> Map (Map at getGraphCollection(HBaseDataSource.java:125)) -> Filter (Filter at getGraph(BaseGraphCollection.java:82)) (1/2) (77393775f2f5e4ee3df790c3b98fa8c4) switched from DEPLOYING to RUNNING.
03/06/2020 13:13:14.391  INFO [org.apache.flink.runtime.taskmanager.Task] CHAIN DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) -> Map (Map at getGraphCollection(HBaseDataSource.java:125)) -> Filter (Filter at getGraph(BaseGraphCollection.java:82)) (2/2) (c0bee93248ded4bbff5301f05863bb2d) switched from DEPLOYING to RUNNING.
03/06/2020 13:13:14.392  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] CHAIN DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) -> Map (Map at getGraphCollection(HBaseDataSource.java:125)) -> Filter (Filter at getGraph(BaseGraphCollection.java:82)) (2/2) (c0bee93248ded4bbff5301f05863bb2d) switched from DEPLOYING to RUNNING.
03/06/2020 13:13:14.396  INFO [org.apache.flink.addons.hbase.AbstractTableInputFormat] Initializing HBaseConfiguration
03/06/2020 13:13:14.407  INFO [org.apache.flink.addons.hbase.AbstractTableInputFormat] Initializing HBaseConfiguration
03/06/2020 13:13:14.593 DEBUG [org.apache.flink.runtime.operators.DataSourceTask] Start registering input and output:  CHAIN DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) -> Map (Map at getGraphCollection(HBaseDataSource.java:125)) -> Filter (Filter at getGraph(BaseGraphCollection.java:82)) (1/2)
03/06/2020 13:13:14.594 DEBUG [org.apache.flink.runtime.operators.DataSourceTask] Start registering input and output:  CHAIN DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) -> Map (Map at getGraphCollection(HBaseDataSource.java:125)) -> Filter (Filter at getGraph(BaseGraphCollection.java:82)) (2/2)
03/06/2020 13:13:14.688 DEBUG [org.apache.flink.runtime.operators.DataSourceTask] Finished registering input and output:  CHAIN DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) -> Map (Map at getGraphCollection(HBaseDataSource.java:125)) -> Filter (Filter at getGraph(BaseGraphCollection.java:82)) (2/2)
03/06/2020 13:13:14.695 DEBUG [org.apache.flink.runtime.operators.DataSourceTask] Starting data source operator:  CHAIN DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) -> Map (Map at getGraphCollection(HBaseDataSource.java:125)) -> Filter (Filter at getGraph(BaseGraphCollection.java:82)) (2/2)
03/06/2020 13:13:14.695  WARN [org.apache.flink.metrics.MetricGroup] The operator name DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) exceeded the 80 characters length limit and was truncated.
03/06/2020 13:13:14.696 DEBUG [org.apache.flink.runtime.operators.DataSourceTask] Rich Source detected. Initializing runtime context.:  CHAIN DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) -> Map (Map at getGraphCollection(HBaseDataSource.java:125)) -> Filter (Filter at getGraph(BaseGraphCollection.java:82)) (2/2)
03/06/2020 13:13:14.698 DEBUG [org.apache.flink.runtime.operators.DataSourceTask] Rich Source detected. Opening the InputFormat.:  CHAIN DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) -> Map (Map at getGraphCollection(HBaseDataSource.java:125)) -> Filter (Filter at getGraph(BaseGraphCollection.java:82)) (2/2)
03/06/2020 13:13:14.698 DEBUG [org.apache.flink.runtime.operators.DataSourceTask] DataSourceTask object reuse: DISABLED.
03/06/2020 13:13:14.698 DEBUG [org.apache.flink.runtime.operators.BatchTask] Start task code:  Map (Map at getGraphCollection(HBaseDataSource.java:125)) (2/2)
03/06/2020 13:13:14.698 DEBUG [org.apache.flink.runtime.operators.BatchTask] Start task code:  Filter (Filter at getGraph(BaseGraphCollection.java:82)) (2/2)
03/06/2020 13:13:14.703  INFO [org.apache.flink.api.common.io.LocatableInputSplitAssigner] Assigning remote split to host localhost
03/06/2020 13:13:14.703 DEBUG [org.apache.flink.runtime.jobmaster.JobMaster] Send next input split Locatable Split (0) at [ubuntu:16201].
03/06/2020 13:13:14.714 DEBUG [org.apache.flink.runtime.operators.DataSourceTask] Finished registering input and output:  CHAIN DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) -> Map (Map at getGraphCollection(HBaseDataSource.java:125)) -> Filter (Filter at getGraph(BaseGraphCollection.java:82)) (1/2)
03/06/2020 13:13:14.715 DEBUG [org.apache.flink.runtime.operators.DataSourceTask] Starting data source operator:  CHAIN DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) -> Map (Map at getGraphCollection(HBaseDataSource.java:125)) -> Filter (Filter at getGraph(BaseGraphCollection.java:82)) (1/2)
03/06/2020 13:13:14.715  WARN [org.apache.flink.metrics.MetricGroup] The operator name DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) exceeded the 80 characters length limit and was truncated.
03/06/2020 13:13:14.718 DEBUG [org.apache.flink.runtime.operators.DataSourceTask] Opening input split Locatable Split (0) at [ubuntu:16201]:  CHAIN DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) -> Map (Map at getGraphCollection(HBaseDataSource.java:125)) -> Filter (Filter at getGraph(BaseGraphCollection.java:82)) (2/2)
03/06/2020 13:13:14.720 DEBUG [org.apache.flink.runtime.operators.DataSourceTask] Rich Source detected. Initializing runtime context.:  CHAIN DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) -> Map (Map at getGraphCollection(HBaseDataSource.java:125)) -> Filter (Filter at getGraph(BaseGraphCollection.java:82)) (1/2)
03/06/2020 13:13:14.723 DEBUG [org.apache.flink.runtime.operators.DataSourceTask] Rich Source detected. Opening the InputFormat.:  CHAIN DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) -> Map (Map at getGraphCollection(HBaseDataSource.java:125)) -> Filter (Filter at getGraph(BaseGraphCollection.java:82)) (1/2)
03/06/2020 13:13:14.723 DEBUG [org.apache.flink.runtime.operators.DataSourceTask] DataSourceTask object reuse: DISABLED.
03/06/2020 13:13:14.723 DEBUG [org.apache.flink.runtime.operators.BatchTask] Start task code:  Map (Map at getGraphCollection(HBaseDataSource.java:125)) (1/2)
03/06/2020 13:13:14.725 DEBUG [org.apache.flink.runtime.operators.BatchTask] Start task code:  Filter (Filter at getGraph(BaseGraphCollection.java:82)) (1/2)
03/06/2020 13:13:14.726 DEBUG [org.apache.flink.api.common.io.LocatableInputSplitAssigner] No more input splits remaining.
03/06/2020 13:13:14.726 DEBUG [org.apache.flink.runtime.jobmaster.JobMaster] Send next input split null.
03/06/2020 13:13:14.726  INFO [org.apache.flink.addons.hbase.AbstractTableInputFormat] opening split (this=org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat@5d15eaac)[0|[ubuntu:16201]|-|-]
03/06/2020 13:13:14.727 DEBUG [org.apache.flink.runtime.operators.DataSourceTask] Starting to read input from split Locatable Split (0) at [ubuntu:16201]:  CHAIN DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) -> Map (Map at getGraphCollection(HBaseDataSource.java:125)) -> Filter (Filter at getGraph(BaseGraphCollection.java:82)) (2/2)
03/06/2020 13:13:14.727 DEBUG [org.apache.flink.runtime.operators.BatchTask] Finished task code:  Map (Map at getGraphCollection(HBaseDataSource.java:125)) (1/2)
03/06/2020 13:13:14.734 DEBUG [org.apache.flink.runtime.operators.BatchTask] Finished task code:  Filter (Filter at getGraph(BaseGraphCollection.java:82)) (1/2)
03/06/2020 13:13:14.734 DEBUG [org.apache.flink.runtime.operators.DataSourceTask] Rich Source detected. Closing the InputFormat.:  CHAIN DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) -> Map (Map at getGraphCollection(HBaseDataSource.java:125)) -> Filter (Filter at getGraph(BaseGraphCollection.java:82)) (1/2)
03/06/2020 13:13:14.735 DEBUG [org.apache.flink.runtime.operators.DataSourceTask] Finished data source operator:  CHAIN DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) -> Map (Map at getGraphCollection(HBaseDataSource.java:125)) -> Filter (Filter at getGraph(BaseGraphCollection.java:82)) (1/2)
03/06/2020 13:13:14.782 DEBUG [org.apache.flink.shaded.netty4.io.netty.buffer.AbstractByteBuf] -Dorg.apache.flink.shaded.netty4.io.netty.buffer.checkAccessible: true
03/06/2020 13:13:14.783 DEBUG [org.apache.flink.shaded.netty4.io.netty.buffer.AbstractByteBuf] -Dorg.apache.flink.shaded.netty4.io.netty.buffer.checkBounds: true
03/06/2020 13:13:14.785 DEBUG [org.apache.flink.shaded.netty4.io.netty.util.ResourceLeakDetectorFactory] Loaded default ResourceLeakDetector: org.apache.flink.shaded.netty4.io.netty.util.ResourceLeakDetector@68bb26ac
03/06/2020 13:13:14.787 DEBUG [org.apache.flink.runtime.io.network.partition.PipelinedSubpartition] CHAIN DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) -> Map (Map at getGraphCollection(HBaseDataSource.java:125)) -> Filter (Filter at getGraph(BaseGraphCollection.java:82)) (1/2) (77393775f2f5e4ee3df790c3b98fa8c4): Finished PipelinedSubpartition#0 [number of buffers: 1 (0 bytes), number of buffers in backlog: 0, finished? true, read view? false].
03/06/2020 13:13:14.798  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] DataSink (collect()) (1/2) (dc37bd76e64ad936c96a5c22129b6b70) switched from CREATED to SCHEDULED.
03/06/2020 13:13:14.798 DEBUG [org.apache.flink.runtime.scheduler.DefaultExecutionSlotAllocator] Allocate slot with id SlotRequestId{d4dc659780ffcf2b99572775f390c5c0} for execution 3cd62e156787952e99db0c94cf0769f0_0
03/06/2020 13:13:14.799 DEBUG [org.apache.flink.runtime.jobmaster.slotpool.SchedulerImpl] Received slot request [SlotRequestId{d4dc659780ffcf2b99572775f390c5c0}] for task: null
03/06/2020 13:13:14.801  INFO [org.apache.flink.runtime.taskmanager.Task] CHAIN DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) -> Map (Map at getGraphCollection(HBaseDataSource.java:125)) -> Filter (Filter at getGraph(BaseGraphCollection.java:82)) (1/2) (77393775f2f5e4ee3df790c3b98fa8c4) switched from RUNNING to FINISHED.
03/06/2020 13:13:14.830  INFO [org.apache.flink.runtime.taskmanager.Task] Freeing task resources for CHAIN DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) -> Map (Map at getGraphCollection(HBaseDataSource.java:125)) -> Filter (Filter at getGraph(BaseGraphCollection.java:82)) (1/2) (77393775f2f5e4ee3df790c3b98fa8c4).
03/06/2020 13:13:14.830 DEBUG [org.apache.flink.runtime.taskmanager.Task] Release task CHAIN DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) -> Map (Map at getGraphCollection(HBaseDataSource.java:125)) -> Filter (Filter at getGraph(BaseGraphCollection.java:82)) (1/2) network resources (state: FINISHED).
03/06/2020 13:13:14.830 DEBUG [org.apache.flink.runtime.io.network.TaskEventDispatcher] unregistering 0fa8733ed407d2a8faf354b6a49dcab8@77393775f2f5e4ee3df790c3b98fa8c4
03/06/2020 13:13:14.830  INFO [org.apache.flink.runtime.taskmanager.Task] Ensuring all FileSystem streams are closed for task CHAIN DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) -> Map (Map at getGraphCollection(HBaseDataSource.java:125)) -> Filter (Filter at getGraph(BaseGraphCollection.java:82)) (1/2) (77393775f2f5e4ee3df790c3b98fa8c4) [FINISHED]
03/06/2020 13:13:14.812 DEBUG [org.apache.flink.runtime.jobmaster.slotpool.SlotSharingManager] Create single task slot [SlotRequestId{d4dc659780ffcf2b99572775f390c5c0}] in multi task slot [SlotRequestId{c2d9090807187f747ef6e9eac628f692}] for group 3cd62e156787952e99db0c94cf0769f0.
03/06/2020 13:13:14.833  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutor] Un-registering task and sending final execution state FINISHED to JobManager for task CHAIN DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) -> Map (Map at getGraphCollection(HBaseDataSource.java:125)) -> Filter (Filter at getGraph(BaseGraphCollection.java:82)) (1/2) 77393775f2f5e4ee3df790c3b98fa8c4.
03/06/2020 13:13:14.844  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] DataSink (collect()) (1/2) (dc37bd76e64ad936c96a5c22129b6b70) switched from SCHEDULED to DEPLOYING.
03/06/2020 13:13:14.844  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] Deploying DataSink (collect()) (1/2) (attempt #0) to 860855ef-8204-47f1-97b9-688ca96b77ac @ localhost (dataPort=-1)
03/06/2020 13:13:14.865  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] CHAIN DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) -> Map (Map at getGraphCollection(HBaseDataSource.java:125)) -> Filter (Filter at getGraph(BaseGraphCollection.java:82)) (1/2) (77393775f2f5e4ee3df790c3b98fa8c4) switched from RUNNING to FINISHED.
03/06/2020 13:13:14.865 DEBUG [org.apache.flink.runtime.executiongraph.ExecutionGraph] Ignoring transition of vertex CHAIN DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) -> Map (Map at getGraphCollection(HBaseDataSource.java:125)) -> Filter (Filter at getGraph(BaseGraphCollection.java:82)) (1/2) - execution #0 to FAILED while being FINISHED.
03/06/2020 13:13:14.874 DEBUG [org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager] Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[/tmp/localState/aid_25d6adf2da1523d007e7207a564168d1], jobID=27a49aaf7533a153067b6fcce6e8f170, jobVertexID=3cd62e156787952e99db0c94cf0769f0, subtaskIndex=0}} for 27a49aaf7533a153067b6fcce6e8f170 - 3cd62e156787952e99db0c94cf0769f0 - 0 under allocation id 25d6adf2da1523d007e7207a564168d1.
03/06/2020 13:13:14.945 DEBUG [org.apache.flink.runtime.io.network.partition.consumer.SingleInputGateFactory] DataSink (collect()) (1/2) (dc37bd76e64ad936c96a5c22129b6b70): Created 1 input channels (local: 1, remote: 0, unknown: 0).
03/06/2020 13:13:14.973  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutor] Received task DataSink (collect()) (1/2).
03/06/2020 13:13:14.981  INFO [org.apache.flink.runtime.taskmanager.Task] DataSink (collect()) (1/2) (dc37bd76e64ad936c96a5c22129b6b70) switched from CREATED to DEPLOYING.
03/06/2020 13:13:14.999  INFO [org.apache.flink.runtime.taskmanager.Task] Creating FileSystem stream leak safety net for task DataSink (collect()) (1/2) (dc37bd76e64ad936c96a5c22129b6b70) [DEPLOYING]
03/06/2020 13:13:15.000  INFO [org.apache.flink.runtime.taskmanager.Task] Loading JAR files for task DataSink (collect()) (1/2) (dc37bd76e64ad936c96a5c22129b6b70) [DEPLOYING].
03/06/2020 13:13:15.000 DEBUG [org.apache.flink.runtime.taskmanager.Task] Getting user code class loader for task dc37bd76e64ad936c96a5c22129b6b70 at library cache manager took 0 milliseconds
03/06/2020 13:13:15.005  INFO [org.apache.flink.runtime.taskmanager.Task] Registering task at network: DataSink (collect()) (1/2) (dc37bd76e64ad936c96a5c22129b6b70) [DEPLOYING].
03/06/2020 13:13:15.005 DEBUG [org.apache.flink.runtime.io.network.buffer.LocalBufferPool] Using a local buffer pool with 0-8 buffers
03/06/2020 13:13:15.006 DEBUG [org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel] LocalInputChannel [0fa8733ed407d2a8faf354b6a49dcab8@77393775f2f5e4ee3df790c3b98fa8c4]: Requesting LOCAL subpartition 0 of partition 0fa8733ed407d2a8faf354b6a49dcab8@77393775f2f5e4ee3df790c3b98fa8c4.
03/06/2020 13:13:15.007 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionManager] Requesting subpartition 0 of ReleaseOnConsumptionResultPartition 0fa8733ed407d2a8faf354b6a49dcab8@77393775f2f5e4ee3df790c3b98fa8c4 [PIPELINED, 1 subpartitions, 1 pending consumptions].
03/06/2020 13:13:15.008 DEBUG [org.apache.flink.runtime.io.network.partition.PipelinedSubpartition] CHAIN DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) -> Map (Map at getGraphCollection(HBaseDataSource.java:125)) -> Filter (Filter at getGraph(BaseGraphCollection.java:82)) (1/2) (77393775f2f5e4ee3df790c3b98fa8c4): Creating read view for subpartition 0 of partition 0fa8733ed407d2a8faf354b6a49dcab8@77393775f2f5e4ee3df790c3b98fa8c4.
03/06/2020 13:13:15.009 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartition] Created PipelinedSubpartitionView(index: 0) of ResultPartition 0fa8733ed407d2a8faf354b6a49dcab8@77393775f2f5e4ee3df790c3b98fa8c4
03/06/2020 13:13:15.017  INFO [org.apache.flink.runtime.taskmanager.Task] DataSink (collect()) (1/2) (dc37bd76e64ad936c96a5c22129b6b70) switched from DEPLOYING to RUNNING.
03/06/2020 13:13:15.022  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] DataSink (collect()) (1/2) (dc37bd76e64ad936c96a5c22129b6b70) switched from DEPLOYING to RUNNING.
03/06/2020 13:13:15.066 DEBUG [org.apache.flink.runtime.operators.DataSinkTask] Start registering input and output:  DataSink (collect()) (1/2)
03/06/2020 13:13:15.140 DEBUG [org.apache.flink.runtime.operators.DataSinkTask] Finished registering input and output:  DataSink (collect()) (1/2)
03/06/2020 13:13:15.146 DEBUG [org.apache.flink.runtime.operators.DataSinkTask] Starting data sink operator:  DataSink (collect()) (1/2)
03/06/2020 13:13:15.148 DEBUG [org.apache.flink.runtime.operators.DataSinkTask] Rich Sink detected. Initializing runtime context.:  DataSink (collect()) (1/2)
03/06/2020 13:13:15.163 DEBUG [org.apache.flink.runtime.operators.DataSinkTask] Starting to produce output:  DataSink (collect()) (1/2)
03/06/2020 13:13:15.192 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartition] ReleaseOnConsumptionResultPartition 0fa8733ed407d2a8faf354b6a49dcab8@77393775f2f5e4ee3df790c3b98fa8c4 [PIPELINED, 1 subpartitions, 0 pending consumptions]: Received consumed notification for subpartition 0.
03/06/2020 13:13:15.196  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] DataSink (collect()) (2/2) (4fbe480a642b1f257d8ce80dc5a1f989) switched from CREATED to SCHEDULED.
03/06/2020 13:13:15.204 DEBUG [org.apache.flink.runtime.scheduler.DefaultExecutionSlotAllocator] Allocate slot with id SlotRequestId{74c19ed407af63b5475bdfd446fbcdd1} for execution 3cd62e156787952e99db0c94cf0769f0_1
03/06/2020 13:13:15.204 DEBUG [org.apache.flink.runtime.jobmaster.slotpool.SchedulerImpl] Received slot request [SlotRequestId{74c19ed407af63b5475bdfd446fbcdd1}] for task: null
03/06/2020 13:13:15.204 DEBUG [org.apache.flink.runtime.jobmaster.slotpool.SlotSharingManager] Create single task slot [SlotRequestId{74c19ed407af63b5475bdfd446fbcdd1}] in multi task slot [SlotRequestId{ccec96e44355f6545f22bea59c161ac9}] for group 3cd62e156787952e99db0c94cf0769f0.
03/06/2020 13:13:15.204  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] DataSink (collect()) (2/2) (4fbe480a642b1f257d8ce80dc5a1f989) switched from SCHEDULED to DEPLOYING.
03/06/2020 13:13:15.205  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] Deploying DataSink (collect()) (2/2) (attempt #0) to 860855ef-8204-47f1-97b9-688ca96b77ac @ localhost (dataPort=-1)
03/06/2020 13:13:15.204 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionManager] Received consume notification from ReleaseOnConsumptionResultPartition 0fa8733ed407d2a8faf354b6a49dcab8@77393775f2f5e4ee3df790c3b98fa8c4 [PIPELINED, 1 subpartitions, 0 pending consumptions].
03/06/2020 13:13:15.207 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartition] CHAIN DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) -> Map (Map at getGraphCollection(HBaseDataSource.java:125)) -> Filter (Filter at getGraph(BaseGraphCollection.java:82)) (1/2) (77393775f2f5e4ee3df790c3b98fa8c4): Releasing ReleaseOnConsumptionResultPartition 0fa8733ed407d2a8faf354b6a49dcab8@77393775f2f5e4ee3df790c3b98fa8c4 [PIPELINED, 1 subpartitions, 0 pending consumptions].
03/06/2020 13:13:15.214 DEBUG [org.apache.flink.runtime.io.network.partition.PipelinedSubpartition] CHAIN DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) -> Map (Map at getGraphCollection(HBaseDataSource.java:125)) -> Filter (Filter at getGraph(BaseGraphCollection.java:82)) (1/2) (77393775f2f5e4ee3df790c3b98fa8c4): Released PipelinedSubpartition#0 [number of buffers: 1 (4 bytes), number of buffers in backlog: 0, finished? true, read view? false].
03/06/2020 13:13:15.214 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionManager] Released partition 0fa8733ed407d2a8faf354b6a49dcab8 produced by 77393775f2f5e4ee3df790c3b98fa8c4.
03/06/2020 13:13:15.215 DEBUG [org.apache.flink.runtime.operators.DataSinkTask] Finished data sink operator:  DataSink (collect()) (1/2)
03/06/2020 13:13:15.215  INFO [org.apache.flink.runtime.taskmanager.Task] DataSink (collect()) (1/2) (dc37bd76e64ad936c96a5c22129b6b70) switched from RUNNING to FINISHED.
03/06/2020 13:13:15.215  INFO [org.apache.flink.runtime.taskmanager.Task] Freeing task resources for DataSink (collect()) (1/2) (dc37bd76e64ad936c96a5c22129b6b70).
03/06/2020 13:13:15.215 DEBUG [org.apache.flink.runtime.taskmanager.Task] Release task DataSink (collect()) (1/2) network resources (state: FINISHED).
03/06/2020 13:13:15.216 DEBUG [org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate] DataSink (collect()) (1/2) (dc37bd76e64ad936c96a5c22129b6b70): Releasing org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate@6f7645e3.
03/06/2020 13:13:15.216  INFO [org.apache.flink.runtime.taskmanager.Task] Ensuring all FileSystem streams are closed for task DataSink (collect()) (1/2) (dc37bd76e64ad936c96a5c22129b6b70) [FINISHED]
03/06/2020 13:13:15.208 DEBUG [org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager] Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[/tmp/localState/aid_7e6c6acb9ede8f5a9ae4c73175ba2ff1], jobID=27a49aaf7533a153067b6fcce6e8f170, jobVertexID=3cd62e156787952e99db0c94cf0769f0, subtaskIndex=1}} for 27a49aaf7533a153067b6fcce6e8f170 - 3cd62e156787952e99db0c94cf0769f0 - 1 under allocation id 7e6c6acb9ede8f5a9ae4c73175ba2ff1.
03/06/2020 13:13:15.233 DEBUG [org.apache.flink.runtime.io.network.partition.consumer.SingleInputGateFactory] DataSink (collect()) (2/2) (4fbe480a642b1f257d8ce80dc5a1f989): Created 1 input channels (local: 1, remote: 0, unknown: 0).
03/06/2020 13:13:15.237  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutor] Received task DataSink (collect()) (2/2).
03/06/2020 13:13:15.252  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutor] Un-registering task and sending final execution state FINISHED to JobManager for task DataSink (collect()) (1/2) dc37bd76e64ad936c96a5c22129b6b70.
03/06/2020 13:13:15.262  INFO [org.apache.flink.runtime.taskmanager.Task] DataSink (collect()) (2/2) (4fbe480a642b1f257d8ce80dc5a1f989) switched from CREATED to DEPLOYING.
03/06/2020 13:13:15.263  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] DataSink (collect()) (1/2) (dc37bd76e64ad936c96a5c22129b6b70) switched from RUNNING to FINISHED.
03/06/2020 13:13:15.278 DEBUG [org.apache.flink.runtime.executiongraph.ExecutionGraph] Ignoring transition of vertex DataSink (collect()) (1/2) - execution #0 to FAILED while being FINISHED.
03/06/2020 13:13:15.278 DEBUG [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] Releasing slot [SlotRequestId{20e7926a2367fcf5ae6b16b7dd8a8eca}] because: Release multi task slot because all children have been released.
03/06/2020 13:13:15.279  INFO [org.apache.flink.runtime.taskmanager.Task] Creating FileSystem stream leak safety net for task DataSink (collect()) (2/2) (4fbe480a642b1f257d8ce80dc5a1f989) [DEPLOYING]
03/06/2020 13:13:15.279  INFO [org.apache.flink.runtime.taskmanager.Task] Loading JAR files for task DataSink (collect()) (2/2) (4fbe480a642b1f257d8ce80dc5a1f989) [DEPLOYING].
03/06/2020 13:13:15.279 DEBUG [org.apache.flink.runtime.taskmanager.Task] Getting user code class loader for task 4fbe480a642b1f257d8ce80dc5a1f989 at library cache manager took 0 milliseconds
03/06/2020 13:13:15.280  INFO [org.apache.flink.runtime.taskmanager.Task] Registering task at network: DataSink (collect()) (2/2) (4fbe480a642b1f257d8ce80dc5a1f989) [DEPLOYING].
03/06/2020 13:13:15.280 DEBUG [org.apache.flink.runtime.io.network.buffer.LocalBufferPool] Using a local buffer pool with 0-8 buffers
03/06/2020 13:13:15.280 DEBUG [org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel] LocalInputChannel [7483b008bac320fb0b462f7d262e6cda@c0bee93248ded4bbff5301f05863bb2d]: Requesting LOCAL subpartition 0 of partition 7483b008bac320fb0b462f7d262e6cda@c0bee93248ded4bbff5301f05863bb2d.
03/06/2020 13:13:15.286 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionManager] Requesting subpartition 0 of ReleaseOnConsumptionResultPartition 7483b008bac320fb0b462f7d262e6cda@c0bee93248ded4bbff5301f05863bb2d [PIPELINED, 1 subpartitions, 1 pending consumptions].
03/06/2020 13:13:15.297 DEBUG [org.apache.flink.runtime.io.network.partition.PipelinedSubpartition] CHAIN DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) -> Map (Map at getGraphCollection(HBaseDataSource.java:125)) -> Filter (Filter at getGraph(BaseGraphCollection.java:82)) (2/2) (c0bee93248ded4bbff5301f05863bb2d): Creating read view for subpartition 0 of partition 7483b008bac320fb0b462f7d262e6cda@c0bee93248ded4bbff5301f05863bb2d.
03/06/2020 13:13:15.297 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartition] Created PipelinedSubpartitionView(index: 0) of ResultPartition 7483b008bac320fb0b462f7d262e6cda@c0bee93248ded4bbff5301f05863bb2d
03/06/2020 13:13:15.298  INFO [org.apache.flink.runtime.taskmanager.Task] DataSink (collect()) (2/2) (4fbe480a642b1f257d8ce80dc5a1f989) switched from DEPLOYING to RUNNING.
03/06/2020 13:13:15.298 DEBUG [org.apache.flink.runtime.operators.DataSinkTask] Start registering input and output:  DataSink (collect()) (2/2)
03/06/2020 13:13:15.304 DEBUG [org.apache.flink.runtime.operators.DataSinkTask] Finished registering input and output:  DataSink (collect()) (2/2)
03/06/2020 13:13:15.304 DEBUG [org.apache.flink.runtime.operators.DataSinkTask] Starting data sink operator:  DataSink (collect()) (2/2)
03/06/2020 13:13:15.312 DEBUG [org.apache.flink.runtime.operators.DataSinkTask] Rich Sink detected. Initializing runtime context.:  DataSink (collect()) (2/2)
03/06/2020 13:13:15.312 DEBUG [org.apache.flink.runtime.operators.DataSinkTask] Starting to produce output:  DataSink (collect()) (2/2)
03/06/2020 13:13:15.316 DEBUG [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] Adding returned slot [25d6adf2da1523d007e7207a564168d1] to available slots
03/06/2020 13:13:15.319  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] DataSink (collect()) (2/2) (4fbe480a642b1f257d8ce80dc5a1f989) switched from DEPLOYING to RUNNING.
03/06/2020 13:13:15.672 DEBUG [org.apache.flink.runtime.operators.DataSourceTask] Closing input split Locatable Split (0) at [ubuntu:16201]:  CHAIN DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) -> Map (Map at getGraphCollection(HBaseDataSource.java:125)) -> Filter (Filter at getGraph(BaseGraphCollection.java:82)) (2/2)
03/06/2020 13:13:15.672  INFO [org.apache.flink.addons.hbase.AbstractTableInputFormat] Closing split (scanned 1822 rows)
03/06/2020 13:13:15.694 DEBUG [org.apache.flink.api.common.io.LocatableInputSplitAssigner] No more input splits remaining.
03/06/2020 13:13:15.697 DEBUG [org.apache.flink.runtime.jobmaster.JobMaster] Send next input split null.
03/06/2020 13:13:15.698 DEBUG [org.apache.flink.runtime.operators.BatchTask] Finished task code:  Map (Map at getGraphCollection(HBaseDataSource.java:125)) (2/2)
03/06/2020 13:13:15.698 DEBUG [org.apache.flink.runtime.operators.BatchTask] Finished task code:  Filter (Filter at getGraph(BaseGraphCollection.java:82)) (2/2)
03/06/2020 13:13:15.704 DEBUG [org.apache.flink.runtime.operators.DataSourceTask] Rich Source detected. Closing the InputFormat.:  CHAIN DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) -> Map (Map at getGraphCollection(HBaseDataSource.java:125)) -> Filter (Filter at getGraph(BaseGraphCollection.java:82)) (2/2)
03/06/2020 13:13:15.704 DEBUG [org.apache.flink.runtime.operators.DataSourceTask] Finished data source operator:  CHAIN DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) -> Map (Map at getGraphCollection(HBaseDataSource.java:125)) -> Filter (Filter at getGraph(BaseGraphCollection.java:82)) (2/2)
03/06/2020 13:13:15.704 DEBUG [org.apache.flink.runtime.io.network.partition.PipelinedSubpartition] CHAIN DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) -> Map (Map at getGraphCollection(HBaseDataSource.java:125)) -> Filter (Filter at getGraph(BaseGraphCollection.java:82)) (2/2) (c0bee93248ded4bbff5301f05863bb2d): Finished PipelinedSubpartition#0 [number of buffers: 13 (364633 bytes), number of buffers in backlog: 0, finished? true, read view? true].
03/06/2020 13:13:15.704  INFO [org.apache.flink.runtime.taskmanager.Task] CHAIN DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) -> Map (Map at getGraphCollection(HBaseDataSource.java:125)) -> Filter (Filter at getGraph(BaseGraphCollection.java:82)) (2/2) (c0bee93248ded4bbff5301f05863bb2d) switched from RUNNING to FINISHED.
03/06/2020 13:13:15.704  INFO [org.apache.flink.runtime.taskmanager.Task] Freeing task resources for CHAIN DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) -> Map (Map at getGraphCollection(HBaseDataSource.java:125)) -> Filter (Filter at getGraph(BaseGraphCollection.java:82)) (2/2) (c0bee93248ded4bbff5301f05863bb2d).
03/06/2020 13:13:15.704 DEBUG [org.apache.flink.runtime.taskmanager.Task] Release task CHAIN DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) -> Map (Map at getGraphCollection(HBaseDataSource.java:125)) -> Filter (Filter at getGraph(BaseGraphCollection.java:82)) (2/2) network resources (state: FINISHED).
03/06/2020 13:13:15.704 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartition] ReleaseOnConsumptionResultPartition 7483b008bac320fb0b462f7d262e6cda@c0bee93248ded4bbff5301f05863bb2d [PIPELINED, 1 subpartitions, 0 pending consumptions]: Received consumed notification for subpartition 0.
03/06/2020 13:13:15.705 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionManager] Received consume notification from ReleaseOnConsumptionResultPartition 7483b008bac320fb0b462f7d262e6cda@c0bee93248ded4bbff5301f05863bb2d [PIPELINED, 1 subpartitions, 0 pending consumptions].
03/06/2020 13:13:15.704 DEBUG [org.apache.flink.runtime.io.network.TaskEventDispatcher] unregistering 7483b008bac320fb0b462f7d262e6cda@c0bee93248ded4bbff5301f05863bb2d
03/06/2020 13:13:15.705 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartition] CHAIN DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) -> Map (Map at getGraphCollection(HBaseDataSource.java:125)) -> Filter (Filter at getGraph(BaseGraphCollection.java:82)) (2/2) (c0bee93248ded4bbff5301f05863bb2d): Releasing ReleaseOnConsumptionResultPartition 7483b008bac320fb0b462f7d262e6cda@c0bee93248ded4bbff5301f05863bb2d [PIPELINED, 1 subpartitions, 0 pending consumptions].
03/06/2020 13:13:15.706 DEBUG [org.apache.flink.runtime.io.network.partition.PipelinedSubpartition] CHAIN DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) -> Map (Map at getGraphCollection(HBaseDataSource.java:125)) -> Filter (Filter at getGraph(BaseGraphCollection.java:82)) (2/2) (c0bee93248ded4bbff5301f05863bb2d): Released PipelinedSubpartition#0 [number of buffers: 13 (364637 bytes), number of buffers in backlog: 0, finished? true, read view? false].
03/06/2020 13:13:15.706 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionManager] Released partition 7483b008bac320fb0b462f7d262e6cda produced by c0bee93248ded4bbff5301f05863bb2d.
03/06/2020 13:13:15.706 DEBUG [org.apache.flink.runtime.operators.DataSinkTask] Finished data sink operator:  DataSink (collect()) (2/2)
03/06/2020 13:13:15.706  INFO [org.apache.flink.runtime.taskmanager.Task] DataSink (collect()) (2/2) (4fbe480a642b1f257d8ce80dc5a1f989) switched from RUNNING to FINISHED.
03/06/2020 13:13:15.706  INFO [org.apache.flink.runtime.taskmanager.Task] Freeing task resources for DataSink (collect()) (2/2) (4fbe480a642b1f257d8ce80dc5a1f989).
03/06/2020 13:13:15.706 DEBUG [org.apache.flink.runtime.taskmanager.Task] Release task DataSink (collect()) (2/2) network resources (state: FINISHED).
03/06/2020 13:13:15.706 DEBUG [org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate] DataSink (collect()) (2/2) (4fbe480a642b1f257d8ce80dc5a1f989): Releasing org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate@3e609d56.
03/06/2020 13:13:15.709  INFO [org.apache.flink.runtime.taskmanager.Task] Ensuring all FileSystem streams are closed for task DataSink (collect()) (2/2) (4fbe480a642b1f257d8ce80dc5a1f989) [FINISHED]
03/06/2020 13:13:15.710  INFO [org.apache.flink.runtime.taskmanager.Task] Ensuring all FileSystem streams are closed for task CHAIN DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) -> Map (Map at getGraphCollection(HBaseDataSource.java:125)) -> Filter (Filter at getGraph(BaseGraphCollection.java:82)) (2/2) (c0bee93248ded4bbff5301f05863bb2d) [FINISHED]
03/06/2020 13:13:15.711  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutor] Un-registering task and sending final execution state FINISHED to JobManager for task DataSink (collect()) (2/2) 4fbe480a642b1f257d8ce80dc5a1f989.
03/06/2020 13:13:15.730  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] DataSink (collect()) (2/2) (4fbe480a642b1f257d8ce80dc5a1f989) switched from RUNNING to FINISHED.
03/06/2020 13:13:15.731 DEBUG [org.apache.flink.runtime.executiongraph.ExecutionGraph] Ignoring transition of vertex DataSink (collect()) (2/2) - execution #0 to FAILED while being FINISHED.
03/06/2020 13:13:15.731  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutor] Un-registering task and sending final execution state FINISHED to JobManager for task CHAIN DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) -> Map (Map at getGraphCollection(HBaseDataSource.java:125)) -> Filter (Filter at getGraph(BaseGraphCollection.java:82)) (2/2) c0bee93248ded4bbff5301f05863bb2d.
03/06/2020 13:13:15.732  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] CHAIN DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) -> Map (Map at getGraphCollection(HBaseDataSource.java:125)) -> Filter (Filter at getGraph(BaseGraphCollection.java:82)) (2/2) (c0bee93248ded4bbff5301f05863bb2d) switched from RUNNING to FINISHED.
03/06/2020 13:13:15.732 DEBUG [org.apache.flink.runtime.executiongraph.ExecutionGraph] Ignoring transition of vertex CHAIN DataSource (at getGraphCollection(HBaseDataSource.java:121) (org.gradoop.storage.hbase.impl.io.inputformats.VertexTableInputFormat)) -> Map (Map at getGraphCollection(HBaseDataSource.java:125)) -> Filter (Filter at getGraph(BaseGraphCollection.java:82)) (2/2) - execution #0 to FAILED while being FINISHED.
03/06/2020 13:13:15.732 DEBUG [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] Releasing slot [SlotRequestId{2d34d8eae62035d32d8295684ad0410a}] because: Release multi task slot because all children have been released.
03/06/2020 13:13:15.732 DEBUG [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] Adding returned slot [7e6c6acb9ede8f5a9ae4c73175ba2ff1] to available slots
03/06/2020 13:13:15.737  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] Job Flink Java Job at Wed Jun 03 13:13:07 CEST 2020 (27a49aaf7533a153067b6fcce6e8f170) switched from state RUNNING to FINISHED.
03/06/2020 13:13:15.811  INFO [org.apache.flink.runtime.minicluster.MiniCluster] Shutting down Flink Mini Cluster
03/06/2020 13:13:15.811  INFO [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Shutting down rest endpoint.
03/06/2020 13:13:15.967  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutor] Stopping TaskExecutor akka://flink/user/taskmanager_0.
03/06/2020 13:13:15.972 DEBUG [org.apache.flink.runtime.taskexecutor.TaskExecutor] Close ResourceManager connection c5f30994e2a46ce95025a9f3520d6b83.
org.apache.flink.util.FlinkException: The TaskExecutor is shutting down.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.onStop(TaskExecutor.java:359)
	at org.apache.flink.runtime.rpc.RpcEndpoint.internalCallOnStop(RpcEndpoint.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor$StartedState.terminate(AkkaRpcActor.java:509)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleControlMessage(AkkaRpcActor.java:175)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction$class.applyOrElse(PartialFunction.scala:123)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at akka.actor.Actor$class.aroundReceive(Actor.scala:517)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
03/06/2020 13:13:15.993 DEBUG [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl] Free slot TaskSlot(index:0, state:ACTIVE, resource profile: ResourceProfile{managedMemory=64,000mb (67108864 bytes), networkMemory=32,000mb (33554432 bytes)}, allocationId: 25d6adf2da1523d007e7207a564168d1, jobId: 27a49aaf7533a153067b6fcce6e8f170).
org.apache.flink.util.FlinkException: Closing task slot table
	at org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.closeAsync(TaskSlotTableImpl.java:160)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.onStop(TaskExecutor.java:375)
	at org.apache.flink.runtime.rpc.RpcEndpoint.internalCallOnStop(RpcEndpoint.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor$StartedState.terminate(AkkaRpcActor.java:509)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleControlMessage(AkkaRpcActor.java:175)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction$class.applyOrElse(PartialFunction.scala:123)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at akka.actor.Actor$class.aroundReceive(Actor.scala:517)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
03/06/2020 13:13:16.002 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the org.apache.flink.api.java.typeutils.runtime.TupleSerializer
03/06/2020 13:13:16.008 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the [B
03/06/2020 13:13:16.009 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the java.lang.Integer
03/06/2020 13:13:16.009 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the java.lang.Integer
03/06/2020 13:13:16.019 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the java.lang.Integer
03/06/2020 13:13:16.020 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the java.lang.Boolean
03/06/2020 13:13:16.020 DEBUG [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl] Free slot TaskSlot(index:1, state:ACTIVE, resource profile: ResourceProfile{managedMemory=64,000mb (67108864 bytes), networkMemory=32,000mb (33554432 bytes)}, allocationId: 7e6c6acb9ede8f5a9ae4c73175ba2ff1, jobId: 27a49aaf7533a153067b6fcce6e8f170).
org.apache.flink.util.FlinkException: Closing task slot table
	at org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.closeAsync(TaskSlotTableImpl.java:160)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.onStop(TaskExecutor.java:375)
	at org.apache.flink.runtime.rpc.RpcEndpoint.internalCallOnStop(RpcEndpoint.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor$StartedState.terminate(AkkaRpcActor.java:509)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleControlMessage(AkkaRpcActor.java:175)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction$class.applyOrElse(PartialFunction.scala:123)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at akka.actor.Actor$class.aroundReceive(Actor.scala:517)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
03/06/2020 13:13:16.051  INFO [org.apache.flink.table.module.ModuleManager] Got FunctionDefinition as from module core
03/06/2020 13:13:16.060  INFO [org.apache.flink.table.module.ModuleManager] Got FunctionDefinition as from module core
03/06/2020 13:13:16.060  INFO [org.apache.flink.table.module.ModuleManager] Got FunctionDefinition as from module core
03/06/2020 13:13:16.061  INFO [org.apache.flink.table.module.ModuleManager] Got FunctionDefinition as from module core
03/06/2020 13:13:16.061  INFO [org.apache.flink.runtime.taskexecutor.JobLeaderService] Stop job leader service.
03/06/2020 13:13:16.061  INFO [org.apache.flink.table.module.ModuleManager] Got FunctionDefinition as from module core
03/06/2020 13:13:16.062  INFO [org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager] Shutting down TaskExecutorLocalStateStoresManager.
03/06/2020 13:13:16.052  INFO [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Removing cache directory /tmp/flink-web-ui
03/06/2020 13:13:16.115  INFO [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Shut down complete.
03/06/2020 13:13:16.119  INFO [org.apache.flink.table.module.ModuleManager] Got FunctionDefinition equals from module core
03/06/2020 13:13:16.198 DEBUG [org.apache.flink.runtime.io.disk.iomanager.IOManager] Shutting down I/O manager.
03/06/2020 13:13:16.224  INFO [org.apache.flink.runtime.io.disk.FileChannelManagerImpl] FileChannelManager removed spill file directory /tmp/flink-io-da99f944-7252-436a-9d83-e42d8385a726
03/06/2020 13:13:16.224  INFO [org.apache.flink.runtime.io.network.NettyShuffleEnvironment] Shutting down the network environment and its components.
03/06/2020 13:13:16.224 DEBUG [org.apache.flink.runtime.io.network.NettyShuffleEnvironment] Shutting down network connection manager
03/06/2020 13:13:16.224 DEBUG [org.apache.flink.runtime.io.network.NettyShuffleEnvironment] Shutting down intermediate result partition manager
03/06/2020 13:13:16.224 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionManager] Releasing 0 partitions because of shutdown.
03/06/2020 13:13:16.224 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionManager] Successful shutdown.
03/06/2020 13:13:16.236  INFO [org.apache.flink.runtime.io.disk.FileChannelManagerImpl] FileChannelManager removed spill file directory /tmp/flink-netty-shuffle-bcd7517c-3d0e-4036-9a10-fb94db71e494
03/06/2020 13:13:16.237  INFO [org.apache.flink.runtime.taskexecutor.KvStateService] Shutting down the kvState service and its components.
03/06/2020 13:13:16.237  INFO [org.apache.flink.runtime.taskexecutor.JobLeaderService] Stop job leader service.
03/06/2020 13:13:16.242  INFO [org.apache.flink.runtime.filecache.FileCache] removed file cache directory /tmp/flink-dist-cache-11a3ee57-b067-4783-8d4a-c653797ca52b
03/06/2020 13:13:16.250  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutor] Stopped TaskExecutor akka://flink/user/taskmanager_0.
03/06/2020 13:13:16.310  INFO [org.apache.flink.runtime.dispatcher.StandaloneDispatcher] Job 27a49aaf7533a153067b6fcce6e8f170 reached globally terminal state FINISHED.
03/06/2020 13:13:16.321  INFO [org.apache.flink.runtime.resourcemanager.StandaloneResourceManager] Closing TaskExecutor connection 860855ef-8204-47f1-97b9-688ca96b77ac because: The TaskExecutor is shutting down.
03/06/2020 13:13:16.324 DEBUG [org.apache.flink.runtime.resourcemanager.slotmanager.SlotManagerImpl] Unregister TaskManager e4211fd15853f4a2b71a32cc83830ff7 from the SlotManager.
03/06/2020 13:13:16.339  INFO [org.apache.flink.runtime.resourcemanager.StandaloneResourceManager] Shut down cluster because application is in CANCELED, diagnostics DispatcherResourceManagerComponent has been closed..
03/06/2020 13:13:16.347 DEBUG [org.apache.flink.runtime.jobmaster.JobMaster] Disconnect TaskExecutor 860855ef-8204-47f1-97b9-688ca96b77ac because: The TaskExecutor is shutting down.
03/06/2020 13:13:16.354  INFO [org.apache.flink.runtime.jobmaster.JobMaster] Stopping the JobMaster for job Flink Java Job at Wed Jun 03 13:13:07 CEST 2020(27a49aaf7533a153067b6fcce6e8f170).
03/06/2020 13:13:16.362  INFO [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] Suspending SlotPool.
03/06/2020 13:13:16.363 DEBUG [org.apache.flink.runtime.jobmaster.JobMaster] Close ResourceManager connection c5f30994e2a46ce95025a9f3520d6b83.
org.apache.flink.util.FlinkException: JobManager is shutting down.
	at org.apache.flink.runtime.jobmaster.JobMaster.onStop(JobMaster.java:350)
	at org.apache.flink.runtime.rpc.RpcEndpoint.internalCallOnStop(RpcEndpoint.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor$StartedState.terminate(AkkaRpcActor.java:509)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleControlMessage(AkkaRpcActor.java:175)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction$class.applyOrElse(PartialFunction.scala:123)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at akka.actor.Actor$class.aroundReceive(Actor.scala:517)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
03/06/2020 13:13:16.363  INFO [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] Stopping SlotPool.
03/06/2020 13:13:16.364 DEBUG [org.apache.flink.runtime.resourcemanager.JobLeaderIdService] Found a new job leader null@null.
03/06/2020 13:13:16.418  INFO [org.apache.flink.runtime.entrypoint.component.DispatcherResourceManagerComponent] Closing components.
03/06/2020 13:13:16.431  INFO [org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess] Stopping SessionDispatcherLeaderProcess.
03/06/2020 13:13:16.464  INFO [org.apache.flink.runtime.resourcemanager.StandaloneResourceManager] Disconnect job manager a23494c3a73eb1ac29d2309e1fa2474c@akka://flink/user/jobmanager_1 for job 27a49aaf7533a153067b6fcce6e8f170 from the resource manager.
03/06/2020 13:13:16.465 DEBUG [org.apache.flink.runtime.resourcemanager.StandaloneResourceManager] Discard job leader lost leadership for outdated leader a23494c3a73eb1ac29d2309e1fa2474c for job 27a49aaf7533a153067b6fcce6e8f170.
03/06/2020 13:13:16.465  INFO [org.apache.flink.runtime.resourcemanager.slotmanager.SlotManagerImpl] Closing the SlotManager.
03/06/2020 13:13:16.465  INFO [org.apache.flink.runtime.resourcemanager.slotmanager.SlotManagerImpl] Suspending the SlotManager.
03/06/2020 13:13:16.474  INFO [org.apache.flink.runtime.dispatcher.StandaloneDispatcher] Stopping dispatcher akka://flink/user/dispatcher.
03/06/2020 13:13:16.474  INFO [org.apache.flink.runtime.dispatcher.StandaloneDispatcher] Stopping all currently running jobs of dispatcher akka://flink/user/dispatcher.
03/06/2020 13:13:16.475  INFO [org.apache.flink.runtime.rest.handler.legacy.backpressure.BackPressureRequestCoordinator] Shutting down back pressure request coordinator.
03/06/2020 13:13:16.475  INFO [org.apache.flink.runtime.dispatcher.StandaloneDispatcher] Stopped dispatcher akka://flink/user/dispatcher.
03/06/2020 13:13:16.485  INFO [org.apache.flink.runtime.rpc.akka.AkkaRpcService] Stopping Akka RPC service.
03/06/2020 13:13:16.540  INFO [akka.remote.RemoteActorRefProvider$RemotingTerminator] Shutting down remote daemon.
03/06/2020 13:13:16.574  INFO [akka.remote.RemoteActorRefProvider$RemotingTerminator] Remote daemon shut down; proceeding with flushing remote transports.
03/06/2020 13:13:16.721 DEBUG [org.apache.flink.table.planner.plan.optimize.program.FlinkGroupProgram] iteration: 1
03/06/2020 13:13:16.755 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#334: Apply rule [TableScanRule] to [rel#231:LogicalTableScan.NONE.any.None: 0.false.UNKNOWN(table=[Unregistered_DataStream_8])]
03/06/2020 13:13:16.759 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#334: Rule TableScanRule arguments [rel#231:LogicalTableScan.NONE.any.None: 0.false.UNKNOWN(table=[Unregistered_DataStream_8])] produced LogicalTableScan#264
03/06/2020 13:13:16.760 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#335: Apply rule [TableScanRule] to [rel#238:LogicalTableScan.NONE.any.None: 0.false.UNKNOWN(table=[Unregistered_DataStream_9])]
03/06/2020 13:13:16.761 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#335: Rule TableScanRule arguments [rel#238:LogicalTableScan.NONE.any.None: 0.false.UNKNOWN(table=[Unregistered_DataStream_9])] produced LogicalTableScan#265
03/06/2020 13:13:16.761 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#262:LogicalSink.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#261,name=DataStreamTableSink,fields=v_label, X, Y, v_id_layout, degree, v_id)
03/06/2020 13:13:16.763 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#260:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#259,v_label=$4,X=$6,Y=$7,v_id_layout=$5,degree=$1,v_id=$0)
03/06/2020 13:13:16.763 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#258:LogicalFilter.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#257,condition==($0, $3))
03/06/2020 13:13:16.763 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#256:LogicalJoin.NONE.any.None: 0.false.UNKNOWN(left=HepRelVertex#252,right=HepRelVertex#255,condition=true,joinType=inner)
03/06/2020 13:13:16.763 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#251:LogicalFilter.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#250,condition==($2, _UTF-16LE'true'))
03/06/2020 13:13:16.764 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#249:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#248,v_id=AS($0, _UTF-16LE'v_id'),degree=AS($1.f1, _UTF-16LE'degree'),bool=AS($1.f0, _UTF-16LE'bool'))
03/06/2020 13:13:16.765 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#247:LogicalAggregate.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#246,group={1},TMP_0=CurrentVertex($0, $1, $2))
03/06/2020 13:13:16.765 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#245:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#244,bool=AS($0, _UTF-16LE'bool'),v_id=AS($1, _UTF-16LE'v_id'),degree=AS($2, _UTF-16LE'degree'))
03/06/2020 13:13:16.765 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#231:LogicalTableScan.NONE.any.None: 0.false.UNKNOWN(table=[Unregistered_DataStream_8])
03/06/2020 13:13:16.765 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#254:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#253,v_id_2=AS($0, _UTF-16LE'v_id_2'),v_label=AS($1, _UTF-16LE'v_label'),v_id_layout=AS($2, _UTF-16LE'v_id_layout'),X=AS($3, _UTF-16LE'X'),Y=AS($4, _UTF-16LE'Y'))
03/06/2020 13:13:16.766 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#238:LogicalTableScan.NONE.any.None: 0.false.UNKNOWN(table=[Unregistered_DataStream_9])
03/06/2020 13:13:16.777 DEBUG [org.apache.flink.table.planner.plan.optimize.program.FlinkGroupProgram] optimize convert table references before rewriting sub-queries to semi-join cost 35 ms.
optimize result:
 LogicalSink(name=[DataStreamTableSink], fields=[v_label, X, Y, v_id_layout, degree, v_id])
+- LogicalProject(v_label=[$4], X=[$6], Y=[$7], v_id_layout=[$5], degree=[$1], v_id=[$0])
   +- LogicalFilter(condition=[=($0, $3)])
      +- LogicalJoin(condition=[true], joinType=[inner])
         :- LogicalFilter(condition=[=($2, _UTF-16LE'true')])
         :  +- LogicalProject(v_id=[AS($0, _UTF-16LE'v_id')], degree=[AS($1.f1, _UTF-16LE'degree')], bool=[AS($1.f0, _UTF-16LE'bool')])
         :     +- LogicalAggregate(group=[{1}], TMP_0=[CurrentVertex($0, $1, $2)])
         :        +- LogicalProject(bool=[AS($0, _UTF-16LE'bool')], v_id=[AS($1, _UTF-16LE'v_id')], degree=[AS($2, _UTF-16LE'degree')])
         :           +- LogicalTableScan(table=[[Unregistered_DataStream_8]])
         +- LogicalProject(v_id_2=[AS($0, _UTF-16LE'v_id_2')], v_label=[AS($1, _UTF-16LE'v_label')], v_id_layout=[AS($2, _UTF-16LE'v_id_layout')], X=[AS($3, _UTF-16LE'X')], Y=[AS($4, _UTF-16LE'Y')])
            +- LogicalTableScan(table=[[Unregistered_DataStream_9]])

03/06/2020 13:13:16.779 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#336: Apply rule [SimplifyFilterConditionRule:simplifySubQuery] to [rel#273:LogicalFilter.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#272,condition==($2, _UTF-16LE'true'))]
03/06/2020 13:13:16.810  INFO [akka.remote.RemoteActorRefProvider$RemotingTerminator] Remoting shut down.
03/06/2020 13:13:16.827 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#337: Apply rule [SimplifyFilterConditionRule:simplifySubQuery] to [rel#280:LogicalFilter.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#279,condition==($0, $3))]
03/06/2020 13:13:16.829 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#339: Apply rule [FlinkJoinPushExpressionsRule] to [rel#278:LogicalJoin.NONE.any.None: 0.false.UNKNOWN(left=HepRelVertex#274,right=HepRelVertex#277,condition=true,joinType=inner)]
03/06/2020 13:13:16.833 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#284:LogicalSink.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#283,name=DataStreamTableSink,fields=v_label, X, Y, v_id_layout, degree, v_id)
03/06/2020 13:13:16.833 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#282:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#281,v_label=$4,X=$6,Y=$7,v_id_layout=$5,degree=$1,v_id=$0)
03/06/2020 13:13:16.833 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#280:LogicalFilter.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#279,condition==($0, $3))
03/06/2020 13:13:16.833 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#278:LogicalJoin.NONE.any.None: 0.false.UNKNOWN(left=HepRelVertex#274,right=HepRelVertex#277,condition=true,joinType=inner)
03/06/2020 13:13:16.834 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#273:LogicalFilter.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#272,condition==($2, _UTF-16LE'true'))
03/06/2020 13:13:16.834 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#271:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#270,v_id=AS($0, _UTF-16LE'v_id'),degree=AS($1.f1, _UTF-16LE'degree'),bool=AS($1.f0, _UTF-16LE'bool'))
03/06/2020 13:13:16.834 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#269:LogicalAggregate.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#268,group={1},TMP_0=CurrentVertex($0, $1, $2))
03/06/2020 13:13:16.834 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#267:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#266,bool=AS($0, _UTF-16LE'bool'),v_id=AS($1, _UTF-16LE'v_id'),degree=AS($2, _UTF-16LE'degree'))
03/06/2020 13:13:16.834 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#231:LogicalTableScan.NONE.any.None: 0.false.UNKNOWN(table=[Unregistered_DataStream_8])
03/06/2020 13:13:16.834 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#276:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#275,v_id_2=AS($0, _UTF-16LE'v_id_2'),v_label=AS($1, _UTF-16LE'v_label'),v_id_layout=AS($2, _UTF-16LE'v_id_layout'),X=AS($3, _UTF-16LE'X'),Y=AS($4, _UTF-16LE'Y'))
03/06/2020 13:13:16.834 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#238:LogicalTableScan.NONE.any.None: 0.false.UNKNOWN(table=[Unregistered_DataStream_9])
03/06/2020 13:13:16.835 DEBUG [org.apache.flink.table.planner.plan.optimize.program.FlinkGroupProgram] optimize rewrite sub-queries to semi-join cost 58 ms.
optimize result:
 LogicalSink(name=[DataStreamTableSink], fields=[v_label, X, Y, v_id_layout, degree, v_id])
+- LogicalProject(v_label=[$4], X=[$6], Y=[$7], v_id_layout=[$5], degree=[$1], v_id=[$0])
   +- LogicalFilter(condition=[=($0, $3)])
      +- LogicalJoin(condition=[true], joinType=[inner])
         :- LogicalFilter(condition=[=($2, _UTF-16LE'true')])
         :  +- LogicalProject(v_id=[AS($0, _UTF-16LE'v_id')], degree=[AS($1.f1, _UTF-16LE'degree')], bool=[AS($1.f0, _UTF-16LE'bool')])
         :     +- LogicalAggregate(group=[{1}], TMP_0=[CurrentVertex($0, $1, $2)])
         :        +- LogicalProject(bool=[AS($0, _UTF-16LE'bool')], v_id=[AS($1, _UTF-16LE'v_id')], degree=[AS($2, _UTF-16LE'degree')])
         :           +- LogicalTableScan(table=[[Unregistered_DataStream_8]])
         +- LogicalProject(v_id_2=[AS($0, _UTF-16LE'v_id_2')], v_label=[AS($1, _UTF-16LE'v_label')], v_id_layout=[AS($2, _UTF-16LE'v_id_layout')], X=[AS($3, _UTF-16LE'X')], Y=[AS($4, _UTF-16LE'Y')])
            +- LogicalTableScan(table=[[Unregistered_DataStream_9]])

03/06/2020 13:13:16.839 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#305:LogicalSink.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#304,name=DataStreamTableSink,fields=v_label, X, Y, v_id_layout, degree, v_id)
03/06/2020 13:13:16.840 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#303:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#302,v_label=$4,X=$6,Y=$7,v_id_layout=$5,degree=$1,v_id=$0)
03/06/2020 13:13:16.840 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#301:LogicalFilter.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#300,condition==($0, $3))
03/06/2020 13:13:16.840 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#299:LogicalJoin.NONE.any.None: 0.false.UNKNOWN(left=HepRelVertex#295,right=HepRelVertex#298,condition=true,joinType=inner)
03/06/2020 13:13:16.840 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#294:LogicalFilter.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#293,condition==($2, _UTF-16LE'true'))
03/06/2020 13:13:16.843 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#292:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#291,v_id=AS($0, _UTF-16LE'v_id'),degree=AS($1.f1, _UTF-16LE'degree'),bool=AS($1.f0, _UTF-16LE'bool'))
03/06/2020 13:13:16.843 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#290:LogicalAggregate.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#289,group={1},TMP_0=CurrentVertex($0, $1, $2))
03/06/2020 13:13:16.844 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#288:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#287,bool=AS($0, _UTF-16LE'bool'),v_id=AS($1, _UTF-16LE'v_id'),degree=AS($2, _UTF-16LE'degree'))
03/06/2020 13:13:16.844 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#231:LogicalTableScan.NONE.any.None: 0.false.UNKNOWN(table=[Unregistered_DataStream_8])
03/06/2020 13:13:16.844 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#297:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#296,v_id_2=AS($0, _UTF-16LE'v_id_2'),v_label=AS($1, _UTF-16LE'v_label'),v_id_layout=AS($2, _UTF-16LE'v_id_layout'),X=AS($3, _UTF-16LE'X'),Y=AS($4, _UTF-16LE'Y'))
03/06/2020 13:13:16.844 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#238:LogicalTableScan.NONE.any.None: 0.false.UNKNOWN(table=[Unregistered_DataStream_9])
03/06/2020 13:13:16.845 DEBUG [org.apache.flink.table.planner.plan.optimize.program.FlinkGroupProgram] optimize sub-queries remove cost 8 ms.
optimize result:
 LogicalSink(name=[DataStreamTableSink], fields=[v_label, X, Y, v_id_layout, degree, v_id])
+- LogicalProject(v_label=[$4], X=[$6], Y=[$7], v_id_layout=[$5], degree=[$1], v_id=[$0])
   +- LogicalFilter(condition=[=($0, $3)])
      +- LogicalJoin(condition=[true], joinType=[inner])
         :- LogicalFilter(condition=[=($2, _UTF-16LE'true')])
         :  +- LogicalProject(v_id=[AS($0, _UTF-16LE'v_id')], degree=[AS($1.f1, _UTF-16LE'degree')], bool=[AS($1.f0, _UTF-16LE'bool')])
         :     +- LogicalAggregate(group=[{1}], TMP_0=[CurrentVertex($0, $1, $2)])
         :        +- LogicalProject(bool=[AS($0, _UTF-16LE'bool')], v_id=[AS($1, _UTF-16LE'v_id')], degree=[AS($2, _UTF-16LE'degree')])
         :           +- LogicalTableScan(table=[[Unregistered_DataStream_8]])
         +- LogicalProject(v_id_2=[AS($0, _UTF-16LE'v_id_2')], v_label=[AS($1, _UTF-16LE'v_label')], v_id_layout=[AS($2, _UTF-16LE'v_id_layout')], X=[AS($3, _UTF-16LE'X')], Y=[AS($4, _UTF-16LE'Y')])
            +- LogicalTableScan(table=[[Unregistered_DataStream_9]])

03/06/2020 13:13:16.848 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#340: Apply rule [TableScanRule] to [rel#231:LogicalTableScan.NONE.any.None: 0.false.UNKNOWN(table=[Unregistered_DataStream_8])]
03/06/2020 13:13:16.849 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#340: Rule TableScanRule arguments [rel#231:LogicalTableScan.NONE.any.None: 0.false.UNKNOWN(table=[Unregistered_DataStream_8])] produced LogicalTableScan#327
03/06/2020 13:13:16.849 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#341: Apply rule [TableScanRule] to [rel#238:LogicalTableScan.NONE.any.None: 0.false.UNKNOWN(table=[Unregistered_DataStream_9])]
03/06/2020 13:13:16.849 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#341: Rule TableScanRule arguments [rel#238:LogicalTableScan.NONE.any.None: 0.false.UNKNOWN(table=[Unregistered_DataStream_9])] produced LogicalTableScan#328
03/06/2020 13:13:16.849 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#325:LogicalSink.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#324,name=DataStreamTableSink,fields=v_label, X, Y, v_id_layout, degree, v_id)
03/06/2020 13:13:16.850 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#323:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#322,v_label=$4,X=$6,Y=$7,v_id_layout=$5,degree=$1,v_id=$0)
03/06/2020 13:13:16.850 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#321:LogicalFilter.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#320,condition==($0, $3))
03/06/2020 13:13:16.850 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#319:LogicalJoin.NONE.any.None: 0.false.UNKNOWN(left=HepRelVertex#315,right=HepRelVertex#318,condition=true,joinType=inner)
03/06/2020 13:13:16.851 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#314:LogicalFilter.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#313,condition==($2, _UTF-16LE'true'))
03/06/2020 13:13:16.851 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#312:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#311,v_id=AS($0, _UTF-16LE'v_id'),degree=AS($1.f1, _UTF-16LE'degree'),bool=AS($1.f0, _UTF-16LE'bool'))
03/06/2020 13:13:16.851 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#310:LogicalAggregate.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#309,group={1},TMP_0=CurrentVertex($0, $1, $2))
03/06/2020 13:13:16.851 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#308:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#307,bool=AS($0, _UTF-16LE'bool'),v_id=AS($1, _UTF-16LE'v_id'),degree=AS($2, _UTF-16LE'degree'))
03/06/2020 13:13:16.851 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#231:LogicalTableScan.NONE.any.None: 0.false.UNKNOWN(table=[Unregistered_DataStream_8])
03/06/2020 13:13:16.851 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#317:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#316,v_id_2=AS($0, _UTF-16LE'v_id_2'),v_label=AS($1, _UTF-16LE'v_label'),v_id_layout=AS($2, _UTF-16LE'v_id_layout'),X=AS($3, _UTF-16LE'X'),Y=AS($4, _UTF-16LE'Y'))
03/06/2020 13:13:16.851 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#238:LogicalTableScan.NONE.any.None: 0.false.UNKNOWN(table=[Unregistered_DataStream_9])
03/06/2020 13:13:16.884 DEBUG [org.apache.flink.table.planner.plan.optimize.program.FlinkGroupProgram] optimize convert table references after sub-queries removed cost 6 ms.
optimize result:
 LogicalSink(name=[DataStreamTableSink], fields=[v_label, X, Y, v_id_layout, degree, v_id])
+- LogicalProject(v_label=[$4], X=[$6], Y=[$7], v_id_layout=[$5], degree=[$1], v_id=[$0])
   +- LogicalFilter(condition=[=($0, $3)])
      +- LogicalJoin(condition=[true], joinType=[inner])
         :- LogicalFilter(condition=[=($2, _UTF-16LE'true')])
         :  +- LogicalProject(v_id=[AS($0, _UTF-16LE'v_id')], degree=[AS($1.f1, _UTF-16LE'degree')], bool=[AS($1.f0, _UTF-16LE'bool')])
         :     +- LogicalAggregate(group=[{1}], TMP_0=[CurrentVertex($0, $1, $2)])
         :        +- LogicalProject(bool=[AS($0, _UTF-16LE'bool')], v_id=[AS($1, _UTF-16LE'v_id')], degree=[AS($2, _UTF-16LE'degree')])
         :           +- LogicalTableScan(table=[[Unregistered_DataStream_8]])
         +- LogicalProject(v_id_2=[AS($0, _UTF-16LE'v_id_2')], v_label=[AS($1, _UTF-16LE'v_label')], v_id_layout=[AS($2, _UTF-16LE'v_id_layout')], X=[AS($3, _UTF-16LE'X')], Y=[AS($4, _UTF-16LE'Y')])
            +- LogicalTableScan(table=[[Unregistered_DataStream_9]])

03/06/2020 13:13:16.896 DEBUG [org.apache.flink.table.planner.plan.optimize.program.FlinkChainedProgram] optimize subquery_rewrite cost 170 ms.
optimize result: 
LogicalSink(name=[DataStreamTableSink], fields=[v_label, X, Y, v_id_layout, degree, v_id])
+- LogicalProject(v_label=[$4], X=[$6], Y=[$7], v_id_layout=[$5], degree=[$1], v_id=[$0])
   +- LogicalFilter(condition=[=($0, $3)])
      +- LogicalJoin(condition=[true], joinType=[inner])
         :- LogicalFilter(condition=[=($2, _UTF-16LE'true')])
         :  +- LogicalProject(v_id=[AS($0, _UTF-16LE'v_id')], degree=[AS($1.f1, _UTF-16LE'degree')], bool=[AS($1.f0, _UTF-16LE'bool')])
         :     +- LogicalAggregate(group=[{1}], TMP_0=[CurrentVertex($0, $1, $2)])
         :        +- LogicalProject(bool=[AS($0, _UTF-16LE'bool')], v_id=[AS($1, _UTF-16LE'v_id')], degree=[AS($2, _UTF-16LE'degree')])
         :           +- LogicalTableScan(table=[[Unregistered_DataStream_8]])
         +- LogicalProject(v_id_2=[AS($0, _UTF-16LE'v_id_2')], v_label=[AS($1, _UTF-16LE'v_label')], v_id_layout=[AS($2, _UTF-16LE'v_id_layout')], X=[AS($3, _UTF-16LE'X')], Y=[AS($4, _UTF-16LE'Y')])
            +- LogicalTableScan(table=[[Unregistered_DataStream_9]])

03/06/2020 13:13:16.909 DEBUG [org.apache.flink.table.planner.plan.optimize.program.FlinkGroupProgram] iteration: 1
03/06/2020 13:13:16.925 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#342: Apply rule [TableScanRule] to [rel#231:LogicalTableScan.NONE.any.None: 0.false.UNKNOWN(table=[Unregistered_DataStream_8])]
03/06/2020 13:13:16.926 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#342: Rule TableScanRule arguments [rel#231:LogicalTableScan.NONE.any.None: 0.false.UNKNOWN(table=[Unregistered_DataStream_8])] produced LogicalTableScan#349
03/06/2020 13:13:16.927 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#343: Apply rule [TableScanRule] to [rel#238:LogicalTableScan.NONE.any.None: 0.false.UNKNOWN(table=[Unregistered_DataStream_9])]
03/06/2020 13:13:16.927 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#343: Rule TableScanRule arguments [rel#238:LogicalTableScan.NONE.any.None: 0.false.UNKNOWN(table=[Unregistered_DataStream_9])] produced LogicalTableScan#350
03/06/2020 13:13:16.927 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#347:LogicalSink.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#346,name=DataStreamTableSink,fields=v_label, X, Y, v_id_layout, degree, v_id)
03/06/2020 13:13:16.935 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#345:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#344,v_label=$4,X=$6,Y=$7,v_id_layout=$5,degree=$1,v_id=$0)
03/06/2020 13:13:16.935 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#343:LogicalFilter.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#342,condition==($0, $3))
03/06/2020 13:13:16.935 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#341:LogicalJoin.NONE.any.None: 0.false.UNKNOWN(left=HepRelVertex#337,right=HepRelVertex#340,condition=true,joinType=inner)
03/06/2020 13:13:16.935 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#336:LogicalFilter.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#335,condition==($2, _UTF-16LE'true'))
03/06/2020 13:13:16.935 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#334:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#333,v_id=AS($0, _UTF-16LE'v_id'),degree=AS($1.f1, _UTF-16LE'degree'),bool=AS($1.f0, _UTF-16LE'bool'))
03/06/2020 13:13:16.941 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#332:LogicalAggregate.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#331,group={1},TMP_0=CurrentVertex($0, $1, $2))
03/06/2020 13:13:16.941 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#330:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#329,bool=AS($0, _UTF-16LE'bool'),v_id=AS($1, _UTF-16LE'v_id'),degree=AS($2, _UTF-16LE'degree'))
03/06/2020 13:13:16.941 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#231:LogicalTableScan.NONE.any.None: 0.false.UNKNOWN(table=[Unregistered_DataStream_8])
03/06/2020 13:13:16.942 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#339:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#338,v_id_2=AS($0, _UTF-16LE'v_id_2'),v_label=AS($1, _UTF-16LE'v_label'),v_id_layout=AS($2, _UTF-16LE'v_id_layout'),X=AS($3, _UTF-16LE'X'),Y=AS($4, _UTF-16LE'Y'))
03/06/2020 13:13:16.942 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#238:LogicalTableScan.NONE.any.None: 0.false.UNKNOWN(table=[Unregistered_DataStream_9])
03/06/2020 13:13:16.943 DEBUG [org.apache.flink.table.planner.plan.optimize.program.FlinkGroupProgram] optimize convert correlate to temporal table join cost 33 ms.
optimize result:
 LogicalSink(name=[DataStreamTableSink], fields=[v_label, X, Y, v_id_layout, degree, v_id])
+- LogicalProject(v_label=[$4], X=[$6], Y=[$7], v_id_layout=[$5], degree=[$1], v_id=[$0])
   +- LogicalFilter(condition=[=($0, $3)])
      +- LogicalJoin(condition=[true], joinType=[inner])
         :- LogicalFilter(condition=[=($2, _UTF-16LE'true')])
         :  +- LogicalProject(v_id=[AS($0, _UTF-16LE'v_id')], degree=[AS($1.f1, _UTF-16LE'degree')], bool=[AS($1.f0, _UTF-16LE'bool')])
         :     +- LogicalAggregate(group=[{1}], TMP_0=[CurrentVertex($0, $1, $2)])
         :        +- LogicalProject(bool=[AS($0, _UTF-16LE'bool')], v_id=[AS($1, _UTF-16LE'v_id')], degree=[AS($2, _UTF-16LE'degree')])
         :           +- LogicalTableScan(table=[[Unregistered_DataStream_8]])
         +- LogicalProject(v_id_2=[AS($0, _UTF-16LE'v_id_2')], v_label=[AS($1, _UTF-16LE'v_label')], v_id_layout=[AS($2, _UTF-16LE'v_id_layout')], X=[AS($3, _UTF-16LE'X')], Y=[AS($4, _UTF-16LE'Y')])
            +- LogicalTableScan(table=[[Unregistered_DataStream_9]])

03/06/2020 13:13:16.948 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#369:LogicalSink.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#368,name=DataStreamTableSink,fields=v_label, X, Y, v_id_layout, degree, v_id)
03/06/2020 13:13:16.957 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#367:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#366,v_label=$4,X=$6,Y=$7,v_id_layout=$5,degree=$1,v_id=$0)
03/06/2020 13:13:16.971 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#365:LogicalFilter.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#364,condition==($0, $3))
03/06/2020 13:13:16.971 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#363:LogicalJoin.NONE.any.None: 0.false.UNKNOWN(left=HepRelVertex#359,right=HepRelVertex#362,condition=true,joinType=inner)
03/06/2020 13:13:16.971 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#358:LogicalFilter.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#357,condition==($2, _UTF-16LE'true'))
03/06/2020 13:13:16.981 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#356:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#355,v_id=AS($0, _UTF-16LE'v_id'),degree=AS($1.f1, _UTF-16LE'degree'),bool=AS($1.f0, _UTF-16LE'bool'))
03/06/2020 13:13:16.982 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#354:LogicalAggregate.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#353,group={1},TMP_0=CurrentVertex($0, $1, $2))
03/06/2020 13:13:16.982 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#352:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#351,bool=AS($0, _UTF-16LE'bool'),v_id=AS($1, _UTF-16LE'v_id'),degree=AS($2, _UTF-16LE'degree'))
03/06/2020 13:13:16.982 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#231:LogicalTableScan.NONE.any.None: 0.false.UNKNOWN(table=[Unregistered_DataStream_8])
03/06/2020 13:13:16.983 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#361:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#360,v_id_2=AS($0, _UTF-16LE'v_id_2'),v_label=AS($1, _UTF-16LE'v_label'),v_id_layout=AS($2, _UTF-16LE'v_id_layout'),X=AS($3, _UTF-16LE'X'),Y=AS($4, _UTF-16LE'Y'))
03/06/2020 13:13:16.983 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#238:LogicalTableScan.NONE.any.None: 0.false.UNKNOWN(table=[Unregistered_DataStream_9])
03/06/2020 13:13:16.983 DEBUG [org.apache.flink.table.planner.plan.optimize.program.FlinkGroupProgram] optimize convert enumerable table scan cost 37 ms.
optimize result:
 LogicalSink(name=[DataStreamTableSink], fields=[v_label, X, Y, v_id_layout, degree, v_id])
+- LogicalProject(v_label=[$4], X=[$6], Y=[$7], v_id_layout=[$5], degree=[$1], v_id=[$0])
   +- LogicalFilter(condition=[=($0, $3)])
      +- LogicalJoin(condition=[true], joinType=[inner])
         :- LogicalFilter(condition=[=($2, _UTF-16LE'true')])
         :  +- LogicalProject(v_id=[AS($0, _UTF-16LE'v_id')], degree=[AS($1.f1, _UTF-16LE'degree')], bool=[AS($1.f0, _UTF-16LE'bool')])
         :     +- LogicalAggregate(group=[{1}], TMP_0=[CurrentVertex($0, $1, $2)])
         :        +- LogicalProject(bool=[AS($0, _UTF-16LE'bool')], v_id=[AS($1, _UTF-16LE'v_id')], degree=[AS($2, _UTF-16LE'degree')])
         :           +- LogicalTableScan(table=[[Unregistered_DataStream_8]])
         +- LogicalProject(v_id_2=[AS($0, _UTF-16LE'v_id_2')], v_label=[AS($1, _UTF-16LE'v_label')], v_id_layout=[AS($2, _UTF-16LE'v_id_layout')], X=[AS($3, _UTF-16LE'X')], Y=[AS($4, _UTF-16LE'Y')])
            +- LogicalTableScan(table=[[Unregistered_DataStream_9]])

03/06/2020 13:13:16.984 DEBUG [org.apache.flink.table.planner.plan.optimize.program.FlinkChainedProgram] optimize temporal_join_rewrite cost 75 ms.
optimize result: 
LogicalSink(name=[DataStreamTableSink], fields=[v_label, X, Y, v_id_layout, degree, v_id])
+- LogicalProject(v_label=[$4], X=[$6], Y=[$7], v_id_layout=[$5], degree=[$1], v_id=[$0])
   +- LogicalFilter(condition=[=($0, $3)])
      +- LogicalJoin(condition=[true], joinType=[inner])
         :- LogicalFilter(condition=[=($2, _UTF-16LE'true')])
         :  +- LogicalProject(v_id=[AS($0, _UTF-16LE'v_id')], degree=[AS($1.f1, _UTF-16LE'degree')], bool=[AS($1.f0, _UTF-16LE'bool')])
         :     +- LogicalAggregate(group=[{1}], TMP_0=[CurrentVertex($0, $1, $2)])
         :        +- LogicalProject(bool=[AS($0, _UTF-16LE'bool')], v_id=[AS($1, _UTF-16LE'v_id')], degree=[AS($2, _UTF-16LE'degree')])
         :           +- LogicalTableScan(table=[[Unregistered_DataStream_8]])
         +- LogicalProject(v_id_2=[AS($0, _UTF-16LE'v_id_2')], v_label=[AS($1, _UTF-16LE'v_label')], v_id_layout=[AS($2, _UTF-16LE'v_id_layout')], X=[AS($3, _UTF-16LE'X')], Y=[AS($4, _UTF-16LE'Y')])
            +- LogicalTableScan(table=[[Unregistered_DataStream_9]])

03/06/2020 13:13:16.985 DEBUG [org.apache.flink.table.planner.plan.optimize.program.FlinkChainedProgram] optimize decorrelate cost 1 ms.
optimize result: 
LogicalSink(name=[DataStreamTableSink], fields=[v_label, X, Y, v_id_layout, degree, v_id])
+- LogicalProject(v_label=[$4], X=[$6], Y=[$7], v_id_layout=[$5], degree=[$1], v_id=[$0])
   +- LogicalFilter(condition=[=($0, $3)])
      +- LogicalJoin(condition=[true], joinType=[inner])
         :- LogicalFilter(condition=[=($2, _UTF-16LE'true')])
         :  +- LogicalProject(v_id=[AS($0, _UTF-16LE'v_id')], degree=[AS($1.f1, _UTF-16LE'degree')], bool=[AS($1.f0, _UTF-16LE'bool')])
         :     +- LogicalAggregate(group=[{1}], TMP_0=[CurrentVertex($0, $1, $2)])
         :        +- LogicalProject(bool=[AS($0, _UTF-16LE'bool')], v_id=[AS($1, _UTF-16LE'v_id')], degree=[AS($2, _UTF-16LE'degree')])
         :           +- LogicalTableScan(table=[[Unregistered_DataStream_8]])
         +- LogicalProject(v_id_2=[AS($0, _UTF-16LE'v_id_2')], v_label=[AS($1, _UTF-16LE'v_label')], v_id_layout=[AS($2, _UTF-16LE'v_id_layout')], X=[AS($3, _UTF-16LE'X')], Y=[AS($4, _UTF-16LE'Y')])
            +- LogicalTableScan(table=[[Unregistered_DataStream_9]])

03/06/2020 13:13:17.035  INFO [org.apache.flink.runtime.rpc.akka.AkkaRpcService] Stopping Akka RPC service.
03/06/2020 13:13:17.055  INFO [org.apache.flink.runtime.rpc.akka.AkkaRpcService] Stopped Akka RPC service.
03/06/2020 13:13:17.056  INFO [org.apache.flink.runtime.blob.PermanentBlobCache] Shutting down BLOB cache
03/06/2020 13:13:17.069  INFO [org.apache.flink.runtime.blob.TransientBlobCache] Shutting down BLOB cache
03/06/2020 13:13:17.123  INFO [org.apache.flink.runtime.blob.BlobServer] Stopped BLOB server at 0.0.0.0:39029
03/06/2020 13:13:17.127  INFO [org.apache.flink.runtime.rpc.akka.AkkaRpcService] Stopped Akka RPC service.
03/06/2020 13:13:17.142 DEBUG [org.apache.flink.table.planner.plan.optimize.program.FlinkChainedProgram] optimize time_indicator cost 154 ms.
optimize result: 
LogicalSink(name=[DataStreamTableSink], fields=[v_label, X, Y, v_id_layout, degree, v_id])
+- LogicalProject(v_label=[$4], X=[$6], Y=[$7], v_id_layout=[$5], degree=[$1], v_id=[$0])
   +- LogicalFilter(condition=[=($0, $3)])
      +- LogicalJoin(condition=[true], joinType=[inner])
         :- LogicalFilter(condition=[=($2, _UTF-16LE'true')])
         :  +- LogicalProject(v_id=[AS($0, _UTF-16LE'v_id')], degree=[AS($1.f1, _UTF-16LE'degree')], bool=[AS($1.f0, _UTF-16LE'bool')])
         :     +- LogicalAggregate(group=[{1}], TMP_0=[CurrentVertex($0, $1, $2)])
         :        +- LogicalProject(bool=[AS($0, _UTF-16LE'bool')], v_id=[AS($1, _UTF-16LE'v_id')], degree=[AS($2, _UTF-16LE'degree')])
         :           +- LogicalTableScan(table=[[Unregistered_DataStream_8]])
         +- LogicalProject(v_id_2=[AS($0, _UTF-16LE'v_id_2')], v_label=[AS($1, _UTF-16LE'v_label')], v_id_layout=[AS($2, _UTF-16LE'v_id_layout')], X=[AS($3, _UTF-16LE'X')], Y=[AS($4, _UTF-16LE'Y')])
            +- LogicalTableScan(table=[[Unregistered_DataStream_9]])

03/06/2020 13:13:17.145 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#344: Apply rule [SimplifyFilterConditionRule] to [rel#387:LogicalFilter.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#386,condition==($2, _UTF-16LE'true'))]
03/06/2020 13:13:17.145 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#345: Apply rule [SimplifyFilterConditionRule] to [rel#394:LogicalFilter.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#393,condition==($0, $3))]
03/06/2020 13:13:17.146 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#346: Apply rule [SimplifyJoinConditionRule] to [rel#392:LogicalJoin.NONE.any.None: 0.false.UNKNOWN(left=HepRelVertex#388,right=HepRelVertex#391,condition=true,joinType=inner)]
03/06/2020 13:13:17.146 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#348: Apply rule [JoinPushExpressionsRule] to [rel#392:LogicalJoin.NONE.any.None: 0.false.UNKNOWN(left=HepRelVertex#388,right=HepRelVertex#391,condition=true,joinType=inner)]
03/06/2020 13:13:17.147 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#356: Apply rule [ReduceExpressionsRule(Filter)] to [rel#387:LogicalFilter.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#386,condition==($2, _UTF-16LE'true'))]
03/06/2020 13:13:17.239 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#357: Apply rule [ReduceExpressionsRule(Filter)] to [rel#394:LogicalFilter.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#393,condition==($0, $3))]
03/06/2020 13:13:17.341 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#358: Apply rule [ReduceExpressionsRule(Project)] to [rel#381:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#380,bool=AS($0, _UTF-16LE'bool'),v_id=AS($1, _UTF-16LE'v_id'),degree=AS($2, _UTF-16LE'degree'))]
03/06/2020 13:13:17.343 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#359: Apply rule [ReduceExpressionsRule(Project)] to [rel#385:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#384,v_id=AS($0, _UTF-16LE'v_id'),degree=AS($1.f1, _UTF-16LE'degree'),bool=AS($1.f0, _UTF-16LE'bool'))]
03/06/2020 13:13:17.344 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#360: Apply rule [ReduceExpressionsRule(Project)] to [rel#390:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#389,v_id_2=AS($0, _UTF-16LE'v_id_2'),v_label=AS($1, _UTF-16LE'v_label'),v_id_layout=AS($2, _UTF-16LE'v_id_layout'),X=AS($3, _UTF-16LE'X'),Y=AS($4, _UTF-16LE'Y'))]
03/06/2020 13:13:17.344 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#361: Apply rule [ReduceExpressionsRule(Project)] to [rel#396:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#395,v_label=$4,X=$6,Y=$7,v_id_layout=$5,degree=$1,v_id=$0)]
03/06/2020 13:13:17.345 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#362: Apply rule [ReduceExpressionsRule(Join)] to [rel#392:LogicalJoin.NONE.any.None: 0.false.UNKNOWN(left=HepRelVertex#388,right=HepRelVertex#391,condition=true,joinType=inner)]
03/06/2020 13:13:17.366 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#364: Apply rule [ConvertToNotInOrInRule] to [rel#387:LogicalFilter.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#386,condition==($2, _UTF-16LE'true'))]
03/06/2020 13:13:17.396 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#365: Apply rule [ConvertToNotInOrInRule] to [rel#394:LogicalFilter.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#393,condition==($0, $3))]
03/06/2020 13:13:17.401 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#398:LogicalSink.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#397,name=DataStreamTableSink,fields=v_label, X, Y, v_id_layout, degree, v_id)
03/06/2020 13:13:17.401 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#396:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#395,v_label=$4,X=$6,Y=$7,v_id_layout=$5,degree=$1,v_id=$0)
03/06/2020 13:13:17.401 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#394:LogicalFilter.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#393,condition==($0, $3))
03/06/2020 13:13:17.401 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#392:LogicalJoin.NONE.any.None: 0.false.UNKNOWN(left=HepRelVertex#388,right=HepRelVertex#391,condition=true,joinType=inner)
03/06/2020 13:13:17.401 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#387:LogicalFilter.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#386,condition==($2, _UTF-16LE'true'))
03/06/2020 13:13:17.401 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#385:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#384,v_id=AS($0, _UTF-16LE'v_id'),degree=AS($1.f1, _UTF-16LE'degree'),bool=AS($1.f0, _UTF-16LE'bool'))
03/06/2020 13:13:17.401 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#383:LogicalAggregate.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#382,group={1},TMP_0=CurrentVertex($0, $1, $2))
03/06/2020 13:13:17.401 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#381:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#380,bool=AS($0, _UTF-16LE'bool'),v_id=AS($1, _UTF-16LE'v_id'),degree=AS($2, _UTF-16LE'degree'))
03/06/2020 13:13:17.401 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#231:LogicalTableScan.NONE.any.None: 0.false.UNKNOWN(table=[Unregistered_DataStream_8])
03/06/2020 13:13:17.402 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#390:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#389,v_id_2=AS($0, _UTF-16LE'v_id_2'),v_label=AS($1, _UTF-16LE'v_label'),v_id_layout=AS($2, _UTF-16LE'v_id_layout'),X=AS($3, _UTF-16LE'X'),Y=AS($4, _UTF-16LE'Y'))
03/06/2020 13:13:17.402 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#238:LogicalTableScan.NONE.any.None: 0.false.UNKNOWN(table=[Unregistered_DataStream_9])
03/06/2020 13:13:17.408 DEBUG [org.apache.flink.table.planner.plan.optimize.program.FlinkChainedProgram] optimize default_rewrite cost 259 ms.
optimize result: 
LogicalSink(name=[DataStreamTableSink], fields=[v_label, X, Y, v_id_layout, degree, v_id])
+- LogicalProject(v_label=[$4], X=[$6], Y=[$7], v_id_layout=[$5], degree=[$1], v_id=[$0])
   +- LogicalFilter(condition=[=($0, $3)])
      +- LogicalJoin(condition=[true], joinType=[inner])
         :- LogicalFilter(condition=[=($2, _UTF-16LE'true')])
         :  +- LogicalProject(v_id=[AS($0, _UTF-16LE'v_id')], degree=[AS($1.f1, _UTF-16LE'degree')], bool=[AS($1.f0, _UTF-16LE'bool')])
         :     +- LogicalAggregate(group=[{1}], TMP_0=[CurrentVertex($0, $1, $2)])
         :        +- LogicalProject(bool=[AS($0, _UTF-16LE'bool')], v_id=[AS($1, _UTF-16LE'v_id')], degree=[AS($2, _UTF-16LE'degree')])
         :           +- LogicalTableScan(table=[[Unregistered_DataStream_8]])
         +- LogicalProject(v_id_2=[AS($0, _UTF-16LE'v_id_2')], v_label=[AS($1, _UTF-16LE'v_label')], v_id_layout=[AS($2, _UTF-16LE'v_id_layout')], X=[AS($3, _UTF-16LE'X')], Y=[AS($4, _UTF-16LE'Y')])
            +- LogicalTableScan(table=[[Unregistered_DataStream_9]])

03/06/2020 13:13:17.408 DEBUG [org.apache.flink.table.planner.plan.optimize.program.FlinkGroupProgram] iteration: 1
03/06/2020 13:13:17.410 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#366: Apply rule [ReduceExpressionsRule(Project)] to [rel#402:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#401,bool=AS($0, _UTF-16LE'bool'),v_id=AS($1, _UTF-16LE'v_id'),degree=AS($2, _UTF-16LE'degree'))]
03/06/2020 13:13:17.411 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#367: Apply rule [ReduceExpressionsRule(Project)] to [rel#406:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#405,v_id=AS($0, _UTF-16LE'v_id'),degree=AS($1.f1, _UTF-16LE'degree'),bool=AS($1.f0, _UTF-16LE'bool'))]
03/06/2020 13:13:17.412 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#368: Apply rule [ReduceExpressionsRule(Project)] to [rel#411:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#410,v_id_2=AS($0, _UTF-16LE'v_id_2'),v_label=AS($1, _UTF-16LE'v_label'),v_id_layout=AS($2, _UTF-16LE'v_id_layout'),X=AS($3, _UTF-16LE'X'),Y=AS($4, _UTF-16LE'Y'))]
03/06/2020 13:13:17.414 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#369: Apply rule [FilterProjectTransposeRule] to [rel#408:LogicalFilter.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#407,condition==($2, _UTF-16LE'true')), rel#406:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#405,v_id=AS($0, _UTF-16LE'v_id'),degree=AS($1.f1, _UTF-16LE'degree'),bool=AS($1.f0, _UTF-16LE'bool'))]
03/06/2020 13:13:17.416 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#369: Rule FilterProjectTransposeRule arguments [rel#408:LogicalFilter.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#407,condition==($2, _UTF-16LE'true')), rel#406:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#405,v_id=AS($0, _UTF-16LE'v_id'),degree=AS($1.f1, _UTF-16LE'degree'),bool=AS($1.f0, _UTF-16LE'bool'))] produced LogicalProject#422
03/06/2020 13:13:17.417 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#370: Apply rule [ReduceExpressionsRule(Project)] to [rel#402:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#401,bool=AS($0, _UTF-16LE'bool'),v_id=AS($1, _UTF-16LE'v_id'),degree=AS($2, _UTF-16LE'degree'))]
03/06/2020 13:13:17.418 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#371: Apply rule [FilterAggregateTransposeRule] to [rel#421:LogicalFilter.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#405,condition==(AS($1.f0, _UTF-16LE'bool'), _UTF-16LE'true')), rel#404:LogicalAggregate.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#403,group={1},TMP_0=CurrentVertex($0, $1, $2))]
03/06/2020 13:13:17.418 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#372: Apply rule [SimplifyFilterConditionRule] to [rel#421:LogicalFilter.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#405,condition==(AS($1.f0, _UTF-16LE'bool'), _UTF-16LE'true'))]
03/06/2020 13:13:17.420 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#373: Apply rule [ReduceExpressionsRule(Filter)] to [rel#421:LogicalFilter.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#405,condition==(AS($1.f0, _UTF-16LE'bool'), _UTF-16LE'true'))]
03/06/2020 13:13:17.421 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#374: Apply rule [ReduceExpressionsRule(Project)] to [rel#424:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#423,v_id=AS($0, _UTF-16LE'v_id'),degree=AS($1.f1, _UTF-16LE'degree'),bool=AS($1.f0, _UTF-16LE'bool'))]
03/06/2020 13:13:17.421 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#375: Apply rule [ReduceExpressionsRule(Project)] to [rel#411:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#410,v_id_2=AS($0, _UTF-16LE'v_id_2'),v_label=AS($1, _UTF-16LE'v_label'),v_id_layout=AS($2, _UTF-16LE'v_id_layout'),X=AS($3, _UTF-16LE'X'),Y=AS($4, _UTF-16LE'Y'))]
03/06/2020 13:13:17.422 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#376: Apply rule [FilterJoinRule:FilterJoinRule:no-filter] to [rel#413:LogicalJoin.NONE.any.None: 0.false.UNKNOWN(left=HepRelVertex#425,right=HepRelVertex#412,condition=true,joinType=inner)]
03/06/2020 13:13:17.422 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#377: Apply rule [SimplifyJoinConditionRule] to [rel#413:LogicalJoin.NONE.any.None: 0.false.UNKNOWN(left=HepRelVertex#425,right=HepRelVertex#412,condition=true,joinType=inner)]
03/06/2020 13:13:17.422 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#379: Apply rule [JoinPushExpressionsRule] to [rel#413:LogicalJoin.NONE.any.None: 0.false.UNKNOWN(left=HepRelVertex#425,right=HepRelVertex#412,condition=true,joinType=inner)]
03/06/2020 13:13:17.423 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#380: Apply rule [ReduceExpressionsRule(Join)] to [rel#413:LogicalJoin.NONE.any.None: 0.false.UNKNOWN(left=HepRelVertex#425,right=HepRelVertex#412,condition=true,joinType=inner)]
03/06/2020 13:13:17.423 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#381: Apply rule [FilterJoinRule:FilterJoinRule:filter] to [rel#415:LogicalFilter.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#414,condition==($0, $3)), rel#413:LogicalJoin.NONE.any.None: 0.false.UNKNOWN(left=HepRelVertex#425,right=HepRelVertex#412,condition=true,joinType=inner)]
03/06/2020 13:13:17.425 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#381: Rule FilterJoinRule:FilterJoinRule:filter arguments [rel#415:LogicalFilter.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#414,condition==($0, $3)), rel#413:LogicalJoin.NONE.any.None: 0.false.UNKNOWN(left=HepRelVertex#425,right=HepRelVertex#412,condition=true,joinType=inner)] produced LogicalJoin#427
03/06/2020 13:13:17.427 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#382: Apply rule [ReduceExpressionsRule(Project)] to [rel#402:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#401,bool=AS($0, _UTF-16LE'bool'),v_id=AS($1, _UTF-16LE'v_id'),degree=AS($2, _UTF-16LE'degree'))]
03/06/2020 13:13:17.429 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#383: Apply rule [FilterAggregateTransposeRule] to [rel#421:LogicalFilter.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#405,condition==(AS($1.f0, _UTF-16LE'bool'), _UTF-16LE'true')), rel#404:LogicalAggregate.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#403,group={1},TMP_0=CurrentVertex($0, $1, $2))]
03/06/2020 13:13:17.430 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#384: Apply rule [SimplifyFilterConditionRule] to [rel#421:LogicalFilter.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#405,condition==(AS($1.f0, _UTF-16LE'bool'), _UTF-16LE'true'))]
03/06/2020 13:13:17.434 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#385: Apply rule [ReduceExpressionsRule(Filter)] to [rel#421:LogicalFilter.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#405,condition==(AS($1.f0, _UTF-16LE'bool'), _UTF-16LE'true'))]
03/06/2020 13:13:17.435 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#386: Apply rule [ReduceExpressionsRule(Project)] to [rel#411:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#410,v_id_2=AS($0, _UTF-16LE'v_id_2'),v_label=AS($1, _UTF-16LE'v_label'),v_id_layout=AS($2, _UTF-16LE'v_id_layout'),X=AS($3, _UTF-16LE'X'),Y=AS($4, _UTF-16LE'Y'))]
03/06/2020 13:13:17.439 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#387: Apply rule [ReduceExpressionsRule(Project)] to [rel#424:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#423,v_id=AS($0, _UTF-16LE'v_id'),degree=AS($1.f1, _UTF-16LE'degree'),bool=AS($1.f0, _UTF-16LE'bool'))]
03/06/2020 13:13:17.439 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#388: Apply rule [FilterJoinRule:FilterJoinRule:no-filter] to [rel#427:LogicalJoin.NONE.any.None: 0.false.UNKNOWN(left=HepRelVertex#425,right=HepRelVertex#412,condition==($0, $3),joinType=inner)]
03/06/2020 13:13:17.439 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#389: Apply rule [SimplifyJoinConditionRule] to [rel#427:LogicalJoin.NONE.any.None: 0.false.UNKNOWN(left=HepRelVertex#425,right=HepRelVertex#412,condition==($0, $3),joinType=inner)]
03/06/2020 13:13:17.442 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#391: Apply rule [JoinPushExpressionsRule] to [rel#427:LogicalJoin.NONE.any.None: 0.false.UNKNOWN(left=HepRelVertex#425,right=HepRelVertex#412,condition==($0, $3),joinType=inner)]
03/06/2020 13:13:17.443 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#392: Apply rule [ReduceExpressionsRule(Join)] to [rel#427:LogicalJoin.NONE.any.None: 0.false.UNKNOWN(left=HepRelVertex#425,right=HepRelVertex#412,condition==($0, $3),joinType=inner)]
03/06/2020 13:13:17.443 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#393: Apply rule [ReduceExpressionsRule(Project)] to [rel#417:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#416,v_label=$4,X=$6,Y=$7,v_id_layout=$5,degree=$1,v_id=$0)]
03/06/2020 13:13:17.445 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#419:LogicalSink.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#418,name=DataStreamTableSink,fields=v_label, X, Y, v_id_layout, degree, v_id)
03/06/2020 13:13:17.445 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#417:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#416,v_label=$4,X=$6,Y=$7,v_id_layout=$5,degree=$1,v_id=$0)
03/06/2020 13:13:17.445 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#427:LogicalJoin.NONE.any.None: 0.false.UNKNOWN(left=HepRelVertex#425,right=HepRelVertex#412,condition==($0, $3),joinType=inner)
03/06/2020 13:13:17.445 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#424:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#423,v_id=AS($0, _UTF-16LE'v_id'),degree=AS($1.f1, _UTF-16LE'degree'),bool=AS($1.f0, _UTF-16LE'bool'))
03/06/2020 13:13:17.446 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#421:LogicalFilter.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#405,condition==(AS($1.f0, _UTF-16LE'bool'), _UTF-16LE'true'))
03/06/2020 13:13:17.446 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#404:LogicalAggregate.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#403,group={1},TMP_0=CurrentVertex($0, $1, $2))
03/06/2020 13:13:17.446 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#402:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#401,bool=AS($0, _UTF-16LE'bool'),v_id=AS($1, _UTF-16LE'v_id'),degree=AS($2, _UTF-16LE'degree'))
03/06/2020 13:13:17.446 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#231:LogicalTableScan.NONE.any.None: 0.false.UNKNOWN(table=[Unregistered_DataStream_8])
03/06/2020 13:13:17.448 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#411:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#410,v_id_2=AS($0, _UTF-16LE'v_id_2'),v_label=AS($1, _UTF-16LE'v_label'),v_id_layout=AS($2, _UTF-16LE'v_id_layout'),X=AS($3, _UTF-16LE'X'),Y=AS($4, _UTF-16LE'Y'))
03/06/2020 13:13:17.448 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#238:LogicalTableScan.NONE.any.None: 0.false.UNKNOWN(table=[Unregistered_DataStream_9])
03/06/2020 13:13:17.449 DEBUG [org.apache.flink.table.planner.plan.optimize.program.FlinkGroupProgram] optimize filter rules cost 40 ms.
optimize result:
 LogicalSink(name=[DataStreamTableSink], fields=[v_label, X, Y, v_id_layout, degree, v_id])
+- LogicalProject(v_label=[$4], X=[$6], Y=[$7], v_id_layout=[$5], degree=[$1], v_id=[$0])
   +- LogicalJoin(condition=[=($0, $3)], joinType=[inner])
      :- LogicalProject(v_id=[AS($0, _UTF-16LE'v_id')], degree=[AS($1.f1, _UTF-16LE'degree')], bool=[AS($1.f0, _UTF-16LE'bool')])
      :  +- LogicalFilter(condition=[=(AS($1.f0, _UTF-16LE'bool'), _UTF-16LE'true')])
      :     +- LogicalAggregate(group=[{1}], TMP_0=[CurrentVertex($0, $1, $2)])
      :        +- LogicalProject(bool=[AS($0, _UTF-16LE'bool')], v_id=[AS($1, _UTF-16LE'v_id')], degree=[AS($2, _UTF-16LE'degree')])
      :           +- LogicalTableScan(table=[[Unregistered_DataStream_8]])
      +- LogicalProject(v_id_2=[AS($0, _UTF-16LE'v_id_2')], v_label=[AS($1, _UTF-16LE'v_label')], v_id_layout=[AS($2, _UTF-16LE'v_id_layout')], X=[AS($3, _UTF-16LE'X')], Y=[AS($4, _UTF-16LE'Y')])
         +- LogicalTableScan(table=[[Unregistered_DataStream_9]])

03/06/2020 13:13:17.465 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#446:LogicalSink.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#445,name=DataStreamTableSink,fields=v_label, X, Y, v_id_layout, degree, v_id)
03/06/2020 13:13:17.472 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#444:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#443,v_label=$4,X=$6,Y=$7,v_id_layout=$5,degree=$1,v_id=$0)
03/06/2020 13:13:17.472 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#442:LogicalJoin.NONE.any.None: 0.false.UNKNOWN(left=HepRelVertex#438,right=HepRelVertex#441,condition==($0, $3),joinType=inner)
03/06/2020 13:13:17.472 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#437:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#436,v_id=AS($0, _UTF-16LE'v_id'),degree=AS($1.f1, _UTF-16LE'degree'),bool=AS($1.f0, _UTF-16LE'bool'))
03/06/2020 13:13:17.472 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#435:LogicalFilter.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#434,condition==(AS($1.f0, _UTF-16LE'bool'), _UTF-16LE'true'))
03/06/2020 13:13:17.472 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#433:LogicalAggregate.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#432,group={1},TMP_0=CurrentVertex($0, $1, $2))
03/06/2020 13:13:17.472 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#431:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#430,bool=AS($0, _UTF-16LE'bool'),v_id=AS($1, _UTF-16LE'v_id'),degree=AS($2, _UTF-16LE'degree'))
03/06/2020 13:13:17.472 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#231:LogicalTableScan.NONE.any.None: 0.false.UNKNOWN(table=[Unregistered_DataStream_8])
03/06/2020 13:13:17.474 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#440:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#439,v_id_2=AS($0, _UTF-16LE'v_id_2'),v_label=AS($1, _UTF-16LE'v_label'),v_id_layout=AS($2, _UTF-16LE'v_id_layout'),X=AS($3, _UTF-16LE'X'),Y=AS($4, _UTF-16LE'Y'))
03/06/2020 13:13:17.474 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#238:LogicalTableScan.NONE.any.None: 0.false.UNKNOWN(table=[Unregistered_DataStream_9])
03/06/2020 13:13:17.477 DEBUG [org.apache.flink.table.planner.plan.optimize.program.FlinkGroupProgram] optimize push predicate into table scan cost 25 ms.
optimize result:
 LogicalSink(name=[DataStreamTableSink], fields=[v_label, X, Y, v_id_layout, degree, v_id])
+- LogicalProject(v_label=[$4], X=[$6], Y=[$7], v_id_layout=[$5], degree=[$1], v_id=[$0])
   +- LogicalJoin(condition=[=($0, $3)], joinType=[inner])
      :- LogicalProject(v_id=[AS($0, _UTF-16LE'v_id')], degree=[AS($1.f1, _UTF-16LE'degree')], bool=[AS($1.f0, _UTF-16LE'bool')])
      :  +- LogicalFilter(condition=[=(AS($1.f0, _UTF-16LE'bool'), _UTF-16LE'true')])
      :     +- LogicalAggregate(group=[{1}], TMP_0=[CurrentVertex($0, $1, $2)])
      :        +- LogicalProject(bool=[AS($0, _UTF-16LE'bool')], v_id=[AS($1, _UTF-16LE'v_id')], degree=[AS($2, _UTF-16LE'degree')])
      :           +- LogicalTableScan(table=[[Unregistered_DataStream_8]])
      +- LogicalProject(v_id_2=[AS($0, _UTF-16LE'v_id_2')], v_label=[AS($1, _UTF-16LE'v_label')], v_id_layout=[AS($2, _UTF-16LE'v_id_layout')], X=[AS($3, _UTF-16LE'X')], Y=[AS($4, _UTF-16LE'Y')])
         +- LogicalTableScan(table=[[Unregistered_DataStream_9]])

03/06/2020 13:13:17.486 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#464:LogicalSink.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#463,name=DataStreamTableSink,fields=v_label, X, Y, v_id_layout, degree, v_id)
03/06/2020 13:13:17.487 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#462:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#461,v_label=$4,X=$6,Y=$7,v_id_layout=$5,degree=$1,v_id=$0)
03/06/2020 13:13:17.487 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#460:LogicalJoin.NONE.any.None: 0.false.UNKNOWN(left=HepRelVertex#456,right=HepRelVertex#459,condition==($0, $3),joinType=inner)
03/06/2020 13:13:17.487 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#455:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#454,v_id=AS($0, _UTF-16LE'v_id'),degree=AS($1.f1, _UTF-16LE'degree'),bool=AS($1.f0, _UTF-16LE'bool'))
03/06/2020 13:13:17.487 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#453:LogicalFilter.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#452,condition==(AS($1.f0, _UTF-16LE'bool'), _UTF-16LE'true'))
03/06/2020 13:13:17.487 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#451:LogicalAggregate.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#450,group={1},TMP_0=CurrentVertex($0, $1, $2))
03/06/2020 13:13:17.487 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#449:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#448,bool=AS($0, _UTF-16LE'bool'),v_id=AS($1, _UTF-16LE'v_id'),degree=AS($2, _UTF-16LE'degree'))
03/06/2020 13:13:17.487 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#231:LogicalTableScan.NONE.any.None: 0.false.UNKNOWN(table=[Unregistered_DataStream_8])
03/06/2020 13:13:17.487 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#458:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=HepRelVertex#457,v_id_2=AS($0, _UTF-16LE'v_id_2'),v_label=AS($1, _UTF-16LE'v_label'),v_id_layout=AS($2, _UTF-16LE'v_id_layout'),X=AS($3, _UTF-16LE'X'),Y=AS($4, _UTF-16LE'Y'))
03/06/2020 13:13:17.487 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#238:LogicalTableScan.NONE.any.None: 0.false.UNKNOWN(table=[Unregistered_DataStream_9])
03/06/2020 13:13:17.487 DEBUG [org.apache.flink.table.planner.plan.optimize.program.FlinkGroupProgram] optimize prune empty after predicate push down cost 9 ms.
optimize result:
 LogicalSink(name=[DataStreamTableSink], fields=[v_label, X, Y, v_id_layout, degree, v_id])
+- LogicalProject(v_label=[$4], X=[$6], Y=[$7], v_id_layout=[$5], degree=[$1], v_id=[$0])
   +- LogicalJoin(condition=[=($0, $3)], joinType=[inner])
      :- LogicalProject(v_id=[AS($0, _UTF-16LE'v_id')], degree=[AS($1.f1, _UTF-16LE'degree')], bool=[AS($1.f0, _UTF-16LE'bool')])
      :  +- LogicalFilter(condition=[=(AS($1.f0, _UTF-16LE'bool'), _UTF-16LE'true')])
      :     +- LogicalAggregate(group=[{1}], TMP_0=[CurrentVertex($0, $1, $2)])
      :        +- LogicalProject(bool=[AS($0, _UTF-16LE'bool')], v_id=[AS($1, _UTF-16LE'v_id')], degree=[AS($2, _UTF-16LE'degree')])
      :           +- LogicalTableScan(table=[[Unregistered_DataStream_8]])
      +- LogicalProject(v_id_2=[AS($0, _UTF-16LE'v_id_2')], v_label=[AS($1, _UTF-16LE'v_label')], v_id_layout=[AS($2, _UTF-16LE'v_id_layout')], X=[AS($3, _UTF-16LE'X')], Y=[AS($4, _UTF-16LE'Y')])
         +- LogicalTableScan(table=[[Unregistered_DataStream_9]])

03/06/2020 13:13:17.488 DEBUG [org.apache.flink.table.planner.plan.optimize.program.FlinkChainedProgram] optimize predicate_pushdown cost 79 ms.
optimize result: 
LogicalSink(name=[DataStreamTableSink], fields=[v_label, X, Y, v_id_layout, degree, v_id])
+- LogicalProject(v_label=[$4], X=[$6], Y=[$7], v_id_layout=[$5], degree=[$1], v_id=[$0])
   +- LogicalJoin(condition=[=($0, $3)], joinType=[inner])
      :- LogicalProject(v_id=[AS($0, _UTF-16LE'v_id')], degree=[AS($1.f1, _UTF-16LE'degree')], bool=[AS($1.f0, _UTF-16LE'bool')])
      :  +- LogicalFilter(condition=[=(AS($1.f0, _UTF-16LE'bool'), _UTF-16LE'true')])
      :     +- LogicalAggregate(group=[{1}], TMP_0=[CurrentVertex($0, $1, $2)])
      :        +- LogicalProject(bool=[AS($0, _UTF-16LE'bool')], v_id=[AS($1, _UTF-16LE'v_id')], degree=[AS($2, _UTF-16LE'degree')])
      :           +- LogicalTableScan(table=[[Unregistered_DataStream_8]])
      +- LogicalProject(v_id_2=[AS($0, _UTF-16LE'v_id_2')], v_label=[AS($1, _UTF-16LE'v_label')], v_id_layout=[AS($2, _UTF-16LE'v_id_layout')], X=[AS($3, _UTF-16LE'X')], Y=[AS($4, _UTF-16LE'Y')])
         +- LogicalTableScan(table=[[Unregistered_DataStream_9]])

03/06/2020 13:13:17.556 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 1/1; PHASE = PRE_PROCESS_MDR; COST = {inf}
03/06/2020 13:13:17.557 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 2/1; PHASE = PRE_PROCESS; COST = {inf}
03/06/2020 13:13:17.557 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 3/1; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:17.576 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [FlinkLogicalSinkConverter(in:NONE,out:LOGICAL)] rels [rel#482:LogicalSink.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#481,name=DataStreamTableSink,fields=v_label, X, Y, v_id_layout, degree, v_id)]
03/06/2020 13:13:17.578 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#626: Apply rule [FlinkLogicalSinkConverter(in:NONE,out:LOGICAL)] to [rel#482:LogicalSink.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#481,name=DataStreamTableSink,fields=v_label, X, Y, v_id_layout, degree, v_id)]
03/06/2020 13:13:17.578 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#487 via FlinkLogicalSinkConverter(in:NONE,out:LOGICAL)
03/06/2020 13:13:17.886 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#626 generated 1 successors: [rel#487:FlinkLogicalSink.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#486,name=DataStreamTableSink,fields=v_label, X, Y, v_id_layout, degree, v_id)]
03/06/2020 13:13:17.886 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 4/2; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:17.886 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [FlinkProjectJoinTransposeRule] rels [rel#480:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#479,v_label=$4,X=$6,Y=$7,v_id_layout=$5,degree=$1,v_id=$0), rel#478:LogicalJoin.NONE.any.None: 0.false.UNKNOWN(left=RelSubset#474,right=RelSubset#477,condition==($0, $3),joinType=inner)]
03/06/2020 13:13:17.887 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#594: Apply rule [FlinkProjectJoinTransposeRule] to [rel#480:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#479,v_label=$4,X=$6,Y=$7,v_id_layout=$5,degree=$1,v_id=$0), rel#478:LogicalJoin.NONE.any.None: 0.false.UNKNOWN(left=RelSubset#474,right=RelSubset#477,condition==($0, $3),joinType=inner)]
03/06/2020 13:13:17.899 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#494 via FlinkProjectJoinTransposeRule
03/06/2020 13:13:17.903 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#594 generated 1 successors: [LogicalProject#494]
03/06/2020 13:13:17.903 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 5/3; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:17.903 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [FlinkProjectJoinTransposeRule] rels [rel#499:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#498,v_label=$3,X=$5,Y=$6,v_id_layout=$4,degree=$1,v_id=$0), rel#497:LogicalJoin.NONE.any.None: 0.false.UNKNOWN(left=RelSubset#495,right=RelSubset#496,condition==($0, $2),joinType=inner)]
03/06/2020 13:13:17.903 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#733: Apply rule [FlinkProjectJoinTransposeRule] to [rel#499:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#498,v_label=$3,X=$5,Y=$6,v_id_layout=$4,degree=$1,v_id=$0), rel#497:LogicalJoin.NONE.any.None: 0.false.UNKNOWN(left=RelSubset#495,right=RelSubset#496,condition==($0, $2),joinType=inner)]
03/06/2020 13:13:17.903 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#733 generated 0 successors.
03/06/2020 13:13:17.903 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 6/4; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:17.903 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [ProjectToCalcRule] rels [rel#499:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#498,v_label=$3,X=$5,Y=$6,v_id_layout=$4,degree=$1,v_id=$0)]
03/06/2020 13:13:17.903 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#752: Apply rule [ProjectToCalcRule] to [rel#499:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#498,v_label=$3,X=$5,Y=$6,v_id_layout=$4,degree=$1,v_id=$0)]
03/06/2020 13:13:17.904 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#500 via ProjectToCalcRule
03/06/2020 13:13:17.904 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#752 generated 1 successors: [rel#500:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#498,expr#0..6={inputs},v_label=$t3,X=$t5,Y=$t6,v_id_layout=$t4,degree=$t1,v_id=$t0)]
03/06/2020 13:13:17.904 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 7/5; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:17.905 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [rel#500:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#498,expr#0..6={inputs},v_label=$t3,X=$t5,Y=$t6,v_id_layout=$t4,degree=$t1,v_id=$t0)]
03/06/2020 13:13:17.905 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#765: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#500:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#498,expr#0..6={inputs},v_label=$t3,X=$t5,Y=$t6,v_id_layout=$t4,degree=$t1,v_id=$t0)]
03/06/2020 13:13:17.905 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#502 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
03/06/2020 13:13:17.909 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#765 generated 1 successors: [rel#502:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#501,select=v_label, X, Y, v_id_layout, degree, v_id)]
03/06/2020 13:13:17.909 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 8/6; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:17.909 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [ProjectToCalcRule] rels [rel#480:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#479,v_label=$4,X=$6,Y=$7,v_id_layout=$5,degree=$1,v_id=$0)]
03/06/2020 13:13:17.909 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#613: Apply rule [ProjectToCalcRule] to [rel#480:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#479,v_label=$4,X=$6,Y=$7,v_id_layout=$5,degree=$1,v_id=$0)]
03/06/2020 13:13:17.909 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#508 via ProjectToCalcRule
03/06/2020 13:13:17.910 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#613 generated 1 successors: [rel#508:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#479,expr#0..7={inputs},v_label=$t4,X=$t6,Y=$t7,v_id_layout=$t5,degree=$t1,v_id=$t0)]
03/06/2020 13:13:17.910 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 9/7; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:17.910 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [rel#508:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#479,expr#0..7={inputs},v_label=$t4,X=$t6,Y=$t7,v_id_layout=$t5,degree=$t1,v_id=$t0)]
03/06/2020 13:13:17.910 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#785: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#508:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#479,expr#0..7={inputs},v_label=$t4,X=$t6,Y=$t7,v_id_layout=$t5,degree=$t1,v_id=$t0)]
03/06/2020 13:13:17.910 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#510 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
03/06/2020 13:13:17.913 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#785 generated 1 successors: [rel#510:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#509,select=v_label, X, Y, v_id_layout, degree, v_id)]
03/06/2020 13:13:17.913 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 10/8; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:17.913 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [SimplifyJoinConditionRule] rels [rel#497:LogicalJoin.NONE.any.None: 0.false.UNKNOWN(left=RelSubset#495,right=RelSubset#496,condition==($0, $2),joinType=inner)]
03/06/2020 13:13:17.913 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#715: Apply rule [SimplifyJoinConditionRule] to [rel#497:LogicalJoin.NONE.any.None: 0.false.UNKNOWN(left=RelSubset#495,right=RelSubset#496,condition==($0, $2),joinType=inner)]
03/06/2020 13:13:17.914 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#715 generated 0 successors.
03/06/2020 13:13:17.914 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 11/9; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:17.914 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [SimplifyJoinConditionRule] rels [rel#478:LogicalJoin.NONE.any.None: 0.false.UNKNOWN(left=RelSubset#474,right=RelSubset#477,condition==($0, $3),joinType=inner)]
03/06/2020 13:13:17.914 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#576: Apply rule [SimplifyJoinConditionRule] to [rel#478:LogicalJoin.NONE.any.None: 0.false.UNKNOWN(left=RelSubset#474,right=RelSubset#477,condition==($0, $3),joinType=inner)]
03/06/2020 13:13:17.914 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#576 generated 0 successors.
03/06/2020 13:13:17.915 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 12/10; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:17.915 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [FlinkJoinPushExpressionsRule] rels [rel#497:LogicalJoin.NONE.any.None: 0.false.UNKNOWN(left=RelSubset#495,right=RelSubset#496,condition==($0, $2),joinType=inner)]
03/06/2020 13:13:17.915 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#717: Apply rule [FlinkJoinPushExpressionsRule] to [rel#497:LogicalJoin.NONE.any.None: 0.false.UNKNOWN(left=RelSubset#495,right=RelSubset#496,condition==($0, $2),joinType=inner)]
03/06/2020 13:13:17.916 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#717 generated 0 successors.
03/06/2020 13:13:17.916 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 13/11; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:17.916 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [FlinkJoinPushExpressionsRule] rels [rel#478:LogicalJoin.NONE.any.None: 0.false.UNKNOWN(left=RelSubset#474,right=RelSubset#477,condition==($0, $3),joinType=inner)]
03/06/2020 13:13:17.916 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#578: Apply rule [FlinkJoinPushExpressionsRule] to [rel#478:LogicalJoin.NONE.any.None: 0.false.UNKNOWN(left=RelSubset#474,right=RelSubset#477,condition==($0, $3),joinType=inner)]
03/06/2020 13:13:17.916 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#578 generated 0 successors.
03/06/2020 13:13:17.916 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 14/12; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:17.916 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [FlinkLogicalJoinConverter(in:NONE,out:LOGICAL)] rels [rel#497:LogicalJoin.NONE.any.None: 0.false.UNKNOWN(left=RelSubset#495,right=RelSubset#496,condition==($0, $2),joinType=inner)]
03/06/2020 13:13:17.916 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#720: Apply rule [FlinkLogicalJoinConverter(in:NONE,out:LOGICAL)] to [rel#497:LogicalJoin.NONE.any.None: 0.false.UNKNOWN(left=RelSubset#495,right=RelSubset#496,condition==($0, $2),joinType=inner)]
03/06/2020 13:13:17.920 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#518 via FlinkLogicalJoinConverter(in:NONE,out:LOGICAL)
03/06/2020 13:13:18.225 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#720 generated 1 successors: [rel#518:FlinkLogicalJoin.LOGICAL.any.None: 0.false.UNKNOWN(left=RelSubset#516,right=RelSubset#517,condition==($0, $2),joinType=inner)]
03/06/2020 13:13:18.225 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 15/13; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:18.225 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [FlinkLogicalJoinConverter(in:NONE,out:LOGICAL)] rels [rel#478:LogicalJoin.NONE.any.None: 0.false.UNKNOWN(left=RelSubset#474,right=RelSubset#477,condition==($0, $3),joinType=inner)]
03/06/2020 13:13:18.225 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#581: Apply rule [FlinkLogicalJoinConverter(in:NONE,out:LOGICAL)] to [rel#478:LogicalJoin.NONE.any.None: 0.false.UNKNOWN(left=RelSubset#474,right=RelSubset#477,condition==($0, $3),joinType=inner)]
03/06/2020 13:13:18.225 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#522 via FlinkLogicalJoinConverter(in:NONE,out:LOGICAL)
03/06/2020 13:13:18.247 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#581 generated 1 successors: [rel#522:FlinkLogicalJoin.LOGICAL.any.None: 0.false.UNKNOWN(left=RelSubset#520,right=RelSubset#521,condition==($0, $3),joinType=inner)]
03/06/2020 13:13:18.247 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 16/14; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:18.247 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [FilterJoinRule:FilterJoinRule:no-filter] rels [rel#497:LogicalJoin.NONE.any.None: 0.false.UNKNOWN(left=RelSubset#495,right=RelSubset#496,condition==($0, $2),joinType=inner)]
03/06/2020 13:13:18.247 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#708: Apply rule [FilterJoinRule:FilterJoinRule:no-filter] to [rel#497:LogicalJoin.NONE.any.None: 0.false.UNKNOWN(left=RelSubset#495,right=RelSubset#496,condition==($0, $2),joinType=inner)]
03/06/2020 13:13:18.248 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#708 generated 0 successors.
03/06/2020 13:13:18.248 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 17/15; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:18.248 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [FilterJoinRule:FilterJoinRule:no-filter] rels [rel#478:LogicalJoin.NONE.any.None: 0.false.UNKNOWN(left=RelSubset#474,right=RelSubset#477,condition==($0, $3),joinType=inner)]
03/06/2020 13:13:18.248 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#569: Apply rule [FilterJoinRule:FilterJoinRule:no-filter] to [rel#478:LogicalJoin.NONE.any.None: 0.false.UNKNOWN(left=RelSubset#474,right=RelSubset#477,condition==($0, $3),joinType=inner)]
03/06/2020 13:13:18.248 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#569 generated 0 successors.
03/06/2020 13:13:18.248 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 18/16; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:18.248 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [FlinkJoinPushExpressionsRule] rels [rel#518:FlinkLogicalJoin.LOGICAL.any.None: 0.false.UNKNOWN(left=RelSubset#516,right=RelSubset#517,condition==($0, $2),joinType=inner)]
03/06/2020 13:13:18.248 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#803: Apply rule [FlinkJoinPushExpressionsRule] to [rel#518:FlinkLogicalJoin.LOGICAL.any.None: 0.false.UNKNOWN(left=RelSubset#516,right=RelSubset#517,condition==($0, $2),joinType=inner)]
03/06/2020 13:13:18.248 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#803 generated 0 successors.
03/06/2020 13:13:18.248 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 19/17; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:18.248 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [FlinkJoinPushExpressionsRule] rels [rel#522:FlinkLogicalJoin.LOGICAL.any.None: 0.false.UNKNOWN(left=RelSubset#520,right=RelSubset#521,condition==($0, $3),joinType=inner)]
03/06/2020 13:13:18.257 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#816: Apply rule [FlinkJoinPushExpressionsRule] to [rel#522:FlinkLogicalJoin.LOGICAL.any.None: 0.false.UNKNOWN(left=RelSubset#520,right=RelSubset#521,condition==($0, $3),joinType=inner)]
03/06/2020 13:13:18.258 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#816 generated 0 successors.
03/06/2020 13:13:18.258 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 20/18; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:18.258 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [FilterJoinRule:FilterJoinRule:no-filter] rels [rel#518:FlinkLogicalJoin.LOGICAL.any.None: 0.false.UNKNOWN(left=RelSubset#516,right=RelSubset#517,condition==($0, $2),joinType=inner)]
03/06/2020 13:13:18.259 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#799: Apply rule [FilterJoinRule:FilterJoinRule:no-filter] to [rel#518:FlinkLogicalJoin.LOGICAL.any.None: 0.false.UNKNOWN(left=RelSubset#516,right=RelSubset#517,condition==($0, $2),joinType=inner)]
03/06/2020 13:13:18.259 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#799 generated 0 successors.
03/06/2020 13:13:18.259 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 21/19; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:18.259 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [FilterJoinRule:FilterJoinRule:no-filter] rels [rel#522:FlinkLogicalJoin.LOGICAL.any.None: 0.false.UNKNOWN(left=RelSubset#520,right=RelSubset#521,condition==($0, $3),joinType=inner)]
03/06/2020 13:13:18.259 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#812: Apply rule [FilterJoinRule:FilterJoinRule:no-filter] to [rel#522:FlinkLogicalJoin.LOGICAL.any.None: 0.false.UNKNOWN(left=RelSubset#520,right=RelSubset#521,condition==($0, $3),joinType=inner)]
03/06/2020 13:13:18.259 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#812 generated 0 successors.
03/06/2020 13:13:18.261 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 22/20; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:18.264 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [ProjectToCalcRule] rels [rel#473:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#472,v_id=AS($0, _UTF-16LE'v_id'),degree=AS($1.f1, _UTF-16LE'degree'),bool=AS($1.f0, _UTF-16LE'bool'))]
03/06/2020 13:13:18.264 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#512: Apply rule [ProjectToCalcRule] to [rel#473:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#472,v_id=AS($0, _UTF-16LE'v_id'),degree=AS($1.f1, _UTF-16LE'degree'),bool=AS($1.f0, _UTF-16LE'bool'))]
03/06/2020 13:13:18.266 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#526 via ProjectToCalcRule
03/06/2020 13:13:18.268 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#512 generated 1 successors: [rel#526:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#472,expr#0..1={inputs},expr#2=_UTF-16LE'v_id',expr#3=AS($t0, $t2),expr#4=$t1.f1,expr#5=_UTF-16LE'degree',expr#6=AS($t4, $t5),expr#7=$t1.f0,expr#8=_UTF-16LE'bool',expr#9=AS($t7, $t8),v_id=$t3,degree=$t6,bool=$t9)]
03/06/2020 13:13:18.269 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 23/21; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:18.270 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [ProjectToCalcRule] rels [rel#476:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#475,v_id_2=AS($0, _UTF-16LE'v_id_2'),v_label=AS($1, _UTF-16LE'v_label'),v_id_layout=AS($2, _UTF-16LE'v_id_layout'),X=AS($3, _UTF-16LE'X'),Y=AS($4, _UTF-16LE'Y'))]
03/06/2020 13:13:18.270 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#556: Apply rule [ProjectToCalcRule] to [rel#476:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#475,v_id_2=AS($0, _UTF-16LE'v_id_2'),v_label=AS($1, _UTF-16LE'v_label'),v_id_layout=AS($2, _UTF-16LE'v_id_layout'),X=AS($3, _UTF-16LE'X'),Y=AS($4, _UTF-16LE'Y'))]
03/06/2020 13:13:18.273 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#527 via ProjectToCalcRule
03/06/2020 13:13:18.274 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#556 generated 1 successors: [rel#527:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#475,expr#0..4={inputs},expr#5=_UTF-16LE'v_id_2',expr#6=AS($t0, $t5),expr#7=_UTF-16LE'v_label',expr#8=AS($t1, $t7),expr#9=_UTF-16LE'v_id_layout',expr#10=AS($t2, $t9),expr#11=_UTF-16LE'X',expr#12=AS($t3, $t11),expr#13=_UTF-16LE'Y',expr#14=AS($t4, $t13),v_id_2=$t6,v_label=$t8,v_id_layout=$t10,X=$t12,Y=$t14)]
03/06/2020 13:13:18.274 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 24/22; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:18.274 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [FlinkLogicalDataStreamTableScanConverter(in:NONE,out:LOGICAL)] rels [rel#238:LogicalTableScan.NONE.any.None: 0.false.UNKNOWN(table=[Unregistered_DataStream_9])]
03/06/2020 13:13:18.277 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#528: Apply rule [FlinkLogicalDataStreamTableScanConverter(in:NONE,out:LOGICAL)] to [rel#238:LogicalTableScan.NONE.any.None: 0.false.UNKNOWN(table=[Unregistered_DataStream_9])]
03/06/2020 13:13:18.280 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#528 via FlinkLogicalDataStreamTableScanConverter(in:NONE,out:LOGICAL)
03/06/2020 13:13:18.370 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#528 generated 1 successors: [rel#528:FlinkLogicalDataStreamTableScan.LOGICAL.any.None: 0.false.UNKNOWN(table=[Unregistered_DataStream_9])]
03/06/2020 13:13:18.370 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 25/23; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:18.371 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [rel#526:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#472,expr#0..1={inputs},expr#2=_UTF-16LE'v_id',expr#3=AS($t0, $t2),expr#4=$t1.f1,expr#5=_UTF-16LE'degree',expr#6=AS($t4, $t5),expr#7=$t1.f0,expr#8=_UTF-16LE'bool',expr#9=AS($t7, $t8),v_id=$t3,degree=$t6,bool=$t9)]
03/06/2020 13:13:18.371 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#832: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#526:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#472,expr#0..1={inputs},expr#2=_UTF-16LE'v_id',expr#3=AS($t0, $t2),expr#4=$t1.f1,expr#5=_UTF-16LE'degree',expr#6=AS($t4, $t5),expr#7=$t1.f0,expr#8=_UTF-16LE'bool',expr#9=AS($t7, $t8),v_id=$t3,degree=$t6,bool=$t9)]
03/06/2020 13:13:18.371 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#531 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
03/06/2020 13:13:18.480 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#832 generated 1 successors: [rel#531:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#530,select=v_id, TMP_0.f1 AS degree, TMP_0.f0 AS bool)]
03/06/2020 13:13:18.480 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 26/24; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:18.480 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [rel#527:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#475,expr#0..4={inputs},expr#5=_UTF-16LE'v_id_2',expr#6=AS($t0, $t5),expr#7=_UTF-16LE'v_label',expr#8=AS($t1, $t7),expr#9=_UTF-16LE'v_id_layout',expr#10=AS($t2, $t9),expr#11=_UTF-16LE'X',expr#12=AS($t3, $t11),expr#13=_UTF-16LE'Y',expr#14=AS($t4, $t13),v_id_2=$t6,v_label=$t8,v_id_layout=$t10,X=$t12,Y=$t14)]
03/06/2020 13:13:18.480 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#845: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#527:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#475,expr#0..4={inputs},expr#5=_UTF-16LE'v_id_2',expr#6=AS($t0, $t5),expr#7=_UTF-16LE'v_label',expr#8=AS($t1, $t7),expr#9=_UTF-16LE'v_id_layout',expr#10=AS($t2, $t9),expr#11=_UTF-16LE'X',expr#12=AS($t3, $t11),expr#13=_UTF-16LE'Y',expr#14=AS($t4, $t13),v_id_2=$t6,v_label=$t8,v_id_layout=$t10,X=$t12,Y=$t14)]
03/06/2020 13:13:18.481 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#533 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
03/06/2020 13:13:18.517 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#845 generated 1 successors: [rel#533:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#529,select=f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y)]
03/06/2020 13:13:18.517 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 27/25; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:18.518 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [ProjectFilterTransposeRule] rels [rel#473:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#472,v_id=AS($0, _UTF-16LE'v_id'),degree=AS($1.f1, _UTF-16LE'degree'),bool=AS($1.f0, _UTF-16LE'bool')), rel#471:LogicalFilter.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#470,condition==(AS($1.f0, _UTF-16LE'bool'), _UTF-16LE'true'))]
03/06/2020 13:13:18.518 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#492: Apply rule [ProjectFilterTransposeRule] to [rel#473:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#472,v_id=AS($0, _UTF-16LE'v_id'),degree=AS($1.f1, _UTF-16LE'degree'),bool=AS($1.f0, _UTF-16LE'bool')), rel#471:LogicalFilter.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#470,condition==(AS($1.f0, _UTF-16LE'bool'), _UTF-16LE'true'))]
03/06/2020 13:13:18.521 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#492 generated 0 successors.
03/06/2020 13:13:18.521 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 28/26; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:18.521 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [FilterToCalcRule] rels [rel#471:LogicalFilter.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#470,condition==(AS($1.f0, _UTF-16LE'bool'), _UTF-16LE'true'))]
03/06/2020 13:13:18.522 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#480: Apply rule [FilterToCalcRule] to [rel#471:LogicalFilter.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#470,condition==(AS($1.f0, _UTF-16LE'bool'), _UTF-16LE'true'))]
03/06/2020 13:13:18.523 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#535 via FilterToCalcRule
03/06/2020 13:13:18.532 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#480 generated 1 successors: [rel#535:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#470,expr#0..1={inputs},expr#2=$t1.f0,expr#3=_UTF-16LE'bool',expr#4=AS($t2, $t3),expr#5=_UTF-16LE'true',expr#6==($t4, $t5),v_id=$t0,TMP_0=$t1,$condition=$t6)]
03/06/2020 13:13:18.532 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 29/27; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:18.533 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [FlinkCalcMergeRule] rels [rel#526:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#472,expr#0..1={inputs},expr#2=_UTF-16LE'v_id',expr#3=AS($t0, $t2),expr#4=$t1.f1,expr#5=_UTF-16LE'degree',expr#6=AS($t4, $t5),expr#7=$t1.f0,expr#8=_UTF-16LE'bool',expr#9=AS($t7, $t8),v_id=$t3,degree=$t6,bool=$t9), rel#535:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#470,expr#0..1={inputs},expr#2=$t1.f0,expr#3=_UTF-16LE'bool',expr#4=AS($t2, $t3),expr#5=_UTF-16LE'true',expr#6==($t4, $t5),v_id=$t0,TMP_0=$t1,$condition=$t6)]
03/06/2020 13:13:18.533 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#883: Apply rule [FlinkCalcMergeRule] to [rel#526:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#472,expr#0..1={inputs},expr#2=_UTF-16LE'v_id',expr#3=AS($t0, $t2),expr#4=$t1.f1,expr#5=_UTF-16LE'degree',expr#6=AS($t4, $t5),expr#7=$t1.f0,expr#8=_UTF-16LE'bool',expr#9=AS($t7, $t8),v_id=$t3,degree=$t6,bool=$t9), rel#535:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#470,expr#0..1={inputs},expr#2=$t1.f0,expr#3=_UTF-16LE'bool',expr#4=AS($t2, $t3),expr#5=_UTF-16LE'true',expr#6==($t4, $t5),v_id=$t0,TMP_0=$t1,$condition=$t6)]
03/06/2020 13:13:18.540 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#536 via FlinkCalcMergeRule
03/06/2020 13:13:18.543 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#883 generated 1 successors: [rel#536:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#470,expr#0..1={inputs},expr#2=_UTF-16LE'v_id',expr#3=AS($t0, $t2),expr#4=$t1.f1,expr#5=_UTF-16LE'degree',expr#6=AS($t4, $t5),expr#7=$t1.f0,expr#8=_UTF-16LE'bool',expr#9=AS($t7, $t8),expr#10=_UTF-16LE'true',expr#11==($t9, $t10),v_id=$t3,degree=$t6,bool=$t9,$condition=$t11)]
03/06/2020 13:13:18.543 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 30/28; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:18.543 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [rel#536:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#470,expr#0..1={inputs},expr#2=_UTF-16LE'v_id',expr#3=AS($t0, $t2),expr#4=$t1.f1,expr#5=_UTF-16LE'degree',expr#6=AS($t4, $t5),expr#7=$t1.f0,expr#8=_UTF-16LE'bool',expr#9=AS($t7, $t8),expr#10=_UTF-16LE'true',expr#11==($t9, $t10),v_id=$t3,degree=$t6,bool=$t9,$condition=$t11)]
03/06/2020 13:13:18.543 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#898: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#536:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#470,expr#0..1={inputs},expr#2=_UTF-16LE'v_id',expr#3=AS($t0, $t2),expr#4=$t1.f1,expr#5=_UTF-16LE'degree',expr#6=AS($t4, $t5),expr#7=$t1.f0,expr#8=_UTF-16LE'bool',expr#9=AS($t7, $t8),expr#10=_UTF-16LE'true',expr#11==($t9, $t10),v_id=$t3,degree=$t6,bool=$t9,$condition=$t11)]
03/06/2020 13:13:18.546 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#538 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
03/06/2020 13:13:18.556 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#898 generated 1 successors: [rel#538:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#537,select=v_id, TMP_0.f1 AS degree, TMP_0.f0 AS bool,where==(TMP_0.f0, _UTF-16LE'true'))]
03/06/2020 13:13:18.557 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 31/29; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:18.557 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [ProjectCalcMergeRule] rels [rel#473:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#472,v_id=AS($0, _UTF-16LE'v_id'),degree=AS($1.f1, _UTF-16LE'degree'),bool=AS($1.f0, _UTF-16LE'bool')), rel#535:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#470,expr#0..1={inputs},expr#2=$t1.f0,expr#3=_UTF-16LE'bool',expr#4=AS($t2, $t3),expr#5=_UTF-16LE'true',expr#6==($t4, $t5),v_id=$t0,TMP_0=$t1,$condition=$t6)]
03/06/2020 13:13:18.565 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#880: Apply rule [ProjectCalcMergeRule] to [rel#473:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#472,v_id=AS($0, _UTF-16LE'v_id'),degree=AS($1.f1, _UTF-16LE'degree'),bool=AS($1.f0, _UTF-16LE'bool')), rel#535:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#470,expr#0..1={inputs},expr#2=$t1.f0,expr#3=_UTF-16LE'bool',expr#4=AS($t2, $t3),expr#5=_UTF-16LE'true',expr#6==($t4, $t5),v_id=$t0,TMP_0=$t1,$condition=$t6)]
03/06/2020 13:13:18.573 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#540 via ProjectCalcMergeRule
03/06/2020 13:13:18.573 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#880 generated 1 successors: [rel#540:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#470,expr#0..1={inputs},expr#2=_UTF-16LE'v_id',expr#3=AS($t0, $t2),expr#4=$t1.f1,expr#5=_UTF-16LE'degree',expr#6=AS($t4, $t5),expr#7=$t1.f0,expr#8=_UTF-16LE'bool',expr#9=AS($t7, $t8),expr#10=_UTF-16LE'true',expr#11==($t9, $t10),v_id=$t3,degree=$t6,bool=$t9,$condition=$t11)]
03/06/2020 13:13:18.575 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 32/30; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:18.575 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [rel#535:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#470,expr#0..1={inputs},expr#2=$t1.f0,expr#3=_UTF-16LE'bool',expr#4=AS($t2, $t3),expr#5=_UTF-16LE'true',expr#6==($t4, $t5),v_id=$t0,TMP_0=$t1,$condition=$t6)]
03/06/2020 13:13:18.575 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#885: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#535:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#470,expr#0..1={inputs},expr#2=$t1.f0,expr#3=_UTF-16LE'bool',expr#4=AS($t2, $t3),expr#5=_UTF-16LE'true',expr#6==($t4, $t5),v_id=$t0,TMP_0=$t1,$condition=$t6)]
03/06/2020 13:13:18.575 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#541 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
03/06/2020 13:13:18.586 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#885 generated 1 successors: [rel#541:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#537,select=v_id, TMP_0,where==(TMP_0.f0, _UTF-16LE'true'))]
03/06/2020 13:13:18.587 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 33/31; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:18.588 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)] rels [rel#469:LogicalAggregate.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#468,group={1},TMP_0=CurrentVertex($0, $1, $2))]
03/06/2020 13:13:18.588 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#443: Apply rule [FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)] to [rel#469:LogicalAggregate.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#468,group={1},TMP_0=CurrentVertex($0, $1, $2))]
03/06/2020 13:13:18.596 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#544 via FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)
03/06/2020 13:13:18.755 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#443 generated 1 successors: [rel#544:FlinkLogicalAggregate.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#543,group={1},TMP_0=CurrentVertex($0, $1, $2))]
03/06/2020 13:13:18.758 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 34/32; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:18.759 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [FilterAggregateTransposeRule] rels [rel#471:LogicalFilter.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#470,condition==(AS($1.f0, _UTF-16LE'bool'), _UTF-16LE'true')), rel#469:LogicalAggregate.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#468,group={1},TMP_0=CurrentVertex($0, $1, $2))]
03/06/2020 13:13:18.759 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#471: Apply rule [FilterAggregateTransposeRule] to [rel#471:LogicalFilter.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#470,condition==(AS($1.f0, _UTF-16LE'bool'), _UTF-16LE'true')), rel#469:LogicalAggregate.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#468,group={1},TMP_0=CurrentVertex($0, $1, $2))]
03/06/2020 13:13:18.760 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#471 generated 0 successors.
03/06/2020 13:13:18.760 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 35/33; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:18.760 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [AggregateProjectPullUpConstantsRule] rels [rel#469:LogicalAggregate.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#468,group={1},TMP_0=CurrentVertex($0, $1, $2)), rel#467:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#466,bool=AS($0, _UTF-16LE'bool'),v_id=AS($1, _UTF-16LE'v_id'),degree=AS($2, _UTF-16LE'degree'))]
03/06/2020 13:13:18.762 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#453: Apply rule [AggregateProjectPullUpConstantsRule] to [rel#469:LogicalAggregate.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#468,group={1},TMP_0=CurrentVertex($0, $1, $2)), rel#467:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#466,bool=AS($0, _UTF-16LE'bool'),v_id=AS($1, _UTF-16LE'v_id'),degree=AS($2, _UTF-16LE'degree'))]
03/06/2020 13:13:18.762 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#453 generated 0 successors.
03/06/2020 13:13:18.762 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 36/34; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:18.763 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [AggregateProjectMergeRule] rels [rel#469:LogicalAggregate.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#468,group={1},TMP_0=CurrentVertex($0, $1, $2)), rel#467:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#466,bool=AS($0, _UTF-16LE'bool'),v_id=AS($1, _UTF-16LE'v_id'),degree=AS($2, _UTF-16LE'degree'))]
03/06/2020 13:13:18.765 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#439: Apply rule [AggregateProjectMergeRule] to [rel#469:LogicalAggregate.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#468,group={1},TMP_0=CurrentVertex($0, $1, $2)), rel#467:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#466,bool=AS($0, _UTF-16LE'bool'),v_id=AS($1, _UTF-16LE'v_id'),degree=AS($2, _UTF-16LE'degree'))]
03/06/2020 13:13:18.765 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#439 generated 0 successors.
03/06/2020 13:13:18.765 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 37/35; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:18.765 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [FlinkCalcMergeRule] rels [rel#531:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#530,select=v_id, TMP_0.f1 AS degree, TMP_0.f0 AS bool), rel#541:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#537,select=v_id, TMP_0,where==(TMP_0.f0, _UTF-16LE'true'))]
03/06/2020 13:13:18.765 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#915: Apply rule [FlinkCalcMergeRule] to [rel#531:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#530,select=v_id, TMP_0.f1 AS degree, TMP_0.f0 AS bool), rel#541:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#537,select=v_id, TMP_0,where==(TMP_0.f0, _UTF-16LE'true'))]
03/06/2020 13:13:18.774 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#545 via FlinkCalcMergeRule
03/06/2020 13:13:18.781 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#915 generated 1 successors: [rel#545:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#537,select=v_id, TMP_0.f1 AS degree, TMP_0.f0 AS bool,where==(TMP_0.f0, _UTF-16LE'true'))]
03/06/2020 13:13:18.781 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 38/36; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:18.781 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [ProjectToCalcRule] rels [rel#467:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#466,bool=AS($0, _UTF-16LE'bool'),v_id=AS($1, _UTF-16LE'v_id'),degree=AS($2, _UTF-16LE'degree'))]
03/06/2020 13:13:18.781 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#431: Apply rule [ProjectToCalcRule] to [rel#467:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#466,bool=AS($0, _UTF-16LE'bool'),v_id=AS($1, _UTF-16LE'v_id'),degree=AS($2, _UTF-16LE'degree'))]
03/06/2020 13:13:18.782 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#546 via ProjectToCalcRule
03/06/2020 13:13:18.783 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#431 generated 1 successors: [rel#546:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#466,expr#0..2={inputs},expr#3=_UTF-16LE'bool',expr#4=AS($t0, $t3),expr#5=_UTF-16LE'v_id',expr#6=AS($t1, $t5),expr#7=_UTF-16LE'degree',expr#8=AS($t2, $t7),bool=$t4,v_id=$t6,degree=$t8)]
03/06/2020 13:13:18.783 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 39/37; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:18.783 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [rel#546:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#466,expr#0..2={inputs},expr#3=_UTF-16LE'bool',expr#4=AS($t0, $t3),expr#5=_UTF-16LE'v_id',expr#6=AS($t1, $t5),expr#7=_UTF-16LE'degree',expr#8=AS($t2, $t7),bool=$t4,v_id=$t6,degree=$t8)]
03/06/2020 13:13:18.783 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#937: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#546:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#466,expr#0..2={inputs},expr#3=_UTF-16LE'bool',expr#4=AS($t0, $t3),expr#5=_UTF-16LE'v_id',expr#6=AS($t1, $t5),expr#7=_UTF-16LE'degree',expr#8=AS($t2, $t7),bool=$t4,v_id=$t6,degree=$t8)]
03/06/2020 13:13:18.783 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#548 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
03/06/2020 13:13:18.814 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#937 generated 1 successors: [rel#548:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#547,select=f0 AS bool, f1 AS v_id, f2 AS degree)]
03/06/2020 13:13:18.823 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 40/38; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:18.823 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [FlinkLogicalDataStreamTableScanConverter(in:NONE,out:LOGICAL)] rels [rel#231:LogicalTableScan.NONE.any.None: 0.false.UNKNOWN(table=[Unregistered_DataStream_8])]
03/06/2020 13:13:18.823 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#403: Apply rule [FlinkLogicalDataStreamTableScanConverter(in:NONE,out:LOGICAL)] to [rel#231:LogicalTableScan.NONE.any.None: 0.false.UNKNOWN(table=[Unregistered_DataStream_8])]
03/06/2020 13:13:18.824 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#549 via FlinkLogicalDataStreamTableScanConverter(in:NONE,out:LOGICAL)
03/06/2020 13:13:19.047 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#403 generated 1 successors: [rel#549:FlinkLogicalDataStreamTableScan.LOGICAL.any.None: 0.false.UNKNOWN(table=[Unregistered_DataStream_8])]
03/06/2020 13:13:19.055 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 41/39; PHASE = OPTIMIZE; COST = {5.3299972766842544E8 rows, 1.3309994553368511E9 cpu, 1.2553995098031658E10 io, 0.0 network, 0.0 memory}
03/06/2020 13:13:19.067 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [ProjectToCalcRule] rels [rel#491:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#474,v_id=$0,degree=$1)]
03/06/2020 13:13:19.068 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#664: Apply rule [ProjectToCalcRule] to [rel#491:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#474,v_id=$0,degree=$1)]
03/06/2020 13:13:19.068 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#550 via ProjectToCalcRule
03/06/2020 13:13:19.069 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#664 generated 1 successors: [rel#550:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#474,expr#0..2={inputs},v_id=$t0,degree=$t1)]
03/06/2020 13:13:19.069 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 42/40; PHASE = OPTIMIZE; COST = {5.3299972766842544E8 rows, 1.3309994553368511E9 cpu, 1.2553995098031658E10 io, 0.0 network, 0.0 memory}
03/06/2020 13:13:19.070 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [FlinkCalcMergeRule] rels [rel#550:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#474,expr#0..2={inputs},v_id=$t0,degree=$t1), rel#536:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#470,expr#0..1={inputs},expr#2=_UTF-16LE'v_id',expr#3=AS($t0, $t2),expr#4=$t1.f1,expr#5=_UTF-16LE'degree',expr#6=AS($t4, $t5),expr#7=$t1.f0,expr#8=_UTF-16LE'bool',expr#9=AS($t7, $t8),expr#10=_UTF-16LE'true',expr#11==($t9, $t10),v_id=$t3,degree=$t6,bool=$t9,$condition=$t11)]
03/06/2020 13:13:19.070 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#961: Apply rule [FlinkCalcMergeRule] to [rel#550:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#474,expr#0..2={inputs},v_id=$t0,degree=$t1), rel#536:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#470,expr#0..1={inputs},expr#2=_UTF-16LE'v_id',expr#3=AS($t0, $t2),expr#4=$t1.f1,expr#5=_UTF-16LE'degree',expr#6=AS($t4, $t5),expr#7=$t1.f0,expr#8=_UTF-16LE'bool',expr#9=AS($t7, $t8),expr#10=_UTF-16LE'true',expr#11==($t9, $t10),v_id=$t3,degree=$t6,bool=$t9,$condition=$t11)]
03/06/2020 13:13:19.081 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#551 via FlinkCalcMergeRule
03/06/2020 13:13:19.086 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#961 generated 1 successors: [rel#551:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#470,expr#0..1={inputs},expr#2=_UTF-16LE'v_id',expr#3=AS($t0, $t2),expr#4=$t1.f1,expr#5=_UTF-16LE'degree',expr#6=AS($t4, $t5),expr#7=$t1.f0,expr#8=_UTF-16LE'bool',expr#9=AS($t7, $t8),expr#10=_UTF-16LE'true',expr#11==($t9, $t10),v_id=$t3,degree=$t6,$condition=$t11)]
03/06/2020 13:13:19.087 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 43/41; PHASE = OPTIMIZE; COST = {5.3299972766842544E8 rows, 1.3309994553368511E9 cpu, 1.2553995098031658E10 io, 0.0 network, 0.0 memory}
03/06/2020 13:13:19.091 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [FlinkCalcMergeRule] rels [rel#550:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#474,expr#0..2={inputs},v_id=$t0,degree=$t1), rel#526:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#472,expr#0..1={inputs},expr#2=_UTF-16LE'v_id',expr#3=AS($t0, $t2),expr#4=$t1.f1,expr#5=_UTF-16LE'degree',expr#6=AS($t4, $t5),expr#7=$t1.f0,expr#8=_UTF-16LE'bool',expr#9=AS($t7, $t8),v_id=$t3,degree=$t6,bool=$t9)]
03/06/2020 13:13:19.092 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#960: Apply rule [FlinkCalcMergeRule] to [rel#550:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#474,expr#0..2={inputs},v_id=$t0,degree=$t1), rel#526:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#472,expr#0..1={inputs},expr#2=_UTF-16LE'v_id',expr#3=AS($t0, $t2),expr#4=$t1.f1,expr#5=_UTF-16LE'degree',expr#6=AS($t4, $t5),expr#7=$t1.f0,expr#8=_UTF-16LE'bool',expr#9=AS($t7, $t8),v_id=$t3,degree=$t6,bool=$t9)]
03/06/2020 13:13:19.118 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#552 via FlinkCalcMergeRule
03/06/2020 13:13:19.122 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#960 generated 1 successors: [rel#552:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#472,expr#0..1={inputs},expr#2=_UTF-16LE'v_id',expr#3=AS($t0, $t2),expr#4=$t1.f1,expr#5=_UTF-16LE'degree',expr#6=AS($t4, $t5),v_id=$t3,degree=$t6)]
03/06/2020 13:13:19.124 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 44/42; PHASE = OPTIMIZE; COST = {5.3299972766842544E8 rows, 1.3309994553368511E9 cpu, 1.2553995098031658E10 io, 0.0 network, 0.0 memory}
03/06/2020 13:13:19.128 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [FlinkCalcMergeRule] rels [rel#552:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#472,expr#0..1={inputs},expr#2=_UTF-16LE'v_id',expr#3=AS($t0, $t2),expr#4=$t1.f1,expr#5=_UTF-16LE'degree',expr#6=AS($t4, $t5),v_id=$t3,degree=$t6), rel#535:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#470,expr#0..1={inputs},expr#2=$t1.f0,expr#3=_UTF-16LE'bool',expr#4=AS($t2, $t3),expr#5=_UTF-16LE'true',expr#6==($t4, $t5),v_id=$t0,TMP_0=$t1,$condition=$t6)]
03/06/2020 13:13:19.132 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#986: Apply rule [FlinkCalcMergeRule] to [rel#552:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#472,expr#0..1={inputs},expr#2=_UTF-16LE'v_id',expr#3=AS($t0, $t2),expr#4=$t1.f1,expr#5=_UTF-16LE'degree',expr#6=AS($t4, $t5),v_id=$t3,degree=$t6), rel#535:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#470,expr#0..1={inputs},expr#2=$t1.f0,expr#3=_UTF-16LE'bool',expr#4=AS($t2, $t3),expr#5=_UTF-16LE'true',expr#6==($t4, $t5),v_id=$t0,TMP_0=$t1,$condition=$t6)]
03/06/2020 13:13:19.136 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#553 via FlinkCalcMergeRule
03/06/2020 13:13:19.141 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#986 generated 1 successors: [rel#553:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#470,expr#0..1={inputs},expr#2=_UTF-16LE'v_id',expr#3=AS($t0, $t2),expr#4=$t1.f1,expr#5=_UTF-16LE'degree',expr#6=AS($t4, $t5),expr#7=$t1.f0,expr#8=_UTF-16LE'bool',expr#9=AS($t7, $t8),expr#10=_UTF-16LE'true',expr#11==($t9, $t10),v_id=$t3,degree=$t6,$condition=$t11)]
03/06/2020 13:13:19.142 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 45/43; PHASE = OPTIMIZE; COST = {5.3299972766842544E8 rows, 1.3309994553368511E9 cpu, 1.2553995098031658E10 io, 0.0 network, 0.0 memory}
03/06/2020 13:13:19.147 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [rel#552:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#472,expr#0..1={inputs},expr#2=_UTF-16LE'v_id',expr#3=AS($t0, $t2),expr#4=$t1.f1,expr#5=_UTF-16LE'degree',expr#6=AS($t4, $t5),v_id=$t3,degree=$t6)]
03/06/2020 13:13:19.147 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#989: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#552:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#472,expr#0..1={inputs},expr#2=_UTF-16LE'v_id',expr#3=AS($t0, $t2),expr#4=$t1.f1,expr#5=_UTF-16LE'degree',expr#6=AS($t4, $t5),v_id=$t3,degree=$t6)]
03/06/2020 13:13:19.147 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#554 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
03/06/2020 13:13:19.158 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#989 generated 1 successors: [rel#554:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#530,select=v_id, TMP_0.f1 AS degree)]
03/06/2020 13:13:19.158 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 46/44; PHASE = OPTIMIZE; COST = {5.3299972766842544E8 rows, 1.3309994553368511E9 cpu, 1.2553995098031658E10 io, 0.0 network, 0.0 memory}
03/06/2020 13:13:19.159 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [rel#551:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#470,expr#0..1={inputs},expr#2=_UTF-16LE'v_id',expr#3=AS($t0, $t2),expr#4=$t1.f1,expr#5=_UTF-16LE'degree',expr#6=AS($t4, $t5),expr#7=$t1.f0,expr#8=_UTF-16LE'bool',expr#9=AS($t7, $t8),expr#10=_UTF-16LE'true',expr#11==($t9, $t10),v_id=$t3,degree=$t6,$condition=$t11)]
03/06/2020 13:13:19.159 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#976: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#551:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#470,expr#0..1={inputs},expr#2=_UTF-16LE'v_id',expr#3=AS($t0, $t2),expr#4=$t1.f1,expr#5=_UTF-16LE'degree',expr#6=AS($t4, $t5),expr#7=$t1.f0,expr#8=_UTF-16LE'bool',expr#9=AS($t7, $t8),expr#10=_UTF-16LE'true',expr#11==($t9, $t10),v_id=$t3,degree=$t6,$condition=$t11)]
03/06/2020 13:13:19.159 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#555 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
03/06/2020 13:13:19.165 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#976 generated 1 successors: [rel#555:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#537,select=v_id, TMP_0.f1 AS degree,where==(TMP_0.f0, _UTF-16LE'true'))]
03/06/2020 13:13:19.171 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 47/45; PHASE = OPTIMIZE; COST = {5.3299972766842544E8 rows, 1.3309994553368511E9 cpu, 1.2553995098031658E10 io, 0.0 network, 0.0 memory}
03/06/2020 13:13:19.172 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [rel#550:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#474,expr#0..2={inputs},v_id=$t0,degree=$t1)]
03/06/2020 13:13:19.172 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#964: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#550:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#474,expr#0..2={inputs},v_id=$t0,degree=$t1)]
03/06/2020 13:13:19.174 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#556 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
03/06/2020 13:13:19.181 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#964 generated 1 successors: [rel#556:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#520,select=v_id, degree)]
03/06/2020 13:13:19.182 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 48/46; PHASE = OPTIMIZE; COST = {5.3299972766842544E8 rows, 1.3309994553368511E9 cpu, 1.2553995098031658E10 io, 0.0 network, 0.0 memory}
03/06/2020 13:13:19.182 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [ProjectToCalcRule] rels [rel#492:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#477,v_id_2=$0,v_label=$1,v_id_layout=$2,X=$3,Y=$4)]
03/06/2020 13:13:19.182 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#695: Apply rule [ProjectToCalcRule] to [rel#492:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#477,v_id_2=$0,v_label=$1,v_id_layout=$2,X=$3,Y=$4)]
03/06/2020 13:13:19.185 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#557 via ProjectToCalcRule
03/06/2020 13:13:19.198 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#695 generated 1 successors: [rel#557:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#477,expr#0..4={inputs},v_id_2=$t0,v_label=$t1,v_id_layout=$t2,X=$t3,Y=$t4)]
03/06/2020 13:13:19.201 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 49/47; PHASE = OPTIMIZE; COST = {5.3299972766842544E8 rows, 1.3309994553368511E9 cpu, 1.2553995098031658E10 io, 0.0 network, 0.0 memory}
03/06/2020 13:13:19.202 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [FlinkCalcMergeRule] rels [rel#557:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#477,expr#0..4={inputs},v_id_2=$t0,v_label=$t1,v_id_layout=$t2,X=$t3,Y=$t4), rel#527:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#475,expr#0..4={inputs},expr#5=_UTF-16LE'v_id_2',expr#6=AS($t0, $t5),expr#7=_UTF-16LE'v_label',expr#8=AS($t1, $t7),expr#9=_UTF-16LE'v_id_layout',expr#10=AS($t2, $t9),expr#11=_UTF-16LE'X',expr#12=AS($t3, $t11),expr#13=_UTF-16LE'Y',expr#14=AS($t4, $t13),v_id_2=$t6,v_label=$t8,v_id_layout=$t10,X=$t12,Y=$t14)]
03/06/2020 13:13:19.207 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1026: Apply rule [FlinkCalcMergeRule] to [rel#557:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#477,expr#0..4={inputs},v_id_2=$t0,v_label=$t1,v_id_layout=$t2,X=$t3,Y=$t4), rel#527:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#475,expr#0..4={inputs},expr#5=_UTF-16LE'v_id_2',expr#6=AS($t0, $t5),expr#7=_UTF-16LE'v_label',expr#8=AS($t1, $t7),expr#9=_UTF-16LE'v_id_layout',expr#10=AS($t2, $t9),expr#11=_UTF-16LE'X',expr#12=AS($t3, $t11),expr#13=_UTF-16LE'Y',expr#14=AS($t4, $t13),v_id_2=$t6,v_label=$t8,v_id_layout=$t10,X=$t12,Y=$t14)]
03/06/2020 13:13:19.210 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#558 via FlinkCalcMergeRule
03/06/2020 13:13:19.222 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1026 generated 1 successors: [rel#558:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#475,expr#0..4={inputs},expr#5=_UTF-16LE'v_id_2',expr#6=AS($t0, $t5),expr#7=_UTF-16LE'v_label',expr#8=AS($t1, $t7),expr#9=_UTF-16LE'v_id_layout',expr#10=AS($t2, $t9),expr#11=_UTF-16LE'X',expr#12=AS($t3, $t11),expr#13=_UTF-16LE'Y',expr#14=AS($t4, $t13),v_id_2=$t6,v_label=$t8,v_id_layout=$t10,X=$t12,Y=$t14)]
03/06/2020 13:13:19.223 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 50/48; PHASE = OPTIMIZE; COST = {5.3299972766842544E8 rows, 1.3294995915026383E9 cpu, 1.2535996732021107E10 io, 0.0 network, 0.0 memory}
03/06/2020 13:13:19.256 DEBUG [org.apache.calcite.plan.RelOptPlanner] Skip match: rule [FlinkCalcMergeRule] rels [rel#557:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#477,expr#0..4={inputs},v_id_2=$t0,v_label=$t1,v_id_layout=$t2,X=$t3,Y=$t4), rel#557:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#477,expr#0..4={inputs},v_id_2=$t0,v_label=$t1,v_id_layout=$t2,X=$t3,Y=$t4)]
03/06/2020 13:13:19.256 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] rels [rel#557:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#477,expr#0..4={inputs},v_id_2=$t0,v_label=$t1,v_id_layout=$t2,X=$t3,Y=$t4)]
03/06/2020 13:13:19.256 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1029: Apply rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)] to [rel#557:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#477,expr#0..4={inputs},v_id_2=$t0,v_label=$t1,v_id_layout=$t2,X=$t3,Y=$t4)]
03/06/2020 13:13:19.257 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#559 via FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)
03/06/2020 13:13:19.258 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1029 generated 1 successors: [rel#559:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#521,select=v_id_2, v_label, v_id_layout, X, Y)]
03/06/2020 13:13:19.258 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 51/49; PHASE = OPTIMIZE; COST = {5.3299972766842544E8 rows, 1.3294995915026383E9 cpu, 1.2535996732021107E10 io, 0.0 network, 0.0 memory}
03/06/2020 13:13:19.258 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [ProjectRemoveRule] rels [rel#492:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#477,v_id_2=$0,v_label=$1,v_id_layout=$2,X=$3,Y=$4)]
03/06/2020 13:13:19.258 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#679: Apply rule [ProjectRemoveRule] to [rel#492:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#477,v_id_2=$0,v_label=$1,v_id_layout=$2,X=$3,Y=$4)]
03/06/2020 13:13:19.258 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#477 via ProjectRemoveRule
03/06/2020 13:13:19.258 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#679 generated 1 successors: [rel#477:Subset#16.NONE.any.None: 0.false.UNKNOWN]
03/06/2020 13:13:19.258 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 52/50; PHASE = OPTIMIZE; COST = {5.3299972766842544E8 rows, 1.3294995915026383E9 cpu, 1.2535996732021107E10 io, 0.0 network, 0.0 memory}
03/06/2020 13:13:19.258 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [ProjectMergeRule:force_mode] rels [rel#491:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#474,v_id=$0,degree=$1), rel#473:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#472,v_id=AS($0, _UTF-16LE'v_id'),degree=AS($1.f1, _UTF-16LE'degree'),bool=AS($1.f0, _UTF-16LE'bool'))]
03/06/2020 13:13:19.258 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#647: Apply rule [ProjectMergeRule:force_mode] to [rel#491:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#474,v_id=$0,degree=$1), rel#473:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#472,v_id=AS($0, _UTF-16LE'v_id'),degree=AS($1.f1, _UTF-16LE'degree'),bool=AS($1.f0, _UTF-16LE'bool'))]
03/06/2020 13:13:19.259 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#560 via ProjectMergeRule:force_mode
03/06/2020 13:13:19.259 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#647 generated 1 successors: [rel#560:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#472,v_id=AS($0, _UTF-16LE'v_id'),degree=AS($1.f1, _UTF-16LE'degree'))]
03/06/2020 13:13:19.259 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 53/51; PHASE = OPTIMIZE; COST = {5.3299972766842544E8 rows, 1.3294995915026383E9 cpu, 1.2535996732021107E10 io, 0.0 network, 0.0 memory}
03/06/2020 13:13:19.260 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [ProjectToCalcRule] rels [rel#560:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#472,v_id=AS($0, _UTF-16LE'v_id'),degree=AS($1.f1, _UTF-16LE'degree'))]
03/06/2020 13:13:19.260 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1156: Apply rule [ProjectToCalcRule] to [rel#560:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#472,v_id=AS($0, _UTF-16LE'v_id'),degree=AS($1.f1, _UTF-16LE'degree'))]
03/06/2020 13:13:19.260 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#561 via ProjectToCalcRule
03/06/2020 13:13:19.260 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1156 generated 1 successors: [rel#561:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#472,expr#0..1={inputs},expr#2=_UTF-16LE'v_id',expr#3=AS($t0, $t2),expr#4=$t1.f1,expr#5=_UTF-16LE'degree',expr#6=AS($t4, $t5),v_id=$t3,degree=$t6)]
03/06/2020 13:13:19.260 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 54/52; PHASE = OPTIMIZE; COST = {5.3299972766842544E8 rows, 1.3294995915026383E9 cpu, 1.2535996732021107E10 io, 0.0 network, 0.0 memory}
03/06/2020 13:13:19.260 DEBUG [org.apache.calcite.plan.RelOptPlanner] Skip match: rule [ProjectMergeRule:force_mode] rels [rel#492:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#477,v_id_2=$0,v_label=$1,v_id_layout=$2,X=$3,Y=$4), rel#492:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#477,v_id_2=$0,v_label=$1,v_id_layout=$2,X=$3,Y=$4)]
03/06/2020 13:13:19.268 DEBUG [org.apache.calcite.plan.RelOptPlanner] Skip match: rule [ProjectMergeRule:force_mode] rels [rel#492:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#477,v_id_2=$0,v_label=$1,v_id_layout=$2,X=$3,Y=$4), rel#476:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#475,v_id_2=AS($0, _UTF-16LE'v_id_2'),v_label=AS($1, _UTF-16LE'v_label'),v_id_layout=AS($2, _UTF-16LE'v_id_layout'),X=AS($3, _UTF-16LE'X'),Y=AS($4, _UTF-16LE'Y'))]
03/06/2020 13:13:19.268 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [ProjectFilterTransposeRule] rels [rel#560:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#472,v_id=AS($0, _UTF-16LE'v_id'),degree=AS($1.f1, _UTF-16LE'degree')), rel#471:LogicalFilter.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#470,condition==(AS($1.f0, _UTF-16LE'bool'), _UTF-16LE'true'))]
03/06/2020 13:13:19.268 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1135: Apply rule [ProjectFilterTransposeRule] to [rel#560:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#472,v_id=AS($0, _UTF-16LE'v_id'),degree=AS($1.f1, _UTF-16LE'degree')), rel#471:LogicalFilter.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#470,condition==(AS($1.f0, _UTF-16LE'bool'), _UTF-16LE'true'))]
03/06/2020 13:13:19.271 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1135 generated 0 successors.
03/06/2020 13:13:19.271 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 55/53; PHASE = OPTIMIZE; COST = {5.3299972766842544E8 rows, 1.3294995915026383E9 cpu, 1.2535996732021107E10 io, 0.0 network, 0.0 memory}
03/06/2020 13:13:19.271 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [ProjectCalcMergeRule] rels [rel#560:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#472,v_id=AS($0, _UTF-16LE'v_id'),degree=AS($1.f1, _UTF-16LE'degree')), rel#535:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#470,expr#0..1={inputs},expr#2=$t1.f0,expr#3=_UTF-16LE'bool',expr#4=AS($t2, $t3),expr#5=_UTF-16LE'true',expr#6==($t4, $t5),v_id=$t0,TMP_0=$t1,$condition=$t6)]
03/06/2020 13:13:19.271 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1154: Apply rule [ProjectCalcMergeRule] to [rel#560:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#472,v_id=AS($0, _UTF-16LE'v_id'),degree=AS($1.f1, _UTF-16LE'degree')), rel#535:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#470,expr#0..1={inputs},expr#2=$t1.f0,expr#3=_UTF-16LE'bool',expr#4=AS($t2, $t3),expr#5=_UTF-16LE'true',expr#6==($t4, $t5),v_id=$t0,TMP_0=$t1,$condition=$t6)]
03/06/2020 13:13:19.285 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#562 via ProjectCalcMergeRule
03/06/2020 13:13:19.287 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1154 generated 1 successors: [rel#562:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#470,expr#0..1={inputs},expr#2=_UTF-16LE'v_id',expr#3=AS($t0, $t2),expr#4=$t1.f1,expr#5=_UTF-16LE'degree',expr#6=AS($t4, $t5),expr#7=$t1.f0,expr#8=_UTF-16LE'bool',expr#9=AS($t7, $t8),expr#10=_UTF-16LE'true',expr#11==($t9, $t10),v_id=$t3,degree=$t6,$condition=$t11)]
03/06/2020 13:13:19.291 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 56/54; PHASE = OPTIMIZE; COST = {5.3299972766842544E8 rows, 1.3294995915026383E9 cpu, 1.2535996732021107E10 io, 0.0 network, 0.0 memory}
03/06/2020 13:13:19.291 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [ProjectCalcMergeRule] rels [rel#491:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#474,v_id=$0,degree=$1), rel#536:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#470,expr#0..1={inputs},expr#2=_UTF-16LE'v_id',expr#3=AS($t0, $t2),expr#4=$t1.f1,expr#5=_UTF-16LE'degree',expr#6=AS($t4, $t5),expr#7=$t1.f0,expr#8=_UTF-16LE'bool',expr#9=AS($t7, $t8),expr#10=_UTF-16LE'true',expr#11==($t9, $t10),v_id=$t3,degree=$t6,bool=$t9,$condition=$t11)]
03/06/2020 13:13:19.292 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#894: Apply rule [ProjectCalcMergeRule] to [rel#491:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#474,v_id=$0,degree=$1), rel#536:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#470,expr#0..1={inputs},expr#2=_UTF-16LE'v_id',expr#3=AS($t0, $t2),expr#4=$t1.f1,expr#5=_UTF-16LE'degree',expr#6=AS($t4, $t5),expr#7=$t1.f0,expr#8=_UTF-16LE'bool',expr#9=AS($t7, $t8),expr#10=_UTF-16LE'true',expr#11==($t9, $t10),v_id=$t3,degree=$t6,bool=$t9,$condition=$t11)]
03/06/2020 13:13:19.292 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#563 via ProjectCalcMergeRule
03/06/2020 13:13:19.292 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#894 generated 1 successors: [rel#563:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#470,expr#0..1={inputs},expr#2=_UTF-16LE'v_id',expr#3=AS($t0, $t2),expr#4=$t1.f1,expr#5=_UTF-16LE'degree',expr#6=AS($t4, $t5),expr#7=$t1.f0,expr#8=_UTF-16LE'bool',expr#9=AS($t7, $t8),expr#10=_UTF-16LE'true',expr#11==($t9, $t10),v_id=$t3,degree=$t6,$condition=$t11)]
03/06/2020 13:13:19.300 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 57/55; PHASE = OPTIMIZE; COST = {5.3299972766842544E8 rows, 1.3294995915026383E9 cpu, 1.2535996732021107E10 io, 0.0 network, 0.0 memory}
03/06/2020 13:13:19.307 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [ProjectCalcMergeRule] rels [rel#491:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#474,v_id=$0,degree=$1), rel#526:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#472,expr#0..1={inputs},expr#2=_UTF-16LE'v_id',expr#3=AS($t0, $t2),expr#4=$t1.f1,expr#5=_UTF-16LE'degree',expr#6=AS($t4, $t5),expr#7=$t1.f0,expr#8=_UTF-16LE'bool',expr#9=AS($t7, $t8),v_id=$t3,degree=$t6,bool=$t9)]
03/06/2020 13:13:19.307 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#828: Apply rule [ProjectCalcMergeRule] to [rel#491:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#474,v_id=$0,degree=$1), rel#526:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#472,expr#0..1={inputs},expr#2=_UTF-16LE'v_id',expr#3=AS($t0, $t2),expr#4=$t1.f1,expr#5=_UTF-16LE'degree',expr#6=AS($t4, $t5),expr#7=$t1.f0,expr#8=_UTF-16LE'bool',expr#9=AS($t7, $t8),v_id=$t3,degree=$t6,bool=$t9)]
03/06/2020 13:13:19.308 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#564 via ProjectCalcMergeRule
03/06/2020 13:13:19.312 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#828 generated 1 successors: [rel#564:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#472,expr#0..1={inputs},expr#2=_UTF-16LE'v_id',expr#3=AS($t0, $t2),expr#4=$t1.f1,expr#5=_UTF-16LE'degree',expr#6=AS($t4, $t5),v_id=$t3,degree=$t6)]
03/06/2020 13:13:19.313 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 58/56; PHASE = OPTIMIZE; COST = {5.3299972766842544E8 rows, 1.3294995915026383E9 cpu, 1.2535996732021107E10 io, 0.0 network, 0.0 memory}
03/06/2020 13:13:19.313 DEBUG [org.apache.calcite.plan.RelOptPlanner] Skip match: rule [ProjectCalcMergeRule] rels [rel#492:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#477,v_id_2=$0,v_label=$1,v_id_layout=$2,X=$3,Y=$4), rel#557:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#477,expr#0..4={inputs},v_id_2=$t0,v_label=$t1,v_id_layout=$t2,X=$t3,Y=$t4)]
03/06/2020 13:13:19.313 DEBUG [org.apache.calcite.plan.RelOptPlanner] Skip match: rule [ProjectCalcMergeRule] rels [rel#492:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#477,v_id_2=$0,v_label=$1,v_id_layout=$2,X=$3,Y=$4), rel#527:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#475,expr#0..4={inputs},expr#5=_UTF-16LE'v_id_2',expr#6=AS($t0, $t5),expr#7=_UTF-16LE'v_label',expr#8=AS($t1, $t7),expr#9=_UTF-16LE'v_id_layout',expr#10=AS($t2, $t9),expr#11=_UTF-16LE'X',expr#12=AS($t3, $t11),expr#13=_UTF-16LE'Y',expr#14=AS($t4, $t13),v_id_2=$t6,v_label=$t8,v_id_layout=$t10,X=$t12,Y=$t14)]
03/06/2020 13:13:19.313 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [FlinkCalcMergeRule] rels [rel#556:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#520,select=v_id, degree), rel#538:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#537,select=v_id, TMP_0.f1 AS degree, TMP_0.f0 AS bool,where==(TMP_0.f0, _UTF-16LE'true'))]
03/06/2020 13:13:19.313 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1015: Apply rule [FlinkCalcMergeRule] to [rel#556:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#520,select=v_id, degree), rel#538:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#537,select=v_id, TMP_0.f1 AS degree, TMP_0.f0 AS bool,where==(TMP_0.f0, _UTF-16LE'true'))]
03/06/2020 13:13:19.314 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#565 via FlinkCalcMergeRule
03/06/2020 13:13:19.314 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1015 generated 1 successors: [rel#565:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#537,select=v_id, TMP_0.f1 AS degree,where==(TMP_0.f0, _UTF-16LE'true'))]
03/06/2020 13:13:19.315 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 59/57; PHASE = OPTIMIZE; COST = {5.3299972766842544E8 rows, 1.3294995915026383E9 cpu, 1.2535996732021107E10 io, 0.0 network, 0.0 memory}
03/06/2020 13:13:19.315 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [FlinkCalcMergeRule] rels [rel#556:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#520,select=v_id, degree), rel#531:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#530,select=v_id, TMP_0.f1 AS degree, TMP_0.f0 AS bool)]
03/06/2020 13:13:19.315 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1014: Apply rule [FlinkCalcMergeRule] to [rel#556:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#520,select=v_id, degree), rel#531:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#530,select=v_id, TMP_0.f1 AS degree, TMP_0.f0 AS bool)]
03/06/2020 13:13:19.326 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#566 via FlinkCalcMergeRule
03/06/2020 13:13:19.326 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1014 generated 1 successors: [rel#566:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#530,select=v_id, TMP_0.f1 AS degree)]
03/06/2020 13:13:19.327 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 60/58; PHASE = OPTIMIZE; COST = {5.3299972766842544E8 rows, 1.3294995915026383E9 cpu, 1.2535996732021107E10 io, 0.0 network, 0.0 memory}
03/06/2020 13:13:19.327 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [FlinkCalcMergeRule] rels [rel#554:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#530,select=v_id, TMP_0.f1 AS degree), rel#541:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#537,select=v_id, TMP_0,where==(TMP_0.f0, _UTF-16LE'true'))]
03/06/2020 13:13:19.327 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#997: Apply rule [FlinkCalcMergeRule] to [rel#554:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#530,select=v_id, TMP_0.f1 AS degree), rel#541:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#537,select=v_id, TMP_0,where==(TMP_0.f0, _UTF-16LE'true'))]
03/06/2020 13:13:19.331 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#567 via FlinkCalcMergeRule
03/06/2020 13:13:19.332 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#997 generated 1 successors: [rel#567:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#537,select=v_id, TMP_0.f1 AS degree,where==(TMP_0.f0, _UTF-16LE'true'))]
03/06/2020 13:13:19.332 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 61/59; PHASE = OPTIMIZE; COST = {5.3299972766842544E8 rows, 1.3294995915026383E9 cpu, 1.2535996732021107E10 io, 0.0 network, 0.0 memory}
03/06/2020 13:13:19.332 DEBUG [org.apache.calcite.plan.RelOptPlanner] Skip match: rule [FlinkCalcMergeRule] rels [rel#559:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#521,select=v_id_2, v_label, v_id_layout, X, Y), rel#559:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#521,select=v_id_2, v_label, v_id_layout, X, Y)]
03/06/2020 13:13:19.332 DEBUG [org.apache.calcite.plan.RelOptPlanner] Skip match: rule [FlinkCalcMergeRule] rels [rel#559:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#521,select=v_id_2, v_label, v_id_layout, X, Y), rel#533:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#529,select=f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y)]
03/06/2020 13:13:19.333 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 62/1; PHASE = CLEANUP; COST = {5.3299972766842544E8 rows, 1.3294995915026383E9 cpu, 1.2535996732021107E10 io, 0.0 network, 0.0 memory}
03/06/2020 13:13:19.547 DEBUG [org.apache.calcite.plan.RelOptPlanner] Cheapest plan:
FlinkLogicalSink(name=[DataStreamTableSink], fields=[v_label, X, Y, v_id_layout, degree, v_id]): rowcount = 1.5E7, cumulative cost = {5.3299972766842544E8 rows, 1.3294995915026383E9 cpu, 1.2535996732021107E10 io, 0.0 network, 0.0 memory}, id = 574
  FlinkLogicalCalc(select=[v_label, X, Y, v_id_layout, degree, v_id]): rowcount = 1.5E7, cumulative cost = {5.1799972766842544E8 rows, 1.3144995915026383E9 cpu, 1.2535996732021107E10 io, 0.0 network, 0.0 memory}, id = 573
    FlinkLogicalJoin(condition=[=($0, $2)], joinType=[inner]): rowcount = 1.5E7, cumulative cost = {5.0299972766842544E8 rows, 1.3144995915026383E9 cpu, 1.2535996732021107E10 io, 0.0 network, 0.0 memory}, id = 572
      FlinkLogicalCalc(select=[v_id, TMP_0.f1 AS degree], where=[=(TMP_0.f0, _UTF-16LE'true')]): rowcount = 1499863.83421273, cumulative cost = {3.014998638342127E8 rows, 6.129997276684254E8 cpu, 7.2E9 io, 0.0 network, 0.0 memory}, id = 570
        FlinkLogicalAggregate(group=[{1}], TMP_0=[CurrentVertex($0, $1, $2)]): rowcount = 9999092.228084866, cumulative cost = {3.0E8 rows, 6.1E8 cpu, 7.2E9 io, 0.0 network, 0.0 memory}, id = 569
          FlinkLogicalCalc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]): rowcount = 1.0E8, cumulative cost = {2.0E8 rows, 4.0E8 cpu, 3.6E9 io, 0.0 network, 0.0 memory}, id = 568
            FlinkLogicalDataStreamTableScan(table=[[Unregistered_DataStream_8]]): rowcount = 1.0E8, cumulative cost = {1.0E8 rows, 1.0E8 cpu, 3.6E9 io, 0.0 network, 0.0 memory}, id = 549
      FlinkLogicalCalc(select=[f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y]): rowcount = 1.0E8, cumulative cost = {2.0E8 rows, 6.0E8 cpu, 5.2E9 io, 0.0 network, 0.0 memory}, id = 571
        FlinkLogicalDataStreamTableScan(table=[[Unregistered_DataStream_9]]): rowcount = 1.0E8, cumulative cost = {1.0E8 rows, 1.0E8 cpu, 5.2E9 io, 0.0 network, 0.0 memory}, id = 528

03/06/2020 13:13:19.554 DEBUG [org.apache.calcite.plan.RelOptPlanner] Provenance:
FlinkLogicalSink#574
  direct
    rel#487:FlinkLogicalSink.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#486,name=DataStreamTableSink,fields=v_label, X, Y, v_id_layout, degree, v_id)
      call#626 rule [FlinkLogicalSinkConverter(in:NONE,out:LOGICAL)]
        rel#482:LogicalSink.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#481,name=DataStreamTableSink,fields=v_label, X, Y, v_id_layout, degree, v_id)
          no parent
FlinkLogicalCalc#573
  direct
    rel#502:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#501,select=v_label, X, Y, v_id_layout, degree, v_id)
      call#765 rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)]
        rel#500:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#498,expr#0..6={inputs},v_label=$t3,X=$t5,Y=$t6,v_id_layout=$t4,degree=$t1,v_id=$t0)
          call#752 rule [ProjectToCalcRule]
            rel#499:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#498,v_label=$3,X=$5,Y=$6,v_id_layout=$4,degree=$1,v_id=$0)
              call#594 rule [FlinkProjectJoinTransposeRule]
                rel#480:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#479,v_label=$4,X=$6,Y=$7,v_id_layout=$5,degree=$1,v_id=$0)
                  no parent
                rel#478:LogicalJoin.NONE.any.None: 0.false.UNKNOWN(left=RelSubset#474,right=RelSubset#477,condition==($0, $3),joinType=inner)
                  no parent
FlinkLogicalJoin#572
  direct
    rel#518:FlinkLogicalJoin.LOGICAL.any.None: 0.false.UNKNOWN(left=RelSubset#516,right=RelSubset#521,condition==($0, $2),joinType=inner)
      call#720 rule [FlinkLogicalJoinConverter(in:NONE,out:LOGICAL)]
        rel#497:LogicalJoin.NONE.any.None: 0.false.UNKNOWN(left=RelSubset#495,right=RelSubset#477,condition==($0, $2),joinType=inner)
          call#594 rule [FlinkProjectJoinTransposeRule]
            rel#480 (see above)
            rel#478 (see above)
FlinkLogicalCalc#570
  direct
    rel#555:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#537,select=v_id, TMP_0.f1 AS degree,where==(TMP_0.f0, _UTF-16LE'true'))
      call#976 rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)]
        rel#551:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#470,expr#0..1={inputs},expr#2=_UTF-16LE'v_id',expr#3=AS($t0, $t2),expr#4=$t1.f1,expr#5=_UTF-16LE'degree',expr#6=AS($t4, $t5),expr#7=$t1.f0,expr#8=_UTF-16LE'bool',expr#9=AS($t7, $t8),expr#10=_UTF-16LE'true',expr#11==($t9, $t10),v_id=$t3,degree=$t6,$condition=$t11)
          call#961 rule [FlinkCalcMergeRule]
            rel#550:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#474,expr#0..2={inputs},v_id=$t0,degree=$t1)
              call#664 rule [ProjectToCalcRule]
                rel#491:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#474,v_id=$0,degree=$1)
                  call#594 rule [FlinkProjectJoinTransposeRule]
                    rel#480 (see above)
                    rel#478 (see above)
            rel#536:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#470,expr#0..1={inputs},expr#2=_UTF-16LE'v_id',expr#3=AS($t0, $t2),expr#4=$t1.f1,expr#5=_UTF-16LE'degree',expr#6=AS($t4, $t5),expr#7=$t1.f0,expr#8=_UTF-16LE'bool',expr#9=AS($t7, $t8),expr#10=_UTF-16LE'true',expr#11==($t9, $t10),v_id=$t3,degree=$t6,bool=$t9,$condition=$t11)
              call#883 rule [FlinkCalcMergeRule]
                rel#526:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#472,expr#0..1={inputs},expr#2=_UTF-16LE'v_id',expr#3=AS($t0, $t2),expr#4=$t1.f1,expr#5=_UTF-16LE'degree',expr#6=AS($t4, $t5),expr#7=$t1.f0,expr#8=_UTF-16LE'bool',expr#9=AS($t7, $t8),v_id=$t3,degree=$t6,bool=$t9)
                  call#512 rule [ProjectToCalcRule]
                    rel#473:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#472,v_id=AS($0, _UTF-16LE'v_id'),degree=AS($1.f1, _UTF-16LE'degree'),bool=AS($1.f0, _UTF-16LE'bool'))
                      no parent
                rel#535:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#470,expr#0..1={inputs},expr#2=$t1.f0,expr#3=_UTF-16LE'bool',expr#4=AS($t2, $t3),expr#5=_UTF-16LE'true',expr#6==($t4, $t5),v_id=$t0,TMP_0=$t1,$condition=$t6)
                  call#480 rule [FilterToCalcRule]
                    rel#471:LogicalFilter.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#470,condition==(AS($1.f0, _UTF-16LE'bool'), _UTF-16LE'true'))
                      no parent
FlinkLogicalAggregate#569
  direct
    rel#544:FlinkLogicalAggregate.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#543,group={1},TMP_0=CurrentVertex($0, $1, $2))
      call#443 rule [FlinkLogicalAggregateStreamConverter(in:NONE,out:LOGICAL)]
        rel#469:LogicalAggregate.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#468,group={1},TMP_0=CurrentVertex($0, $1, $2))
          no parent
FlinkLogicalCalc#568
  direct
    rel#548:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#547,select=f0 AS bool, f1 AS v_id, f2 AS degree)
      call#937 rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)]
        rel#546:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#466,expr#0..2={inputs},expr#3=_UTF-16LE'bool',expr#4=AS($t0, $t3),expr#5=_UTF-16LE'v_id',expr#6=AS($t1, $t5),expr#7=_UTF-16LE'degree',expr#8=AS($t2, $t7),bool=$t4,v_id=$t6,degree=$t8)
          call#431 rule [ProjectToCalcRule]
            rel#467:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#466,bool=AS($0, _UTF-16LE'bool'),v_id=AS($1, _UTF-16LE'v_id'),degree=AS($2, _UTF-16LE'degree'))
              no parent
rel#549:FlinkLogicalDataStreamTableScan.LOGICAL.any.None: 0.false.UNKNOWN(table=[Unregistered_DataStream_8])
  call#403 rule [FlinkLogicalDataStreamTableScanConverter(in:NONE,out:LOGICAL)]
    rel#231:LogicalTableScan.NONE.any.None: 0.false.UNKNOWN(table=[Unregistered_DataStream_8])
      no parent
FlinkLogicalCalc#571
  direct
    rel#533:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#529,select=f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y)
      call#845 rule [FlinkLogicalCalcConverter(in:NONE,out:LOGICAL)]
        rel#527:LogicalCalc.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#475,expr#0..4={inputs},expr#5=_UTF-16LE'v_id_2',expr#6=AS($t0, $t5),expr#7=_UTF-16LE'v_label',expr#8=AS($t1, $t7),expr#9=_UTF-16LE'v_id_layout',expr#10=AS($t2, $t9),expr#11=_UTF-16LE'X',expr#12=AS($t3, $t11),expr#13=_UTF-16LE'Y',expr#14=AS($t4, $t13),v_id_2=$t6,v_label=$t8,v_id_layout=$t10,X=$t12,Y=$t14)
          call#556 rule [ProjectToCalcRule]
            rel#476:LogicalProject.NONE.any.None: 0.false.UNKNOWN(input=RelSubset#475,v_id_2=AS($0, _UTF-16LE'v_id_2'),v_label=AS($1, _UTF-16LE'v_label'),v_id_layout=AS($2, _UTF-16LE'v_id_layout'),X=AS($3, _UTF-16LE'X'),Y=AS($4, _UTF-16LE'Y'))
              no parent
rel#528:FlinkLogicalDataStreamTableScan.LOGICAL.any.None: 0.false.UNKNOWN(table=[Unregistered_DataStream_9])
  call#528 rule [FlinkLogicalDataStreamTableScanConverter(in:NONE,out:LOGICAL)]
    rel#238:LogicalTableScan.NONE.any.None: 0.false.UNKNOWN(table=[Unregistered_DataStream_9])
      no parent

03/06/2020 13:13:19.559 DEBUG [org.apache.flink.table.planner.plan.optimize.program.FlinkChainedProgram] optimize logical cost 2067 ms.
optimize result: 
FlinkLogicalSink(name=[DataStreamTableSink], fields=[v_label, X, Y, v_id_layout, degree, v_id])
+- FlinkLogicalCalc(select=[v_label, X, Y, v_id_layout, degree, v_id])
   +- FlinkLogicalJoin(condition=[=($0, $2)], joinType=[inner])
      :- FlinkLogicalCalc(select=[v_id, TMP_0.f1 AS degree], where=[=(TMP_0.f0, _UTF-16LE'true')])
      :  +- FlinkLogicalAggregate(group=[{1}], TMP_0=[CurrentVertex($0, $1, $2)])
      :     +- FlinkLogicalCalc(select=[f0 AS bool, f1 AS v_id, f2 AS degree])
      :        +- FlinkLogicalDataStreamTableScan(table=[[Unregistered_DataStream_8]])
      +- FlinkLogicalCalc(select=[f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y])
         +- FlinkLogicalDataStreamTableScan(table=[[Unregistered_DataStream_9]])

03/06/2020 13:13:19.579 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#589:FlinkLogicalSink.LOGICAL.any.None: 0.false.UNKNOWN(input=HepRelVertex#588,name=DataStreamTableSink,fields=v_label, X, Y, v_id_layout, degree, v_id)
03/06/2020 13:13:19.579 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#587:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=HepRelVertex#586,select=v_label, X, Y, v_id_layout, degree, v_id)
03/06/2020 13:13:19.579 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#585:FlinkLogicalJoin.LOGICAL.any.None: 0.false.UNKNOWN(left=HepRelVertex#581,right=HepRelVertex#584,condition==($0, $2),joinType=inner)
03/06/2020 13:13:19.579 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#580:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=HepRelVertex#579,select=v_id, TMP_0.f1 AS degree,where==(TMP_0.f0, _UTF-16LE'true'))
03/06/2020 13:13:19.579 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#578:FlinkLogicalAggregate.LOGICAL.any.None: 0.false.UNKNOWN(input=HepRelVertex#577,group={1},TMP_0=CurrentVertex($0, $1, $2))
03/06/2020 13:13:19.579 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#576:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=HepRelVertex#575,select=f0 AS bool, f1 AS v_id, f2 AS degree)
03/06/2020 13:13:19.579 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#549:FlinkLogicalDataStreamTableScan.LOGICAL.any.None: 0.false.UNKNOWN(table=[Unregistered_DataStream_8])
03/06/2020 13:13:19.580 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#583:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=HepRelVertex#582,select=f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y)
03/06/2020 13:13:19.580 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#528:FlinkLogicalDataStreamTableScan.LOGICAL.any.None: 0.false.UNKNOWN(table=[Unregistered_DataStream_9])
03/06/2020 13:13:19.581 DEBUG [org.apache.flink.table.planner.plan.optimize.program.FlinkChainedProgram] optimize logical_rewrite cost 21 ms.
optimize result: 
FlinkLogicalSink(name=[DataStreamTableSink], fields=[v_label, X, Y, v_id_layout, degree, v_id])
+- FlinkLogicalCalc(select=[v_label, X, Y, v_id_layout, degree, v_id])
   +- FlinkLogicalJoin(condition=[=($0, $2)], joinType=[inner])
      :- FlinkLogicalCalc(select=[v_id, TMP_0.f1 AS degree], where=[=(TMP_0.f0, _UTF-16LE'true')])
      :  +- FlinkLogicalAggregate(group=[{1}], TMP_0=[CurrentVertex($0, $1, $2)])
      :     +- FlinkLogicalCalc(select=[f0 AS bool, f1 AS v_id, f2 AS degree])
      :        +- FlinkLogicalDataStreamTableScan(table=[[Unregistered_DataStream_8]])
      +- FlinkLogicalCalc(select=[f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y])
         +- FlinkLogicalDataStreamTableScan(table=[[Unregistered_DataStream_9]])

03/06/2020 13:13:19.781 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 1/1; PHASE = PRE_PROCESS_MDR; COST = {inf}
03/06/2020 13:13:19.782 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 2/1; PHASE = PRE_PROCESS; COST = {inf}
03/06/2020 13:13:19.782 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 3/1; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:19.783 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [StreamExecSinkRule(in:LOGICAL,out:STREAM_PHYSICAL)] rels [rel#605:FlinkLogicalSink.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#604,name=DataStreamTableSink,fields=v_label, X, Y, v_id_layout, degree, v_id)]
03/06/2020 13:13:19.783 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1280: Apply rule [StreamExecSinkRule(in:LOGICAL,out:STREAM_PHYSICAL)] to [rel#605:FlinkLogicalSink.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#604,name=DataStreamTableSink,fields=v_label, X, Y, v_id_layout, degree, v_id)]
03/06/2020 13:13:19.783 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#610 via StreamExecSinkRule(in:LOGICAL,out:STREAM_PHYSICAL)
03/06/2020 13:13:19.791 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1280 generated 1 successors: [rel#610:StreamExecSink.STREAM_PHYSICAL.any.None: 0.false.UNKNOWN(input=RelSubset#609,name=DataStreamTableSink,fields=v_label, X, Y, v_id_layout, degree, v_id)]
03/06/2020 13:13:19.791 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 4/2; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:19.791 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)] rels [rel#603:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#602,select=v_label, X, Y, v_id_layout, degree, v_id)]
03/06/2020 13:13:19.791 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1262: Apply rule [StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)] to [rel#603:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#602,select=v_label, X, Y, v_id_layout, degree, v_id)]
03/06/2020 13:13:19.791 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#612 via StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)
03/06/2020 13:13:19.798 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1262 generated 1 successors: [rel#612:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.UNKNOWN(input=RelSubset#611,select=v_label, X, Y, v_id_layout, degree, v_id)]
03/06/2020 13:13:19.799 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 5/3; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:19.799 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [StreamExecJoinRule] rels [rel#601:FlinkLogicalJoin.LOGICAL.any.None: 0.false.UNKNOWN(left=RelSubset#597,right=RelSubset#600,condition==($0, $2),joinType=inner), rel#596:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#595,select=v_id, TMP_0.f1 AS degree,where==(TMP_0.f0, _UTF-16LE'true')), rel#599:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#598,select=f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y)]
03/06/2020 13:13:19.799 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1248: Apply rule [StreamExecJoinRule] to [rel#601:FlinkLogicalJoin.LOGICAL.any.None: 0.false.UNKNOWN(left=RelSubset#597,right=RelSubset#600,condition==($0, $2),joinType=inner), rel#596:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#595,select=v_id, TMP_0.f1 AS degree,where==(TMP_0.f0, _UTF-16LE'true')), rel#599:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#598,select=f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y)]
03/06/2020 13:13:19.834 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#615 via StreamExecJoinRule
03/06/2020 13:13:20.030 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1248 generated 1 successors: [rel#615:StreamExecJoin.STREAM_PHYSICAL.any.None: 0.false.UNKNOWN(left=RelSubset#613,right=RelSubset#614,joinType=InnerJoin,where==(v_id, v_id_2),select=v_id, degree, v_id_2, v_label, v_id_layout, X, Y,leftInputSpec=JoinKeyContainsUniqueKey,rightInputSpec=NoUniqueKey)]
03/06/2020 13:13:20.039 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 6/4; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:20.040 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)] rels [rel#596:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#595,select=v_id, TMP_0.f1 AS degree,where==(TMP_0.f0, _UTF-16LE'true'))]
03/06/2020 13:13:20.040 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1212: Apply rule [StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)] to [rel#596:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#595,select=v_id, TMP_0.f1 AS degree,where==(TMP_0.f0, _UTF-16LE'true'))]
03/06/2020 13:13:20.040 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#617 via StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)
03/06/2020 13:13:20.125 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1212 generated 1 successors: [rel#617:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.UNKNOWN(input=RelSubset#616,select=v_id, TMP_0.f1 AS degree,where==(TMP_0.f0, _UTF-16LE'true'))]
03/06/2020 13:13:20.125 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 7/5; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:20.125 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [FlinkExpandConversionRule] rels [rel#619:AbstractConverter.STREAM_PHYSICAL.hash[0]true.None: 0.false.UNKNOWN(input=RelSubset#618,convention=STREAM_PHYSICAL,FlinkRelDistributionTraitDef=hash[0]true,MiniBatchIntervalTraitDef=None: 0,UpdateAsRetractionTraitDef=false,AccModeTraitDef=UNKNOWN), rel#617:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.UNKNOWN(input=RelSubset#616,select=v_id, TMP_0.f1 AS degree,where==(TMP_0.f0, _UTF-16LE'true'))]
03/06/2020 13:13:20.125 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1290: Apply rule [FlinkExpandConversionRule] to [rel#619:AbstractConverter.STREAM_PHYSICAL.hash[0]true.None: 0.false.UNKNOWN(input=RelSubset#618,convention=STREAM_PHYSICAL,FlinkRelDistributionTraitDef=hash[0]true,MiniBatchIntervalTraitDef=None: 0,UpdateAsRetractionTraitDef=false,AccModeTraitDef=UNKNOWN), rel#617:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.UNKNOWN(input=RelSubset#616,select=v_id, TMP_0.f1 AS degree,where==(TMP_0.f0, _UTF-16LE'true'))]
03/06/2020 13:13:20.126 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#620 via FlinkExpandConversionRule
03/06/2020 13:13:20.159 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1290 generated 1 successors: [StreamExecExchange#620]
03/06/2020 13:13:20.159 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 8/6; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:20.160 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)] rels [rel#599:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#598,select=f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y)]
03/06/2020 13:13:20.160 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1236: Apply rule [StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)] to [rel#599:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#598,select=f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y)]
03/06/2020 13:13:20.160 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#623 via StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)
03/06/2020 13:13:20.162 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1236 generated 1 successors: [rel#623:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.UNKNOWN(input=RelSubset#622,select=f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y)]
03/06/2020 13:13:20.162 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 9/7; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:20.162 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [FlinkExpandConversionRule] rels [rel#625:AbstractConverter.STREAM_PHYSICAL.hash[0]true.None: 0.false.UNKNOWN(input=RelSubset#624,convention=STREAM_PHYSICAL,FlinkRelDistributionTraitDef=hash[0]true,MiniBatchIntervalTraitDef=None: 0,UpdateAsRetractionTraitDef=false,AccModeTraitDef=UNKNOWN), rel#623:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.UNKNOWN(input=RelSubset#622,select=f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y)]
03/06/2020 13:13:20.163 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1296: Apply rule [FlinkExpandConversionRule] to [rel#625:AbstractConverter.STREAM_PHYSICAL.hash[0]true.None: 0.false.UNKNOWN(input=RelSubset#624,convention=STREAM_PHYSICAL,FlinkRelDistributionTraitDef=hash[0]true,MiniBatchIntervalTraitDef=None: 0,UpdateAsRetractionTraitDef=false,AccModeTraitDef=UNKNOWN), rel#623:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.UNKNOWN(input=RelSubset#622,select=f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y)]
03/06/2020 13:13:20.163 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#626 via FlinkExpandConversionRule
03/06/2020 13:13:20.164 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1296 generated 1 successors: [StreamExecExchange#626]
03/06/2020 13:13:20.164 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 10/8; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:20.164 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [StreamExecGroupAggregateRule(in:LOGICAL,out:STREAM_PHYSICAL)] rels [rel#594:FlinkLogicalAggregate.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#593,group={1},TMP_0=CurrentVertex($0, $1, $2))]
03/06/2020 13:13:20.164 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1202: Apply rule [StreamExecGroupAggregateRule(in:LOGICAL,out:STREAM_PHYSICAL)] to [rel#594:FlinkLogicalAggregate.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#593,group={1},TMP_0=CurrentVertex($0, $1, $2))]
03/06/2020 13:13:20.684 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#629 via StreamExecGroupAggregateRule(in:LOGICAL,out:STREAM_PHYSICAL)
03/06/2020 13:13:20.772 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1202 generated 1 successors: [rel#629:StreamExecGroupAggregate.STREAM_PHYSICAL.any.None: 0.false.UNKNOWN(input=RelSubset#628,groupBy=v_id,select=v_id, CurrentVertex(bool, v_id, degree) AS TMP_0)]
03/06/2020 13:13:20.773 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 11/9; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:20.774 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [StreamExecDataStreamScanRule(in:LOGICAL,out:STREAM_PHYSICAL)] rels [rel#528:FlinkLogicalDataStreamTableScan.LOGICAL.any.None: 0.false.UNKNOWN(table=[Unregistered_DataStream_9])]
03/06/2020 13:13:20.775 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1224: Apply rule [StreamExecDataStreamScanRule(in:LOGICAL,out:STREAM_PHYSICAL)] to [rel#528:FlinkLogicalDataStreamTableScan.LOGICAL.any.None: 0.false.UNKNOWN(table=[Unregistered_DataStream_9])]
03/06/2020 13:13:20.777 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#630 via StreamExecDataStreamScanRule(in:LOGICAL,out:STREAM_PHYSICAL)
03/06/2020 13:13:20.879 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1224 generated 1 successors: [rel#630:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.false.UNKNOWN(table=[Unregistered_DataStream_9],fields=f0, f1, f2, f3, f4)]
03/06/2020 13:13:20.880 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 12/10; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:20.880 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)] rels [rel#592:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#591,select=f0 AS bool, f1 AS v_id, f2 AS degree)]
03/06/2020 13:13:20.880 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1190: Apply rule [StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)] to [rel#592:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#591,select=f0 AS bool, f1 AS v_id, f2 AS degree)]
03/06/2020 13:13:20.880 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#632 via StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)
03/06/2020 13:13:20.881 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1190 generated 1 successors: [rel#632:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.UNKNOWN(input=RelSubset#631,select=f0 AS bool, f1 AS v_id, f2 AS degree)]
03/06/2020 13:13:20.881 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 13/11; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:20.881 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [FlinkExpandConversionRule] rels [rel#634:AbstractConverter.STREAM_PHYSICAL.hash[1]true.None: 0.false.UNKNOWN(input=RelSubset#633,convention=STREAM_PHYSICAL,FlinkRelDistributionTraitDef=hash[1]true,MiniBatchIntervalTraitDef=None: 0,UpdateAsRetractionTraitDef=false,AccModeTraitDef=UNKNOWN), rel#632:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.UNKNOWN(input=RelSubset#631,select=f0 AS bool, f1 AS v_id, f2 AS degree)]
03/06/2020 13:13:20.881 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1306: Apply rule [FlinkExpandConversionRule] to [rel#634:AbstractConverter.STREAM_PHYSICAL.hash[1]true.None: 0.false.UNKNOWN(input=RelSubset#633,convention=STREAM_PHYSICAL,FlinkRelDistributionTraitDef=hash[1]true,MiniBatchIntervalTraitDef=None: 0,UpdateAsRetractionTraitDef=false,AccModeTraitDef=UNKNOWN), rel#632:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.UNKNOWN(input=RelSubset#631,select=f0 AS bool, f1 AS v_id, f2 AS degree)]
03/06/2020 13:13:20.882 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#635 via FlinkExpandConversionRule
03/06/2020 13:13:20.899 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1306 generated 1 successors: [StreamExecExchange#635]
03/06/2020 13:13:20.899 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 14/12; PHASE = OPTIMIZE; COST = {inf}
03/06/2020 13:13:20.899 DEBUG [org.apache.calcite.plan.RelOptPlanner] Pop match: rule [StreamExecDataStreamScanRule(in:LOGICAL,out:STREAM_PHYSICAL)] rels [rel#549:FlinkLogicalDataStreamTableScan.LOGICAL.any.None: 0.false.UNKNOWN(table=[Unregistered_DataStream_8])]
03/06/2020 13:13:20.899 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1178: Apply rule [StreamExecDataStreamScanRule(in:LOGICAL,out:STREAM_PHYSICAL)] to [rel#549:FlinkLogicalDataStreamTableScan.LOGICAL.any.None: 0.false.UNKNOWN(table=[Unregistered_DataStream_8])]
03/06/2020 13:13:20.899 DEBUG [org.apache.calcite.plan.RelOptPlanner] Transform to: rel#637 via StreamExecDataStreamScanRule(in:LOGICAL,out:STREAM_PHYSICAL)
03/06/2020 13:13:21.254 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1178 generated 1 successors: [rel#637:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.false.UNKNOWN(table=[Unregistered_DataStream_8],fields=f0, f1, f2)]
03/06/2020 13:13:21.257 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 15/13; PHASE = OPTIMIZE; COST = {7.645002E8 rows, 3.72672502E10 cpu, 8.8E9 io, 9.16E9 network, 0.0 memory}
03/06/2020 13:13:21.271 DEBUG [org.apache.calcite.plan.RelOptPlanner] PLANNER = org.apache.calcite.plan.volcano.VolcanoPlanner@4f66ffc8; TICK = 16/1; PHASE = CLEANUP; COST = {7.645002E8 rows, 3.72672502E10 cpu, 8.8E9 io, 9.16E9 network, 0.0 memory}
03/06/2020 13:13:21.714 DEBUG [org.apache.calcite.plan.RelOptPlanner] Cheapest plan:
StreamExecSink(name=[DataStreamTableSink], fields=[v_label, X, Y, v_id_layout, degree, v_id]): rowcount = 1.725E7, cumulative cost = {7.645002E8 rows, 3.72672502E10 cpu, 8.8E9 io, 9.16E9 network, 0.0 memory}, id = 648
  StreamExecCalc(select=[v_label, X, Y, v_id_layout, degree, v_id]): rowcount = 1.725E7, cumulative cost = {7.472502E8 rows, 3.72500002E10 cpu, 8.8E9 io, 9.16E9 network, 0.0 memory}, id = 647
    StreamExecJoin(joinType=[InnerJoin], where=[=(v_id, v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]): rowcount = 1.725E7, cumulative cost = {7.300002E8 rows, 3.72500002E10 cpu, 8.8E9 io, 9.16E9 network, 0.0 memory}, id = 646
      StreamExecExchange(distribution=[hash[v_id]]): rowcount = 1.5E7, cumulative cost = {4.3E8 rows, 1.985E10 cpu, 3.6E9 io, 3.96E9 network, 0.0 memory}, id = 643
        StreamExecCalc(select=[v_id, TMP_0.f1 AS degree], where=[=(TMP_0.f0, _UTF-16LE'true')]): rowcount = 1.5E7, cumulative cost = {4.15E8 rows, 1.733E10 cpu, 3.6E9 io, 3.6E9 network, 0.0 memory}, id = 642
          StreamExecGroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]): rowcount = 1.0E8, cumulative cost = {4.0E8 rows, 1.73E10 cpu, 3.6E9 io, 3.6E9 network, 0.0 memory}, id = 641
            StreamExecExchange(distribution=[hash[v_id]]): rowcount = 1.0E8, cumulative cost = {3.0E8 rows, 1.72E10 cpu, 3.6E9 io, 3.6E9 network, 0.0 memory}, id = 640
              StreamExecCalc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]): rowcount = 1.0E8, cumulative cost = {2.0E8 rows, 4.0E8 cpu, 3.6E9 io, 0.0 network, 0.0 memory}, id = 639
                StreamExecDataStreamScan(table=[[Unregistered_DataStream_8]], fields=[f0, f1, f2]): rowcount = 1.0E8, cumulative cost = {1.0E8 rows, 1.0E8 cpu, 3.6E9 io, 0.0 network, 0.0 memory}, id = 637
      StreamExecExchange(distribution=[hash[v_id_2]]): rowcount = 1.0E8, cumulative cost = {3.0E8 rows, 1.74E10 cpu, 5.2E9 io, 5.2E9 network, 0.0 memory}, id = 645
        StreamExecCalc(select=[f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y]): rowcount = 1.0E8, cumulative cost = {2.0E8 rows, 6.0E8 cpu, 5.2E9 io, 0.0 network, 0.0 memory}, id = 644
          StreamExecDataStreamScan(table=[[Unregistered_DataStream_9]], fields=[f0, f1, f2, f3, f4]): rowcount = 1.0E8, cumulative cost = {1.0E8 rows, 1.0E8 cpu, 5.2E9 io, 0.0 network, 0.0 memory}, id = 630

03/06/2020 13:13:21.725 DEBUG [org.apache.calcite.plan.RelOptPlanner] Provenance:
StreamExecSink#648
  direct
    rel#610:StreamExecSink.STREAM_PHYSICAL.any.None: 0.false.UNKNOWN(input=RelSubset#609,name=DataStreamTableSink,fields=v_label, X, Y, v_id_layout, degree, v_id)
      call#1280 rule [StreamExecSinkRule(in:LOGICAL,out:STREAM_PHYSICAL)]
        rel#605:FlinkLogicalSink.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#604,name=DataStreamTableSink,fields=v_label, X, Y, v_id_layout, degree, v_id)
          no parent
StreamExecCalc#647
  direct
    rel#612:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.UNKNOWN(input=RelSubset#611,select=v_label, X, Y, v_id_layout, degree, v_id)
      call#1262 rule [StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)]
        rel#603:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#602,select=v_label, X, Y, v_id_layout, degree, v_id)
          no parent
StreamExecJoin#646
  direct
    rel#615:StreamExecJoin.STREAM_PHYSICAL.any.None: 0.false.UNKNOWN(left=RelSubset#613,right=RelSubset#614,joinType=InnerJoin,where==(v_id, v_id_2),select=v_id, degree, v_id_2, v_label, v_id_layout, X, Y,leftInputSpec=JoinKeyContainsUniqueKey,rightInputSpec=NoUniqueKey)
      call#1248 rule [StreamExecJoinRule]
        rel#601:FlinkLogicalJoin.LOGICAL.any.None: 0.false.UNKNOWN(left=RelSubset#597,right=RelSubset#600,condition==($0, $2),joinType=inner)
          no parent
        rel#596:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#595,select=v_id, TMP_0.f1 AS degree,where==(TMP_0.f0, _UTF-16LE'true'))
          no parent
        rel#599:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#598,select=f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y)
          no parent
StreamExecExchange#643
  direct
    rel#621:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.false.UNKNOWN(input=RelSubset#618,distribution=hash[v_id])
      call#1290 rule [FlinkExpandConversionRule]
        rel#619:AbstractConverter.STREAM_PHYSICAL.hash[0]true.None: 0.false.UNKNOWN(input=RelSubset#618,convention=STREAM_PHYSICAL,FlinkRelDistributionTraitDef=hash[0]true,MiniBatchIntervalTraitDef=None: 0,UpdateAsRetractionTraitDef=false,AccModeTraitDef=UNKNOWN)
          call#1212 rule [StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)]
            rel#596 (see above)
        rel#617:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.UNKNOWN(input=RelSubset#616,select=v_id, TMP_0.f1 AS degree,where==(TMP_0.f0, _UTF-16LE'true'))
          call#1212 rule [StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)]
            rel#596 (see above)
StreamExecCalc#642
  direct
    rel#617 (see above)
StreamExecGroupAggregate#641
  direct
    rel#629:StreamExecGroupAggregate.STREAM_PHYSICAL.any.None: 0.false.UNKNOWN(input=RelSubset#628,groupBy=v_id,select=v_id, CurrentVertex(bool, v_id, degree) AS TMP_0)
      call#1202 rule [StreamExecGroupAggregateRule(in:LOGICAL,out:STREAM_PHYSICAL)]
        rel#594:FlinkLogicalAggregate.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#593,group={1},TMP_0=CurrentVertex($0, $1, $2))
          no parent
StreamExecExchange#640
  direct
    rel#636:StreamExecExchange.STREAM_PHYSICAL.hash[1]true.None: 0.false.UNKNOWN(input=RelSubset#633,distribution=hash[v_id])
      call#1306 rule [FlinkExpandConversionRule]
        rel#634:AbstractConverter.STREAM_PHYSICAL.hash[1]true.None: 0.false.UNKNOWN(input=RelSubset#633,convention=STREAM_PHYSICAL,FlinkRelDistributionTraitDef=hash[1]true,MiniBatchIntervalTraitDef=None: 0,UpdateAsRetractionTraitDef=false,AccModeTraitDef=UNKNOWN)
          call#1190 rule [StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)]
            rel#592:FlinkLogicalCalc.LOGICAL.any.None: 0.false.UNKNOWN(input=RelSubset#591,select=f0 AS bool, f1 AS v_id, f2 AS degree)
              no parent
        rel#632:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.UNKNOWN(input=RelSubset#631,select=f0 AS bool, f1 AS v_id, f2 AS degree)
          call#1190 rule [StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)]
            rel#592 (see above)
StreamExecCalc#639
  direct
    rel#632 (see above)
rel#637:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.false.UNKNOWN(table=[Unregistered_DataStream_8],fields=f0, f1, f2)
  call#1178 rule [StreamExecDataStreamScanRule(in:LOGICAL,out:STREAM_PHYSICAL)]
    rel#549:FlinkLogicalDataStreamTableScan.LOGICAL.any.None: 0.false.UNKNOWN(table=[Unregistered_DataStream_8])
      no parent
StreamExecExchange#645
  direct
    rel#627:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.false.UNKNOWN(input=RelSubset#624,distribution=hash[v_id_2])
      call#1296 rule [FlinkExpandConversionRule]
        rel#625:AbstractConverter.STREAM_PHYSICAL.hash[0]true.None: 0.false.UNKNOWN(input=RelSubset#624,convention=STREAM_PHYSICAL,FlinkRelDistributionTraitDef=hash[0]true,MiniBatchIntervalTraitDef=None: 0,UpdateAsRetractionTraitDef=false,AccModeTraitDef=UNKNOWN)
          call#1236 rule [StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)]
            rel#599 (see above)
        rel#623:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.UNKNOWN(input=RelSubset#622,select=f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y)
          call#1236 rule [StreamExecCalcRule(in:LOGICAL,out:STREAM_PHYSICAL)]
            rel#599 (see above)
StreamExecCalc#644
  direct
    rel#623 (see above)
rel#630:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.false.UNKNOWN(table=[Unregistered_DataStream_9],fields=f0, f1, f2, f3, f4)
  call#1224 rule [StreamExecDataStreamScanRule(in:LOGICAL,out:STREAM_PHYSICAL)]
    rel#528:FlinkLogicalDataStreamTableScan.LOGICAL.any.None: 0.false.UNKNOWN(table=[Unregistered_DataStream_9])
      no parent

03/06/2020 13:13:21.755 DEBUG [org.apache.flink.table.planner.plan.optimize.program.FlinkChainedProgram] optimize physical cost 2144 ms.
optimize result: 
Sink(name=[DataStreamTableSink], fields=[v_label, X, Y, v_id_layout, degree, v_id])
+- Calc(select=[v_label, X, Y, v_id_layout, degree, v_id])
   +- Join(joinType=[InnerJoin], where=[=(v_id, v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey])
      :- Exchange(distribution=[hash[v_id]])
      :  +- Calc(select=[v_id, TMP_0.f1 AS degree], where=[=(TMP_0.f0, _UTF-16LE'true')])
      :     +- GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0])
      :        +- Exchange(distribution=[hash[v_id]])
      :           +- Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree])
      :              +- DataStreamScan(table=[[Unregistered_DataStream_8]], fields=[f0, f1, f2])
      +- Exchange(distribution=[hash[v_id_2]])
         +- Calc(select=[f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y])
            +- DataStreamScan(table=[[Unregistered_DataStream_9]], fields=[f0, f1, f2, f3, f4])

03/06/2020 13:13:21.760 DEBUG [org.apache.flink.table.planner.plan.optimize.program.FlinkGroupProgram] iteration: 1
03/06/2020 13:13:21.793 DEBUG [org.apache.flink.table.planner.plan.optimize.program.FlinkGroupProgram] optimize init for retraction cost 2 ms.
optimize result:
 Sink(name=[DataStreamTableSink], fields=[v_label, X, Y, v_id_layout, degree, v_id])
+- Calc(select=[v_label, X, Y, v_id_layout, degree, v_id])
   +- Join(joinType=[InnerJoin], where=[=(v_id, v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey])
      :- Exchange(distribution=[hash[v_id]])
      :  +- Calc(select=[v_id, TMP_0.f1 AS degree], where=[=(TMP_0.f0, _UTF-16LE'true')])
      :     +- GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0])
      :        +- Exchange(distribution=[hash[v_id]])
      :           +- Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree])
      :              +- DataStreamScan(table=[[Unregistered_DataStream_8]], fields=[f0, f1, f2])
      +- Exchange(distribution=[hash[v_id_2]])
         +- Calc(select=[f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y])
            +- DataStreamScan(table=[[Unregistered_DataStream_9]], fields=[f0, f1, f2, f3, f4])

03/06/2020 13:13:21.815 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1312: Apply rule [AssignDefaultRetractionRule] to [rel#637:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.false.UNKNOWN(table=[Unregistered_DataStream_8],fields=f0, f1, f2)]
03/06/2020 13:13:21.825 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1312: Rule AssignDefaultRetractionRule arguments [rel#637:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.false.UNKNOWN(table=[Unregistered_DataStream_8],fields=f0, f1, f2)] produced StreamExecDataStreamScan#673
03/06/2020 13:13:21.831 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1313: Apply rule [AssignDefaultRetractionRule] to [rel#673:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.false.Acc(table=[Unregistered_DataStream_8],fields=f0, f1, f2)]
03/06/2020 13:13:21.833 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1314: Apply rule [AssignDefaultRetractionRule] to [rel#652:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.UNKNOWN(input=HepRelVertex#651,select=f0 AS bool, f1 AS v_id, f2 AS degree)]
03/06/2020 13:13:21.833 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1314: Rule AssignDefaultRetractionRule arguments [rel#652:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.UNKNOWN(input=HepRelVertex#651,select=f0 AS bool, f1 AS v_id, f2 AS degree)] produced StreamExecCalc#675
03/06/2020 13:13:21.833 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1315: Apply rule [AssignDefaultRetractionRule] to [rel#673:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.false.Acc(table=[Unregistered_DataStream_8],fields=f0, f1, f2)]
03/06/2020 13:13:21.833 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1316: Apply rule [AssignDefaultRetractionRule] to [rel#675:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#674,select=f0 AS bool, f1 AS v_id, f2 AS degree)]
03/06/2020 13:13:21.833 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1317: Apply rule [AssignDefaultRetractionRule] to [rel#654:StreamExecExchange.STREAM_PHYSICAL.hash[1]true.None: 0.false.UNKNOWN(input=HepRelVertex#653,distribution=hash[v_id])]
03/06/2020 13:13:21.834 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1317: Rule AssignDefaultRetractionRule arguments [rel#654:StreamExecExchange.STREAM_PHYSICAL.hash[1]true.None: 0.false.UNKNOWN(input=HepRelVertex#653,distribution=hash[v_id])] produced StreamExecExchange#677
03/06/2020 13:13:21.835 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1318: Apply rule [AssignDefaultRetractionRule] to [rel#673:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.false.Acc(table=[Unregistered_DataStream_8],fields=f0, f1, f2)]
03/06/2020 13:13:21.836 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1319: Apply rule [AssignDefaultRetractionRule] to [rel#675:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#674,select=f0 AS bool, f1 AS v_id, f2 AS degree)]
03/06/2020 13:13:21.836 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1320: Apply rule [AssignDefaultRetractionRule] to [rel#677:StreamExecExchange.STREAM_PHYSICAL.hash[1]true.None: 0.false.Acc(input=HepRelVertex#676,distribution=hash[v_id])]
03/06/2020 13:13:21.838 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1321: Apply rule [AssignDefaultRetractionRule] to [rel#630:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.false.UNKNOWN(table=[Unregistered_DataStream_9],fields=f0, f1, f2, f3, f4)]
03/06/2020 13:13:21.839 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1321: Rule AssignDefaultRetractionRule arguments [rel#630:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.false.UNKNOWN(table=[Unregistered_DataStream_9],fields=f0, f1, f2, f3, f4)] produced StreamExecDataStreamScan#679
03/06/2020 13:13:21.840 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1322: Apply rule [AssignDefaultRetractionRule] to [rel#673:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.false.Acc(table=[Unregistered_DataStream_8],fields=f0, f1, f2)]
03/06/2020 13:13:21.840 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1323: Apply rule [AssignDefaultRetractionRule] to [rel#675:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#674,select=f0 AS bool, f1 AS v_id, f2 AS degree)]
03/06/2020 13:13:21.840 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1324: Apply rule [AssignDefaultRetractionRule] to [rel#677:StreamExecExchange.STREAM_PHYSICAL.hash[1]true.None: 0.false.Acc(input=HepRelVertex#676,distribution=hash[v_id])]
03/06/2020 13:13:21.840 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1325: Apply rule [AssignDefaultRetractionRule] to [rel#679:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.false.Acc(table=[Unregistered_DataStream_9],fields=f0, f1, f2, f3, f4)]
03/06/2020 13:13:21.840 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1326: Apply rule [AssignDefaultRetractionRule] to [rel#656:StreamExecGroupAggregate.STREAM_PHYSICAL.any.None: 0.false.UNKNOWN(input=HepRelVertex#655,groupBy=v_id,select=v_id, CurrentVertex(bool, v_id, degree) AS TMP_0)]
03/06/2020 13:13:21.842 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1326: Rule AssignDefaultRetractionRule arguments [rel#656:StreamExecGroupAggregate.STREAM_PHYSICAL.any.None: 0.false.UNKNOWN(input=HepRelVertex#655,groupBy=v_id,select=v_id, CurrentVertex(bool, v_id, degree) AS TMP_0)] produced StreamExecGroupAggregate#681
03/06/2020 13:13:21.855 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1327: Apply rule [AssignDefaultRetractionRule] to [rel#673:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.false.Acc(table=[Unregistered_DataStream_8],fields=f0, f1, f2)]
03/06/2020 13:13:21.856 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1328: Apply rule [AssignDefaultRetractionRule] to [rel#675:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#674,select=f0 AS bool, f1 AS v_id, f2 AS degree)]
03/06/2020 13:13:21.856 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1329: Apply rule [AssignDefaultRetractionRule] to [rel#677:StreamExecExchange.STREAM_PHYSICAL.hash[1]true.None: 0.false.Acc(input=HepRelVertex#676,distribution=hash[v_id])]
03/06/2020 13:13:21.857 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1330: Apply rule [AssignDefaultRetractionRule] to [rel#679:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.false.Acc(table=[Unregistered_DataStream_9],fields=f0, f1, f2, f3, f4)]
03/06/2020 13:13:21.857 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1331: Apply rule [AssignDefaultRetractionRule] to [rel#681:StreamExecGroupAggregate.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#678,groupBy=v_id,select=v_id, CurrentVertex(bool, v_id, degree) AS TMP_0)]
03/06/2020 13:13:21.858 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1332: Apply rule [AssignDefaultRetractionRule] to [rel#663:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.UNKNOWN(input=HepRelVertex#662,select=f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y)]
03/06/2020 13:13:21.858 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1332: Rule AssignDefaultRetractionRule arguments [rel#663:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.UNKNOWN(input=HepRelVertex#662,select=f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y)] produced StreamExecCalc#683
03/06/2020 13:13:21.860 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1333: Apply rule [AssignDefaultRetractionRule] to [rel#673:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.false.Acc(table=[Unregistered_DataStream_8],fields=f0, f1, f2)]
03/06/2020 13:13:21.862 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1334: Apply rule [AssignDefaultRetractionRule] to [rel#675:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#674,select=f0 AS bool, f1 AS v_id, f2 AS degree)]
03/06/2020 13:13:21.862 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1335: Apply rule [AssignDefaultRetractionRule] to [rel#677:StreamExecExchange.STREAM_PHYSICAL.hash[1]true.None: 0.false.Acc(input=HepRelVertex#676,distribution=hash[v_id])]
03/06/2020 13:13:21.862 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1336: Apply rule [AssignDefaultRetractionRule] to [rel#679:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.false.Acc(table=[Unregistered_DataStream_9],fields=f0, f1, f2, f3, f4)]
03/06/2020 13:13:21.862 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1337: Apply rule [AssignDefaultRetractionRule] to [rel#681:StreamExecGroupAggregate.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#678,groupBy=v_id,select=v_id, CurrentVertex(bool, v_id, degree) AS TMP_0)]
03/06/2020 13:13:21.862 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1338: Apply rule [AssignDefaultRetractionRule] to [rel#683:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#680,select=f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y)]
03/06/2020 13:13:21.863 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1339: Apply rule [AssignDefaultRetractionRule] to [rel#658:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.UNKNOWN(input=HepRelVertex#657,select=v_id, TMP_0.f1 AS degree,where==(TMP_0.f0, _UTF-16LE'true'))]
03/06/2020 13:13:21.863 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1339: Rule AssignDefaultRetractionRule arguments [rel#658:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.UNKNOWN(input=HepRelVertex#657,select=v_id, TMP_0.f1 AS degree,where==(TMP_0.f0, _UTF-16LE'true'))] produced StreamExecCalc#685
03/06/2020 13:13:21.864 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1340: Apply rule [AssignDefaultRetractionRule] to [rel#673:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.false.Acc(table=[Unregistered_DataStream_8],fields=f0, f1, f2)]
03/06/2020 13:13:21.867 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1341: Apply rule [AssignDefaultRetractionRule] to [rel#675:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#674,select=f0 AS bool, f1 AS v_id, f2 AS degree)]
03/06/2020 13:13:21.867 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1342: Apply rule [AssignDefaultRetractionRule] to [rel#677:StreamExecExchange.STREAM_PHYSICAL.hash[1]true.None: 0.false.Acc(input=HepRelVertex#676,distribution=hash[v_id])]
03/06/2020 13:13:21.867 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1343: Apply rule [AssignDefaultRetractionRule] to [rel#679:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.false.Acc(table=[Unregistered_DataStream_9],fields=f0, f1, f2, f3, f4)]
03/06/2020 13:13:21.867 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1344: Apply rule [AssignDefaultRetractionRule] to [rel#681:StreamExecGroupAggregate.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#678,groupBy=v_id,select=v_id, CurrentVertex(bool, v_id, degree) AS TMP_0)]
03/06/2020 13:13:21.867 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1345: Apply rule [AssignDefaultRetractionRule] to [rel#683:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#680,select=f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y)]
03/06/2020 13:13:21.867 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1346: Apply rule [AssignDefaultRetractionRule] to [rel#685:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#682,select=v_id, TMP_0.f1 AS degree,where==(TMP_0.f0, _UTF-16LE'true'))]
03/06/2020 13:13:21.868 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1347: Apply rule [AssignDefaultRetractionRule] to [rel#665:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.false.UNKNOWN(input=HepRelVertex#664,distribution=hash[v_id_2])]
03/06/2020 13:13:21.868 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1347: Rule AssignDefaultRetractionRule arguments [rel#665:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.false.UNKNOWN(input=HepRelVertex#664,distribution=hash[v_id_2])] produced StreamExecExchange#687
03/06/2020 13:13:21.872 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1348: Apply rule [AssignDefaultRetractionRule] to [rel#673:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.false.Acc(table=[Unregistered_DataStream_8],fields=f0, f1, f2)]
03/06/2020 13:13:21.874 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1349: Apply rule [AssignDefaultRetractionRule] to [rel#675:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#674,select=f0 AS bool, f1 AS v_id, f2 AS degree)]
03/06/2020 13:13:21.876 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1350: Apply rule [AssignDefaultRetractionRule] to [rel#677:StreamExecExchange.STREAM_PHYSICAL.hash[1]true.None: 0.false.Acc(input=HepRelVertex#676,distribution=hash[v_id])]
03/06/2020 13:13:21.876 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1351: Apply rule [AssignDefaultRetractionRule] to [rel#679:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.false.Acc(table=[Unregistered_DataStream_9],fields=f0, f1, f2, f3, f4)]
03/06/2020 13:13:21.877 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1352: Apply rule [AssignDefaultRetractionRule] to [rel#681:StreamExecGroupAggregate.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#678,groupBy=v_id,select=v_id, CurrentVertex(bool, v_id, degree) AS TMP_0)]
03/06/2020 13:13:21.880 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1353: Apply rule [AssignDefaultRetractionRule] to [rel#683:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#680,select=f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y)]
03/06/2020 13:13:21.880 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1354: Apply rule [AssignDefaultRetractionRule] to [rel#685:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#682,select=v_id, TMP_0.f1 AS degree,where==(TMP_0.f0, _UTF-16LE'true'))]
03/06/2020 13:13:21.880 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1355: Apply rule [AssignDefaultRetractionRule] to [rel#687:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.false.Acc(input=HepRelVertex#684,distribution=hash[v_id_2])]
03/06/2020 13:13:21.880 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1356: Apply rule [AssignDefaultRetractionRule] to [rel#660:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.false.UNKNOWN(input=HepRelVertex#659,distribution=hash[v_id])]
03/06/2020 13:13:21.880 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1356: Rule AssignDefaultRetractionRule arguments [rel#660:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.false.UNKNOWN(input=HepRelVertex#659,distribution=hash[v_id])] produced StreamExecExchange#689
03/06/2020 13:13:21.891 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1357: Apply rule [AssignDefaultRetractionRule] to [rel#673:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.false.Acc(table=[Unregistered_DataStream_8],fields=f0, f1, f2)]
03/06/2020 13:13:21.891 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1358: Apply rule [AssignDefaultRetractionRule] to [rel#675:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#674,select=f0 AS bool, f1 AS v_id, f2 AS degree)]
03/06/2020 13:13:21.891 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1359: Apply rule [AssignDefaultRetractionRule] to [rel#677:StreamExecExchange.STREAM_PHYSICAL.hash[1]true.None: 0.false.Acc(input=HepRelVertex#676,distribution=hash[v_id])]
03/06/2020 13:13:21.891 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1360: Apply rule [AssignDefaultRetractionRule] to [rel#681:StreamExecGroupAggregate.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#678,groupBy=v_id,select=v_id, CurrentVertex(bool, v_id, degree) AS TMP_0)]
03/06/2020 13:13:21.891 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1361: Apply rule [AssignDefaultRetractionRule] to [rel#679:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.false.Acc(table=[Unregistered_DataStream_9],fields=f0, f1, f2, f3, f4)]
03/06/2020 13:13:21.891 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1362: Apply rule [AssignDefaultRetractionRule] to [rel#685:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#682,select=v_id, TMP_0.f1 AS degree,where==(TMP_0.f0, _UTF-16LE'true'))]
03/06/2020 13:13:21.891 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1363: Apply rule [AssignDefaultRetractionRule] to [rel#683:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#680,select=f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y)]
03/06/2020 13:13:21.891 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1364: Apply rule [AssignDefaultRetractionRule] to [rel#689:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.false.Acc(input=HepRelVertex#686,distribution=hash[v_id])]
03/06/2020 13:13:21.891 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1365: Apply rule [AssignDefaultRetractionRule] to [rel#687:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.false.Acc(input=HepRelVertex#684,distribution=hash[v_id_2])]
03/06/2020 13:13:21.891 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1366: Apply rule [AssignDefaultRetractionRule] to [rel#667:StreamExecJoin.STREAM_PHYSICAL.any.None: 0.false.UNKNOWN(left=HepRelVertex#690,right=HepRelVertex#688,joinType=InnerJoin,where==(v_id, v_id_2),select=v_id, degree, v_id_2, v_label, v_id_layout, X, Y,leftInputSpec=JoinKeyContainsUniqueKey,rightInputSpec=NoUniqueKey)]
03/06/2020 13:13:21.894 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1366: Rule AssignDefaultRetractionRule arguments [rel#667:StreamExecJoin.STREAM_PHYSICAL.any.None: 0.false.UNKNOWN(left=HepRelVertex#690,right=HepRelVertex#688,joinType=InnerJoin,where==(v_id, v_id_2),select=v_id, degree, v_id_2, v_label, v_id_layout, X, Y,leftInputSpec=JoinKeyContainsUniqueKey,rightInputSpec=NoUniqueKey)] produced StreamExecJoin#691
03/06/2020 13:13:21.905 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1367: Apply rule [AssignDefaultRetractionRule] to [rel#673:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.false.Acc(table=[Unregistered_DataStream_8],fields=f0, f1, f2)]
03/06/2020 13:13:21.906 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1368: Apply rule [AssignDefaultRetractionRule] to [rel#675:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#674,select=f0 AS bool, f1 AS v_id, f2 AS degree)]
03/06/2020 13:13:21.906 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1369: Apply rule [AssignDefaultRetractionRule] to [rel#677:StreamExecExchange.STREAM_PHYSICAL.hash[1]true.None: 0.false.Acc(input=HepRelVertex#676,distribution=hash[v_id])]
03/06/2020 13:13:21.906 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1370: Apply rule [AssignDefaultRetractionRule] to [rel#679:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.false.Acc(table=[Unregistered_DataStream_9],fields=f0, f1, f2, f3, f4)]
03/06/2020 13:13:21.907 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1371: Apply rule [AssignDefaultRetractionRule] to [rel#681:StreamExecGroupAggregate.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#678,groupBy=v_id,select=v_id, CurrentVertex(bool, v_id, degree) AS TMP_0)]
03/06/2020 13:13:21.907 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1372: Apply rule [AssignDefaultRetractionRule] to [rel#683:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#680,select=f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y)]
03/06/2020 13:13:21.907 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1373: Apply rule [AssignDefaultRetractionRule] to [rel#685:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#682,select=v_id, TMP_0.f1 AS degree,where==(TMP_0.f0, _UTF-16LE'true'))]
03/06/2020 13:13:21.914 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1374: Apply rule [AssignDefaultRetractionRule] to [rel#687:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.false.Acc(input=HepRelVertex#684,distribution=hash[v_id_2])]
03/06/2020 13:13:21.914 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1375: Apply rule [AssignDefaultRetractionRule] to [rel#689:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.false.Acc(input=HepRelVertex#686,distribution=hash[v_id])]
03/06/2020 13:13:21.915 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1376: Apply rule [AssignDefaultRetractionRule] to [rel#691:StreamExecJoin.STREAM_PHYSICAL.any.None: 0.false.Acc(left=HepRelVertex#690,right=HepRelVertex#688,joinType=InnerJoin,where==(v_id, v_id_2),select=v_id, degree, v_id_2, v_label, v_id_layout, X, Y,leftInputSpec=JoinKeyContainsUniqueKey,rightInputSpec=NoUniqueKey)]
03/06/2020 13:13:21.915 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1377: Apply rule [AssignDefaultRetractionRule] to [rel#669:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.UNKNOWN(input=HepRelVertex#668,select=v_label, X, Y, v_id_layout, degree, v_id)]
03/06/2020 13:13:21.915 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1377: Rule AssignDefaultRetractionRule arguments [rel#669:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.UNKNOWN(input=HepRelVertex#668,select=v_label, X, Y, v_id_layout, degree, v_id)] produced StreamExecCalc#693
03/06/2020 13:13:21.918 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1378: Apply rule [AssignDefaultRetractionRule] to [rel#673:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.false.Acc(table=[Unregistered_DataStream_8],fields=f0, f1, f2)]
03/06/2020 13:13:21.918 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1379: Apply rule [AssignDefaultRetractionRule] to [rel#675:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#674,select=f0 AS bool, f1 AS v_id, f2 AS degree)]
03/06/2020 13:13:21.920 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1380: Apply rule [AssignDefaultRetractionRule] to [rel#677:StreamExecExchange.STREAM_PHYSICAL.hash[1]true.None: 0.false.Acc(input=HepRelVertex#676,distribution=hash[v_id])]
03/06/2020 13:13:21.920 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1381: Apply rule [AssignDefaultRetractionRule] to [rel#679:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.false.Acc(table=[Unregistered_DataStream_9],fields=f0, f1, f2, f3, f4)]
03/06/2020 13:13:21.920 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1382: Apply rule [AssignDefaultRetractionRule] to [rel#681:StreamExecGroupAggregate.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#678,groupBy=v_id,select=v_id, CurrentVertex(bool, v_id, degree) AS TMP_0)]
03/06/2020 13:13:21.920 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1383: Apply rule [AssignDefaultRetractionRule] to [rel#683:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#680,select=f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y)]
03/06/2020 13:13:21.921 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1384: Apply rule [AssignDefaultRetractionRule] to [rel#685:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#682,select=v_id, TMP_0.f1 AS degree,where==(TMP_0.f0, _UTF-16LE'true'))]
03/06/2020 13:13:21.921 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1385: Apply rule [AssignDefaultRetractionRule] to [rel#687:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.false.Acc(input=HepRelVertex#684,distribution=hash[v_id_2])]
03/06/2020 13:13:21.921 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1386: Apply rule [AssignDefaultRetractionRule] to [rel#689:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.false.Acc(input=HepRelVertex#686,distribution=hash[v_id])]
03/06/2020 13:13:21.922 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1387: Apply rule [AssignDefaultRetractionRule] to [rel#691:StreamExecJoin.STREAM_PHYSICAL.any.None: 0.false.Acc(left=HepRelVertex#690,right=HepRelVertex#688,joinType=InnerJoin,where==(v_id, v_id_2),select=v_id, degree, v_id_2, v_label, v_id_layout, X, Y,leftInputSpec=JoinKeyContainsUniqueKey,rightInputSpec=NoUniqueKey)]
03/06/2020 13:13:21.922 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1388: Apply rule [AssignDefaultRetractionRule] to [rel#693:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#692,select=v_label, X, Y, v_id_layout, degree, v_id)]
03/06/2020 13:13:21.922 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1389: Apply rule [AssignDefaultRetractionRule] to [rel#671:StreamExecSink.STREAM_PHYSICAL.any.None: 0.true.UNKNOWN(input=HepRelVertex#670,name=DataStreamTableSink,fields=v_label, X, Y, v_id_layout, degree, v_id)]
03/06/2020 13:13:21.924 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1389: Rule AssignDefaultRetractionRule arguments [rel#671:StreamExecSink.STREAM_PHYSICAL.any.None: 0.true.UNKNOWN(input=HepRelVertex#670,name=DataStreamTableSink,fields=v_label, X, Y, v_id_layout, degree, v_id)] produced StreamExecSink#695
03/06/2020 13:13:21.925 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1390: Apply rule [AssignDefaultRetractionRule] to [rel#673:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.false.Acc(table=[Unregistered_DataStream_8],fields=f0, f1, f2)]
03/06/2020 13:13:21.927 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1391: Apply rule [AssignDefaultRetractionRule] to [rel#675:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#674,select=f0 AS bool, f1 AS v_id, f2 AS degree)]
03/06/2020 13:13:21.928 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1392: Apply rule [AssignDefaultRetractionRule] to [rel#677:StreamExecExchange.STREAM_PHYSICAL.hash[1]true.None: 0.false.Acc(input=HepRelVertex#676,distribution=hash[v_id])]
03/06/2020 13:13:21.928 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1393: Apply rule [AssignDefaultRetractionRule] to [rel#679:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.false.Acc(table=[Unregistered_DataStream_9],fields=f0, f1, f2, f3, f4)]
03/06/2020 13:13:21.928 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1394: Apply rule [AssignDefaultRetractionRule] to [rel#681:StreamExecGroupAggregate.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#678,groupBy=v_id,select=v_id, CurrentVertex(bool, v_id, degree) AS TMP_0)]
03/06/2020 13:13:21.929 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1395: Apply rule [AssignDefaultRetractionRule] to [rel#683:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#680,select=f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y)]
03/06/2020 13:13:21.930 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1396: Apply rule [AssignDefaultRetractionRule] to [rel#685:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#682,select=v_id, TMP_0.f1 AS degree,where==(TMP_0.f0, _UTF-16LE'true'))]
03/06/2020 13:13:21.931 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1397: Apply rule [AssignDefaultRetractionRule] to [rel#687:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.false.Acc(input=HepRelVertex#684,distribution=hash[v_id_2])]
03/06/2020 13:13:21.933 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1398: Apply rule [AssignDefaultRetractionRule] to [rel#689:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.false.Acc(input=HepRelVertex#686,distribution=hash[v_id])]
03/06/2020 13:13:21.933 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1399: Apply rule [AssignDefaultRetractionRule] to [rel#691:StreamExecJoin.STREAM_PHYSICAL.any.None: 0.false.Acc(left=HepRelVertex#690,right=HepRelVertex#688,joinType=InnerJoin,where==(v_id, v_id_2),select=v_id, degree, v_id_2, v_label, v_id_layout, X, Y,leftInputSpec=JoinKeyContainsUniqueKey,rightInputSpec=NoUniqueKey)]
03/06/2020 13:13:21.933 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1400: Apply rule [AssignDefaultRetractionRule] to [rel#693:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#692,select=v_label, X, Y, v_id_layout, degree, v_id)]
03/06/2020 13:13:21.934 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1401: Apply rule [AssignDefaultRetractionRule] to [rel#695:StreamExecSink.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#694,name=DataStreamTableSink,fields=v_label, X, Y, v_id_layout, degree, v_id)]
03/06/2020 13:13:21.934 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1402: Apply rule [SetUpdatesAsRetractionRule] to [rel#673:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.false.Acc(table=[Unregistered_DataStream_8],fields=f0, f1, f2)]
03/06/2020 13:13:21.934 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1403: Apply rule [SetUpdatesAsRetractionRule] to [rel#675:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#674,select=f0 AS bool, f1 AS v_id, f2 AS degree)]
03/06/2020 13:13:21.934 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1404: Apply rule [SetUpdatesAsRetractionRule] to [rel#677:StreamExecExchange.STREAM_PHYSICAL.hash[1]true.None: 0.false.Acc(input=HepRelVertex#676,distribution=hash[v_id])]
03/06/2020 13:13:21.935 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1405: Apply rule [SetUpdatesAsRetractionRule] to [rel#679:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.false.Acc(table=[Unregistered_DataStream_9],fields=f0, f1, f2, f3, f4)]
03/06/2020 13:13:21.935 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1406: Apply rule [SetUpdatesAsRetractionRule] to [rel#681:StreamExecGroupAggregate.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#678,groupBy=v_id,select=v_id, CurrentVertex(bool, v_id, degree) AS TMP_0)]
03/06/2020 13:13:21.939 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1406: Rule SetUpdatesAsRetractionRule arguments [rel#681:StreamExecGroupAggregate.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#678,groupBy=v_id,select=v_id, CurrentVertex(bool, v_id, degree) AS TMP_0)] produced StreamExecGroupAggregate#698
03/06/2020 13:13:21.941 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1407: Apply rule [SetUpdatesAsRetractionRule] to [rel#673:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.false.Acc(table=[Unregistered_DataStream_8],fields=f0, f1, f2)]
03/06/2020 13:13:21.943 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1408: Apply rule [SetUpdatesAsRetractionRule] to [rel#675:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#674,select=f0 AS bool, f1 AS v_id, f2 AS degree)]
03/06/2020 13:13:21.944 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1409: Apply rule [SetUpdatesAsRetractionRule] to [rel#697:StreamExecExchange.STREAM_PHYSICAL.hash[1]true.None: 0.true.Acc(input=HepRelVertex#676,distribution=hash[v_id])]
03/06/2020 13:13:21.946 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1409: Rule SetUpdatesAsRetractionRule arguments [rel#697:StreamExecExchange.STREAM_PHYSICAL.hash[1]true.None: 0.true.Acc(input=HepRelVertex#676,distribution=hash[v_id])] produced StreamExecExchange#703
03/06/2020 13:13:21.949 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1410: Apply rule [SetUpdatesAsRetractionRule] to [rel#673:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.false.Acc(table=[Unregistered_DataStream_8],fields=f0, f1, f2)]
03/06/2020 13:13:21.951 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1411: Apply rule [SetUpdatesAsRetractionRule] to [rel#702:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#674,select=f0 AS bool, f1 AS v_id, f2 AS degree)]
03/06/2020 13:13:21.952 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1411: Rule SetUpdatesAsRetractionRule arguments [rel#702:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#674,select=f0 AS bool, f1 AS v_id, f2 AS degree)] produced StreamExecCalc#708
03/06/2020 13:13:21.959 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1412: Apply rule [SetUpdatesAsRetractionRule] to [rel#707:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.true.Acc(table=[Unregistered_DataStream_8],fields=f0, f1, f2)]
03/06/2020 13:13:21.959 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1413: Apply rule [SetUpdatesAsRetractionRule] to [rel#710:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#709,select=f0 AS bool, f1 AS v_id, f2 AS degree)]
03/06/2020 13:13:21.960 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1414: Apply rule [SetUpdatesAsRetractionRule] to [rel#705:StreamExecExchange.STREAM_PHYSICAL.hash[1]true.None: 0.true.Acc(input=HepRelVertex#704,distribution=hash[v_id])]
03/06/2020 13:13:21.960 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1415: Apply rule [SetUpdatesAsRetractionRule] to [rel#679:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.false.Acc(table=[Unregistered_DataStream_9],fields=f0, f1, f2, f3, f4)]
03/06/2020 13:13:21.960 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1416: Apply rule [SetUpdatesAsRetractionRule] to [rel#700:StreamExecGroupAggregate.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#699,groupBy=v_id,select=v_id, CurrentVertex(bool, v_id, degree) AS TMP_0)]
03/06/2020 13:13:21.961 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1417: Apply rule [SetUpdatesAsRetractionRule] to [rel#683:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#680,select=f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y)]
03/06/2020 13:13:21.965 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1418: Apply rule [SetUpdatesAsRetractionRule] to [rel#685:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#682,select=v_id, TMP_0.f1 AS degree,where==(TMP_0.f0, _UTF-16LE'true'))]
03/06/2020 13:13:21.965 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1419: Apply rule [SetUpdatesAsRetractionRule] to [rel#687:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.false.Acc(input=HepRelVertex#684,distribution=hash[v_id_2])]
03/06/2020 13:13:21.965 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1420: Apply rule [SetUpdatesAsRetractionRule] to [rel#689:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.false.Acc(input=HepRelVertex#686,distribution=hash[v_id])]
03/06/2020 13:13:21.965 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1421: Apply rule [SetUpdatesAsRetractionRule] to [rel#691:StreamExecJoin.STREAM_PHYSICAL.any.None: 0.false.Acc(left=HepRelVertex#690,right=HepRelVertex#688,joinType=InnerJoin,where==(v_id, v_id_2),select=v_id, degree, v_id_2, v_label, v_id_layout, X, Y,leftInputSpec=JoinKeyContainsUniqueKey,rightInputSpec=NoUniqueKey)]
03/06/2020 13:13:22.120 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1421: Rule SetUpdatesAsRetractionRule arguments [rel#691:StreamExecJoin.STREAM_PHYSICAL.any.None: 0.false.Acc(left=HepRelVertex#690,right=HepRelVertex#688,joinType=InnerJoin,where==(v_id, v_id_2),select=v_id, degree, v_id_2, v_label, v_id_layout, X, Y,leftInputSpec=JoinKeyContainsUniqueKey,rightInputSpec=NoUniqueKey)] produced StreamExecJoin#713
03/06/2020 13:13:22.170 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1422: Apply rule [SetUpdatesAsRetractionRule] to [rel#707:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.true.Acc(table=[Unregistered_DataStream_8],fields=f0, f1, f2)]
03/06/2020 13:13:22.173 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1423: Apply rule [SetUpdatesAsRetractionRule] to [rel#710:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#709,select=f0 AS bool, f1 AS v_id, f2 AS degree)]
03/06/2020 13:13:22.174 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1424: Apply rule [SetUpdatesAsRetractionRule] to [rel#705:StreamExecExchange.STREAM_PHYSICAL.hash[1]true.None: 0.true.Acc(input=HepRelVertex#704,distribution=hash[v_id])]
03/06/2020 13:13:22.174 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1425: Apply rule [SetUpdatesAsRetractionRule] to [rel#679:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.false.Acc(table=[Unregistered_DataStream_9],fields=f0, f1, f2, f3, f4)]
03/06/2020 13:13:22.174 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1426: Apply rule [SetUpdatesAsRetractionRule] to [rel#700:StreamExecGroupAggregate.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#699,groupBy=v_id,select=v_id, CurrentVertex(bool, v_id, degree) AS TMP_0)]
03/06/2020 13:13:22.174 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1427: Apply rule [SetUpdatesAsRetractionRule] to [rel#683:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#680,select=f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y)]
03/06/2020 13:13:22.175 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1428: Apply rule [SetUpdatesAsRetractionRule] to [rel#685:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#682,select=v_id, TMP_0.f1 AS degree,where==(TMP_0.f0, _UTF-16LE'true'))]
03/06/2020 13:13:22.175 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1429: Apply rule [SetUpdatesAsRetractionRule] to [rel#712:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.true.Acc(input=HepRelVertex#684,distribution=hash[v_id_2])]
03/06/2020 13:13:22.176 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1429: Rule SetUpdatesAsRetractionRule arguments [rel#712:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.true.Acc(input=HepRelVertex#684,distribution=hash[v_id_2])] produced StreamExecExchange#718
03/06/2020 13:13:22.193 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1430: Apply rule [SetUpdatesAsRetractionRule] to [rel#707:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.true.Acc(table=[Unregistered_DataStream_8],fields=f0, f1, f2)]
03/06/2020 13:13:22.197 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1431: Apply rule [SetUpdatesAsRetractionRule] to [rel#710:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#709,select=f0 AS bool, f1 AS v_id, f2 AS degree)]
03/06/2020 13:13:22.205 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1432: Apply rule [SetUpdatesAsRetractionRule] to [rel#705:StreamExecExchange.STREAM_PHYSICAL.hash[1]true.None: 0.true.Acc(input=HepRelVertex#704,distribution=hash[v_id])]
03/06/2020 13:13:22.207 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1433: Apply rule [SetUpdatesAsRetractionRule] to [rel#679:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.false.Acc(table=[Unregistered_DataStream_9],fields=f0, f1, f2, f3, f4)]
03/06/2020 13:13:22.209 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1434: Apply rule [SetUpdatesAsRetractionRule] to [rel#700:StreamExecGroupAggregate.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#699,groupBy=v_id,select=v_id, CurrentVertex(bool, v_id, degree) AS TMP_0)]
03/06/2020 13:13:22.209 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1435: Apply rule [SetUpdatesAsRetractionRule] to [rel#717:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#680,select=f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y)]
03/06/2020 13:13:22.211 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1435: Rule SetUpdatesAsRetractionRule arguments [rel#717:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#680,select=f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y)] produced StreamExecCalc#723
03/06/2020 13:13:22.214 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1436: Apply rule [SetUpdatesAsRetractionRule] to [rel#707:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.true.Acc(table=[Unregistered_DataStream_8],fields=f0, f1, f2)]
03/06/2020 13:13:22.221 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1437: Apply rule [SetUpdatesAsRetractionRule] to [rel#710:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#709,select=f0 AS bool, f1 AS v_id, f2 AS degree)]
03/06/2020 13:13:22.222 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1438: Apply rule [SetUpdatesAsRetractionRule] to [rel#705:StreamExecExchange.STREAM_PHYSICAL.hash[1]true.None: 0.true.Acc(input=HepRelVertex#704,distribution=hash[v_id])]
03/06/2020 13:13:22.223 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1439: Apply rule [SetUpdatesAsRetractionRule] to [rel#722:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.true.Acc(table=[Unregistered_DataStream_9],fields=f0, f1, f2, f3, f4)]
03/06/2020 13:13:22.223 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1440: Apply rule [SetUpdatesAsRetractionRule] to [rel#700:StreamExecGroupAggregate.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#699,groupBy=v_id,select=v_id, CurrentVertex(bool, v_id, degree) AS TMP_0)]
03/06/2020 13:13:22.223 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1441: Apply rule [SetUpdatesAsRetractionRule] to [rel#725:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#724,select=f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y)]
03/06/2020 13:13:22.224 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1442: Apply rule [SetUpdatesAsRetractionRule] to [rel#685:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#682,select=v_id, TMP_0.f1 AS degree,where==(TMP_0.f0, _UTF-16LE'true'))]
03/06/2020 13:13:22.225 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1443: Apply rule [SetUpdatesAsRetractionRule] to [rel#720:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.true.Acc(input=HepRelVertex#719,distribution=hash[v_id_2])]
03/06/2020 13:13:22.225 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1444: Apply rule [SetUpdatesAsRetractionRule] to [rel#689:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.false.Acc(input=HepRelVertex#686,distribution=hash[v_id])]
03/06/2020 13:13:22.227 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1445: Apply rule [SetUpdatesAsRetractionRule] to [rel#715:StreamExecJoin.STREAM_PHYSICAL.any.None: 0.false.Acc(left=HepRelVertex#690,right=HepRelVertex#721,joinType=InnerJoin,where==(v_id, v_id_2),select=v_id, degree, v_id_2, v_label, v_id_layout, X, Y,leftInputSpec=JoinKeyContainsUniqueKey,rightInputSpec=NoUniqueKey)]
03/06/2020 13:13:22.229 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1446: Apply rule [SetUpdatesAsRetractionRule] to [rel#693:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#692,select=v_label, X, Y, v_id_layout, degree, v_id)]
03/06/2020 13:13:22.231 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1447: Apply rule [SetUpdatesAsRetractionRule] to [rel#695:StreamExecSink.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#694,name=DataStreamTableSink,fields=v_label, X, Y, v_id_layout, degree, v_id)]
03/06/2020 13:13:22.232 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1447: Rule SetUpdatesAsRetractionRule arguments [rel#695:StreamExecSink.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#694,name=DataStreamTableSink,fields=v_label, X, Y, v_id_layout, degree, v_id)] produced StreamExecSink#728
03/06/2020 13:13:22.271 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1448: Apply rule [SetUpdatesAsRetractionRule] to [rel#707:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.true.Acc(table=[Unregistered_DataStream_8],fields=f0, f1, f2)]
03/06/2020 13:13:22.271 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1449: Apply rule [SetUpdatesAsRetractionRule] to [rel#710:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#709,select=f0 AS bool, f1 AS v_id, f2 AS degree)]
03/06/2020 13:13:22.271 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1450: Apply rule [SetUpdatesAsRetractionRule] to [rel#705:StreamExecExchange.STREAM_PHYSICAL.hash[1]true.None: 0.true.Acc(input=HepRelVertex#704,distribution=hash[v_id])]
03/06/2020 13:13:22.271 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1451: Apply rule [SetUpdatesAsRetractionRule] to [rel#722:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.true.Acc(table=[Unregistered_DataStream_9],fields=f0, f1, f2, f3, f4)]
03/06/2020 13:13:22.271 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1452: Apply rule [SetUpdatesAsRetractionRule] to [rel#700:StreamExecGroupAggregate.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#699,groupBy=v_id,select=v_id, CurrentVertex(bool, v_id, degree) AS TMP_0)]
03/06/2020 13:13:22.271 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1453: Apply rule [SetUpdatesAsRetractionRule] to [rel#725:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#724,select=f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y)]
03/06/2020 13:13:22.271 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1454: Apply rule [SetUpdatesAsRetractionRule] to [rel#685:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#682,select=v_id, TMP_0.f1 AS degree,where==(TMP_0.f0, _UTF-16LE'true'))]
03/06/2020 13:13:22.271 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1455: Apply rule [SetUpdatesAsRetractionRule] to [rel#720:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.true.Acc(input=HepRelVertex#719,distribution=hash[v_id_2])]
03/06/2020 13:13:22.271 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1456: Apply rule [SetUpdatesAsRetractionRule] to [rel#689:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.false.Acc(input=HepRelVertex#686,distribution=hash[v_id])]
03/06/2020 13:13:22.272 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1457: Apply rule [SetUpdatesAsRetractionRule] to [rel#715:StreamExecJoin.STREAM_PHYSICAL.any.None: 0.false.Acc(left=HepRelVertex#690,right=HepRelVertex#721,joinType=InnerJoin,where==(v_id, v_id_2),select=v_id, degree, v_id_2, v_label, v_id_layout, X, Y,leftInputSpec=JoinKeyContainsUniqueKey,rightInputSpec=NoUniqueKey)]
03/06/2020 13:13:22.275 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1458: Apply rule [SetUpdatesAsRetractionRule] to [rel#727:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#716,select=v_label, X, Y, v_id_layout, degree, v_id)]
03/06/2020 13:13:22.278 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1458: Rule SetUpdatesAsRetractionRule arguments [rel#727:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#716,select=v_label, X, Y, v_id_layout, degree, v_id)] produced StreamExecCalc#733
03/06/2020 13:13:22.287 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1459: Apply rule [SetUpdatesAsRetractionRule] to [rel#707:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.true.Acc(table=[Unregistered_DataStream_8],fields=f0, f1, f2)]
03/06/2020 13:13:22.295 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1460: Apply rule [SetUpdatesAsRetractionRule] to [rel#710:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#709,select=f0 AS bool, f1 AS v_id, f2 AS degree)]
03/06/2020 13:13:22.295 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1461: Apply rule [SetUpdatesAsRetractionRule] to [rel#705:StreamExecExchange.STREAM_PHYSICAL.hash[1]true.None: 0.true.Acc(input=HepRelVertex#704,distribution=hash[v_id])]
03/06/2020 13:13:22.295 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1462: Apply rule [SetUpdatesAsRetractionRule] to [rel#722:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.true.Acc(table=[Unregistered_DataStream_9],fields=f0, f1, f2, f3, f4)]
03/06/2020 13:13:22.295 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1463: Apply rule [SetUpdatesAsRetractionRule] to [rel#700:StreamExecGroupAggregate.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#699,groupBy=v_id,select=v_id, CurrentVertex(bool, v_id, degree) AS TMP_0)]
03/06/2020 13:13:22.296 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1464: Apply rule [SetUpdatesAsRetractionRule] to [rel#725:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#724,select=f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y)]
03/06/2020 13:13:22.297 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1465: Apply rule [SetUpdatesAsRetractionRule] to [rel#685:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#682,select=v_id, TMP_0.f1 AS degree,where==(TMP_0.f0, _UTF-16LE'true'))]
03/06/2020 13:13:22.299 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1466: Apply rule [SetUpdatesAsRetractionRule] to [rel#720:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.true.Acc(input=HepRelVertex#719,distribution=hash[v_id_2])]
03/06/2020 13:13:22.302 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1467: Apply rule [SetUpdatesAsRetractionRule] to [rel#689:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.false.Acc(input=HepRelVertex#686,distribution=hash[v_id])]
03/06/2020 13:13:22.303 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1468: Apply rule [SetUpdatesAsRetractionRule] to [rel#732:StreamExecJoin.STREAM_PHYSICAL.any.None: 0.true.Acc(left=HepRelVertex#690,right=HepRelVertex#721,joinType=InnerJoin,where==(v_id, v_id_2),select=v_id, degree, v_id_2, v_label, v_id_layout, X, Y,leftInputSpec=JoinKeyContainsUniqueKey,rightInputSpec=NoUniqueKey)]
03/06/2020 13:13:22.304 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1468: Rule SetUpdatesAsRetractionRule arguments [rel#732:StreamExecJoin.STREAM_PHYSICAL.any.None: 0.true.Acc(left=HepRelVertex#690,right=HepRelVertex#721,joinType=InnerJoin,where==(v_id, v_id_2),select=v_id, degree, v_id_2, v_label, v_id_layout, X, Y,leftInputSpec=JoinKeyContainsUniqueKey,rightInputSpec=NoUniqueKey)] produced StreamExecJoin#738
03/06/2020 13:13:22.323 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1469: Apply rule [SetUpdatesAsRetractionRule] to [rel#707:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.true.Acc(table=[Unregistered_DataStream_8],fields=f0, f1, f2)]
03/06/2020 13:13:22.324 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1470: Apply rule [SetUpdatesAsRetractionRule] to [rel#710:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#709,select=f0 AS bool, f1 AS v_id, f2 AS degree)]
03/06/2020 13:13:22.324 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1471: Apply rule [SetUpdatesAsRetractionRule] to [rel#705:StreamExecExchange.STREAM_PHYSICAL.hash[1]true.None: 0.true.Acc(input=HepRelVertex#704,distribution=hash[v_id])]
03/06/2020 13:13:22.325 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1472: Apply rule [SetUpdatesAsRetractionRule] to [rel#722:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.true.Acc(table=[Unregistered_DataStream_9],fields=f0, f1, f2, f3, f4)]
03/06/2020 13:13:22.326 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1473: Apply rule [SetUpdatesAsRetractionRule] to [rel#700:StreamExecGroupAggregate.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#699,groupBy=v_id,select=v_id, CurrentVertex(bool, v_id, degree) AS TMP_0)]
03/06/2020 13:13:22.327 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1474: Apply rule [SetUpdatesAsRetractionRule] to [rel#725:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#724,select=f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y)]
03/06/2020 13:13:22.346 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1475: Apply rule [SetUpdatesAsRetractionRule] to [rel#685:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#682,select=v_id, TMP_0.f1 AS degree,where==(TMP_0.f0, _UTF-16LE'true'))]
03/06/2020 13:13:22.357 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1476: Apply rule [SetUpdatesAsRetractionRule] to [rel#720:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.true.Acc(input=HepRelVertex#726,distribution=hash[v_id_2])]
03/06/2020 13:13:22.359 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1477: Apply rule [SetUpdatesAsRetractionRule] to [rel#737:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.true.Acc(input=HepRelVertex#686,distribution=hash[v_id])]
03/06/2020 13:13:22.359 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1477: Rule SetUpdatesAsRetractionRule arguments [rel#737:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.true.Acc(input=HepRelVertex#686,distribution=hash[v_id])] produced StreamExecExchange#744
03/06/2020 13:13:22.367 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1478: Apply rule [SetUpdatesAsRetractionRule] to [rel#707:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.true.Acc(table=[Unregistered_DataStream_8],fields=f0, f1, f2)]
03/06/2020 13:13:22.370 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1479: Apply rule [SetUpdatesAsRetractionRule] to [rel#710:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#709,select=f0 AS bool, f1 AS v_id, f2 AS degree)]
03/06/2020 13:13:22.371 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1480: Apply rule [SetUpdatesAsRetractionRule] to [rel#705:StreamExecExchange.STREAM_PHYSICAL.hash[1]true.None: 0.true.Acc(input=HepRelVertex#704,distribution=hash[v_id])]
03/06/2020 13:13:22.371 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1481: Apply rule [SetUpdatesAsRetractionRule] to [rel#700:StreamExecGroupAggregate.STREAM_PHYSICAL.any.None: 0.false.Acc(input=HepRelVertex#699,groupBy=v_id,select=v_id, CurrentVertex(bool, v_id, degree) AS TMP_0)]
03/06/2020 13:13:22.371 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1482: Apply rule [SetUpdatesAsRetractionRule] to [rel#722:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.true.Acc(table=[Unregistered_DataStream_9],fields=f0, f1, f2, f3, f4)]
03/06/2020 13:13:22.371 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1483: Apply rule [SetUpdatesAsRetractionRule] to [rel#743:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#701,select=v_id, TMP_0.f1 AS degree,where==(TMP_0.f0, _UTF-16LE'true'))]
03/06/2020 13:13:22.372 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1483: Rule SetUpdatesAsRetractionRule arguments [rel#743:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#701,select=v_id, TMP_0.f1 AS degree,where==(TMP_0.f0, _UTF-16LE'true'))] produced StreamExecCalc#749
03/06/2020 13:13:22.377 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1484: Apply rule [SetUpdatesAsRetractionRule] to [rel#707:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.true.Acc(table=[Unregistered_DataStream_8],fields=f0, f1, f2)]
03/06/2020 13:13:22.382 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1485: Apply rule [SetUpdatesAsRetractionRule] to [rel#710:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#709,select=f0 AS bool, f1 AS v_id, f2 AS degree)]
03/06/2020 13:13:22.383 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1486: Apply rule [SetUpdatesAsRetractionRule] to [rel#705:StreamExecExchange.STREAM_PHYSICAL.hash[1]true.None: 0.true.Acc(input=HepRelVertex#704,distribution=hash[v_id])]
03/06/2020 13:13:22.384 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1487: Apply rule [SetUpdatesAsRetractionRule] to [rel#748:StreamExecGroupAggregate.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#706,groupBy=v_id,select=v_id, CurrentVertex(bool, v_id, degree) AS TMP_0)]
03/06/2020 13:13:22.385 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1488: Apply rule [SetUpdatesAsRetractionRule] to [rel#722:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.true.Acc(table=[Unregistered_DataStream_9],fields=f0, f1, f2, f3, f4)]
03/06/2020 13:13:22.388 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1489: Apply rule [SetUpdatesAsRetractionRule] to [rel#751:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#750,select=v_id, TMP_0.f1 AS degree,where==(TMP_0.f0, _UTF-16LE'true'))]
03/06/2020 13:13:22.391 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1490: Apply rule [SetUpdatesAsRetractionRule] to [rel#725:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#724,select=f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y)]
03/06/2020 13:13:22.391 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1491: Apply rule [SetUpdatesAsRetractionRule] to [rel#746:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.true.Acc(input=HepRelVertex#745,distribution=hash[v_id])]
03/06/2020 13:13:22.391 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1492: Apply rule [SetUpdatesAsRetractionRule] to [rel#720:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.true.Acc(input=HepRelVertex#726,distribution=hash[v_id_2])]
03/06/2020 13:13:22.392 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1493: Apply rule [SetUpdatesAsRetractionRule] to [rel#741:StreamExecJoin.STREAM_PHYSICAL.any.None: 0.true.Acc(left=HepRelVertex#747,right=HepRelVertex#740,joinType=InnerJoin,where==(v_id, v_id_2),select=v_id, degree, v_id_2, v_label, v_id_layout, X, Y,leftInputSpec=JoinKeyContainsUniqueKey,rightInputSpec=NoUniqueKey)]
03/06/2020 13:13:22.392 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1494: Apply rule [SetUpdatesAsRetractionRule] to [rel#735:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#734,select=v_label, X, Y, v_id_layout, degree, v_id)]
03/06/2020 13:13:22.392 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1495: Apply rule [SetUpdatesAsRetractionRule] to [rel#730:StreamExecSink.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#729,name=DataStreamTableSink,fields=v_label, X, Y, v_id_layout, degree, v_id)]
03/06/2020 13:13:22.393 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1496: Apply rule [SetAccModeRule] to [rel#707:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.true.Acc(table=[Unregistered_DataStream_8],fields=f0, f1, f2)]
03/06/2020 13:13:22.398 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1497: Apply rule [SetAccModeRule] to [rel#710:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#709,select=f0 AS bool, f1 AS v_id, f2 AS degree)]
03/06/2020 13:13:22.402 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1498: Apply rule [SetAccModeRule] to [rel#705:StreamExecExchange.STREAM_PHYSICAL.hash[1]true.None: 0.true.Acc(input=HepRelVertex#704,distribution=hash[v_id])]
03/06/2020 13:13:22.403 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1499: Apply rule [SetAccModeRule] to [rel#748:StreamExecGroupAggregate.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#706,groupBy=v_id,select=v_id, CurrentVertex(bool, v_id, degree) AS TMP_0)]
03/06/2020 13:13:22.404 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1499: Rule SetAccModeRule arguments [rel#748:StreamExecGroupAggregate.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#706,groupBy=v_id,select=v_id, CurrentVertex(bool, v_id, degree) AS TMP_0)] produced StreamExecGroupAggregate#753
03/06/2020 13:13:22.409 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1500: Apply rule [SetAccModeRule] to [rel#707:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.true.Acc(table=[Unregistered_DataStream_8],fields=f0, f1, f2)]
03/06/2020 13:13:22.409 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1501: Apply rule [SetAccModeRule] to [rel#710:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#709,select=f0 AS bool, f1 AS v_id, f2 AS degree)]
03/06/2020 13:13:22.411 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1502: Apply rule [SetAccModeRule] to [rel#705:StreamExecExchange.STREAM_PHYSICAL.hash[1]true.None: 0.true.Acc(input=HepRelVertex#704,distribution=hash[v_id])]
03/06/2020 13:13:22.417 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1503: Apply rule [SetAccModeRule] to [rel#753:StreamExecGroupAggregate.STREAM_PHYSICAL.any.None: 0.true.AccRetract(input=HepRelVertex#706,groupBy=v_id,select=v_id, CurrentVertex(bool, v_id, degree) AS TMP_0)]
03/06/2020 13:13:22.420 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1504: Apply rule [SetAccModeRule] to [rel#722:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.true.Acc(table=[Unregistered_DataStream_9],fields=f0, f1, f2, f3, f4)]
03/06/2020 13:13:22.421 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1505: Apply rule [SetAccModeRule] to [rel#751:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#750,select=v_id, TMP_0.f1 AS degree,where==(TMP_0.f0, _UTF-16LE'true'))]
03/06/2020 13:13:22.421 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1505: Rule SetAccModeRule arguments [rel#751:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#750,select=v_id, TMP_0.f1 AS degree,where==(TMP_0.f0, _UTF-16LE'true'))] produced StreamExecCalc#755
03/06/2020 13:13:22.422 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1506: Apply rule [SetAccModeRule] to [rel#707:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.true.Acc(table=[Unregistered_DataStream_8],fields=f0, f1, f2)]
03/06/2020 13:13:22.424 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1507: Apply rule [SetAccModeRule] to [rel#710:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#709,select=f0 AS bool, f1 AS v_id, f2 AS degree)]
03/06/2020 13:13:22.424 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1508: Apply rule [SetAccModeRule] to [rel#705:StreamExecExchange.STREAM_PHYSICAL.hash[1]true.None: 0.true.Acc(input=HepRelVertex#704,distribution=hash[v_id])]
03/06/2020 13:13:22.424 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1509: Apply rule [SetAccModeRule] to [rel#753:StreamExecGroupAggregate.STREAM_PHYSICAL.any.None: 0.true.AccRetract(input=HepRelVertex#706,groupBy=v_id,select=v_id, CurrentVertex(bool, v_id, degree) AS TMP_0)]
03/06/2020 13:13:22.424 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1510: Apply rule [SetAccModeRule] to [rel#722:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.true.Acc(table=[Unregistered_DataStream_9],fields=f0, f1, f2, f3, f4)]
03/06/2020 13:13:22.424 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1511: Apply rule [SetAccModeRule] to [rel#755:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.AccRetract(input=HepRelVertex#754,select=v_id, TMP_0.f1 AS degree,where==(TMP_0.f0, _UTF-16LE'true'))]
03/06/2020 13:13:22.424 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1512: Apply rule [SetAccModeRule] to [rel#725:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#724,select=f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y)]
03/06/2020 13:13:22.426 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1513: Apply rule [SetAccModeRule] to [rel#746:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.true.Acc(input=HepRelVertex#745,distribution=hash[v_id])]
03/06/2020 13:13:22.430 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1513: Rule SetAccModeRule arguments [rel#746:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.true.Acc(input=HepRelVertex#745,distribution=hash[v_id])] produced StreamExecExchange#757
03/06/2020 13:13:22.455 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1514: Apply rule [SetAccModeRule] to [rel#707:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.true.Acc(table=[Unregistered_DataStream_8],fields=f0, f1, f2)]
03/06/2020 13:13:22.457 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1515: Apply rule [SetAccModeRule] to [rel#710:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#709,select=f0 AS bool, f1 AS v_id, f2 AS degree)]
03/06/2020 13:13:22.458 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1516: Apply rule [SetAccModeRule] to [rel#705:StreamExecExchange.STREAM_PHYSICAL.hash[1]true.None: 0.true.Acc(input=HepRelVertex#704,distribution=hash[v_id])]
03/06/2020 13:13:22.458 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1517: Apply rule [SetAccModeRule] to [rel#753:StreamExecGroupAggregate.STREAM_PHYSICAL.any.None: 0.true.AccRetract(input=HepRelVertex#706,groupBy=v_id,select=v_id, CurrentVertex(bool, v_id, degree) AS TMP_0)]
03/06/2020 13:13:22.458 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1518: Apply rule [SetAccModeRule] to [rel#722:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.true.Acc(table=[Unregistered_DataStream_9],fields=f0, f1, f2, f3, f4)]
03/06/2020 13:13:22.458 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1519: Apply rule [SetAccModeRule] to [rel#755:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.AccRetract(input=HepRelVertex#754,select=v_id, TMP_0.f1 AS degree,where==(TMP_0.f0, _UTF-16LE'true'))]
03/06/2020 13:13:22.459 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1520: Apply rule [SetAccModeRule] to [rel#725:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#724,select=f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y)]
03/06/2020 13:13:22.459 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1521: Apply rule [SetAccModeRule] to [rel#757:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.true.AccRetract(input=HepRelVertex#756,distribution=hash[v_id])]
03/06/2020 13:13:22.459 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1522: Apply rule [SetAccModeRule] to [rel#720:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.true.Acc(input=HepRelVertex#726,distribution=hash[v_id_2])]
03/06/2020 13:13:22.460 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1523: Apply rule [SetAccModeRule] to [rel#741:StreamExecJoin.STREAM_PHYSICAL.any.None: 0.true.Acc(left=HepRelVertex#758,right=HepRelVertex#740,joinType=InnerJoin,where==(v_id, v_id_2),select=v_id, degree, v_id_2, v_label, v_id_layout, X, Y,leftInputSpec=JoinKeyContainsUniqueKey,rightInputSpec=NoUniqueKey)]
03/06/2020 13:13:22.462 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1523: Rule SetAccModeRule arguments [rel#741:StreamExecJoin.STREAM_PHYSICAL.any.None: 0.true.Acc(left=HepRelVertex#758,right=HepRelVertex#740,joinType=InnerJoin,where==(v_id, v_id_2),select=v_id, degree, v_id_2, v_label, v_id_layout, X, Y,leftInputSpec=JoinKeyContainsUniqueKey,rightInputSpec=NoUniqueKey)] produced StreamExecJoin#759
03/06/2020 13:13:22.482 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1524: Apply rule [SetAccModeRule] to [rel#707:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.true.Acc(table=[Unregistered_DataStream_8],fields=f0, f1, f2)]
03/06/2020 13:13:22.482 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1525: Apply rule [SetAccModeRule] to [rel#710:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#709,select=f0 AS bool, f1 AS v_id, f2 AS degree)]
03/06/2020 13:13:22.482 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1526: Apply rule [SetAccModeRule] to [rel#705:StreamExecExchange.STREAM_PHYSICAL.hash[1]true.None: 0.true.Acc(input=HepRelVertex#704,distribution=hash[v_id])]
03/06/2020 13:13:22.482 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1527: Apply rule [SetAccModeRule] to [rel#722:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.true.Acc(table=[Unregistered_DataStream_9],fields=f0, f1, f2, f3, f4)]
03/06/2020 13:13:22.487 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1528: Apply rule [SetAccModeRule] to [rel#753:StreamExecGroupAggregate.STREAM_PHYSICAL.any.None: 0.true.AccRetract(input=HepRelVertex#706,groupBy=v_id,select=v_id, CurrentVertex(bool, v_id, degree) AS TMP_0)]
03/06/2020 13:13:22.487 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1529: Apply rule [SetAccModeRule] to [rel#725:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#724,select=f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y)]
03/06/2020 13:13:22.487 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1530: Apply rule [SetAccModeRule] to [rel#755:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.AccRetract(input=HepRelVertex#754,select=v_id, TMP_0.f1 AS degree,where==(TMP_0.f0, _UTF-16LE'true'))]
03/06/2020 13:13:22.488 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1531: Apply rule [SetAccModeRule] to [rel#720:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.true.Acc(input=HepRelVertex#726,distribution=hash[v_id_2])]
03/06/2020 13:13:22.489 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1532: Apply rule [SetAccModeRule] to [rel#757:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.true.AccRetract(input=HepRelVertex#756,distribution=hash[v_id])]
03/06/2020 13:13:22.497 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1533: Apply rule [SetAccModeRule] to [rel#759:StreamExecJoin.STREAM_PHYSICAL.any.None: 0.true.AccRetract(left=HepRelVertex#758,right=HepRelVertex#740,joinType=InnerJoin,where==(v_id, v_id_2),select=v_id, degree, v_id_2, v_label, v_id_layout, X, Y,leftInputSpec=JoinKeyContainsUniqueKey,rightInputSpec=NoUniqueKey)]
03/06/2020 13:13:22.497 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1534: Apply rule [SetAccModeRule] to [rel#735:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#734,select=v_label, X, Y, v_id_layout, degree, v_id)]
03/06/2020 13:13:22.501 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1534: Rule SetAccModeRule arguments [rel#735:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#734,select=v_label, X, Y, v_id_layout, degree, v_id)] produced StreamExecCalc#761
03/06/2020 13:13:22.503 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1535: Apply rule [SetAccModeRule] to [rel#707:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.true.Acc(table=[Unregistered_DataStream_8],fields=f0, f1, f2)]
03/06/2020 13:13:22.503 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1536: Apply rule [SetAccModeRule] to [rel#710:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#709,select=f0 AS bool, f1 AS v_id, f2 AS degree)]
03/06/2020 13:13:22.503 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1537: Apply rule [SetAccModeRule] to [rel#705:StreamExecExchange.STREAM_PHYSICAL.hash[1]true.None: 0.true.Acc(input=HepRelVertex#704,distribution=hash[v_id])]
03/06/2020 13:13:22.503 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1538: Apply rule [SetAccModeRule] to [rel#722:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.true.Acc(table=[Unregistered_DataStream_9],fields=f0, f1, f2, f3, f4)]
03/06/2020 13:13:22.507 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1539: Apply rule [SetAccModeRule] to [rel#753:StreamExecGroupAggregate.STREAM_PHYSICAL.any.None: 0.true.AccRetract(input=HepRelVertex#706,groupBy=v_id,select=v_id, CurrentVertex(bool, v_id, degree) AS TMP_0)]
03/06/2020 13:13:22.508 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1540: Apply rule [SetAccModeRule] to [rel#725:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#724,select=f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y)]
03/06/2020 13:13:22.508 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1541: Apply rule [SetAccModeRule] to [rel#755:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.AccRetract(input=HepRelVertex#754,select=v_id, TMP_0.f1 AS degree,where==(TMP_0.f0, _UTF-16LE'true'))]
03/06/2020 13:13:22.508 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1542: Apply rule [SetAccModeRule] to [rel#720:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.true.Acc(input=HepRelVertex#726,distribution=hash[v_id_2])]
03/06/2020 13:13:22.509 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1543: Apply rule [SetAccModeRule] to [rel#757:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.true.AccRetract(input=HepRelVertex#756,distribution=hash[v_id])]
03/06/2020 13:13:22.509 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1544: Apply rule [SetAccModeRule] to [rel#759:StreamExecJoin.STREAM_PHYSICAL.any.None: 0.true.AccRetract(left=HepRelVertex#758,right=HepRelVertex#740,joinType=InnerJoin,where==(v_id, v_id_2),select=v_id, degree, v_id_2, v_label, v_id_layout, X, Y,leftInputSpec=JoinKeyContainsUniqueKey,rightInputSpec=NoUniqueKey)]
03/06/2020 13:13:22.509 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1545: Apply rule [SetAccModeRule] to [rel#761:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.AccRetract(input=HepRelVertex#760,select=v_label, X, Y, v_id_layout, degree, v_id)]
03/06/2020 13:13:22.509 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1546: Apply rule [SetAccModeRule] to [rel#730:StreamExecSink.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#729,name=DataStreamTableSink,fields=v_label, X, Y, v_id_layout, degree, v_id)]
03/06/2020 13:13:22.517 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1546: Rule SetAccModeRule arguments [rel#730:StreamExecSink.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#729,name=DataStreamTableSink,fields=v_label, X, Y, v_id_layout, degree, v_id)] produced StreamExecSink#763
03/06/2020 13:13:22.520 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1547: Apply rule [SetAccModeRule] to [rel#707:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.true.Acc(table=[Unregistered_DataStream_8],fields=f0, f1, f2)]
03/06/2020 13:13:22.520 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1548: Apply rule [SetAccModeRule] to [rel#710:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#709,select=f0 AS bool, f1 AS v_id, f2 AS degree)]
03/06/2020 13:13:22.520 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1549: Apply rule [SetAccModeRule] to [rel#705:StreamExecExchange.STREAM_PHYSICAL.hash[1]true.None: 0.true.Acc(input=HepRelVertex#704,distribution=hash[v_id])]
03/06/2020 13:13:22.521 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1550: Apply rule [SetAccModeRule] to [rel#722:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.true.Acc(table=[Unregistered_DataStream_9],fields=f0, f1, f2, f3, f4)]
03/06/2020 13:13:22.521 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1551: Apply rule [SetAccModeRule] to [rel#753:StreamExecGroupAggregate.STREAM_PHYSICAL.any.None: 0.true.AccRetract(input=HepRelVertex#706,groupBy=v_id,select=v_id, CurrentVertex(bool, v_id, degree) AS TMP_0)]
03/06/2020 13:13:22.521 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1552: Apply rule [SetAccModeRule] to [rel#725:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#724,select=f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y)]
03/06/2020 13:13:22.521 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1553: Apply rule [SetAccModeRule] to [rel#755:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.AccRetract(input=HepRelVertex#754,select=v_id, TMP_0.f1 AS degree,where==(TMP_0.f0, _UTF-16LE'true'))]
03/06/2020 13:13:22.523 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1554: Apply rule [SetAccModeRule] to [rel#720:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.true.Acc(input=HepRelVertex#726,distribution=hash[v_id_2])]
03/06/2020 13:13:22.526 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1555: Apply rule [SetAccModeRule] to [rel#757:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.true.AccRetract(input=HepRelVertex#756,distribution=hash[v_id])]
03/06/2020 13:13:22.526 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1556: Apply rule [SetAccModeRule] to [rel#759:StreamExecJoin.STREAM_PHYSICAL.any.None: 0.true.AccRetract(left=HepRelVertex#758,right=HepRelVertex#740,joinType=InnerJoin,where==(v_id, v_id_2),select=v_id, degree, v_id_2, v_label, v_id_layout, X, Y,leftInputSpec=JoinKeyContainsUniqueKey,rightInputSpec=NoUniqueKey)]
03/06/2020 13:13:22.526 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1557: Apply rule [SetAccModeRule] to [rel#761:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.AccRetract(input=HepRelVertex#760,select=v_label, X, Y, v_id_layout, degree, v_id)]
03/06/2020 13:13:22.526 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1558: Apply rule [SetAccModeRule] to [rel#763:StreamExecSink.STREAM_PHYSICAL.any.None: 0.true.AccRetract(input=HepRelVertex#762,name=DataStreamTableSink,fields=v_label, X, Y, v_id_layout, degree, v_id)]
03/06/2020 13:13:22.526 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#763:StreamExecSink.STREAM_PHYSICAL.any.None: 0.true.AccRetract(input=HepRelVertex#762,name=DataStreamTableSink,fields=v_label, X, Y, v_id_layout, degree, v_id)
03/06/2020 13:13:22.526 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#761:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.AccRetract(input=HepRelVertex#760,select=v_label, X, Y, v_id_layout, degree, v_id)
03/06/2020 13:13:22.526 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#759:StreamExecJoin.STREAM_PHYSICAL.any.None: 0.true.AccRetract(left=HepRelVertex#758,right=HepRelVertex#740,joinType=InnerJoin,where==(v_id, v_id_2),select=v_id, degree, v_id_2, v_label, v_id_layout, X, Y,leftInputSpec=JoinKeyContainsUniqueKey,rightInputSpec=NoUniqueKey)
03/06/2020 13:13:22.527 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#757:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.true.AccRetract(input=HepRelVertex#756,distribution=hash[v_id])
03/06/2020 13:13:22.528 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#755:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.AccRetract(input=HepRelVertex#754,select=v_id, TMP_0.f1 AS degree,where==(TMP_0.f0, _UTF-16LE'true'))
03/06/2020 13:13:22.530 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#753:StreamExecGroupAggregate.STREAM_PHYSICAL.any.None: 0.true.AccRetract(input=HepRelVertex#706,groupBy=v_id,select=v_id, CurrentVertex(bool, v_id, degree) AS TMP_0)
03/06/2020 13:13:22.530 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#705:StreamExecExchange.STREAM_PHYSICAL.hash[1]true.None: 0.true.Acc(input=HepRelVertex#704,distribution=hash[v_id])
03/06/2020 13:13:22.530 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#710:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#709,select=f0 AS bool, f1 AS v_id, f2 AS degree)
03/06/2020 13:13:22.530 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#707:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.true.Acc(table=[Unregistered_DataStream_8],fields=f0, f1, f2)
03/06/2020 13:13:22.639 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#720:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.true.Acc(input=HepRelVertex#726,distribution=hash[v_id_2])
03/06/2020 13:13:22.647 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#725:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#724,select=f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y)
03/06/2020 13:13:22.647 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#722:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.true.Acc(table=[Unregistered_DataStream_9],fields=f0, f1, f2, f3, f4)
03/06/2020 13:13:22.708 DEBUG [org.apache.flink.table.planner.plan.optimize.program.FlinkGroupProgram] optimize retraction rules cost 884 ms.
optimize result:
 Sink(name=[DataStreamTableSink], fields=[v_label, X, Y, v_id_layout, degree, v_id])
+- Calc(select=[v_label, X, Y, v_id_layout, degree, v_id])
   +- Join(joinType=[InnerJoin], where=[=(v_id, v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey])
      :- Exchange(distribution=[hash[v_id]])
      :  +- Calc(select=[v_id, TMP_0.f1 AS degree], where=[=(TMP_0.f0, _UTF-16LE'true')])
      :     +- GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0])
      :        +- Exchange(distribution=[hash[v_id]])
      :           +- Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree])
      :              +- DataStreamScan(table=[[Unregistered_DataStream_8]], fields=[f0, f1, f2])
      +- Exchange(distribution=[hash[v_id_2]])
         +- Calc(select=[f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y])
            +- DataStreamScan(table=[[Unregistered_DataStream_9]], fields=[f0, f1, f2, f3, f4])

03/06/2020 13:13:22.719 DEBUG [org.apache.flink.table.planner.plan.optimize.program.FlinkGroupProgram] optimize Initialization for mini-batch interval inference cost 0 ms.
optimize result:
 Sink(name=[DataStreamTableSink], fields=[v_label, X, Y, v_id_layout, degree, v_id])
+- Calc(select=[v_label, X, Y, v_id_layout, degree, v_id])
   +- Join(joinType=[InnerJoin], where=[=(v_id, v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey])
      :- Exchange(distribution=[hash[v_id]])
      :  +- Calc(select=[v_id, TMP_0.f1 AS degree], where=[=(TMP_0.f0, _UTF-16LE'true')])
      :     +- GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0])
      :        +- Exchange(distribution=[hash[v_id]])
      :           +- Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree])
      :              +- DataStreamScan(table=[[Unregistered_DataStream_8]], fields=[f0, f1, f2])
      +- Exchange(distribution=[hash[v_id_2]])
         +- Calc(select=[f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y])
            +- DataStreamScan(table=[[Unregistered_DataStream_9]], fields=[f0, f1, f2, f3, f4])

03/06/2020 13:13:22.731 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1559: Apply rule [MiniBatchIntervalInferRule] to [rel#786:StreamExecSink.STREAM_PHYSICAL.any.None: 0.true.AccRetract(input=HepRelVertex#785,name=DataStreamTableSink,fields=v_label, X, Y, v_id_layout, degree, v_id)]
03/06/2020 13:13:22.745 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1560: Apply rule [MiniBatchIntervalInferRule] to [rel#784:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.AccRetract(input=HepRelVertex#783,select=v_label, X, Y, v_id_layout, degree, v_id)]
03/06/2020 13:13:22.747 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1561: Apply rule [MiniBatchIntervalInferRule] to [rel#782:StreamExecJoin.STREAM_PHYSICAL.any.None: 0.true.AccRetract(left=HepRelVertex#776,right=HepRelVertex#781,joinType=InnerJoin,where==(v_id, v_id_2),select=v_id, degree, v_id_2, v_label, v_id_layout, X, Y,leftInputSpec=JoinKeyContainsUniqueKey,rightInputSpec=NoUniqueKey)]
03/06/2020 13:13:22.768 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1562: Apply rule [MiniBatchIntervalInferRule] to [rel#775:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.true.AccRetract(input=HepRelVertex#774,distribution=hash[v_id])]
03/06/2020 13:13:22.774 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1563: Apply rule [MiniBatchIntervalInferRule] to [rel#780:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.true.Acc(input=HepRelVertex#779,distribution=hash[v_id_2])]
03/06/2020 13:13:22.781 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1564: Apply rule [MiniBatchIntervalInferRule] to [rel#773:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.AccRetract(input=HepRelVertex#772,select=v_id, TMP_0.f1 AS degree,where==(TMP_0.f0, _UTF-16LE'true'))]
03/06/2020 13:13:22.782 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1565: Apply rule [MiniBatchIntervalInferRule] to [rel#778:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#777,select=f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y)]
03/06/2020 13:13:22.783 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1566: Apply rule [MiniBatchIntervalInferRule] to [rel#771:StreamExecGroupAggregate.STREAM_PHYSICAL.any.None: 0.true.AccRetract(input=HepRelVertex#770,groupBy=v_id,select=v_id, CurrentVertex(bool, v_id, degree) AS TMP_0)]
03/06/2020 13:13:22.783 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1567: Apply rule [MiniBatchIntervalInferRule] to [rel#722:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.true.Acc(table=[Unregistered_DataStream_9],fields=f0, f1, f2, f3, f4)]
03/06/2020 13:13:22.783 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1568: Apply rule [MiniBatchIntervalInferRule] to [rel#769:StreamExecExchange.STREAM_PHYSICAL.hash[1]true.None: 0.true.Acc(input=HepRelVertex#768,distribution=hash[v_id])]
03/06/2020 13:13:22.785 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1569: Apply rule [MiniBatchIntervalInferRule] to [rel#767:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#766,select=f0 AS bool, f1 AS v_id, f2 AS degree)]
03/06/2020 13:13:22.786 DEBUG [org.apache.calcite.plan.RelOptPlanner] call#1570: Apply rule [MiniBatchIntervalInferRule] to [rel#707:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.true.Acc(table=[Unregistered_DataStream_8],fields=f0, f1, f2)]
03/06/2020 13:13:22.788 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#786:StreamExecSink.STREAM_PHYSICAL.any.None: 0.true.AccRetract(input=HepRelVertex#785,name=DataStreamTableSink,fields=v_label, X, Y, v_id_layout, degree, v_id)
03/06/2020 13:13:22.788 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#784:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.AccRetract(input=HepRelVertex#783,select=v_label, X, Y, v_id_layout, degree, v_id)
03/06/2020 13:13:22.788 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#782:StreamExecJoin.STREAM_PHYSICAL.any.None: 0.true.AccRetract(left=HepRelVertex#776,right=HepRelVertex#781,joinType=InnerJoin,where==(v_id, v_id_2),select=v_id, degree, v_id_2, v_label, v_id_layout, X, Y,leftInputSpec=JoinKeyContainsUniqueKey,rightInputSpec=NoUniqueKey)
03/06/2020 13:13:22.788 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#775:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.true.AccRetract(input=HepRelVertex#774,distribution=hash[v_id])
03/06/2020 13:13:22.788 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#773:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.AccRetract(input=HepRelVertex#772,select=v_id, TMP_0.f1 AS degree,where==(TMP_0.f0, _UTF-16LE'true'))
03/06/2020 13:13:22.788 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#771:StreamExecGroupAggregate.STREAM_PHYSICAL.any.None: 0.true.AccRetract(input=HepRelVertex#770,groupBy=v_id,select=v_id, CurrentVertex(bool, v_id, degree) AS TMP_0)
03/06/2020 13:13:22.788 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#769:StreamExecExchange.STREAM_PHYSICAL.hash[1]true.None: 0.true.Acc(input=HepRelVertex#768,distribution=hash[v_id])
03/06/2020 13:13:22.788 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#767:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#766,select=f0 AS bool, f1 AS v_id, f2 AS degree)
03/06/2020 13:13:22.789 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#707:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.true.Acc(table=[Unregistered_DataStream_8],fields=f0, f1, f2)
03/06/2020 13:13:22.806 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#780:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.true.Acc(input=HepRelVertex#779,distribution=hash[v_id_2])
03/06/2020 13:13:22.808 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#778:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#777,select=f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y)
03/06/2020 13:13:22.813 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#722:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.true.Acc(table=[Unregistered_DataStream_9],fields=f0, f1, f2, f3, f4)
03/06/2020 13:13:22.822 DEBUG [org.apache.flink.table.planner.plan.optimize.program.FlinkGroupProgram] optimize mini-batch interval rules cost 94 ms.
optimize result:
 Sink(name=[DataStreamTableSink], fields=[v_label, X, Y, v_id_layout, degree, v_id])
+- Calc(select=[v_label, X, Y, v_id_layout, degree, v_id])
   +- Join(joinType=[InnerJoin], where=[=(v_id, v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey])
      :- Exchange(distribution=[hash[v_id]])
      :  +- Calc(select=[v_id, TMP_0.f1 AS degree], where=[=(TMP_0.f0, _UTF-16LE'true')])
      :     +- GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0])
      :        +- Exchange(distribution=[hash[v_id]])
      :           +- Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree])
      :              +- DataStreamScan(table=[[Unregistered_DataStream_8]], fields=[f0, f1, f2])
      +- Exchange(distribution=[hash[v_id_2]])
         +- Calc(select=[f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y])
            +- DataStreamScan(table=[[Unregistered_DataStream_9]], fields=[f0, f1, f2, f3, f4])

03/06/2020 13:13:22.876 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#808:StreamExecSink.STREAM_PHYSICAL.any.None: 0.true.AccRetract(input=HepRelVertex#807,name=DataStreamTableSink,fields=v_label, X, Y, v_id_layout, degree, v_id)
03/06/2020 13:13:22.876 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#806:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.AccRetract(input=HepRelVertex#805,select=v_label, X, Y, v_id_layout, degree, v_id)
03/06/2020 13:13:22.876 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#804:StreamExecJoin.STREAM_PHYSICAL.any.None: 0.true.AccRetract(left=HepRelVertex#798,right=HepRelVertex#803,joinType=InnerJoin,where==(v_id, v_id_2),select=v_id, degree, v_id_2, v_label, v_id_layout, X, Y,leftInputSpec=JoinKeyContainsUniqueKey,rightInputSpec=NoUniqueKey)
03/06/2020 13:13:22.876 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#797:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.true.AccRetract(input=HepRelVertex#796,distribution=hash[v_id])
03/06/2020 13:13:22.876 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#795:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.AccRetract(input=HepRelVertex#794,select=v_id, TMP_0.f1 AS degree,where==(TMP_0.f0, _UTF-16LE'true'))
03/06/2020 13:13:22.876 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#793:StreamExecGroupAggregate.STREAM_PHYSICAL.any.None: 0.true.AccRetract(input=HepRelVertex#792,groupBy=v_id,select=v_id, CurrentVertex(bool, v_id, degree) AS TMP_0)
03/06/2020 13:13:22.876 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#791:StreamExecExchange.STREAM_PHYSICAL.hash[1]true.None: 0.true.Acc(input=HepRelVertex#790,distribution=hash[v_id])
03/06/2020 13:13:22.876 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#789:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#788,select=f0 AS bool, f1 AS v_id, f2 AS degree)
03/06/2020 13:13:22.876 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#707:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.true.Acc(table=[Unregistered_DataStream_8],fields=f0, f1, f2)
03/06/2020 13:13:22.879 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#802:StreamExecExchange.STREAM_PHYSICAL.hash[0]true.None: 0.true.Acc(input=HepRelVertex#801,distribution=hash[v_id_2])
03/06/2020 13:13:22.879 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#800:StreamExecCalc.STREAM_PHYSICAL.any.None: 0.true.Acc(input=HepRelVertex#799,select=f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y)
03/06/2020 13:13:22.879 DEBUG [org.apache.calcite.plan.RelOptPlanner] For final plan, using rel#722:StreamExecDataStreamScan.STREAM_PHYSICAL.any.None: 0.true.Acc(table=[Unregistered_DataStream_9],fields=f0, f1, f2, f3, f4)
03/06/2020 13:13:22.909 DEBUG [org.apache.flink.table.planner.plan.optimize.program.FlinkGroupProgram] optimize physical rewrite cost 56 ms.
optimize result:
 Sink(name=[DataStreamTableSink], fields=[v_label, X, Y, v_id_layout, degree, v_id])
+- Calc(select=[v_label, X, Y, v_id_layout, degree, v_id])
   +- Join(joinType=[InnerJoin], where=[=(v_id, v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey])
      :- Exchange(distribution=[hash[v_id]])
      :  +- Calc(select=[v_id, TMP_0.f1 AS degree], where=[=(TMP_0.f0, _UTF-16LE'true')])
      :     +- GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0])
      :        +- Exchange(distribution=[hash[v_id]])
      :           +- Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree])
      :              +- DataStreamScan(table=[[Unregistered_DataStream_8]], fields=[f0, f1, f2])
      +- Exchange(distribution=[hash[v_id_2]])
         +- Calc(select=[f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y])
            +- DataStreamScan(table=[[Unregistered_DataStream_9]], fields=[f0, f1, f2, f3, f4])

03/06/2020 13:13:22.910 DEBUG [org.apache.flink.table.planner.plan.optimize.program.FlinkChainedProgram] optimize physical_rewrite cost 1153 ms.
optimize result: 
Sink(name=[DataStreamTableSink], fields=[v_label, X, Y, v_id_layout, degree, v_id])
+- Calc(select=[v_label, X, Y, v_id_layout, degree, v_id])
   +- Join(joinType=[InnerJoin], where=[=(v_id, v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey])
      :- Exchange(distribution=[hash[v_id]])
      :  +- Calc(select=[v_id, TMP_0.f1 AS degree], where=[=(TMP_0.f0, _UTF-16LE'true')])
      :     +- GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0])
      :        +- Exchange(distribution=[hash[v_id]])
      :           +- Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree])
      :              +- DataStreamScan(table=[[Unregistered_DataStream_8]], fields=[f0, f1, f2])
      +- Exchange(distribution=[hash[v_id_2]])
         +- Calc(select=[f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y])
            +- DataStreamScan(table=[[Unregistered_DataStream_9]], fields=[f0, f1, f2, f3, f4])

03/06/2020 13:13:23.290 DEBUG [org.apache.flink.table.planner.codegen.OperatorCodeGenerator$] Compiling OneInputStreamOperator Code:
SourceConversion
03/06/2020 13:13:23.462 DEBUG [org.apache.flink.table.planner.codegen.OperatorCodeGenerator$] Compiling OneInputStreamOperator Code:
StreamExecCalc
03/06/2020 13:13:25.666 DEBUG [org.apache.flink.table.planner.codegen.OperatorCodeGenerator$] Compiling OneInputStreamOperator Code:
StreamExecCalc
03/06/2020 13:13:25.701 DEBUG [org.apache.flink.table.planner.codegen.OperatorCodeGenerator$] Compiling OneInputStreamOperator Code:
SourceConversion
03/06/2020 13:13:25.718 DEBUG [org.apache.flink.table.planner.codegen.OperatorCodeGenerator$] Compiling OneInputStreamOperator Code:
StreamExecCalc
03/06/2020 13:13:25.826 DEBUG [org.apache.flink.table.planner.codegen.OperatorCodeGenerator$] Compiling OneInputStreamOperator Code:
StreamExecCalc
03/06/2020 13:13:25.858 DEBUG [org.apache.flink.table.planner.codegen.OperatorCodeGenerator$] Compiling OneInputStreamOperator Code:
SinkConversion
03/06/2020 13:13:26.009 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the org.apache.flink.api.common.functions.util.PrintSinkOutputWriter
03/06/2020 13:13:26.040 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the java.lang.Boolean
03/06/2020 13:13:26.052 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the java.lang.String
03/06/2020 13:13:26.053 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the [C
03/06/2020 13:13:26.053 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the java.lang.Integer
03/06/2020 13:13:26.110 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the java.lang.Long
03/06/2020 13:13:26.111 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the org.apache.flink.streaming.api.functions.sink.filesystem.StreamingFileSink$RowFormatBuilder
03/06/2020 13:13:26.111 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the java.lang.Long
03/06/2020 13:13:26.112 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the org.apache.flink.core.fs.Path
03/06/2020 13:13:26.120 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the java.net.URI
03/06/2020 13:13:26.136 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the org.apache.flink.api.common.serialization.SimpleStringEncoder
03/06/2020 13:13:26.137 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the java.lang.String
03/06/2020 13:13:26.142 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the [C
03/06/2020 13:13:26.143 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the java.lang.Integer
03/06/2020 13:13:26.146 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the org.apache.flink.streaming.api.functions.sink.filesystem.bucketassigners.DateTimeBucketAssigner
03/06/2020 13:13:26.147 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the java.lang.String
03/06/2020 13:13:26.150 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the [C
03/06/2020 13:13:26.154 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the java.lang.Integer
03/06/2020 13:13:26.154 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the java.time.ZoneRegion
03/06/2020 13:13:26.169 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the org.apache.flink.streaming.api.functions.sink.filesystem.rollingpolicies.DefaultRollingPolicy
03/06/2020 13:13:26.170 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the java.lang.Long
03/06/2020 13:13:26.171 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the java.lang.Long
03/06/2020 13:13:26.172 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the java.lang.Long
03/06/2020 13:13:26.177 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the org.apache.flink.streaming.api.functions.sink.filesystem.DefaultBucketFactoryImpl
03/06/2020 13:13:26.188 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the org.apache.flink.streaming.api.functions.sink.filesystem.OutputFileConfig
03/06/2020 13:13:26.188 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the java.lang.String
03/06/2020 13:13:26.191 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the [C
03/06/2020 13:13:26.195 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the java.lang.Integer
03/06/2020 13:13:26.195 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the java.lang.String
03/06/2020 13:13:26.195 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the [C
03/06/2020 13:13:26.195 DEBUG [org.apache.flink.api.java.ClosureCleaner] Dig to clean the java.lang.Integer
03/06/2020 13:13:26.229 DEBUG [org.apache.flink.streaming.api.graph.StreamGraphGenerator] Transforming OneInputTransformation{id=7, name='SinkConversionToTuple2', outputType=Java Tuple2<Boolean, Row(rowkey: String, row: Row(f0: Integer))>, parallelism=1}
03/06/2020 13:13:26.240 DEBUG [org.apache.flink.streaming.api.graph.StreamGraphGenerator] Transforming OneInputTransformation{id=6, name='Calc(select=[id, cf])', outputType=BaseRow(id: STRING, cf: ROW<`degree` INT>), parallelism=1}
03/06/2020 13:13:26.243 DEBUG [org.apache.flink.streaming.api.graph.StreamGraphGenerator] Transforming OneInputTransformation{id=5, name='SortLimit(orderBy=[degree DESC], offset=[0], fetch=[10])', outputType=BaseRow(id: STRING, cf: ROW<`degree` INT>, degree: INT), parallelism=1}
03/06/2020 13:13:26.251 DEBUG [org.apache.flink.streaming.api.graph.StreamGraphGenerator] Transforming PartitionTransformation{id=4, name='Partition', outputType=BaseRow(id: STRING, cf: ROW<`degree` INT>, degree: INT), parallelism=1}
03/06/2020 13:13:26.281 DEBUG [org.apache.flink.streaming.api.graph.StreamGraphGenerator] Transforming OneInputTransformation{id=3, name='Calc(select=[id, cf, cf.degree AS degree])', outputType=BaseRow(id: STRING, cf: ROW<`degree` INT>, degree: INT), parallelism=2}
03/06/2020 13:13:26.282 DEBUG [org.apache.flink.streaming.api.graph.StreamGraphGenerator] Transforming OneInputTransformation{id=2, name='SourceConversion(table=[default_catalog.default_database.loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]], fields=[id, cf])', outputType=BaseRow(id: STRING, cf: ROW<`degree` INT>), parallelism=2}
03/06/2020 13:13:26.282 DEBUG [org.apache.flink.streaming.api.graph.StreamGraphGenerator] Transforming SourceTransformation{id=1, name='HBaseTableSource[schema=[id, cf], projectFields=null]', outputType=Row(id: String, cf: Row(degree: Integer)), parallelism=2}
03/06/2020 13:13:26.345 DEBUG [org.apache.flink.streaming.api.graph.StreamGraph] Vertex: 1
03/06/2020 13:13:26.355 DEBUG [org.apache.flink.streaming.api.graph.StreamGraph] Vertex: 2
03/06/2020 13:13:26.361 DEBUG [org.apache.flink.streaming.api.graph.StreamGraph] Vertex: 3
03/06/2020 13:13:26.361 DEBUG [org.apache.flink.streaming.api.graph.StreamGraph] Vertex: 5
03/06/2020 13:13:26.361 DEBUG [org.apache.flink.streaming.api.graph.StreamGraph] Vertex: 6
03/06/2020 13:13:26.362 DEBUG [org.apache.flink.streaming.api.graph.StreamGraph] Vertex: 7
03/06/2020 13:13:26.362 DEBUG [org.apache.flink.streaming.api.graph.StreamGraphGenerator] Transforming OneInputTransformation{id=8, name='Map', outputType=Java Tuple3<String, String, String>, parallelism=2}
03/06/2020 13:13:26.362 DEBUG [org.apache.flink.streaming.api.graph.StreamGraph] Vertex: 8
03/06/2020 13:13:26.364 DEBUG [org.apache.flink.streaming.api.graph.StreamGraphGenerator] Transforming OneInputTransformation{id=21, name='SinkConversionToTuple2', outputType=Java Tuple2<Boolean, Row(v_label: String, X: String, Y: String, v_id_layout: Integer, degree: String, v_id: String)>, parallelism=-1}
03/06/2020 13:13:26.369 DEBUG [org.apache.flink.streaming.api.graph.StreamGraphGenerator] Transforming OneInputTransformation{id=20, name='Calc(select=[v_label, X, Y, v_id_layout, degree, v_id])', outputType=BaseRow(v_label: STRING, X: STRING, Y: STRING, v_id_layout: INT, degree: STRING, v_id: STRING), parallelism=-1}
03/06/2020 13:13:26.370 DEBUG [org.apache.flink.streaming.api.graph.StreamGraphGenerator] Transforming TwoInputTransformation{id=19, name='Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey])', outputType=BaseRow(v_id: STRING, degree: STRING, v_id_2: STRING, v_label: STRING, v_id_layout: INT, X: STRING, Y: STRING), parallelism=-1}
03/06/2020 13:13:26.370 DEBUG [org.apache.flink.streaming.api.graph.StreamGraphGenerator] Transforming PartitionTransformation{id=15, name='Partition', outputType=BaseRow(v_id: STRING, degree: STRING), parallelism=-1}
03/06/2020 13:13:26.372 DEBUG [org.apache.flink.streaming.api.graph.StreamGraphGenerator] Transforming OneInputTransformation{id=14, name='Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')])', outputType=BaseRow(v_id: STRING, degree: STRING), parallelism=-1}
03/06/2020 13:13:26.374 DEBUG [org.apache.flink.streaming.api.graph.StreamGraphGenerator] Transforming OneInputTransformation{id=13, name='GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0])', outputType=BaseRow(v_id: STRING, TMP_0: ROW<`f0` STRING, `f1` STRING>), parallelism=-1}
03/06/2020 13:13:26.374 DEBUG [org.apache.flink.streaming.api.graph.StreamGraphGenerator] Transforming PartitionTransformation{id=12, name='Partition', outputType=BaseRow(bool: STRING, v_id: STRING, degree: STRING), parallelism=-1}
03/06/2020 13:13:26.376 DEBUG [org.apache.flink.streaming.api.graph.StreamGraphGenerator] Transforming OneInputTransformation{id=11, name='Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree])', outputType=BaseRow(bool: STRING, v_id: STRING, degree: STRING), parallelism=2}
03/06/2020 13:13:26.376 DEBUG [org.apache.flink.streaming.api.graph.StreamGraphGenerator] Transforming OneInputTransformation{id=10, name='SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2])', outputType=BaseRow(f0: STRING, f1: STRING, f2: STRING), parallelism=2}
03/06/2020 13:13:26.376 DEBUG [org.apache.flink.streaming.api.graph.StreamGraph] Vertex: 10
03/06/2020 13:13:26.377 DEBUG [org.apache.flink.streaming.api.graph.StreamGraph] Vertex: 11
03/06/2020 13:13:26.377 DEBUG [org.apache.flink.streaming.api.graph.StreamGraph] Vertex: 13
03/06/2020 13:13:26.377 DEBUG [org.apache.flink.streaming.api.graph.StreamGraph] Vertex: 14
03/06/2020 13:13:26.378 DEBUG [org.apache.flink.streaming.api.graph.StreamGraphGenerator] Transforming PartitionTransformation{id=18, name='Partition', outputType=BaseRow(v_id_2: STRING, v_label: STRING, v_id_layout: INT, X: STRING, Y: STRING), parallelism=-1}
03/06/2020 13:13:26.379 DEBUG [org.apache.flink.streaming.api.graph.StreamGraphGenerator] Transforming OneInputTransformation{id=17, name='Calc(select=[f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y])', outputType=BaseRow(v_id_2: STRING, v_label: STRING, v_id_layout: INT, X: STRING, Y: STRING), parallelism=1}
03/06/2020 13:13:26.381 DEBUG [org.apache.flink.streaming.api.graph.StreamGraphGenerator] Transforming OneInputTransformation{id=16, name='SourceConversion(table=[Unregistered_DataStream_9], fields=[f0, f1, f2, f3, f4])', outputType=BaseRow(f0: STRING, f1: STRING, f2: INT, f3: STRING, f4: STRING), parallelism=1}
03/06/2020 13:13:26.381 DEBUG [org.apache.flink.streaming.api.graph.StreamGraphGenerator] Transforming SourceTransformation{id=9, name='Collection Source', outputType=Java Tuple5<String, String, Integer, String, String>, parallelism=1}
03/06/2020 13:13:26.381 DEBUG [org.apache.flink.streaming.api.graph.StreamGraph] Vertex: 9
03/06/2020 13:13:26.382 DEBUG [org.apache.flink.streaming.api.graph.StreamGraph] Vertex: 16
03/06/2020 13:13:26.382 DEBUG [org.apache.flink.streaming.api.graph.StreamGraph] Vertex: 17
03/06/2020 13:13:26.387 DEBUG [org.apache.flink.streaming.api.graph.StreamGraph] CO-TASK: 19
03/06/2020 13:13:26.388 DEBUG [org.apache.flink.streaming.api.graph.StreamGraph] Vertex: 20
03/06/2020 13:13:26.391 DEBUG [org.apache.flink.streaming.api.graph.StreamGraph] Vertex: 21
03/06/2020 13:13:26.391 DEBUG [org.apache.flink.streaming.api.graph.StreamGraphGenerator] Transforming OneInputTransformation{id=22, name='Map', outputType=String, parallelism=2}
03/06/2020 13:13:26.391 DEBUG [org.apache.flink.streaming.api.graph.StreamGraph] Vertex: 22
03/06/2020 13:13:26.391 DEBUG [org.apache.flink.streaming.api.graph.StreamGraphGenerator] Transforming SinkTransformation{id=23, name='Print to Std. Out', outputType=GenericType<java.lang.Object>, parallelism=1}
03/06/2020 13:13:26.391 DEBUG [org.apache.flink.streaming.api.graph.StreamGraph] Vertex: 23
03/06/2020 13:13:26.391 DEBUG [org.apache.flink.streaming.api.graph.StreamGraphGenerator] Transforming SinkTransformation{id=24, name='Unnamed', outputType=GenericType<java.lang.Object>, parallelism=2}
03/06/2020 13:13:26.392 DEBUG [org.apache.flink.streaming.api.graph.StreamGraph] Vertex: 24
03/06/2020 13:13:26.558 DEBUG [org.apache.flink.table.runtime.generated.CompileUtils] Compiling: SourceConversion$1 

 Code:

      public class SourceConversion$1 extends org.apache.flink.table.runtime.operators.AbstractProcessStreamOperator
          implements org.apache.flink.streaming.api.operators.OneInputStreamOperator {

        private final Object[] references;
        private transient org.apache.flink.table.dataformat.DataFormatConverters.RowConverter converter$0;
        private final org.apache.flink.streaming.runtime.streamrecord.StreamRecord outElement = new org.apache.flink.streaming.runtime.streamrecord.StreamRecord(null);

        public SourceConversion$1(
            Object[] references,
            org.apache.flink.streaming.runtime.tasks.StreamTask task,
            org.apache.flink.streaming.api.graph.StreamConfig config,
            org.apache.flink.streaming.api.operators.Output output) throws Exception {
          this.references = references;
          converter$0 = (((org.apache.flink.table.dataformat.DataFormatConverters.RowConverter) references[0]));
          this.setup(task, config, output);
        }

        @Override
        public void open() throws Exception {
          super.open();
          
        }

        @Override
        public void processElement(org.apache.flink.streaming.runtime.streamrecord.StreamRecord element) throws Exception {
          org.apache.flink.table.dataformat.BaseRow in1 = (org.apache.flink.table.dataformat.BaseRow) (org.apache.flink.table.dataformat.BaseRow) converter$0.toInternal((org.apache.flink.types.Row) element.getValue());
          
          
          
          output.collect(outElement.replace(in1));
        }

        

        @Override
        public void close() throws Exception {
           super.close();
          
        }

        
      }
    
03/06/2020 13:13:26.904 DEBUG [org.apache.flink.table.runtime.generated.CompileUtils] Compiling: StreamExecCalc$10 

 Code:

      public class StreamExecCalc$10 extends org.apache.flink.table.runtime.operators.AbstractProcessStreamOperator
          implements org.apache.flink.streaming.api.operators.OneInputStreamOperator {

        private final Object[] references;
        private transient org.apache.flink.table.runtime.typeutils.BinaryStringSerializer typeSerializer$3;
        private transient org.apache.flink.table.runtime.typeutils.BaseRowSerializer typeSerializer$6;
        final org.apache.flink.table.dataformat.BoxedWrapperRow out = new org.apache.flink.table.dataformat.BoxedWrapperRow(3);
        private final org.apache.flink.streaming.runtime.streamrecord.StreamRecord outElement = new org.apache.flink.streaming.runtime.streamrecord.StreamRecord(null);

        public StreamExecCalc$10(
            Object[] references,
            org.apache.flink.streaming.runtime.tasks.StreamTask task,
            org.apache.flink.streaming.api.graph.StreamConfig config,
            org.apache.flink.streaming.api.operators.Output output) throws Exception {
          this.references = references;
          typeSerializer$3 = (((org.apache.flink.table.runtime.typeutils.BinaryStringSerializer) references[0]));
          typeSerializer$6 = (((org.apache.flink.table.runtime.typeutils.BaseRowSerializer) references[1]));
          this.setup(task, config, output);
        }

        @Override
        public void open() throws Exception {
          super.open();
          
        }

        @Override
        public void processElement(org.apache.flink.streaming.runtime.streamrecord.StreamRecord element) throws Exception {
          org.apache.flink.table.dataformat.BaseRow in1 = (org.apache.flink.table.dataformat.BaseRow) element.getValue();
          
          org.apache.flink.table.dataformat.BinaryString field$2;
          boolean isNull$2;
          org.apache.flink.table.dataformat.BinaryString field$4;
          org.apache.flink.table.dataformat.BaseRow field$5;
          boolean isNull$5;
          org.apache.flink.table.dataformat.BaseRow field$7;
          int field$8;
          boolean isNull$8;
          int result$9;
          boolean isNull$9;
          
          
          
          isNull$2 = in1.isNullAt(0);
          field$2 = org.apache.flink.table.dataformat.BinaryString.EMPTY_UTF8;
          if (!isNull$2) {
            field$2 = in1.getString(0);
          }
          field$4 = field$2;
          if (!isNull$2) {
            field$4 = (org.apache.flink.table.dataformat.BinaryString) (typeSerializer$3.copy(field$4));
          }
                  
          
          isNull$5 = in1.isNullAt(1);
          field$5 = null;
          if (!isNull$5) {
            field$5 = in1.getRow(1, 1);
          }
          field$7 = field$5;
          if (!isNull$5) {
            field$7 = (org.apache.flink.table.dataformat.BaseRow) (typeSerializer$6.copy(field$7));
          }
                  
          
          out.setHeader(in1.getHeader());
          
          
          
          
          if (isNull$2) {
            out.setNullAt(0);
          } else {
            out.setNonPrimitiveValue(0, field$4);
          }
                    
          
          
          if (isNull$5) {
            out.setNullAt(1);
          } else {
            out.setNonPrimitiveValue(1, field$7);
          }
                    
          
          
          
          if (isNull$5) {
            result$9 = -1;
            isNull$9 = true;
          }
          else {
            isNull$8 = field$7.isNullAt(0);
          field$8 = -1;
          if (!isNull$8) {
            field$8 = field$7.getInt(0);
          }
            result$9 = field$8;
            isNull$9 = isNull$8;
          }
          
          if (isNull$9) {
            out.setNullAt(2);
          } else {
            out.setInt(2, result$9);
          }
                    
                  
          output.collect(outElement.replace(out));
          
          
        }

        

        @Override
        public void close() throws Exception {
           super.close();
          
        }

        
      }
    
03/06/2020 13:13:27.088 DEBUG [org.apache.flink.table.runtime.generated.CompileUtils] Compiling: StreamExecCalc$18 

 Code:

      public class StreamExecCalc$18 extends org.apache.flink.table.runtime.operators.AbstractProcessStreamOperator
          implements org.apache.flink.streaming.api.operators.OneInputStreamOperator {

        private final Object[] references;
        final org.apache.flink.table.dataformat.BoxedWrapperRow out = new org.apache.flink.table.dataformat.BoxedWrapperRow(2);
        private final org.apache.flink.streaming.runtime.streamrecord.StreamRecord outElement = new org.apache.flink.streaming.runtime.streamrecord.StreamRecord(null);

        public StreamExecCalc$18(
            Object[] references,
            org.apache.flink.streaming.runtime.tasks.StreamTask task,
            org.apache.flink.streaming.api.graph.StreamConfig config,
            org.apache.flink.streaming.api.operators.Output output) throws Exception {
          this.references = references;
          
          this.setup(task, config, output);
        }

        @Override
        public void open() throws Exception {
          super.open();
          
        }

        @Override
        public void processElement(org.apache.flink.streaming.runtime.streamrecord.StreamRecord element) throws Exception {
          org.apache.flink.table.dataformat.BaseRow in1 = (org.apache.flink.table.dataformat.BaseRow) element.getValue();
          
          
          
          
          
          
          out.setHeader(in1.getHeader());
          
          
          
          
          if (in1.isNullAt(1)) {
            out.setNullAt(1);
          } else {
            out.setNonPrimitiveValue(1, in1.getRow(1, 1));
          }
                    
          
          
          if (in1.isNullAt(0)) {
            out.setNullAt(0);
          } else {
            out.setNonPrimitiveValue(0, in1.getString(0));
          }
                    
                  
          output.collect(outElement.replace(out));
          
          
        }

        

        @Override
        public void close() throws Exception {
           super.close();
          
        }

        
      }
    
03/06/2020 13:13:27.117 DEBUG [org.apache.flink.table.runtime.generated.CompileUtils] Compiling: SinkConversion$21 

 Code:

      public class SinkConversion$21 extends org.apache.flink.table.runtime.operators.TableStreamOperator
          implements org.apache.flink.streaming.api.operators.OneInputStreamOperator {

        private final Object[] references;
        private transient org.apache.flink.table.dataformat.DataFormatConverters.RowConverter converter$19;
        private final org.apache.flink.streaming.runtime.streamrecord.StreamRecord outElement = new org.apache.flink.streaming.runtime.streamrecord.StreamRecord(null);

        public SinkConversion$21(
            Object[] references,
            org.apache.flink.streaming.runtime.tasks.StreamTask task,
            org.apache.flink.streaming.api.graph.StreamConfig config,
            org.apache.flink.streaming.api.operators.Output output) throws Exception {
          this.references = references;
          converter$19 = (((org.apache.flink.table.dataformat.DataFormatConverters.RowConverter) references[0]));
          this.setup(task, config, output);
        }

        @Override
        public void open() throws Exception {
          super.open();
          
        }

        @Override
        public void processElement(org.apache.flink.streaming.runtime.streamrecord.StreamRecord element) throws Exception {
          org.apache.flink.table.dataformat.BaseRow in1 = (org.apache.flink.table.dataformat.BaseRow) element.getValue();
          
          
          
          
          
          
          org.apache.flink.api.java.tuple.Tuple2 result$20 = new org.apache.flink.api.java.tuple.Tuple2();
          result$20.setField(org.apache.flink.table.dataformat.util.BaseRowUtil.isAccumulateMsg(in1), 0);
          result$20.setField((org.apache.flink.types.Row) converter$19.toExternal((org.apache.flink.table.dataformat.BaseRow) in1), 1);
          output.collect(outElement.replace(result$20));
                   
          
        }

        

        @Override
        public void close() throws Exception {
           super.close();
          
        }

        
      }
    
03/06/2020 13:13:27.160 DEBUG [org.apache.flink.table.runtime.generated.CompileUtils] Compiling: SourceConversion$60 

 Code:

      public class SourceConversion$60 extends org.apache.flink.table.runtime.operators.AbstractProcessStreamOperator
          implements org.apache.flink.streaming.api.operators.OneInputStreamOperator {

        private final Object[] references;
        private transient org.apache.flink.table.dataformat.DataFormatConverters.TupleConverter converter$59;
        private final org.apache.flink.streaming.runtime.streamrecord.StreamRecord outElement = new org.apache.flink.streaming.runtime.streamrecord.StreamRecord(null);

        public SourceConversion$60(
            Object[] references,
            org.apache.flink.streaming.runtime.tasks.StreamTask task,
            org.apache.flink.streaming.api.graph.StreamConfig config,
            org.apache.flink.streaming.api.operators.Output output) throws Exception {
          this.references = references;
          converter$59 = (((org.apache.flink.table.dataformat.DataFormatConverters.TupleConverter) references[0]));
          this.setup(task, config, output);
        }

        @Override
        public void open() throws Exception {
          super.open();
          
        }

        @Override
        public void processElement(org.apache.flink.streaming.runtime.streamrecord.StreamRecord element) throws Exception {
          org.apache.flink.table.dataformat.BaseRow in1 = (org.apache.flink.table.dataformat.BaseRow) (org.apache.flink.table.dataformat.BaseRow) converter$59.toInternal((org.apache.flink.api.java.tuple.Tuple3) element.getValue());
          
          
          
          output.collect(outElement.replace(in1));
        }

        

        @Override
        public void close() throws Exception {
           super.close();
          
        }

        
      }
    
03/06/2020 13:13:27.184 DEBUG [org.apache.flink.table.runtime.generated.CompileUtils] Compiling: StreamExecCalc$71 

 Code:

      public class StreamExecCalc$71 extends org.apache.flink.table.runtime.operators.AbstractProcessStreamOperator
          implements org.apache.flink.streaming.api.operators.OneInputStreamOperator {

        private final Object[] references;
        private transient org.apache.flink.table.runtime.typeutils.BinaryStringSerializer typeSerializer$62;
        
        private final org.apache.flink.table.dataformat.BinaryString str$64 = org.apache.flink.table.dataformat.BinaryString.fromString("bool");
                   
        
        private final org.apache.flink.table.dataformat.BinaryString str$67 = org.apache.flink.table.dataformat.BinaryString.fromString("v_id");
                   
        
        private final org.apache.flink.table.dataformat.BinaryString str$70 = org.apache.flink.table.dataformat.BinaryString.fromString("degree");
                   
        final org.apache.flink.table.dataformat.BoxedWrapperRow out = new org.apache.flink.table.dataformat.BoxedWrapperRow(3);
        private final org.apache.flink.streaming.runtime.streamrecord.StreamRecord outElement = new org.apache.flink.streaming.runtime.streamrecord.StreamRecord(null);

        public StreamExecCalc$71(
            Object[] references,
            org.apache.flink.streaming.runtime.tasks.StreamTask task,
            org.apache.flink.streaming.api.graph.StreamConfig config,
            org.apache.flink.streaming.api.operators.Output output) throws Exception {
          this.references = references;
          typeSerializer$62 = (((org.apache.flink.table.runtime.typeutils.BinaryStringSerializer) references[0]));
          this.setup(task, config, output);
        }

        @Override
        public void open() throws Exception {
          super.open();
          
        }

        @Override
        public void processElement(org.apache.flink.streaming.runtime.streamrecord.StreamRecord element) throws Exception {
          org.apache.flink.table.dataformat.BaseRow in1 = (org.apache.flink.table.dataformat.BaseRow) element.getValue();
          
          org.apache.flink.table.dataformat.BinaryString field$61;
          boolean isNull$61;
          org.apache.flink.table.dataformat.BinaryString field$63;
          org.apache.flink.table.dataformat.BinaryString field$65;
          boolean isNull$65;
          org.apache.flink.table.dataformat.BinaryString field$66;
          org.apache.flink.table.dataformat.BinaryString field$68;
          boolean isNull$68;
          org.apache.flink.table.dataformat.BinaryString field$69;
          
          
          
          isNull$68 = in1.isNullAt(2);
          field$68 = org.apache.flink.table.dataformat.BinaryString.EMPTY_UTF8;
          if (!isNull$68) {
            field$68 = in1.getString(2);
          }
          field$69 = field$68;
          if (!isNull$68) {
            field$69 = (org.apache.flink.table.dataformat.BinaryString) (typeSerializer$62.copy(field$69));
          }
                  
          
          isNull$61 = in1.isNullAt(0);
          field$61 = org.apache.flink.table.dataformat.BinaryString.EMPTY_UTF8;
          if (!isNull$61) {
            field$61 = in1.getString(0);
          }
          field$63 = field$61;
          if (!isNull$61) {
            field$63 = (org.apache.flink.table.dataformat.BinaryString) (typeSerializer$62.copy(field$63));
          }
                  
          
          isNull$65 = in1.isNullAt(1);
          field$65 = org.apache.flink.table.dataformat.BinaryString.EMPTY_UTF8;
          if (!isNull$65) {
            field$65 = in1.getString(1);
          }
          field$66 = field$65;
          if (!isNull$65) {
            field$66 = (org.apache.flink.table.dataformat.BinaryString) (typeSerializer$62.copy(field$66));
          }
                  
          
          out.setHeader(in1.getHeader());
          
          
          
          
          if (isNull$61) {
            out.setNullAt(0);
          } else {
            out.setNonPrimitiveValue(0, field$63);
          }
                    
          
          
          if (isNull$65) {
            out.setNullAt(1);
          } else {
            out.setNonPrimitiveValue(1, field$66);
          }
                    
          
          
          if (isNull$68) {
            out.setNullAt(2);
          } else {
            out.setNonPrimitiveValue(2, field$69);
          }
                    
                  
          output.collect(outElement.replace(out));
          
          
        }

        

        @Override
        public void close() throws Exception {
           super.close();
          
        }

        
      }
    
03/06/2020 13:13:27.418 DEBUG [org.apache.flink.table.runtime.generated.CompileUtils] Compiling: StreamExecCalc$125 

 Code:

      public class StreamExecCalc$125 extends org.apache.flink.table.runtime.operators.AbstractProcessStreamOperator
          implements org.apache.flink.streaming.api.operators.OneInputStreamOperator {

        private final Object[] references;
        private transient org.apache.flink.table.runtime.typeutils.BaseRowSerializer typeSerializer$110;
        
        private final org.apache.flink.table.dataformat.BinaryString str$114 = org.apache.flink.table.dataformat.BinaryString.fromString("bool");
                   
        
        private final org.apache.flink.table.dataformat.BinaryString str$115 = org.apache.flink.table.dataformat.BinaryString.fromString("true");
                   
        private transient org.apache.flink.table.runtime.typeutils.BinaryStringSerializer typeSerializer$119;
        
        private final org.apache.flink.table.dataformat.BinaryString str$121 = org.apache.flink.table.dataformat.BinaryString.fromString("v_id");
                   
        
        private final org.apache.flink.table.dataformat.BinaryString str$124 = org.apache.flink.table.dataformat.BinaryString.fromString("degree");
                   
        final org.apache.flink.table.dataformat.BoxedWrapperRow out = new org.apache.flink.table.dataformat.BoxedWrapperRow(2);
        private final org.apache.flink.streaming.runtime.streamrecord.StreamRecord outElement = new org.apache.flink.streaming.runtime.streamrecord.StreamRecord(null);

        public StreamExecCalc$125(
            Object[] references,
            org.apache.flink.streaming.runtime.tasks.StreamTask task,
            org.apache.flink.streaming.api.graph.StreamConfig config,
            org.apache.flink.streaming.api.operators.Output output) throws Exception {
          this.references = references;
          typeSerializer$110 = (((org.apache.flink.table.runtime.typeutils.BaseRowSerializer) references[0]));
          typeSerializer$119 = (((org.apache.flink.table.runtime.typeutils.BinaryStringSerializer) references[1]));
          this.setup(task, config, output);
        }

        @Override
        public void open() throws Exception {
          super.open();
          
        }

        @Override
        public void processElement(org.apache.flink.streaming.runtime.streamrecord.StreamRecord element) throws Exception {
          org.apache.flink.table.dataformat.BaseRow in1 = (org.apache.flink.table.dataformat.BaseRow) element.getValue();
          
          org.apache.flink.table.dataformat.BaseRow field$109;
          boolean isNull$109;
          org.apache.flink.table.dataformat.BaseRow field$111;
          org.apache.flink.table.dataformat.BinaryString field$112;
          boolean isNull$112;
          org.apache.flink.table.dataformat.BinaryString result$113;
          boolean isNull$113;
          boolean isNull$116;
          boolean result$117;
          org.apache.flink.table.dataformat.BinaryString field$118;
          boolean isNull$118;
          org.apache.flink.table.dataformat.BinaryString field$120;
          org.apache.flink.table.dataformat.BinaryString field$122;
          boolean isNull$122;
          org.apache.flink.table.dataformat.BinaryString result$123;
          boolean isNull$123;
          
          
          
          isNull$109 = in1.isNullAt(1);
          field$109 = null;
          if (!isNull$109) {
            field$109 = in1.getRow(1, 2);
          }
          field$111 = field$109;
          if (!isNull$109) {
            field$111 = (org.apache.flink.table.dataformat.BaseRow) (typeSerializer$110.copy(field$111));
          }
                  
          
          
          
          if (isNull$109) {
            result$113 = org.apache.flink.table.dataformat.BinaryString.EMPTY_UTF8;
            isNull$113 = true;
          }
          else {
            isNull$112 = field$111.isNullAt(0);
          field$112 = org.apache.flink.table.dataformat.BinaryString.EMPTY_UTF8;
          if (!isNull$112) {
            field$112 = field$111.getString(0);
          }
            result$113 = field$112;
            isNull$113 = isNull$112;
          }
          
          
          isNull$116 = isNull$113 || false;
          result$117 = false;
          if (!isNull$116) {
            
            result$117 = result$113.equals(((org.apache.flink.table.dataformat.BinaryString) str$115));
            
          }
          
          if (result$117) {
            
          isNull$118 = in1.isNullAt(0);
          field$118 = org.apache.flink.table.dataformat.BinaryString.EMPTY_UTF8;
          if (!isNull$118) {
            field$118 = in1.getString(0);
          }
          field$120 = field$118;
          if (!isNull$118) {
            field$120 = (org.apache.flink.table.dataformat.BinaryString) (typeSerializer$119.copy(field$120));
          }
                  
            
          out.setHeader(in1.getHeader());
          
          
          
          
          if (isNull$118) {
            out.setNullAt(0);
          } else {
            out.setNonPrimitiveValue(0, field$120);
          }
                    
          
          
          
          if (isNull$109) {
            result$123 = org.apache.flink.table.dataformat.BinaryString.EMPTY_UTF8;
            isNull$123 = true;
          }
          else {
            isNull$122 = field$111.isNullAt(1);
          field$122 = org.apache.flink.table.dataformat.BinaryString.EMPTY_UTF8;
          if (!isNull$122) {
            field$122 = field$111.getString(1);
          }
            result$123 = field$122;
            isNull$123 = isNull$122;
          }
          
          if (isNull$123) {
            out.setNullAt(1);
          } else {
            out.setNonPrimitiveValue(1, result$123);
          }
                    
                  
          output.collect(outElement.replace(out));
          
          }
          
        }

        

        @Override
        public void close() throws Exception {
           super.close();
          
        }

        
      }
    
03/06/2020 13:13:27.530 DEBUG [org.apache.flink.table.runtime.generated.CompileUtils] Compiling: SourceConversion$128 

 Code:

      public class SourceConversion$128 extends org.apache.flink.table.runtime.operators.AbstractProcessStreamOperator
          implements org.apache.flink.streaming.api.operators.OneInputStreamOperator {

        private final Object[] references;
        private transient org.apache.flink.table.dataformat.DataFormatConverters.TupleConverter converter$127;
        private final org.apache.flink.streaming.runtime.streamrecord.StreamRecord outElement = new org.apache.flink.streaming.runtime.streamrecord.StreamRecord(null);

        public SourceConversion$128(
            Object[] references,
            org.apache.flink.streaming.runtime.tasks.StreamTask task,
            org.apache.flink.streaming.api.graph.StreamConfig config,
            org.apache.flink.streaming.api.operators.Output output) throws Exception {
          this.references = references;
          converter$127 = (((org.apache.flink.table.dataformat.DataFormatConverters.TupleConverter) references[0]));
          this.setup(task, config, output);
        }

        @Override
        public void open() throws Exception {
          super.open();
          
        }

        @Override
        public void processElement(org.apache.flink.streaming.runtime.streamrecord.StreamRecord element) throws Exception {
          org.apache.flink.table.dataformat.BaseRow in1 = (org.apache.flink.table.dataformat.BaseRow) (org.apache.flink.table.dataformat.BaseRow) converter$127.toInternal((org.apache.flink.api.java.tuple.Tuple5) element.getValue());
          
          
          
          output.collect(outElement.replace(in1));
        }

        

        @Override
        public void close() throws Exception {
           super.close();
          
        }

        
      }
    
03/06/2020 13:13:27.756 DEBUG [org.apache.flink.table.runtime.generated.CompileUtils] Compiling: StreamExecCalc$144 

 Code:

      public class StreamExecCalc$144 extends org.apache.flink.table.runtime.operators.AbstractProcessStreamOperator
          implements org.apache.flink.streaming.api.operators.OneInputStreamOperator {

        private final Object[] references;
        private transient org.apache.flink.table.runtime.typeutils.BinaryStringSerializer typeSerializer$130;
        
        private final org.apache.flink.table.dataformat.BinaryString str$132 = org.apache.flink.table.dataformat.BinaryString.fromString("v_id_2");
                   
        
        private final org.apache.flink.table.dataformat.BinaryString str$135 = org.apache.flink.table.dataformat.BinaryString.fromString("v_label");
                   
        
        private final org.apache.flink.table.dataformat.BinaryString str$137 = org.apache.flink.table.dataformat.BinaryString.fromString("v_id_layout");
                   
        
        private final org.apache.flink.table.dataformat.BinaryString str$140 = org.apache.flink.table.dataformat.BinaryString.fromString("X");
                   
        
        private final org.apache.flink.table.dataformat.BinaryString str$143 = org.apache.flink.table.dataformat.BinaryString.fromString("Y");
                   
        final org.apache.flink.table.dataformat.BoxedWrapperRow out = new org.apache.flink.table.dataformat.BoxedWrapperRow(5);
        private final org.apache.flink.streaming.runtime.streamrecord.StreamRecord outElement = new org.apache.flink.streaming.runtime.streamrecord.StreamRecord(null);

        public StreamExecCalc$144(
            Object[] references,
            org.apache.flink.streaming.runtime.tasks.StreamTask task,
            org.apache.flink.streaming.api.graph.StreamConfig config,
            org.apache.flink.streaming.api.operators.Output output) throws Exception {
          this.references = references;
          typeSerializer$130 = (((org.apache.flink.table.runtime.typeutils.BinaryStringSerializer) references[0]));
          this.setup(task, config, output);
        }

        @Override
        public void open() throws Exception {
          super.open();
          
        }

        @Override
        public void processElement(org.apache.flink.streaming.runtime.streamrecord.StreamRecord element) throws Exception {
          org.apache.flink.table.dataformat.BaseRow in1 = (org.apache.flink.table.dataformat.BaseRow) element.getValue();
          
          org.apache.flink.table.dataformat.BinaryString field$129;
          boolean isNull$129;
          org.apache.flink.table.dataformat.BinaryString field$131;
          org.apache.flink.table.dataformat.BinaryString field$133;
          boolean isNull$133;
          org.apache.flink.table.dataformat.BinaryString field$134;
          int field$136;
          boolean isNull$136;
          org.apache.flink.table.dataformat.BinaryString field$138;
          boolean isNull$138;
          org.apache.flink.table.dataformat.BinaryString field$139;
          org.apache.flink.table.dataformat.BinaryString field$141;
          boolean isNull$141;
          org.apache.flink.table.dataformat.BinaryString field$142;
          
          
          isNull$136 = in1.isNullAt(2);
          field$136 = -1;
          if (!isNull$136) {
            field$136 = in1.getInt(2);
          }
          
          isNull$129 = in1.isNullAt(0);
          field$129 = org.apache.flink.table.dataformat.BinaryString.EMPTY_UTF8;
          if (!isNull$129) {
            field$129 = in1.getString(0);
          }
          field$131 = field$129;
          if (!isNull$129) {
            field$131 = (org.apache.flink.table.dataformat.BinaryString) (typeSerializer$130.copy(field$131));
          }
                  
          
          isNull$141 = in1.isNullAt(4);
          field$141 = org.apache.flink.table.dataformat.BinaryString.EMPTY_UTF8;
          if (!isNull$141) {
            field$141 = in1.getString(4);
          }
          field$142 = field$141;
          if (!isNull$141) {
            field$142 = (org.apache.flink.table.dataformat.BinaryString) (typeSerializer$130.copy(field$142));
          }
                  
          
          isNull$133 = in1.isNullAt(1);
          field$133 = org.apache.flink.table.dataformat.BinaryString.EMPTY_UTF8;
          if (!isNull$133) {
            field$133 = in1.getString(1);
          }
          field$134 = field$133;
          if (!isNull$133) {
            field$134 = (org.apache.flink.table.dataformat.BinaryString) (typeSerializer$130.copy(field$134));
          }
                  
          
          isNull$138 = in1.isNullAt(3);
          field$138 = org.apache.flink.table.dataformat.BinaryString.EMPTY_UTF8;
          if (!isNull$138) {
            field$138 = in1.getString(3);
          }
          field$139 = field$138;
          if (!isNull$138) {
            field$139 = (org.apache.flink.table.dataformat.BinaryString) (typeSerializer$130.copy(field$139));
          }
                  
          
          out.setHeader(in1.getHeader());
          
          
          
          
          if (isNull$129) {
            out.setNullAt(0);
          } else {
            out.setNonPrimitiveValue(0, field$131);
          }
                    
          
          
          if (isNull$133) {
            out.setNullAt(1);
          } else {
            out.setNonPrimitiveValue(1, field$134);
          }
                    
          
          
          if (isNull$136) {
            out.setNullAt(2);
          } else {
            out.setInt(2, field$136);
          }
                    
          
          
          if (isNull$138) {
            out.setNullAt(3);
          } else {
            out.setNonPrimitiveValue(3, field$139);
          }
                    
          
          
          if (isNull$141) {
            out.setNullAt(4);
          } else {
            out.setNonPrimitiveValue(4, field$142);
          }
                    
                  
          output.collect(outElement.replace(out));
          
          
        }

        

        @Override
        public void close() throws Exception {
           super.close();
          
        }

        
      }
    
03/06/2020 13:13:28.000 DEBUG [org.apache.flink.table.runtime.generated.CompileUtils] Compiling: StreamExecCalc$151 

 Code:

      public class StreamExecCalc$151 extends org.apache.flink.table.runtime.operators.AbstractProcessStreamOperator
          implements org.apache.flink.streaming.api.operators.OneInputStreamOperator {

        private final Object[] references;
        final org.apache.flink.table.dataformat.BoxedWrapperRow out = new org.apache.flink.table.dataformat.BoxedWrapperRow(6);
        private final org.apache.flink.streaming.runtime.streamrecord.StreamRecord outElement = new org.apache.flink.streaming.runtime.streamrecord.StreamRecord(null);

        public StreamExecCalc$151(
            Object[] references,
            org.apache.flink.streaming.runtime.tasks.StreamTask task,
            org.apache.flink.streaming.api.graph.StreamConfig config,
            org.apache.flink.streaming.api.operators.Output output) throws Exception {
          this.references = references;
          
          this.setup(task, config, output);
        }

        @Override
        public void open() throws Exception {
          super.open();
          
        }

        @Override
        public void processElement(org.apache.flink.streaming.runtime.streamrecord.StreamRecord element) throws Exception {
          org.apache.flink.table.dataformat.BaseRow in1 = (org.apache.flink.table.dataformat.BaseRow) element.getValue();
          
          
          
          
          
          
          out.setHeader(in1.getHeader());
          
          
          
          
          if (in1.isNullAt(3)) {
            out.setNullAt(0);
          } else {
            out.setNonPrimitiveValue(0, in1.getString(3));
          }
                    
          
          
          if (in1.isNullAt(5)) {
            out.setNullAt(1);
          } else {
            out.setNonPrimitiveValue(1, in1.getString(5));
          }
                    
          
          
          if (in1.isNullAt(6)) {
            out.setNullAt(2);
          } else {
            out.setNonPrimitiveValue(2, in1.getString(6));
          }
                    
          
          
          if (in1.isNullAt(1)) {
            out.setNullAt(4);
          } else {
            out.setNonPrimitiveValue(4, in1.getString(1));
          }
                    
          
          
          if (in1.isNullAt(0)) {
            out.setNullAt(5);
          } else {
            out.setNonPrimitiveValue(5, in1.getString(0));
          }
                    
          
          
          if (in1.isNullAt(4)) {
            out.setNullAt(3);
          } else {
            out.setInt(3, in1.getInt(4));
          }
                    
                  
          output.collect(outElement.replace(out));
          
          
        }

        

        @Override
        public void close() throws Exception {
           super.close();
          
        }

        
      }
    
03/06/2020 13:13:28.051 DEBUG [org.apache.flink.table.runtime.generated.CompileUtils] Compiling: SinkConversion$154 

 Code:

      public class SinkConversion$154 extends org.apache.flink.table.runtime.operators.TableStreamOperator
          implements org.apache.flink.streaming.api.operators.OneInputStreamOperator {

        private final Object[] references;
        private transient org.apache.flink.table.dataformat.DataFormatConverters.RowConverter converter$152;
        private final org.apache.flink.streaming.runtime.streamrecord.StreamRecord outElement = new org.apache.flink.streaming.runtime.streamrecord.StreamRecord(null);

        public SinkConversion$154(
            Object[] references,
            org.apache.flink.streaming.runtime.tasks.StreamTask task,
            org.apache.flink.streaming.api.graph.StreamConfig config,
            org.apache.flink.streaming.api.operators.Output output) throws Exception {
          this.references = references;
          converter$152 = (((org.apache.flink.table.dataformat.DataFormatConverters.RowConverter) references[0]));
          this.setup(task, config, output);
        }

        @Override
        public void open() throws Exception {
          super.open();
          
        }

        @Override
        public void processElement(org.apache.flink.streaming.runtime.streamrecord.StreamRecord element) throws Exception {
          org.apache.flink.table.dataformat.BaseRow in1 = (org.apache.flink.table.dataformat.BaseRow) element.getValue();
          
          
          
          
          
          
          org.apache.flink.api.java.tuple.Tuple2 result$153 = new org.apache.flink.api.java.tuple.Tuple2();
          result$153.setField(org.apache.flink.table.dataformat.util.BaseRowUtil.isAccumulateMsg(in1), 0);
          result$153.setField((org.apache.flink.types.Row) converter$152.toExternal((org.apache.flink.table.dataformat.BaseRow) in1), 1);
          output.collect(outElement.replace(result$153));
                   
          
        }

        

        @Override
        public void close() throws Exception {
           super.close();
          
        }

        
      }
    
03/06/2020 13:13:28.490 DEBUG [org.apache.flink.streaming.api.graph.StreamGraphHasherV2] Generated hash 'cbc357ccb763df2852fee8c4fc7d55f2' for node 'Source: HBaseTableSource[schema=[id, cf], projectFields=null]-1' {id: 1, parallelism: 2, user function: }
03/06/2020 13:13:28.507 DEBUG [org.apache.flink.streaming.api.graph.StreamGraphHasherV2] Generated hash '6cdc5bb954874d922eaee11a8e7b5dd5' for node 'Source: Collection Source-9' {id: 9, parallelism: 1, user function: org.apache.flink.streaming.api.functions.source.FromElementsFunction}
03/06/2020 13:13:28.516 DEBUG [org.apache.flink.streaming.api.graph.StreamGraphHasherV2] Generated hash '268c6e26884db845b34fbed5b355f2be' for node 'SourceConversion(table=[default_catalog.default_database.loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]], fields=[id, cf])-2' {id: 2, parallelism: 2, user function: }
03/06/2020 13:13:28.520 DEBUG [org.apache.flink.streaming.api.graph.StreamGraphHasherV2] Generated hash '19894d47902564dfbf88a679e52ed49e' for node 'SourceConversion(table=[Unregistered_DataStream_9], fields=[f0, f1, f2, f3, f4])-16' {id: 16, parallelism: 1, user function: }
03/06/2020 13:13:28.715 DEBUG [org.apache.flink.streaming.api.graph.StreamGraphHasherV2] Generated hash '961f812b71e0974941c334fd7d5c8da9' for node 'Calc(select=[id, cf, cf.degree AS degree])-3' {id: 3, parallelism: 2, user function: }
03/06/2020 13:13:28.718 DEBUG [org.apache.flink.streaming.api.graph.StreamGraphHasherV2] Generated hash '82c4a6eead942893d0c01a3775161323' for node 'Calc(select=[f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y])-17' {id: 17, parallelism: 1, user function: }
03/06/2020 13:13:28.723 DEBUG [org.apache.flink.streaming.api.graph.StreamGraphHasherV2] Generated hash '57df6b5c78b46bc5e7b8e2b883e729a9' for node 'SortLimit(orderBy=[degree DESC], offset=[0], fetch=[10])-5' {id: 5, parallelism: 1, user function: org.apache.flink.table.runtime.operators.rank.AppendOnlyTopNFunction}
03/06/2020 13:13:28.724 DEBUG [org.apache.flink.streaming.api.graph.StreamGraphHasherV2] Generated hash 'c2b501861aaae10089171c0c9a4cc810' for node 'Calc(select=[id, cf])-6' {id: 6, parallelism: 1, user function: }
03/06/2020 13:13:28.725 DEBUG [org.apache.flink.streaming.api.graph.StreamGraphHasherV2] Generated hash '36762bf1d2ec1b7aa259957f5c1fbec3' for node 'SinkConversionToTuple2-7' {id: 7, parallelism: 1, user function: }
03/06/2020 13:13:28.729 DEBUG [org.apache.flink.streaming.api.graph.StreamGraphHasherV2] Generated hash '730748a2d3477923527d4df19c1115d3' for node 'Map-8' {id: 8, parallelism: 2, user function: aljoschaRydzyk.Gradoop_Flink_Prototype.MatchDegreeChoice$1}
03/06/2020 13:13:28.730 DEBUG [org.apache.flink.streaming.api.graph.StreamGraphHasherV2] Generated hash 'cea40dfef71ba11303db8931523861e0' for node 'SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2])-10' {id: 10, parallelism: 2, user function: }
03/06/2020 13:13:28.732 DEBUG [org.apache.flink.streaming.api.graph.StreamGraphHasherV2] Generated hash '9df84b442478cb434a0b4172c7682204' for node 'Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree])-11' {id: 11, parallelism: 2, user function: }
03/06/2020 13:13:28.734 DEBUG [org.apache.flink.streaming.api.graph.StreamGraphHasherV2] Generated hash 'db7de5d6d7db9354bd8e4698740f442c' for node 'GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0])-13' {id: 13, parallelism: 2, user function: org.apache.flink.table.runtime.operators.aggregate.GroupAggFunction}
03/06/2020 13:13:28.734 DEBUG [org.apache.flink.streaming.api.graph.StreamGraphHasherV2] Generated hash '5971f78eebd3a74273268ccf78e1350c' for node 'Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')])-14' {id: 14, parallelism: 2, user function: }
03/06/2020 13:13:28.735 DEBUG [org.apache.flink.streaming.api.graph.StreamGraphHasherV2] Generated hash '2da5af51bbd1dbb7a2c205b96fe7a428' for node 'Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey])-19' {id: 19, parallelism: 2, user function: }
03/06/2020 13:13:28.736 DEBUG [org.apache.flink.streaming.api.graph.StreamGraphHasherV2] Generated hash '851ae0001e60ebfeff9a92d797f0e8a5' for node 'Calc(select=[v_label, X, Y, v_id_layout, degree, v_id])-20' {id: 20, parallelism: 2, user function: }
03/06/2020 13:13:28.736 DEBUG [org.apache.flink.streaming.api.graph.StreamGraphHasherV2] Generated hash '4a29f77aa6210388e24ffaa2e359aff7' for node 'SinkConversionToTuple2-21' {id: 21, parallelism: 2, user function: }
03/06/2020 13:13:28.736 DEBUG [org.apache.flink.streaming.api.graph.StreamGraphHasherV2] Generated hash 'db0ae7f16fcd52af04330fcbb25ead52' for node 'Map-22' {id: 22, parallelism: 2, user function: aljoschaRydzyk.Gradoop_Flink_Prototype.MatchDegreeChoice$3}
03/06/2020 13:13:28.737 DEBUG [org.apache.flink.streaming.api.graph.StreamGraphHasherV2] Generated hash '97062323b8add791924e501dd08b481e' for node 'Sink: Print to Std. Out-23' {id: 23, parallelism: 1, user function: org.apache.flink.streaming.api.functions.sink.PrintSinkFunction}
03/06/2020 13:13:28.738 DEBUG [org.apache.flink.streaming.api.graph.StreamGraphHasherV2] Generated hash '578e2203407d7922d27ba52d4fe96b11' for node 'Sink: Unnamed-24' {id: 24, parallelism: 2, user function: org.apache.flink.streaming.api.functions.sink.filesystem.StreamingFileSink}
03/06/2020 13:13:28.814 DEBUG [org.apache.flink.streaming.api.graph.StreamingJobGraphGenerator] Parallelism set: 1 for 23
03/06/2020 13:13:28.902 DEBUG [org.apache.flink.streaming.api.graph.StreamingJobGraphGenerator] Parallelism set: 2 for 19
03/06/2020 13:13:28.974 DEBUG [org.apache.flink.streaming.api.graph.StreamingJobGraphGenerator] CONNECTED: RebalancePartitioner - 19 -> 23
03/06/2020 13:13:29.001 DEBUG [org.apache.flink.streaming.api.graph.StreamingJobGraphGenerator] Parallelism set: 2 for 13
03/06/2020 13:13:29.101 DEBUG [org.apache.flink.streaming.api.graph.StreamingJobGraphGenerator] CONNECTED: KeyGroupStreamPartitioner - 13 -> 19
03/06/2020 13:13:29.109 DEBUG [org.apache.flink.streaming.api.graph.StreamingJobGraphGenerator] Parallelism set: 2 for 8
03/06/2020 13:13:29.111 DEBUG [org.apache.flink.streaming.api.graph.StreamingJobGraphGenerator] CONNECTED: KeyGroupStreamPartitioner - 8 -> 13
03/06/2020 13:13:29.114 DEBUG [org.apache.flink.streaming.api.graph.StreamingJobGraphGenerator] Parallelism set: 1 for 5
03/06/2020 13:13:29.178 DEBUG [org.apache.flink.streaming.api.graph.StreamingJobGraphGenerator] CONNECTED: RebalancePartitioner - 5 -> 8
03/06/2020 13:13:29.214 DEBUG [org.apache.flink.streaming.api.graph.StreamingJobGraphGenerator] Parallelism set: 2 for 1
03/06/2020 13:13:29.246 DEBUG [org.apache.flink.streaming.api.graph.StreamingJobGraphGenerator] CONNECTED: GlobalPartitioner - 1 -> 5
03/06/2020 13:13:29.301 DEBUG [org.apache.flink.streaming.api.graph.StreamingJobGraphGenerator] Parallelism set: 1 for 9
03/06/2020 13:13:29.306 DEBUG [org.apache.flink.streaming.api.graph.StreamingJobGraphGenerator] CONNECTED: KeyGroupStreamPartitioner - 9 -> 19
03/06/2020 13:13:29.449  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils] The configuration option Key: 'taskmanager.cpu.cores' , default: null (fallback keys: []) required for local execution is not set, setting it to its default value 1.7976931348623157E308
03/06/2020 13:13:29.455  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils] The configuration option Key: 'taskmanager.memory.task.heap.size' , default: null (fallback keys: []) required for local execution is not set, setting it to its default value 9223372036854775807 bytes
03/06/2020 13:13:29.455  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils] The configuration option Key: 'taskmanager.memory.task.off-heap.size' , default: 0 bytes (fallback keys: []) required for local execution is not set, setting it to its default value 9223372036854775807 bytes
03/06/2020 13:13:29.457  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils] The configuration option Key: 'taskmanager.memory.network.min' , default: 64 mb (fallback keys: [{key=taskmanager.network.memory.min, isDeprecated=true}]) required for local execution is not set, setting it to its default value 64 mb
03/06/2020 13:13:29.457  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils] The configuration option Key: 'taskmanager.memory.network.max' , default: 1 gb (fallback keys: [{key=taskmanager.network.memory.max, isDeprecated=true}]) required for local execution is not set, setting it to its default value 64 mb
03/06/2020 13:13:29.458  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils] The configuration option Key: 'taskmanager.memory.managed.size' , default: null (fallback keys: [{key=taskmanager.memory.size, isDeprecated=true}]) required for local execution is not set, setting it to its default value 128 mb
03/06/2020 13:13:29.461  INFO [org.apache.flink.runtime.minicluster.MiniCluster] Starting Flink Mini Cluster
03/06/2020 13:13:29.466 DEBUG [org.apache.flink.runtime.minicluster.MiniCluster] Using configuration MiniClusterConfiguration {singleRpcService=SHARED, numTaskManagers=1, commonBindAddress='null', config={taskmanager.memory.network.min=64 mb, taskmanager.cpu.cores=1.7976931348623157E308, taskmanager.memory.task.off-heap.size=9223372036854775807 bytes, execution.target=local, rest.bind-port=0, taskmanager.memory.network.max=64 mb, execution.attached=true, jobmanager.scheduler=ng, taskmanager.memory.managed.size=128 mb, taskmanager.numberOfTaskSlots=2, taskmanager.memory.task.heap.size=9223372036854775807 bytes, rest.address=localhost}}
03/06/2020 13:13:29.469  INFO [org.apache.flink.runtime.minicluster.MiniCluster] Starting Metrics Registry
03/06/2020 13:13:29.474  INFO [org.apache.flink.runtime.metrics.MetricRegistryImpl] No metrics reporter configured, no metrics will be exposed/reported.
03/06/2020 13:13:29.474  INFO [org.apache.flink.runtime.minicluster.MiniCluster] Starting RPC Service(s)
03/06/2020 13:13:29.724  INFO [akka.event.slf4j.Slf4jLogger] Slf4jLogger started
03/06/2020 13:13:29.735 DEBUG [akka.event.EventStream] logger log1-Slf4jLogger started
03/06/2020 13:13:29.737 DEBUG [akka.event.EventStream] Default Loggers started
03/06/2020 13:13:30.070  INFO [org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils] Trying to start actor system at :0
03/06/2020 13:13:30.091 DEBUG [org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils] Using akka configuration
 Config(SimpleConfigObject({"akka":{"actor":{"default-dispatcher":{"executor":"thread-pool-executor","thread-pool-executor":{"core-pool-size-max":1,"core-pool-size-min":1},"thread-priority":1,"throughput":15,"type":"akka.dispatch.PriorityThreadsDispatcher"},"guardian-supervisor-strategy":"org.apache.flink.runtime.akka.StoppingSupervisorWithoutLoggingActorKilledExceptionStrategy","provider":"akka.remote.RemoteActorRefProvider","warn-about-java-serializer-usage":"off"},"daemonic":"off","jvm-exit-on-fatal-error":"on","log-config-on-start":"off","log-dead-letters":"off","log-dead-letters-during-shutdown":"off","loggers":["akka.event.slf4j.Slf4jLogger"],"logging-filter":"akka.event.slf4j.Slf4jLoggingFilter","loglevel":"DEBUG","remote":{"log-remote-lifecycle-events":"off","netty":{"tcp":{"bind-hostname":"0.0.0.0","bind-port":0,"client-socket-worker-pool":{"pool-size-factor":1,"pool-size-max":2,"pool-size-min":1},"connection-timeout":"20000ms","hostname":"","maximum-frame-size":"10485760b","port":0,"server-socket-worker-pool":{"pool-size-factor":1,"pool-size-max":2,"pool-size-min":1},"tcp-nodelay":"on","transport-class":"akka.remote.transport.netty.NettyTransport"}},"retry-gate-closed-for":"50 ms","startup-timeout":"100000ms","transport-failure-detector":{"acceptable-heartbeat-pause":"6000000ms","heartbeat-interval":"1000000ms","threshold":300}},"serialize-messages":"off","stdout-loglevel":"OFF"}}))
03/06/2020 13:13:30.169  INFO [akka.event.slf4j.Slf4jLogger] Slf4jLogger started
03/06/2020 13:13:30.173 DEBUG [akka.event.EventStream] logger log1-Slf4jLogger started
03/06/2020 13:13:30.173 DEBUG [akka.event.EventStream] Default Loggers started
03/06/2020 13:13:30.173  INFO [akka.remote.Remoting] Starting remoting
03/06/2020 13:13:30.519  INFO [akka.remote.Remoting] Remoting started; listening on addresses :[akka.tcp://flink-metrics@127.0.1.1:40059]
03/06/2020 13:13:31.978  INFO [org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils] Actor system started at akka.tcp://flink-metrics@127.0.1.1:40059
03/06/2020 13:13:31.999  INFO [org.apache.flink.runtime.rpc.akka.AkkaRpcService] Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/MetricQueryService .
03/06/2020 13:13:32.076  INFO [org.apache.flink.runtime.minicluster.MiniCluster] Starting high-availability services
03/06/2020 13:13:32.087  INFO [org.apache.flink.runtime.blob.BlobServer] Created BLOB server storage directory /tmp/blobStore-7c16a8dc-51dc-43f6-ad14-b3a982457911
03/06/2020 13:13:32.123 DEBUG [org.apache.flink.util.NetUtils] Trying to open socket on port 0
03/06/2020 13:13:32.126  INFO [org.apache.flink.runtime.blob.BlobServer] Started BLOB server at 0.0.0.0:43109 - max concurrent requests: 50 - max backlog: 1000
03/06/2020 13:13:32.149  INFO [org.apache.flink.runtime.blob.PermanentBlobCache] Created BLOB cache storage directory /tmp/blobStore-51c445a1-bddc-451a-ab86-c78f495323e8
03/06/2020 13:13:32.172  INFO [org.apache.flink.runtime.blob.TransientBlobCache] Created BLOB cache storage directory /tmp/blobStore-06d8d6d7-5363-4f23-92b6-9fff12a62928
03/06/2020 13:13:32.182  INFO [org.apache.flink.runtime.minicluster.MiniCluster] Starting 1 TaskManger(s)
03/06/2020 13:13:32.189  INFO [org.apache.flink.runtime.taskexecutor.TaskManagerRunner] Starting TaskManager with ResourceID: c6dad6c4-5aed-483e-a3f5-af04f31f7b7e
03/06/2020 13:13:32.240  INFO [org.apache.flink.runtime.taskexecutor.TaskManagerServices] Temporary file directory '/tmp': total 39 GB, usable 23 GB (58,97% usable)
03/06/2020 13:13:32.244  INFO [org.apache.flink.runtime.io.disk.FileChannelManagerImpl] FileChannelManager uses directory /tmp/flink-io-80161287-20ce-471f-9e75-d41564babd95 for spill files.
03/06/2020 13:13:32.261  INFO [org.apache.flink.runtime.io.disk.FileChannelManagerImpl] FileChannelManager uses directory /tmp/flink-netty-shuffle-a1c80bef-0ecb-4cf0-9606-ce437caabafb for spill files.
03/06/2020 13:13:32.987  INFO [org.apache.flink.runtime.io.network.buffer.NetworkBufferPool] Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
03/06/2020 13:13:33.026  INFO [org.apache.flink.runtime.io.network.NettyShuffleEnvironment] Starting the network environment and its components.
03/06/2020 13:13:33.030 DEBUG [org.apache.flink.runtime.io.network.NettyShuffleEnvironment] Starting network connection manager
03/06/2020 13:13:33.030  INFO [org.apache.flink.runtime.taskexecutor.KvStateService] Starting the kvState service and its components.
03/06/2020 13:13:33.041  INFO [org.apache.flink.runtime.taskexecutor.TaskManagerConfiguration] Messages have a max timeout of 10000 ms
03/06/2020 13:13:33.053  INFO [org.apache.flink.runtime.rpc.akka.AkkaRpcService] Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/taskmanager_2 .
03/06/2020 13:13:33.056  INFO [org.apache.flink.runtime.taskexecutor.JobLeaderService] Start job leader service.
03/06/2020 13:13:33.057  INFO [org.apache.flink.runtime.filecache.FileCache] User file cache uses directory /tmp/flink-dist-cache-c02a8175-fe8a-45dd-aa04-d39660dd09e3
03/06/2020 13:13:33.063 DEBUG [org.apache.flink.runtime.entrypoint.component.DefaultDispatcherResourceManagerComponentFactory] Starting Dispatcher REST endpoint.
03/06/2020 13:13:33.063  INFO [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Starting rest endpoint.
03/06/2020 13:13:33.074  WARN [org.apache.flink.runtime.webmonitor.WebMonitorUtils] Log file environment variable 'log.file' is not set.
03/06/2020 13:13:33.074  WARN [org.apache.flink.runtime.webmonitor.WebMonitorUtils] JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'Key: 'web.log.path' , default: null (fallback keys: [{key=jobmanager.web.log.path, isDeprecated=true}])'.
03/06/2020 13:13:33.079 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Failed to load web based job submission extension.
org.apache.flink.util.FlinkException: The module flink-runtime-web could not be found in the class path. Please add this jar in order to enable web based job submission.
	at org.apache.flink.runtime.webmonitor.WebMonitorUtils.loadWebSubmissionExtension(WebMonitorUtils.java:192)
	at org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint.initializeHandlers(DispatcherRestEndpoint.java:98)
	at org.apache.flink.runtime.rest.RestServerEndpoint.start(RestServerEndpoint.java:141)
	at org.apache.flink.runtime.entrypoint.component.DefaultDispatcherResourceManagerComponentFactory.create(DefaultDispatcherResourceManagerComponentFactory.java:165)
	at org.apache.flink.runtime.minicluster.MiniCluster.createDispatcherResourceManagerComponents(MiniCluster.java:394)
	at org.apache.flink.runtime.minicluster.MiniCluster.setupDispatcherResourceManagerComponents(MiniCluster.java:360)
	at org.apache.flink.runtime.minicluster.MiniCluster.start(MiniCluster.java:314)
	at org.apache.flink.client.deployment.executors.LocalExecutor.startMiniCluster(LocalExecutor.java:117)
	at org.apache.flink.client.deployment.executors.LocalExecutor.execute(LocalExecutor.java:63)
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.executeAsync(StreamExecutionEnvironment.java:1733)
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1634)
	at org.apache.flink.streaming.api.environment.LocalStreamEnvironment.execute(LocalStreamEnvironment.java:74)
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1620)
	at aljoschaRydzyk.Gradoop_Flink_Prototype.Execution_Prototype.main(Execution_Prototype.java:185)
03/06/2020 13:13:33.090 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.cluster.ShutdownHandler@1c879f07 under DELETE@/v1/cluster.
03/06/2020 13:13:33.097 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.cluster.ShutdownHandler@1c879f07 under DELETE@/cluster.
03/06/2020 13:13:33.099 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.cluster.DashboardConfigHandler@78e4fa1 under GET@/v1/config.
03/06/2020 13:13:33.101 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.cluster.DashboardConfigHandler@78e4fa1 under GET@/config.
03/06/2020 13:13:33.102 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.cluster.ClusterConfigHandler@4516c2ef under GET@/v1/jobmanager/config.
03/06/2020 13:13:33.102 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.cluster.ClusterConfigHandler@4516c2ef under GET@/jobmanager/config.
03/06/2020 13:13:33.102 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.legacy.ConstantTextHandler@44f338ec under GET@/v1/jobmanager/log.
03/06/2020 13:13:33.102 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.legacy.ConstantTextHandler@44f338ec under GET@/jobmanager/log.
03/06/2020 13:13:33.102 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobManagerMetricsHandler@64acf8d2 under GET@/v1/jobmanager/metrics.
03/06/2020 13:13:33.102 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobManagerMetricsHandler@64acf8d2 under GET@/jobmanager/metrics.
03/06/2020 13:13:33.102 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.legacy.ConstantTextHandler@112a50a1 under GET@/v1/jobmanager/stdout.
03/06/2020 13:13:33.102 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.legacy.ConstantTextHandler@112a50a1 under GET@/jobmanager/stdout.
03/06/2020 13:13:33.102 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.JobIdsHandler@6258f9d1 under GET@/v1/jobs.
03/06/2020 13:13:33.102 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.JobIdsHandler@6258f9d1 under GET@/jobs.
03/06/2020 13:13:33.102 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.JobSubmitHandler@3f31892e under POST@/v1/jobs.
03/06/2020 13:13:33.105 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.JobSubmitHandler@3f31892e under POST@/jobs.
03/06/2020 13:13:33.106 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingJobsMetricsHandler@3cd89c72 under GET@/v1/jobs/metrics.
03/06/2020 13:13:33.106 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingJobsMetricsHandler@3cd89c72 under GET@/jobs/metrics.
03/06/2020 13:13:33.112 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.JobsOverviewHandler@7fb46c10 under GET@/v1/jobs/overview.
03/06/2020 13:13:33.113 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.JobsOverviewHandler@7fb46c10 under GET@/jobs/overview.
03/06/2020 13:13:33.113 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.JobDetailsHandler@5a079446 under GET@/v1/jobs/:jobid.
03/06/2020 13:13:33.113 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.JobDetailsHandler@5a079446 under GET@/jobs/:jobid.
03/06/2020 13:13:33.113 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@694c0ed1 under PATCH@/v1/jobs/:jobid.
03/06/2020 13:13:33.113 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@694c0ed1 under PATCH@/jobs/:jobid.
03/06/2020 13:13:33.113 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.JobAccumulatorsHandler@118f2486 under GET@/v1/jobs/:jobid/accumulators.
03/06/2020 13:13:33.116 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.JobAccumulatorsHandler@118f2486 under GET@/jobs/:jobid/accumulators.
03/06/2020 13:13:33.120 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointingStatisticsHandler@4d071e4b under GET@/v1/jobs/:jobid/checkpoints.
03/06/2020 13:13:33.120 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointingStatisticsHandler@4d071e4b under GET@/jobs/:jobid/checkpoints.
03/06/2020 13:13:33.121 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointConfigHandler@2b441609 under GET@/v1/jobs/:jobid/checkpoints/config.
03/06/2020 13:13:33.122 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointConfigHandler@2b441609 under GET@/jobs/:jobid/checkpoints/config.
03/06/2020 13:13:33.126 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointStatisticDetailsHandler@22f7bf36 under GET@/v1/jobs/:jobid/checkpoints/details/:checkpointid.
03/06/2020 13:13:33.126 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointStatisticDetailsHandler@22f7bf36 under GET@/jobs/:jobid/checkpoints/details/:checkpointid.
03/06/2020 13:13:33.126 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.TaskCheckpointStatisticDetailsHandler@4a3404fa under GET@/v1/jobs/:jobid/checkpoints/details/:checkpointid/subtasks/:vertexid.
03/06/2020 13:13:33.126 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.TaskCheckpointStatisticDetailsHandler@4a3404fa under GET@/jobs/:jobid/checkpoints/details/:checkpointid/subtasks/:vertexid.
03/06/2020 13:13:33.127 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.JobConfigHandler@3fb4beb1 under GET@/v1/jobs/:jobid/config.
03/06/2020 13:13:33.127 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.JobConfigHandler@3fb4beb1 under GET@/jobs/:jobid/config.
03/06/2020 13:13:33.127 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.JobExceptionsHandler@34cb1310 under GET@/v1/jobs/:jobid/exceptions.
03/06/2020 13:13:33.127 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.JobExceptionsHandler@34cb1310 under GET@/jobs/:jobid/exceptions.
03/06/2020 13:13:33.127 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.JobExecutionResultHandler@2b5a04b0 under GET@/v1/jobs/:jobid/execution-result.
03/06/2020 13:13:33.127 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.JobExecutionResultHandler@2b5a04b0 under GET@/jobs/:jobid/execution-result.
03/06/2020 13:13:33.127 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobMetricsHandler@41a3c6f5 under GET@/v1/jobs/:jobid/metrics.
03/06/2020 13:13:33.127 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobMetricsHandler@41a3c6f5 under GET@/jobs/:jobid/metrics.
03/06/2020 13:13:33.127 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.JobPlanHandler@5b78a946 under GET@/v1/jobs/:jobid/plan.
03/06/2020 13:13:33.127 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.JobPlanHandler@5b78a946 under GET@/jobs/:jobid/plan.
03/06/2020 13:13:33.134 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.rescaling.RescalingHandlers$RescalingTriggerHandler@37c762aa under PATCH@/v1/jobs/:jobid/rescaling.
03/06/2020 13:13:33.135 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.rescaling.RescalingHandlers$RescalingTriggerHandler@37c762aa under PATCH@/jobs/:jobid/rescaling.
03/06/2020 13:13:33.135 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.rescaling.RescalingHandlers$RescalingStatusHandler@4c438f66 under GET@/v1/jobs/:jobid/rescaling/:triggerid.
03/06/2020 13:13:33.137 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.rescaling.RescalingHandlers$RescalingStatusHandler@4c438f66 under GET@/jobs/:jobid/rescaling/:triggerid.
03/06/2020 13:13:33.137 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$SavepointTriggerHandler@13087c75 under POST@/v1/jobs/:jobid/savepoints.
03/06/2020 13:13:33.137 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$SavepointTriggerHandler@13087c75 under POST@/jobs/:jobid/savepoints.
03/06/2020 13:13:33.141 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$SavepointStatusHandler@da4c5cb under GET@/v1/jobs/:jobid/savepoints/:triggerid.
03/06/2020 13:13:33.142 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$SavepointStatusHandler@da4c5cb under GET@/jobs/:jobid/savepoints/:triggerid.
03/06/2020 13:13:33.142 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$StopWithSavepointHandler@1fa24e7 under POST@/v1/jobs/:jobid/stop.
03/06/2020 13:13:33.143 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$StopWithSavepointHandler@1fa24e7 under POST@/jobs/:jobid/stop.
03/06/2020 13:13:33.143 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.JobVertexDetailsHandler@5192b301 under GET@/v1/jobs/:jobid/vertices/:vertexid.
03/06/2020 13:13:33.143 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.JobVertexDetailsHandler@5192b301 under GET@/jobs/:jobid/vertices/:vertexid.
03/06/2020 13:13:33.143 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.JobVertexAccumulatorsHandler@1a99692 under GET@/v1/jobs/:jobid/vertices/:vertexid/accumulators.
03/06/2020 13:13:33.143 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.JobVertexAccumulatorsHandler@1a99692 under GET@/jobs/:jobid/vertices/:vertexid/accumulators.
03/06/2020 13:13:33.143 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.JobVertexBackPressureHandler@2a0881f1 under GET@/v1/jobs/:jobid/vertices/:vertexid/backpressure.
03/06/2020 13:13:33.143 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.JobVertexBackPressureHandler@2a0881f1 under GET@/jobs/:jobid/vertices/:vertexid/backpressure.
03/06/2020 13:13:33.144 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobVertexMetricsHandler@7a85454b under GET@/v1/jobs/:jobid/vertices/:vertexid/metrics.
03/06/2020 13:13:33.144 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobVertexMetricsHandler@7a85454b under GET@/jobs/:jobid/vertices/:vertexid/metrics.
03/06/2020 13:13:33.144 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.SubtasksAllAccumulatorsHandler@3ecbfba1 under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/accumulators.
03/06/2020 13:13:33.144 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.SubtasksAllAccumulatorsHandler@3ecbfba1 under GET@/jobs/:jobid/vertices/:vertexid/subtasks/accumulators.
03/06/2020 13:13:33.144 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingSubtasksMetricsHandler@739be7ec under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/metrics.
03/06/2020 13:13:33.144 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingSubtasksMetricsHandler@739be7ec under GET@/jobs/:jobid/vertices/:vertexid/subtasks/metrics.
03/06/2020 13:13:33.144 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.SubtaskCurrentAttemptDetailsHandler@1df2e767 under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex.
03/06/2020 13:13:33.144 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.SubtaskCurrentAttemptDetailsHandler@1df2e767 under GET@/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex.
03/06/2020 13:13:33.144 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.SubtaskExecutionAttemptDetailsHandler@4d0d568f under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/attempts/:attempt.
03/06/2020 13:13:33.144 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.SubtaskExecutionAttemptDetailsHandler@4d0d568f under GET@/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/attempts/:attempt.
03/06/2020 13:13:33.145 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.SubtaskExecutionAttemptAccumulatorsHandler@2c7aba7c under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/attempts/:attempt/accumulators.
03/06/2020 13:13:33.145 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.SubtaskExecutionAttemptAccumulatorsHandler@2c7aba7c under GET@/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/attempts/:attempt/accumulators.
03/06/2020 13:13:33.145 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.metrics.SubtaskMetricsHandler@729c98 under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/metrics.
03/06/2020 13:13:33.145 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.metrics.SubtaskMetricsHandler@729c98 under GET@/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/metrics.
03/06/2020 13:13:33.145 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.SubtasksTimesHandler@a319a2e under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasktimes.
03/06/2020 13:13:33.145 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.SubtasksTimesHandler@a319a2e under GET@/jobs/:jobid/vertices/:vertexid/subtasktimes.
03/06/2020 13:13:33.145 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.JobVertexTaskManagersHandler@2daf0cc9 under GET@/v1/jobs/:jobid/vertices/:vertexid/taskmanagers.
03/06/2020 13:13:33.145 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.JobVertexTaskManagersHandler@2daf0cc9 under GET@/jobs/:jobid/vertices/:vertexid/taskmanagers.
03/06/2020 13:13:33.145 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobVertexWatermarksHandler@54fffa5a under GET@/v1/jobs/:jobid/vertices/:vertexid/watermarks.
03/06/2020 13:13:33.151 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobVertexWatermarksHandler@54fffa5a under GET@/jobs/:jobid/vertices/:vertexid/watermarks.
03/06/2020 13:13:33.151 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@694c0ed1 under GET@/v1/jobs/:jobid/yarn-cancel.
03/06/2020 13:13:33.152 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@694c0ed1 under GET@/jobs/:jobid/yarn-cancel.
03/06/2020 13:13:33.152 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@407d2a01 under GET@/v1/jobs/:jobid/yarn-stop.
03/06/2020 13:13:33.152 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@407d2a01 under GET@/jobs/:jobid/yarn-stop.
03/06/2020 13:13:33.152 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.cluster.ClusterOverviewHandler@461b38ca under GET@/v1/overview.
03/06/2020 13:13:33.152 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.cluster.ClusterOverviewHandler@461b38ca under GET@/overview.
03/06/2020 13:13:33.152 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointDisposalHandlers$SavepointDisposalTriggerHandler@1387bd84 under POST@/v1/savepoint-disposal.
03/06/2020 13:13:33.154 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointDisposalHandlers$SavepointDisposalTriggerHandler@1387bd84 under POST@/savepoint-disposal.
03/06/2020 13:13:33.154 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointDisposalHandlers$SavepointDisposalStatusHandler@3881b884 under GET@/v1/savepoint-disposal/:triggerid.
03/06/2020 13:13:33.155 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointDisposalHandlers$SavepointDisposalStatusHandler@3881b884 under GET@/savepoint-disposal/:triggerid.
03/06/2020 13:13:33.155 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagersHandler@1185b0b7 under GET@/v1/taskmanagers.
03/06/2020 13:13:33.155 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagersHandler@1185b0b7 under GET@/taskmanagers.
03/06/2020 13:13:33.155 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingTaskManagersMetricsHandler@ec70725 under GET@/v1/taskmanagers/metrics.
03/06/2020 13:13:33.155 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingTaskManagersMetricsHandler@ec70725 under GET@/taskmanagers/metrics.
03/06/2020 13:13:33.155 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerDetailsHandler@2082e0e4 under GET@/v1/taskmanagers/:taskmanagerid.
03/06/2020 13:13:33.156 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerDetailsHandler@2082e0e4 under GET@/taskmanagers/:taskmanagerid.
03/06/2020 13:13:33.156 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerLogFileHandler@15f229e8 under GET@/v1/taskmanagers/:taskmanagerid/log.
03/06/2020 13:13:33.156 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerLogFileHandler@15f229e8 under GET@/taskmanagers/:taskmanagerid/log.
03/06/2020 13:13:33.156 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.metrics.TaskManagerMetricsHandler@29ce33e9 under GET@/v1/taskmanagers/:taskmanagerid/metrics.
03/06/2020 13:13:33.156 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.job.metrics.TaskManagerMetricsHandler@29ce33e9 under GET@/taskmanagers/:taskmanagerid/metrics.
03/06/2020 13:13:33.156 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerStdoutFileHandler@1f86f7da under GET@/v1/taskmanagers/:taskmanagerid/stdout.
03/06/2020 13:13:33.156 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerStdoutFileHandler@1f86f7da under GET@/taskmanagers/:taskmanagerid/stdout.
03/06/2020 13:13:33.172 DEBUG [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Binding rest endpoint to null:0.
03/06/2020 13:13:33.172  INFO [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Rest endpoint listening at localhost:33969
03/06/2020 13:13:33.172  INFO [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] Proposing leadership to contender http://localhost:33969
03/06/2020 13:13:33.173  INFO [org.apache.flink.runtime.rpc.akka.AkkaRpcService] Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/resourcemanager .
03/06/2020 13:13:33.174 DEBUG [org.apache.flink.runtime.entrypoint.component.DefaultDispatcherResourceManagerComponentFactory] Starting Dispatcher.
03/06/2020 13:13:33.174  INFO [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] Proposing leadership to contender LeaderContender: DefaultDispatcherRunner
03/06/2020 13:13:33.175  INFO [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] http://localhost:33969 was granted leadership with leaderSessionID=014cef10-554b-4cf5-9f1e-326c4c443b60
03/06/2020 13:13:33.177  INFO [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] Received confirmation of leadership for leader http://localhost:33969 , session=014cef10-554b-4cf5-9f1e-326c4c443b60
03/06/2020 13:13:33.178 DEBUG [org.apache.flink.runtime.entrypoint.component.DefaultDispatcherResourceManagerComponentFactory] Starting ResourceManager.
03/06/2020 13:13:33.178  INFO [org.apache.flink.runtime.minicluster.MiniCluster] Flink Mini Cluster started successfully
03/06/2020 13:13:33.178 DEBUG [org.apache.flink.runtime.dispatcher.runner.DefaultDispatcherRunner] Create new DispatcherLeaderProcess with leader session id a04c774b-19ae-4829-b6b3-58b92613df99.
03/06/2020 13:13:33.179  INFO [org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess] Start SessionDispatcherLeaderProcess.
03/06/2020 13:13:33.179  INFO [org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess] Recover all persisted job graphs.
03/06/2020 13:13:33.179  INFO [org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess] Successfully recovered 0 persisted job graphs.
03/06/2020 13:13:33.180  INFO [org.apache.flink.runtime.rpc.akka.AkkaRpcService] Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/dispatcher .
03/06/2020 13:13:33.188  INFO [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] Received confirmation of leadership for leader akka://flink/user/dispatcher , session=a04c774b-19ae-4829-b6b3-58b92613df99
03/06/2020 13:13:33.188  INFO [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] Proposing leadership to contender LeaderContender: StandaloneResourceManager
03/06/2020 13:13:33.191 DEBUG [org.apache.flink.runtime.rpc.akka.AkkaRpcService] Try to connect to remote RPC endpoint with address akka://flink/user/dispatcher. Returning a org.apache.flink.runtime.dispatcher.DispatcherGateway gateway.
03/06/2020 13:13:33.194  INFO [org.apache.flink.runtime.resourcemanager.StandaloneResourceManager] ResourceManager akka://flink/user/resourcemanager was granted leadership with fencing token b726e9a1aaa6118b3069502acdfa4f3d
03/06/2020 13:13:33.195  INFO [org.apache.flink.runtime.resourcemanager.slotmanager.SlotManagerImpl] Starting the SlotManager.
03/06/2020 13:13:33.195 DEBUG [org.apache.flink.runtime.resourcemanager.StandaloneResourceManager] Trigger heartbeat request.
03/06/2020 13:13:33.195 DEBUG [org.apache.flink.runtime.resourcemanager.StandaloneResourceManager] Trigger heartbeat request.
03/06/2020 13:13:33.197  INFO [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] Received confirmation of leadership for leader akka://flink/user/resourcemanager , session=3069502a-cdfa-4f3d-b726-e9a1aaa6118b
03/06/2020 13:13:33.198  INFO [org.apache.flink.runtime.dispatcher.StandaloneDispatcher] Received JobGraph submission cf350677de1d99f7f7ea8e79709c5624 (test).
03/06/2020 13:13:33.198  INFO [org.apache.flink.runtime.dispatcher.StandaloneDispatcher] Submitting job cf350677de1d99f7f7ea8e79709c5624 (test).
03/06/2020 13:13:33.199  INFO [org.apache.flink.runtime.rpc.akka.AkkaRpcService] Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/jobmanager_3 .
03/06/2020 13:13:33.199  INFO [org.apache.flink.runtime.jobmaster.JobMaster] Initializing job test (cf350677de1d99f7f7ea8e79709c5624).
03/06/2020 13:13:33.201  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutor] Connecting to ResourceManager akka://flink/user/resourcemanager(b726e9a1aaa6118b3069502acdfa4f3d).
03/06/2020 13:13:33.201 DEBUG [org.apache.flink.runtime.rpc.akka.AkkaRpcService] Try to connect to remote RPC endpoint with address akka://flink/user/resourcemanager. Returning a org.apache.flink.runtime.resourcemanager.ResourceManagerGateway gateway.
03/06/2020 13:13:33.202  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutor] Resolved ResourceManager address, beginning registration
03/06/2020 13:13:33.203  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutor] Registration at ResourceManager attempt 1 (timeout=100ms)
03/06/2020 13:13:33.203 DEBUG [org.apache.flink.runtime.rpc.akka.AkkaRpcService] Try to connect to remote RPC endpoint with address akka://flink/user/taskmanager_2. Returning a org.apache.flink.runtime.taskexecutor.TaskExecutorGateway gateway.
03/06/2020 13:13:33.204 DEBUG [org.apache.flink.runtime.rpc.akka.AkkaRpcService] Try to connect to remote RPC endpoint with address akka://flink/user/resourcemanager. Returning a org.apache.flink.runtime.resourcemanager.ResourceManagerGateway gateway.
03/06/2020 13:13:33.204  INFO [org.apache.flink.runtime.resourcemanager.StandaloneResourceManager] Registering TaskManager with ResourceID c6dad6c4-5aed-483e-a3f5-af04f31f7b7e (akka://flink/user/taskmanager_2) at ResourceManager
03/06/2020 13:13:33.205 DEBUG [org.apache.flink.runtime.rpc.akka.AkkaRpcService] Try to connect to remote RPC endpoint with address akka://flink/user/resourcemanager. Returning a org.apache.flink.runtime.resourcemanager.ResourceManagerGateway gateway.
03/06/2020 13:13:33.205  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutor] Successful registration at resource manager akka://flink/user/resourcemanager under registration id 54817bd444f822416fc4182c5a3e3f1a.
03/06/2020 13:13:33.206 DEBUG [org.apache.flink.runtime.resourcemanager.slotmanager.SlotManagerImpl] Registering TaskManager c6dad6c4-5aed-483e-a3f5-af04f31f7b7e under 54817bd444f822416fc4182c5a3e3f1a at the SlotManager.
03/06/2020 13:13:33.211 DEBUG [org.apache.flink.runtime.rpc.akka.AkkaRpcService] Try to connect to remote RPC endpoint with address akka://flink/user/dispatcher. Returning a org.apache.flink.runtime.dispatcher.DispatcherGateway gateway.
03/06/2020 13:13:33.214  INFO [org.apache.flink.runtime.jobmaster.JobMaster] Using restart back off time strategy FixedDelayRestartBackoffTimeStrategy(maxNumberRestartAttempts=2147483647, backoffTimeMS=1000) for test (cf350677de1d99f7f7ea8e79709c5624).
03/06/2020 13:13:33.218  INFO [org.apache.flink.runtime.jobmaster.JobMaster] Running initialization on master for job test (cf350677de1d99f7f7ea8e79709c5624).
03/06/2020 13:13:33.221  INFO [org.apache.flink.addons.hbase.HBaseRowInputFormat] Initializing HBase configuration.
03/06/2020 13:13:33.300  INFO [org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper] Process identifier=hconnection-0x2fe662a6 connecting to ZooKeeper ensemble=localhost:2181
03/06/2020 13:13:33.300  INFO [org.apache.zookeeper.ZooKeeper] Initiating client connection, connectString=localhost:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.PendingWatcher@63592bec
03/06/2020 13:13:33.312  INFO [org.apache.zookeeper.ClientCnxn] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
03/06/2020 13:13:33.322  INFO [org.apache.zookeeper.ClientCnxn] Socket connection established to localhost/127.0.0.1:2181, initiating session
03/06/2020 13:13:33.323 DEBUG [org.apache.zookeeper.ClientCnxn] Session establishment request sent on localhost/127.0.0.1:2181
03/06/2020 13:13:33.325  INFO [org.apache.zookeeper.ClientCnxn] Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x172799b82f20030, negotiated timeout = 90000
03/06/2020 13:13:33.327 DEBUG [org.apache.zookeeper.ClientCnxn] Reading reply sessionid:0x172799b82f20030, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,1045,0  request:: '/hbase/hbaseid,F  response:: s{36,897,1589975516652,1591178147927,3,0,0,0,67,0,36} 
03/06/2020 13:13:33.328 DEBUG [org.apache.zookeeper.ClientCnxn] Reading reply sessionid:0x172799b82f20030, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,1045,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a31363030302affffff9f4357ffffffbf5875150425546a2434306339306330662d663833372d343664652d626233622d363436353332383637336261,s{36,897,1589975516652,1591178147927,3,0,0,0,67,0,36} 
03/06/2020 13:13:33.328 DEBUG [org.apache.hadoop.hbase.ipc.AbstractRpcClient] Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@36bcbdb5, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
03/06/2020 13:13:33.329  INFO [org.apache.flink.runtime.jobmaster.JobMaster] Successfully ran initialization on master in 111 ms.
03/06/2020 13:13:33.329 DEBUG [org.apache.flink.runtime.jobmaster.JobMaster] Adding 7 vertices from job graph test (cf350677de1d99f7f7ea8e79709c5624).
03/06/2020 13:13:33.329 DEBUG [org.apache.flink.runtime.executiongraph.ExecutionGraph] Attaching 7 topologically sorted vertices to existing job graph with 0 vertices and 0 intermediate results.
03/06/2020 13:13:33.330 DEBUG [org.apache.zookeeper.ClientCnxn] Reading reply sessionid:0x172799b82f20030, packet:: clientPath:null serverPath:null finished:false header:: 3,4  replyHeader:: 3,1045,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a31363230317245ffffff8ffffffff46c10ffffffddffffffc050425546a12a67562756e747510ffffffc97e18ffffffa8ffffffa8ffffffeeffffffccffffffa72e100183,s{911,911,1591178156577,1591178156577,0,0,0,0,59,0,911} 
03/06/2020 13:13:33.331 DEBUG [org.apache.zookeeper.ClientCnxn] Reading reply sessionid:0x172799b82f20030, packet:: clientPath:null serverPath:null finished:false header:: 4,8  replyHeader:: 4,1045,0  request:: '/hbase,F  response:: v{'replication,'meta-region-server,'rs,'splitWAL,'backup-masters,'table-lock,'flush-table-proc,'master-maintenance,'region-in-transition,'online-snapshot,'switch,'master,'running,'recovering-regions,'draining,'namespace,'hbaseid,'table} 
03/06/2020 13:13:33.332 DEBUG [org.apache.hadoop.hbase.ipc.RpcConnection] Use SIMPLE authentication for service ClientService, sasl=false
03/06/2020 13:13:33.333 DEBUG [org.apache.hadoop.hbase.ipc.BlockingRpcConnection] Connecting to ubuntu/127.0.1.1:16201
03/06/2020 13:13:33.333 DEBUG [org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher] hconnection-0x2fe662a60x0, quorum=localhost:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
03/06/2020 13:13:33.342 DEBUG [org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher] hconnection-0x2fe662a6-0x172799b82f20030 connected
03/06/2020 13:13:33.365  INFO [org.apache.flink.addons.hbase.AbstractTableInputFormat] Created 1 splits
03/06/2020 13:13:33.369  INFO [org.apache.flink.addons.hbase.AbstractTableInputFormat] created split (this=org.apache.flink.addons.hbase.HBaseRowInputFormat@42f5bedf)[0|[ubuntu:16201]|-|-]
03/06/2020 13:13:33.369 DEBUG [org.apache.flink.runtime.executiongraph.ExecutionGraph] Connecting ExecutionJobVertex cbc357ccb763df2852fee8c4fc7d55f2 (Source: HBaseTableSource[schema=[id, cf], projectFields=null] -> SourceConversion(table=[default_catalog.default_database.loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]], fields=[id, cf]) -> Calc(select=[id, cf, cf.degree AS degree])) to 0 predecessors.
03/06/2020 13:13:33.370 DEBUG [org.apache.flink.runtime.executiongraph.ExecutionGraph] Connecting ExecutionJobVertex 6cdc5bb954874d922eaee11a8e7b5dd5 (Source: Collection Source -> SourceConversion(table=[Unregistered_DataStream_9], fields=[f0, f1, f2, f3, f4]) -> Calc(select=[f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y])) to 0 predecessors.
03/06/2020 13:13:33.370 DEBUG [org.apache.flink.runtime.executiongraph.ExecutionGraph] Connecting ExecutionJobVertex 57df6b5c78b46bc5e7b8e2b883e729a9 (SortLimit(orderBy=[degree DESC], offset=[0], fetch=[10]) -> Calc(select=[id, cf]) -> SinkConversionToTuple2) to 1 predecessors.
03/06/2020 13:13:33.370 DEBUG [org.apache.flink.runtime.executiongraph.ExecutionGraph] Connecting input 0 of vertex 57df6b5c78b46bc5e7b8e2b883e729a9 (SortLimit(orderBy=[degree DESC], offset=[0], fetch=[10]) -> Calc(select=[id, cf]) -> SinkConversionToTuple2) to intermediate result referenced via predecessor cbc357ccb763df2852fee8c4fc7d55f2 (Source: HBaseTableSource[schema=[id, cf], projectFields=null] -> SourceConversion(table=[default_catalog.default_database.loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]], fields=[id, cf]) -> Calc(select=[id, cf, cf.degree AS degree])).
03/06/2020 13:13:33.370 DEBUG [org.apache.flink.runtime.executiongraph.ExecutionGraph] Connecting ExecutionJobVertex 730748a2d3477923527d4df19c1115d3 (Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree])) to 1 predecessors.
03/06/2020 13:13:33.371 DEBUG [org.apache.flink.runtime.executiongraph.ExecutionGraph] Connecting input 0 of vertex 730748a2d3477923527d4df19c1115d3 (Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree])) to intermediate result referenced via predecessor 57df6b5c78b46bc5e7b8e2b883e729a9 (SortLimit(orderBy=[degree DESC], offset=[0], fetch=[10]) -> Calc(select=[id, cf]) -> SinkConversionToTuple2).
03/06/2020 13:13:33.371 DEBUG [org.apache.flink.runtime.executiongraph.ExecutionGraph] Connecting ExecutionJobVertex db7de5d6d7db9354bd8e4698740f442c (GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')])) to 1 predecessors.
03/06/2020 13:13:33.371 DEBUG [org.apache.flink.runtime.executiongraph.ExecutionGraph] Connecting input 0 of vertex db7de5d6d7db9354bd8e4698740f442c (GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')])) to intermediate result referenced via predecessor 730748a2d3477923527d4df19c1115d3 (Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree])).
03/06/2020 13:13:33.371 DEBUG [org.apache.flink.runtime.executiongraph.ExecutionGraph] Connecting ExecutionJobVertex 2da5af51bbd1dbb7a2c205b96fe7a428 (Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed) to 2 predecessors.
03/06/2020 13:13:33.372 DEBUG [org.apache.flink.runtime.executiongraph.ExecutionGraph] Connecting input 0 of vertex 2da5af51bbd1dbb7a2c205b96fe7a428 (Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed) to intermediate result referenced via predecessor db7de5d6d7db9354bd8e4698740f442c (GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')])).
03/06/2020 13:13:33.372 DEBUG [org.apache.flink.runtime.executiongraph.ExecutionGraph] Connecting input 1 of vertex 2da5af51bbd1dbb7a2c205b96fe7a428 (Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed) to intermediate result referenced via predecessor 6cdc5bb954874d922eaee11a8e7b5dd5 (Source: Collection Source -> SourceConversion(table=[Unregistered_DataStream_9], fields=[f0, f1, f2, f3, f4]) -> Calc(select=[f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y])).
03/06/2020 13:13:33.372 DEBUG [org.apache.flink.runtime.executiongraph.ExecutionGraph] Connecting ExecutionJobVertex 97062323b8add791924e501dd08b481e (Sink: Print to Std. Out) to 1 predecessors.
03/06/2020 13:13:33.372 DEBUG [org.apache.flink.runtime.executiongraph.ExecutionGraph] Connecting input 0 of vertex 97062323b8add791924e501dd08b481e (Sink: Print to Std. Out) to intermediate result referenced via predecessor 2da5af51bbd1dbb7a2c205b96fe7a428 (Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed).
03/06/2020 13:13:33.373 DEBUG [org.apache.flink.runtime.jobmaster.JobMaster] Successfully created execution graph from job graph test (cf350677de1d99f7f7ea8e79709c5624).
03/06/2020 13:13:33.443  INFO [org.apache.flink.runtime.jobmaster.JobMaster] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
03/06/2020 13:13:33.475 DEBUG [org.apache.flink.runtime.checkpoint.CheckpointCoordinator] Status of the shared state registry of job cf350677de1d99f7f7ea8e79709c5624 after restore: SharedStateRegistry{registeredStates={}}.
03/06/2020 13:13:33.475 DEBUG [org.apache.flink.runtime.checkpoint.CheckpointCoordinator] Resetting the master hooks.
03/06/2020 13:13:33.478  INFO [org.apache.flink.runtime.executiongraph.failover.flip1.RestartPipelinedRegionStrategy] Start building failover regions.
03/06/2020 13:13:33.479 DEBUG [org.apache.flink.runtime.executiongraph.failover.flip1.RestartPipelinedRegionStrategy] Creating a failover region with 11 vertices.
03/06/2020 13:13:33.479  INFO [org.apache.flink.runtime.executiongraph.failover.flip1.RestartPipelinedRegionStrategy] Created 1 failover regions.
03/06/2020 13:13:33.479  INFO [org.apache.flink.runtime.jobmaster.JobMaster] Using failover strategy org.apache.flink.runtime.executiongraph.failover.flip1.RestartPipelinedRegionStrategy@536a1272 for test (cf350677de1d99f7f7ea8e79709c5624).
03/06/2020 13:13:33.480  INFO [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] Proposing leadership to contender akka://flink/user/jobmanager_3
03/06/2020 13:13:33.481  INFO [org.apache.flink.runtime.jobmaster.JobManagerRunnerImpl] JobManager runner for job test (cf350677de1d99f7f7ea8e79709c5624) was granted leadership with session id 00f8b882-c0a5-4ed1-9320-3913567134c5 at akka://flink/user/jobmanager_3.
03/06/2020 13:13:33.484  INFO [org.apache.flink.runtime.jobmaster.JobMaster] Starting execution of job test (cf350677de1d99f7f7ea8e79709c5624) under job master id 93203913567134c500f8b882c0a54ed1.
03/06/2020 13:13:33.484  INFO [org.apache.flink.runtime.jobmaster.JobMaster] Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.EagerSchedulingStrategy]
03/06/2020 13:13:33.484  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] Job test (cf350677de1d99f7f7ea8e79709c5624) switched from state CREATED to RUNNING.
03/06/2020 13:13:33.488  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] Source: HBaseTableSource[schema=[id, cf], projectFields=null] -> SourceConversion(table=[default_catalog.default_database.loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]], fields=[id, cf]) -> Calc(select=[id, cf, cf.degree AS degree]) (1/2) (b84c3df4861d1ab2874fdf6c2c4b34e1) switched from CREATED to SCHEDULED.
03/06/2020 13:13:33.489  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] Source: HBaseTableSource[schema=[id, cf], projectFields=null] -> SourceConversion(table=[default_catalog.default_database.loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]], fields=[id, cf]) -> Calc(select=[id, cf, cf.degree AS degree]) (2/2) (db3aa1938ec63c4d326136e01fb698e5) switched from CREATED to SCHEDULED.
03/06/2020 13:13:33.489  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] Source: Collection Source -> SourceConversion(table=[Unregistered_DataStream_9], fields=[f0, f1, f2, f3, f4]) -> Calc(select=[f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y]) (1/1) (d74648705093b5c72e78e2c360e29713) switched from CREATED to SCHEDULED.
03/06/2020 13:13:33.489  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] SortLimit(orderBy=[degree DESC], offset=[0], fetch=[10]) -> Calc(select=[id, cf]) -> SinkConversionToTuple2 (1/1) (876cc1eabe833ca7f87c8793f251f04a) switched from CREATED to SCHEDULED.
03/06/2020 13:13:33.489  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (1/2) (4d7a1b8b380293c90670ee95c08224e0) switched from CREATED to SCHEDULED.
03/06/2020 13:13:33.489  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (2/2) (c365017ac85c61dc4f885a5155f06f1e) switched from CREATED to SCHEDULED.
03/06/2020 13:13:33.489  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (1/2) (02de6f076d7957e472f6eb0edbd38dbf) switched from CREATED to SCHEDULED.
03/06/2020 13:13:33.489  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (2/2) (1ff6ef243e2fa7b8aa3f13605b545e75) switched from CREATED to SCHEDULED.
03/06/2020 13:13:33.489  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (1/2) (6dfb6ce5559aca85d7e81c96224f4864) switched from CREATED to SCHEDULED.
03/06/2020 13:13:33.489  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (2/2) (27eb9406de3597496fd0bb48c5e876a5) switched from CREATED to SCHEDULED.
03/06/2020 13:13:33.490  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] Sink: Print to Std. Out (1/1) (26e0302ddaecd3150ec5345d3906b102) switched from CREATED to SCHEDULED.
03/06/2020 13:13:33.490 DEBUG [org.apache.flink.runtime.scheduler.DefaultExecutionSlotAllocator] Allocate slot with id SlotRequestId{202bc16674b0a959aa8fb3d57c7ce2c5} for execution cbc357ccb763df2852fee8c4fc7d55f2_0
03/06/2020 13:13:33.491 DEBUG [org.apache.flink.runtime.jobmaster.slotpool.SchedulerImpl] Received slot request [SlotRequestId{202bc16674b0a959aa8fb3d57c7ce2c5}] for task: null
03/06/2020 13:13:33.492  INFO [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{f1a06e8d90a3a49be59c5acf6026b3b9}]
03/06/2020 13:13:33.492 DEBUG [org.apache.flink.runtime.jobmaster.slotpool.SlotSharingManager] Create multi task slot [SlotRequestId{2d5483855fbf16db71948ed76fba2f43}] in slot [SlotRequestId{f1a06e8d90a3a49be59c5acf6026b3b9}].
03/06/2020 13:13:33.492 DEBUG [org.apache.flink.runtime.jobmaster.slotpool.SlotSharingManager] Create single task slot [SlotRequestId{202bc16674b0a959aa8fb3d57c7ce2c5}] in multi task slot [SlotRequestId{2d5483855fbf16db71948ed76fba2f43}] for group cbc357ccb763df2852fee8c4fc7d55f2.
03/06/2020 13:13:33.492 DEBUG [org.apache.flink.runtime.scheduler.DefaultExecutionSlotAllocator] Allocate slot with id SlotRequestId{cfc39714592b13a093f26c68e8221e92} for execution cbc357ccb763df2852fee8c4fc7d55f2_1
03/06/2020 13:13:33.493 DEBUG [org.apache.flink.runtime.jobmaster.slotpool.SchedulerImpl] Received slot request [SlotRequestId{cfc39714592b13a093f26c68e8221e92}] for task: null
03/06/2020 13:13:33.493  INFO [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{2441ab0ac753774db5fa5db436e75215}]
03/06/2020 13:13:33.493 DEBUG [org.apache.flink.runtime.jobmaster.slotpool.SlotSharingManager] Create multi task slot [SlotRequestId{ebbdaaa942758fb898f0d9a10e608e2d}] in slot [SlotRequestId{2441ab0ac753774db5fa5db436e75215}].
03/06/2020 13:13:33.494 DEBUG [org.apache.flink.runtime.jobmaster.slotpool.SlotSharingManager] Create single task slot [SlotRequestId{cfc39714592b13a093f26c68e8221e92}] in multi task slot [SlotRequestId{ebbdaaa942758fb898f0d9a10e608e2d}] for group cbc357ccb763df2852fee8c4fc7d55f2.
03/06/2020 13:13:33.494 DEBUG [org.apache.flink.runtime.scheduler.DefaultExecutionSlotAllocator] Allocate slot with id SlotRequestId{51c2eb402b0739fc703e8f11e0a80f24} for execution 6cdc5bb954874d922eaee11a8e7b5dd5_0
03/06/2020 13:13:33.494 DEBUG [org.apache.flink.runtime.jobmaster.slotpool.SchedulerImpl] Received slot request [SlotRequestId{51c2eb402b0739fc703e8f11e0a80f24}] for task: null
03/06/2020 13:13:33.495 DEBUG [org.apache.flink.runtime.jobmaster.slotpool.SlotSharingManager] Create single task slot [SlotRequestId{51c2eb402b0739fc703e8f11e0a80f24}] in multi task slot [SlotRequestId{ebbdaaa942758fb898f0d9a10e608e2d}] for group 6cdc5bb954874d922eaee11a8e7b5dd5.
03/06/2020 13:13:33.495 DEBUG [org.apache.flink.runtime.scheduler.DefaultExecutionSlotAllocator] Allocate slot with id SlotRequestId{baaddb941e39015fc75958cf96db7ea6} for execution 57df6b5c78b46bc5e7b8e2b883e729a9_0
03/06/2020 13:13:33.495 DEBUG [org.apache.flink.runtime.scheduler.DefaultExecutionSlotAllocator] Allocate slot with id SlotRequestId{4a62a318e9191179999911434dc3fc5c} for execution 730748a2d3477923527d4df19c1115d3_0
03/06/2020 13:13:33.495 DEBUG [org.apache.flink.runtime.scheduler.DefaultExecutionSlotAllocator] Allocate slot with id SlotRequestId{ffc5f92c83d4657d4b503145b940f0c5} for execution 730748a2d3477923527d4df19c1115d3_1
03/06/2020 13:13:33.495 DEBUG [org.apache.flink.runtime.scheduler.DefaultExecutionSlotAllocator] Allocate slot with id SlotRequestId{ed5773040726a689d7246a379155689b} for execution db7de5d6d7db9354bd8e4698740f442c_0
03/06/2020 13:13:33.496 DEBUG [org.apache.flink.runtime.scheduler.DefaultExecutionSlotAllocator] Allocate slot with id SlotRequestId{1c74235e018ac0cd39d37b55998d9f28} for execution db7de5d6d7db9354bd8e4698740f442c_1
03/06/2020 13:13:33.496 DEBUG [org.apache.flink.runtime.scheduler.DefaultExecutionSlotAllocator] Allocate slot with id SlotRequestId{a0f93d3018c97b5e27c24ef375e98c41} for execution 2da5af51bbd1dbb7a2c205b96fe7a428_0
03/06/2020 13:13:33.496 DEBUG [org.apache.flink.runtime.scheduler.DefaultExecutionSlotAllocator] Allocate slot with id SlotRequestId{719bbc825339394adb0a2807ab0ddd72} for execution 2da5af51bbd1dbb7a2c205b96fe7a428_1
03/06/2020 13:13:33.496 DEBUG [org.apache.flink.runtime.scheduler.DefaultExecutionSlotAllocator] Allocate slot with id SlotRequestId{5097399a191037ebd4eca3eeceeece7a} for execution 97062323b8add791924e501dd08b481e_0
03/06/2020 13:13:33.497  INFO [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] Received confirmation of leadership for leader akka://flink/user/jobmanager_3 , session=00f8b882-c0a5-4ed1-9320-3913567134c5
03/06/2020 13:13:33.498 DEBUG [org.apache.flink.runtime.jobmaster.JobMaster] Trigger heartbeat request.
03/06/2020 13:13:33.498  INFO [org.apache.flink.runtime.jobmaster.JobMaster] Connecting to ResourceManager akka://flink/user/resourcemanager(b726e9a1aaa6118b3069502acdfa4f3d)
03/06/2020 13:13:33.498 DEBUG [org.apache.flink.runtime.rpc.akka.AkkaRpcService] Try to connect to remote RPC endpoint with address akka://flink/user/resourcemanager. Returning a org.apache.flink.runtime.resourcemanager.ResourceManagerGateway gateway.
03/06/2020 13:13:33.499  INFO [org.apache.flink.runtime.jobmaster.JobMaster] Resolved ResourceManager address, beginning registration
03/06/2020 13:13:33.499  INFO [org.apache.flink.runtime.jobmaster.JobMaster] Registration at ResourceManager attempt 1 (timeout=100ms)
03/06/2020 13:13:33.500 DEBUG [org.apache.flink.runtime.resourcemanager.JobLeaderIdService] Add job cf350677de1d99f7f7ea8e79709c5624 to job leader id monitoring.
03/06/2020 13:13:33.500  INFO [org.apache.flink.runtime.resourcemanager.StandaloneResourceManager] Registering job manager 93203913567134c500f8b882c0a54ed1@akka://flink/user/jobmanager_3 for job cf350677de1d99f7f7ea8e79709c5624.
03/06/2020 13:13:33.500 DEBUG [org.apache.flink.runtime.rpc.akka.AkkaRpcService] Try to connect to remote RPC endpoint with address akka://flink/user/jobmanager_3. Returning a org.apache.flink.runtime.jobmaster.JobMasterGateway gateway.
03/06/2020 13:13:33.501 DEBUG [org.apache.flink.runtime.resourcemanager.JobLeaderIdService] Found a new job leader 00f8b882-c0a5-4ed1-9320-3913567134c5@akka://flink/user/jobmanager_3.
03/06/2020 13:13:33.501  INFO [org.apache.flink.runtime.resourcemanager.StandaloneResourceManager] Registered job manager 93203913567134c500f8b882c0a54ed1@akka://flink/user/jobmanager_3 for job cf350677de1d99f7f7ea8e79709c5624.
03/06/2020 13:13:33.502  INFO [org.apache.flink.runtime.jobmaster.JobMaster] JobManager successfully registered at ResourceManager, leader id: b726e9a1aaa6118b3069502acdfa4f3d.
03/06/2020 13:13:33.502  INFO [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] Requesting new slot [SlotRequestId{f1a06e8d90a3a49be59c5acf6026b3b9}] and profile ResourceProfile{UNKNOWN} from resource manager.
03/06/2020 13:13:33.503  INFO [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] Requesting new slot [SlotRequestId{2441ab0ac753774db5fa5db436e75215}] and profile ResourceProfile{UNKNOWN} from resource manager.
03/06/2020 13:13:33.503  INFO [org.apache.flink.runtime.resourcemanager.StandaloneResourceManager] Request slot with profile ResourceProfile{UNKNOWN} for job cf350677de1d99f7f7ea8e79709c5624 with allocation id 25d44a59926bde802cdf946b4a6b94f9.
03/06/2020 13:13:33.503  INFO [org.apache.flink.runtime.resourcemanager.StandaloneResourceManager] Request slot with profile ResourceProfile{UNKNOWN} for job cf350677de1d99f7f7ea8e79709c5624 with allocation id 72c915e615c4f2f98aedf5eb10885367.
03/06/2020 13:13:33.504  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutor] Receive slot request 25d44a59926bde802cdf946b4a6b94f9 for job cf350677de1d99f7f7ea8e79709c5624 from resource manager with leader id b726e9a1aaa6118b3069502acdfa4f3d.
03/06/2020 13:13:33.504 DEBUG [org.apache.flink.runtime.memory.MemoryManager] Initialized MemoryManager with total memory size 67108864 ({OFF_HEAP=67108864}), page size 32768.
03/06/2020 13:13:33.505  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutor] Allocated slot for 25d44a59926bde802cdf946b4a6b94f9.
03/06/2020 13:13:33.505  INFO [org.apache.flink.runtime.taskexecutor.JobLeaderService] Add job cf350677de1d99f7f7ea8e79709c5624 for job leader monitoring.
03/06/2020 13:13:33.505  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutor] Receive slot request 72c915e615c4f2f98aedf5eb10885367 for job cf350677de1d99f7f7ea8e79709c5624 from resource manager with leader id b726e9a1aaa6118b3069502acdfa4f3d.
03/06/2020 13:13:33.506 DEBUG [org.apache.flink.runtime.memory.MemoryManager] Initialized MemoryManager with total memory size 67108864 ({OFF_HEAP=67108864}), page size 32768.
03/06/2020 13:13:33.506  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutor] Allocated slot for 72c915e615c4f2f98aedf5eb10885367.
03/06/2020 13:13:33.506  INFO [org.apache.flink.runtime.taskexecutor.JobLeaderService] Add job cf350677de1d99f7f7ea8e79709c5624 for job leader monitoring.
03/06/2020 13:13:33.509 DEBUG [org.apache.flink.runtime.taskexecutor.JobLeaderService] JobLeaderService's leader retrieval listener reported a new leader for job cf350677de1d99f7f7ea8e79709c5624. However, the service is no longer running.
03/06/2020 13:13:33.509 DEBUG [org.apache.flink.runtime.taskexecutor.JobLeaderService] New leader information for job cf350677de1d99f7f7ea8e79709c5624. Address: akka://flink/user/jobmanager_3, leader id: 93203913567134c500f8b882c0a54ed1.
03/06/2020 13:13:33.510  INFO [org.apache.flink.runtime.taskexecutor.JobLeaderService] Try to register at job manager akka://flink/user/jobmanager_3 with leader id 00f8b882-c0a5-4ed1-9320-3913567134c5.
03/06/2020 13:13:33.510 DEBUG [org.apache.flink.runtime.rpc.akka.AkkaRpcService] Try to connect to remote RPC endpoint with address akka://flink/user/jobmanager_3. Returning a org.apache.flink.runtime.jobmaster.JobMasterGateway gateway.
03/06/2020 13:13:33.514  INFO [org.apache.flink.runtime.taskexecutor.JobLeaderService] Resolved JobManager address, beginning registration
03/06/2020 13:13:33.514  INFO [org.apache.flink.runtime.taskexecutor.JobLeaderService] Registration at JobManager attempt 1 (timeout=100ms)
03/06/2020 13:13:33.514 DEBUG [org.apache.flink.runtime.rpc.akka.AkkaRpcService] Try to connect to remote RPC endpoint with address akka://flink/user/taskmanager_2. Returning a org.apache.flink.runtime.taskexecutor.TaskExecutorGateway gateway.
03/06/2020 13:13:33.528 DEBUG [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] Register new TaskExecutor c6dad6c4-5aed-483e-a3f5-af04f31f7b7e.
03/06/2020 13:13:33.528  INFO [org.apache.flink.runtime.taskexecutor.JobLeaderService] Successful registration at job manager akka://flink/user/jobmanager_3 for job cf350677de1d99f7f7ea8e79709c5624.
03/06/2020 13:13:33.529  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutor] Establish JobManager connection for job cf350677de1d99f7f7ea8e79709c5624.
03/06/2020 13:13:33.529  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutor] Offer reserved slots to the leader of job cf350677de1d99f7f7ea8e79709c5624.
03/06/2020 13:13:33.529 DEBUG [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] Fulfilled slot request [SlotRequestId{f1a06e8d90a3a49be59c5acf6026b3b9}] with allocated slot [25d44a59926bde802cdf946b4a6b94f9].
03/06/2020 13:13:33.530 DEBUG [org.apache.flink.runtime.jobmaster.slotpool.SchedulerImpl] Received slot request [SlotRequestId{baaddb941e39015fc75958cf96db7ea6}] for task: null
03/06/2020 13:13:33.530 DEBUG [org.apache.flink.runtime.jobmaster.slotpool.SlotSharingManager] Create single task slot [SlotRequestId{baaddb941e39015fc75958cf96db7ea6}] in multi task slot [SlotRequestId{2d5483855fbf16db71948ed76fba2f43}] for group 57df6b5c78b46bc5e7b8e2b883e729a9.
03/06/2020 13:13:33.530 DEBUG [org.apache.flink.runtime.jobmaster.slotpool.SchedulerImpl] Received slot request [SlotRequestId{ffc5f92c83d4657d4b503145b940f0c5}] for task: null
03/06/2020 13:13:33.530 DEBUG [org.apache.flink.runtime.jobmaster.slotpool.SlotSharingManager] Create single task slot [SlotRequestId{ffc5f92c83d4657d4b503145b940f0c5}] in multi task slot [SlotRequestId{2d5483855fbf16db71948ed76fba2f43}] for group 730748a2d3477923527d4df19c1115d3.
03/06/2020 13:13:33.531 DEBUG [org.apache.flink.runtime.jobmaster.slotpool.SchedulerImpl] Received slot request [SlotRequestId{4a62a318e9191179999911434dc3fc5c}] for task: null
03/06/2020 13:13:33.531 DEBUG [org.apache.flink.runtime.jobmaster.slotpool.SlotSharingManager] Create single task slot [SlotRequestId{4a62a318e9191179999911434dc3fc5c}] in multi task slot [SlotRequestId{ebbdaaa942758fb898f0d9a10e608e2d}] for group 730748a2d3477923527d4df19c1115d3.
03/06/2020 13:13:33.531 DEBUG [org.apache.flink.runtime.jobmaster.slotpool.SchedulerImpl] Received slot request [SlotRequestId{1c74235e018ac0cd39d37b55998d9f28}] for task: null
03/06/2020 13:13:33.531 DEBUG [org.apache.flink.runtime.jobmaster.slotpool.SlotSharingManager] Create single task slot [SlotRequestId{1c74235e018ac0cd39d37b55998d9f28}] in multi task slot [SlotRequestId{2d5483855fbf16db71948ed76fba2f43}] for group db7de5d6d7db9354bd8e4698740f442c.
03/06/2020 13:13:33.531 DEBUG [org.apache.flink.runtime.jobmaster.slotpool.SchedulerImpl] Received slot request [SlotRequestId{ed5773040726a689d7246a379155689b}] for task: null
03/06/2020 13:13:33.532 DEBUG [org.apache.flink.runtime.jobmaster.slotpool.SlotSharingManager] Create single task slot [SlotRequestId{ed5773040726a689d7246a379155689b}] in multi task slot [SlotRequestId{ebbdaaa942758fb898f0d9a10e608e2d}] for group db7de5d6d7db9354bd8e4698740f442c.
03/06/2020 13:13:33.532 DEBUG [org.apache.flink.runtime.jobmaster.slotpool.SchedulerImpl] Received slot request [SlotRequestId{719bbc825339394adb0a2807ab0ddd72}] for task: null
03/06/2020 13:13:33.532 DEBUG [org.apache.flink.runtime.jobmaster.slotpool.SlotSharingManager] Create single task slot [SlotRequestId{719bbc825339394adb0a2807ab0ddd72}] in multi task slot [SlotRequestId{2d5483855fbf16db71948ed76fba2f43}] for group 2da5af51bbd1dbb7a2c205b96fe7a428.
03/06/2020 13:13:33.533 DEBUG [org.apache.flink.runtime.jobmaster.slotpool.SchedulerImpl] Received slot request [SlotRequestId{a0f93d3018c97b5e27c24ef375e98c41}] for task: null
03/06/2020 13:13:33.534 DEBUG [org.apache.flink.runtime.jobmaster.slotpool.SlotSharingManager] Create single task slot [SlotRequestId{a0f93d3018c97b5e27c24ef375e98c41}] in multi task slot [SlotRequestId{ebbdaaa942758fb898f0d9a10e608e2d}] for group 2da5af51bbd1dbb7a2c205b96fe7a428.
03/06/2020 13:13:33.535 DEBUG [org.apache.flink.runtime.jobmaster.slotpool.SchedulerImpl] Received slot request [SlotRequestId{5097399a191037ebd4eca3eeceeece7a}] for task: null
03/06/2020 13:13:33.535 DEBUG [org.apache.flink.runtime.jobmaster.slotpool.SlotSharingManager] Create single task slot [SlotRequestId{5097399a191037ebd4eca3eeceeece7a}] in multi task slot [SlotRequestId{2d5483855fbf16db71948ed76fba2f43}] for group 97062323b8add791924e501dd08b481e.
03/06/2020 13:13:33.536  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] Source: HBaseTableSource[schema=[id, cf], projectFields=null] -> SourceConversion(table=[default_catalog.default_database.loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]], fields=[id, cf]) -> Calc(select=[id, cf, cf.degree AS degree]) (1/2) (b84c3df4861d1ab2874fdf6c2c4b34e1) switched from SCHEDULED to DEPLOYING.
03/06/2020 13:13:33.536  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] Deploying Source: HBaseTableSource[schema=[id, cf], projectFields=null] -> SourceConversion(table=[default_catalog.default_database.loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]], fields=[id, cf]) -> Calc(select=[id, cf, cf.degree AS degree]) (1/2) (attempt #0) to c6dad6c4-5aed-483e-a3f5-af04f31f7b7e @ localhost (dataPort=-1)
03/06/2020 13:13:33.537  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] Source: HBaseTableSource[schema=[id, cf], projectFields=null] -> SourceConversion(table=[default_catalog.default_database.loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]], fields=[id, cf]) -> Calc(select=[id, cf, cf.degree AS degree]) (2/2) (db3aa1938ec63c4d326136e01fb698e5) switched from SCHEDULED to DEPLOYING.
03/06/2020 13:13:33.537  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] Deploying Source: HBaseTableSource[schema=[id, cf], projectFields=null] -> SourceConversion(table=[default_catalog.default_database.loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]], fields=[id, cf]) -> Calc(select=[id, cf, cf.degree AS degree]) (2/2) (attempt #0) to c6dad6c4-5aed-483e-a3f5-af04f31f7b7e @ localhost (dataPort=-1)
03/06/2020 13:13:33.541 DEBUG [org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager] Registered new allocation id 25d44a59926bde802cdf946b4a6b94f9 for local state stores for job cf350677de1d99f7f7ea8e79709c5624.
03/06/2020 13:13:33.542 DEBUG [org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager] Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[/tmp/localState/aid_25d44a59926bde802cdf946b4a6b94f9], jobID=cf350677de1d99f7f7ea8e79709c5624, jobVertexID=cbc357ccb763df2852fee8c4fc7d55f2, subtaskIndex=0}} for cf350677de1d99f7f7ea8e79709c5624 - cbc357ccb763df2852fee8c4fc7d55f2 - 0 under allocation id 25d44a59926bde802cdf946b4a6b94f9.
03/06/2020 13:13:33.542 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionFactory] Source: HBaseTableSource[schema=[id, cf], projectFields=null] -> SourceConversion(table=[default_catalog.default_database.loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]], fields=[id, cf]) -> Calc(select=[id, cf, cf.degree AS degree]) (1/2) (b84c3df4861d1ab2874fdf6c2c4b34e1): Initialized org.apache.flink.runtime.io.network.partition.ResultPartitionFactory@6439c9d7
03/06/2020 13:13:33.547  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] Source: Collection Source -> SourceConversion(table=[Unregistered_DataStream_9], fields=[f0, f1, f2, f3, f4]) -> Calc(select=[f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y]) (1/1) (d74648705093b5c72e78e2c360e29713) switched from SCHEDULED to DEPLOYING.
03/06/2020 13:13:33.552  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] Deploying Source: Collection Source -> SourceConversion(table=[Unregistered_DataStream_9], fields=[f0, f1, f2, f3, f4]) -> Calc(select=[f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y]) (1/1) (attempt #0) to c6dad6c4-5aed-483e-a3f5-af04f31f7b7e @ localhost (dataPort=-1)
03/06/2020 13:13:33.551  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutor] Received task Source: HBaseTableSource[schema=[id, cf], projectFields=null] -> SourceConversion(table=[default_catalog.default_database.loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]], fields=[id, cf]) -> Calc(select=[id, cf, cf.degree AS degree]) (1/2).
03/06/2020 13:13:33.561  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] SortLimit(orderBy=[degree DESC], offset=[0], fetch=[10]) -> Calc(select=[id, cf]) -> SinkConversionToTuple2 (1/1) (876cc1eabe833ca7f87c8793f251f04a) switched from SCHEDULED to DEPLOYING.
03/06/2020 13:13:33.566  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] Deploying SortLimit(orderBy=[degree DESC], offset=[0], fetch=[10]) -> Calc(select=[id, cf]) -> SinkConversionToTuple2 (1/1) (attempt #0) to c6dad6c4-5aed-483e-a3f5-af04f31f7b7e @ localhost (dataPort=-1)
03/06/2020 13:13:33.572  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (1/2) (4d7a1b8b380293c90670ee95c08224e0) switched from SCHEDULED to DEPLOYING.
03/06/2020 13:13:33.574  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] Deploying Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (1/2) (attempt #0) to c6dad6c4-5aed-483e-a3f5-af04f31f7b7e @ localhost (dataPort=-1)
03/06/2020 13:13:33.575  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (2/2) (c365017ac85c61dc4f885a5155f06f1e) switched from SCHEDULED to DEPLOYING.
03/06/2020 13:13:33.577  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] Deploying Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (2/2) (attempt #0) to c6dad6c4-5aed-483e-a3f5-af04f31f7b7e @ localhost (dataPort=-1)
03/06/2020 13:13:33.577  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (1/2) (02de6f076d7957e472f6eb0edbd38dbf) switched from SCHEDULED to DEPLOYING.
03/06/2020 13:13:33.577  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] Deploying GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (1/2) (attempt #0) to c6dad6c4-5aed-483e-a3f5-af04f31f7b7e @ localhost (dataPort=-1)
03/06/2020 13:13:33.580 DEBUG [org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager] Registered new allocation id 72c915e615c4f2f98aedf5eb10885367 for local state stores for job cf350677de1d99f7f7ea8e79709c5624.
03/06/2020 13:13:33.581 DEBUG [org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager] Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[/tmp/localState/aid_72c915e615c4f2f98aedf5eb10885367], jobID=cf350677de1d99f7f7ea8e79709c5624, jobVertexID=cbc357ccb763df2852fee8c4fc7d55f2, subtaskIndex=1}} for cf350677de1d99f7f7ea8e79709c5624 - cbc357ccb763df2852fee8c4fc7d55f2 - 1 under allocation id 72c915e615c4f2f98aedf5eb10885367.
03/06/2020 13:13:33.581 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionFactory] Source: HBaseTableSource[schema=[id, cf], projectFields=null] -> SourceConversion(table=[default_catalog.default_database.loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]], fields=[id, cf]) -> Calc(select=[id, cf, cf.degree AS degree]) (2/2) (db3aa1938ec63c4d326136e01fb698e5): Initialized org.apache.flink.runtime.io.network.partition.ResultPartitionFactory@6439c9d7
03/06/2020 13:13:33.581  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutor] Received task Source: HBaseTableSource[schema=[id, cf], projectFields=null] -> SourceConversion(table=[default_catalog.default_database.loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]], fields=[id, cf]) -> Calc(select=[id, cf, cf.degree AS degree]) (2/2).
03/06/2020 13:13:33.583  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (2/2) (1ff6ef243e2fa7b8aa3f13605b545e75) switched from SCHEDULED to DEPLOYING.
03/06/2020 13:13:33.584  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] Deploying GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (2/2) (attempt #0) to c6dad6c4-5aed-483e-a3f5-af04f31f7b7e @ localhost (dataPort=-1)
03/06/2020 13:13:33.584  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (1/2) (6dfb6ce5559aca85d7e81c96224f4864) switched from SCHEDULED to DEPLOYING.
03/06/2020 13:13:33.584  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] Deploying Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (1/2) (attempt #0) to c6dad6c4-5aed-483e-a3f5-af04f31f7b7e @ localhost (dataPort=-1)
03/06/2020 13:13:33.584  INFO [org.apache.flink.runtime.taskmanager.Task] Source: HBaseTableSource[schema=[id, cf], projectFields=null] -> SourceConversion(table=[default_catalog.default_database.loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]], fields=[id, cf]) -> Calc(select=[id, cf, cf.degree AS degree]) (1/2) (b84c3df4861d1ab2874fdf6c2c4b34e1) switched from CREATED to DEPLOYING.
03/06/2020 13:13:33.585  INFO [org.apache.flink.runtime.taskmanager.Task] Creating FileSystem stream leak safety net for task Source: HBaseTableSource[schema=[id, cf], projectFields=null] -> SourceConversion(table=[default_catalog.default_database.loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]], fields=[id, cf]) -> Calc(select=[id, cf, cf.degree AS degree]) (1/2) (b84c3df4861d1ab2874fdf6c2c4b34e1) [DEPLOYING]
03/06/2020 13:13:33.588  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (2/2) (27eb9406de3597496fd0bb48c5e876a5) switched from SCHEDULED to DEPLOYING.
03/06/2020 13:13:33.588  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] Deploying Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (2/2) (attempt #0) to c6dad6c4-5aed-483e-a3f5-af04f31f7b7e @ localhost (dataPort=-1)
03/06/2020 13:13:33.589  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] Sink: Print to Std. Out (1/1) (26e0302ddaecd3150ec5345d3906b102) switched from SCHEDULED to DEPLOYING.
03/06/2020 13:13:33.590  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] Deploying Sink: Print to Std. Out (1/1) (attempt #0) to c6dad6c4-5aed-483e-a3f5-af04f31f7b7e @ localhost (dataPort=-1)
03/06/2020 13:13:33.589  INFO [org.apache.flink.runtime.taskmanager.Task] Loading JAR files for task Source: HBaseTableSource[schema=[id, cf], projectFields=null] -> SourceConversion(table=[default_catalog.default_database.loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]], fields=[id, cf]) -> Calc(select=[id, cf, cf.degree AS degree]) (1/2) (b84c3df4861d1ab2874fdf6c2c4b34e1) [DEPLOYING].
03/06/2020 13:13:33.591 DEBUG [org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager] Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[/tmp/localState/aid_72c915e615c4f2f98aedf5eb10885367], jobID=cf350677de1d99f7f7ea8e79709c5624, jobVertexID=6cdc5bb954874d922eaee11a8e7b5dd5, subtaskIndex=0}} for cf350677de1d99f7f7ea8e79709c5624 - 6cdc5bb954874d922eaee11a8e7b5dd5 - 0 under allocation id 72c915e615c4f2f98aedf5eb10885367.
03/06/2020 13:13:33.592 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionFactory] Source: Collection Source -> SourceConversion(table=[Unregistered_DataStream_9], fields=[f0, f1, f2, f3, f4]) -> Calc(select=[f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y]) (1/1) (d74648705093b5c72e78e2c360e29713): Initialized org.apache.flink.runtime.io.network.partition.ResultPartitionFactory@6439c9d7
03/06/2020 13:13:33.592  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutor] Received task Source: Collection Source -> SourceConversion(table=[Unregistered_DataStream_9], fields=[f0, f1, f2, f3, f4]) -> Calc(select=[f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y]) (1/1).
03/06/2020 13:13:33.591  INFO [org.apache.flink.runtime.taskmanager.Task] Source: HBaseTableSource[schema=[id, cf], projectFields=null] -> SourceConversion(table=[default_catalog.default_database.loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]], fields=[id, cf]) -> Calc(select=[id, cf, cf.degree AS degree]) (2/2) (db3aa1938ec63c4d326136e01fb698e5) switched from CREATED to DEPLOYING.
03/06/2020 13:13:33.591 DEBUG [org.apache.flink.runtime.taskmanager.Task] Getting user code class loader for task b84c3df4861d1ab2874fdf6c2c4b34e1 at library cache manager took 0 milliseconds
03/06/2020 13:13:33.593  INFO [org.apache.flink.runtime.taskmanager.Task] Creating FileSystem stream leak safety net for task Source: HBaseTableSource[schema=[id, cf], projectFields=null] -> SourceConversion(table=[default_catalog.default_database.loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]], fields=[id, cf]) -> Calc(select=[id, cf, cf.degree AS degree]) (2/2) (db3aa1938ec63c4d326136e01fb698e5) [DEPLOYING]
03/06/2020 13:13:33.593  INFO [org.apache.flink.runtime.taskmanager.Task] Registering task at network: Source: HBaseTableSource[schema=[id, cf], projectFields=null] -> SourceConversion(table=[default_catalog.default_database.loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]], fields=[id, cf]) -> Calc(select=[id, cf, cf.degree AS degree]) (1/2) (b84c3df4861d1ab2874fdf6c2c4b34e1) [DEPLOYING].
03/06/2020 13:13:33.593 DEBUG [org.apache.flink.runtime.io.network.buffer.LocalBufferPool] Using a local buffer pool with 2-10 buffers
03/06/2020 13:13:33.593 DEBUG [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] Fulfilled slot request [SlotRequestId{2441ab0ac753774db5fa5db436e75215}] with allocated slot [72c915e615c4f2f98aedf5eb10885367].
03/06/2020 13:13:33.593 DEBUG [org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager] Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[/tmp/localState/aid_25d44a59926bde802cdf946b4a6b94f9], jobID=cf350677de1d99f7f7ea8e79709c5624, jobVertexID=57df6b5c78b46bc5e7b8e2b883e729a9, subtaskIndex=0}} for cf350677de1d99f7f7ea8e79709c5624 - 57df6b5c78b46bc5e7b8e2b883e729a9 - 0 under allocation id 25d44a59926bde802cdf946b4a6b94f9.
03/06/2020 13:13:33.599 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionManager] Registered ReleaseOnConsumptionResultPartition 7e12330857e44344bfe04391907a4449@b84c3df4861d1ab2874fdf6c2c4b34e1 [PIPELINED_BOUNDED, 1 subpartitions, 1 pending consumptions].
03/06/2020 13:13:33.600 DEBUG [org.apache.flink.runtime.io.network.TaskEventDispatcher] registering 7e12330857e44344bfe04391907a4449@b84c3df4861d1ab2874fdf6c2c4b34e1
03/06/2020 13:13:33.597  INFO [org.apache.flink.runtime.taskmanager.Task] Loading JAR files for task Source: HBaseTableSource[schema=[id, cf], projectFields=null] -> SourceConversion(table=[default_catalog.default_database.loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]], fields=[id, cf]) -> Calc(select=[id, cf, cf.degree AS degree]) (2/2) (db3aa1938ec63c4d326136e01fb698e5) [DEPLOYING].
03/06/2020 13:13:33.600 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionFactory] SortLimit(orderBy=[degree DESC], offset=[0], fetch=[10]) -> Calc(select=[id, cf]) -> SinkConversionToTuple2 (1/1) (876cc1eabe833ca7f87c8793f251f04a): Initialized org.apache.flink.runtime.io.network.partition.ResultPartitionFactory@6439c9d7
03/06/2020 13:13:33.600 DEBUG [org.apache.flink.runtime.io.network.partition.consumer.SingleInputGateFactory] SortLimit(orderBy=[degree DESC], offset=[0], fetch=[10]) -> Calc(select=[id, cf]) -> SinkConversionToTuple2 (1/1) (876cc1eabe833ca7f87c8793f251f04a): Created 2 input channels (local: 2, remote: 0, unknown: 0).
03/06/2020 13:13:33.601  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutor] Received task SortLimit(orderBy=[degree DESC], offset=[0], fetch=[10]) -> Calc(select=[id, cf]) -> SinkConversionToTuple2 (1/1).
03/06/2020 13:13:33.602 DEBUG [org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager] Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[/tmp/localState/aid_72c915e615c4f2f98aedf5eb10885367], jobID=cf350677de1d99f7f7ea8e79709c5624, jobVertexID=730748a2d3477923527d4df19c1115d3, subtaskIndex=0}} for cf350677de1d99f7f7ea8e79709c5624 - 730748a2d3477923527d4df19c1115d3 - 0 under allocation id 72c915e615c4f2f98aedf5eb10885367.
03/06/2020 13:13:33.602 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionFactory] Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (1/2) (4d7a1b8b380293c90670ee95c08224e0): Initialized org.apache.flink.runtime.io.network.partition.ResultPartitionFactory@6439c9d7
03/06/2020 13:13:33.603 DEBUG [org.apache.flink.runtime.io.network.partition.consumer.SingleInputGateFactory] Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (1/2) (4d7a1b8b380293c90670ee95c08224e0): Created 1 input channels (local: 1, remote: 0, unknown: 0).
03/06/2020 13:13:33.603  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutor] Received task Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (1/2).
03/06/2020 13:13:33.603  INFO [org.apache.flink.runtime.taskmanager.Task] SortLimit(orderBy=[degree DESC], offset=[0], fetch=[10]) -> Calc(select=[id, cf]) -> SinkConversionToTuple2 (1/1) (876cc1eabe833ca7f87c8793f251f04a) switched from CREATED to DEPLOYING.
03/06/2020 13:13:33.600 DEBUG [org.apache.flink.runtime.taskmanager.Task] Getting user code class loader for task db3aa1938ec63c4d326136e01fb698e5 at library cache manager took 0 milliseconds
03/06/2020 13:13:33.604  INFO [org.apache.flink.runtime.taskmanager.Task] Registering task at network: Source: HBaseTableSource[schema=[id, cf], projectFields=null] -> SourceConversion(table=[default_catalog.default_database.loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]], fields=[id, cf]) -> Calc(select=[id, cf, cf.degree AS degree]) (2/2) (db3aa1938ec63c4d326136e01fb698e5) [DEPLOYING].
03/06/2020 13:13:33.605 DEBUG [org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager] Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[/tmp/localState/aid_25d44a59926bde802cdf946b4a6b94f9], jobID=cf350677de1d99f7f7ea8e79709c5624, jobVertexID=730748a2d3477923527d4df19c1115d3, subtaskIndex=1}} for cf350677de1d99f7f7ea8e79709c5624 - 730748a2d3477923527d4df19c1115d3 - 1 under allocation id 25d44a59926bde802cdf946b4a6b94f9.
03/06/2020 13:13:33.605 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionFactory] Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (2/2) (c365017ac85c61dc4f885a5155f06f1e): Initialized org.apache.flink.runtime.io.network.partition.ResultPartitionFactory@6439c9d7
03/06/2020 13:13:33.607 DEBUG [org.apache.flink.runtime.io.network.partition.consumer.SingleInputGateFactory] Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (2/2) (c365017ac85c61dc4f885a5155f06f1e): Created 1 input channels (local: 1, remote: 0, unknown: 0).
03/06/2020 13:13:33.608  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutor] Received task Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (2/2).
03/06/2020 13:13:33.604  INFO [org.apache.flink.runtime.taskmanager.Task] Creating FileSystem stream leak safety net for task SortLimit(orderBy=[degree DESC], offset=[0], fetch=[10]) -> Calc(select=[id, cf]) -> SinkConversionToTuple2 (1/1) (876cc1eabe833ca7f87c8793f251f04a) [DEPLOYING]
03/06/2020 13:13:33.608  INFO [org.apache.flink.runtime.taskmanager.Task] Loading JAR files for task SortLimit(orderBy=[degree DESC], offset=[0], fetch=[10]) -> Calc(select=[id, cf]) -> SinkConversionToTuple2 (1/1) (876cc1eabe833ca7f87c8793f251f04a) [DEPLOYING].
03/06/2020 13:13:33.608 DEBUG [org.apache.flink.runtime.taskmanager.Task] Getting user code class loader for task 876cc1eabe833ca7f87c8793f251f04a at library cache manager took 0 milliseconds
03/06/2020 13:13:33.605 DEBUG [org.apache.flink.runtime.io.network.buffer.LocalBufferPool] Using a local buffer pool with 2-10 buffers
03/06/2020 13:13:33.609  INFO [org.apache.flink.runtime.taskmanager.Task] Registering task at network: SortLimit(orderBy=[degree DESC], offset=[0], fetch=[10]) -> Calc(select=[id, cf]) -> SinkConversionToTuple2 (1/1) (876cc1eabe833ca7f87c8793f251f04a) [DEPLOYING].
03/06/2020 13:13:33.609  INFO [org.apache.flink.runtime.taskmanager.Task] Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (1/2) (4d7a1b8b380293c90670ee95c08224e0) switched from CREATED to DEPLOYING.
03/06/2020 13:13:33.609  INFO [org.apache.flink.runtime.taskmanager.Task] Creating FileSystem stream leak safety net for task Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (1/2) (4d7a1b8b380293c90670ee95c08224e0) [DEPLOYING]
03/06/2020 13:13:33.609  INFO [org.apache.flink.runtime.taskmanager.Task] Loading JAR files for task Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (1/2) (4d7a1b8b380293c90670ee95c08224e0) [DEPLOYING].
03/06/2020 13:13:33.609 DEBUG [org.apache.flink.runtime.taskmanager.Task] Getting user code class loader for task 4d7a1b8b380293c90670ee95c08224e0 at library cache manager took 0 milliseconds
03/06/2020 13:13:33.610  INFO [org.apache.flink.runtime.taskmanager.Task] Registering task at network: Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (1/2) (4d7a1b8b380293c90670ee95c08224e0) [DEPLOYING].
03/06/2020 13:13:33.611 DEBUG [org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager] Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[/tmp/localState/aid_72c915e615c4f2f98aedf5eb10885367], jobID=cf350677de1d99f7f7ea8e79709c5624, jobVertexID=db7de5d6d7db9354bd8e4698740f442c, subtaskIndex=0}} for cf350677de1d99f7f7ea8e79709c5624 - db7de5d6d7db9354bd8e4698740f442c - 0 under allocation id 72c915e615c4f2f98aedf5eb10885367.
03/06/2020 13:13:33.611 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionFactory] GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (1/2) (02de6f076d7957e472f6eb0edbd38dbf): Initialized org.apache.flink.runtime.io.network.partition.ResultPartitionFactory@6439c9d7
03/06/2020 13:13:33.611 DEBUG [org.apache.flink.runtime.io.network.partition.consumer.SingleInputGateFactory] GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (1/2) (02de6f076d7957e472f6eb0edbd38dbf): Created 2 input channels (local: 2, remote: 0, unknown: 0).
03/06/2020 13:13:33.611  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutor] Received task GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (1/2).
03/06/2020 13:13:33.612  INFO [org.apache.flink.runtime.taskmanager.Task] Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (2/2) (c365017ac85c61dc4f885a5155f06f1e) switched from CREATED to DEPLOYING.
03/06/2020 13:13:33.612  INFO [org.apache.flink.runtime.taskmanager.Task] Creating FileSystem stream leak safety net for task Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (2/2) (c365017ac85c61dc4f885a5155f06f1e) [DEPLOYING]
03/06/2020 13:13:33.612  INFO [org.apache.flink.runtime.taskmanager.Task] Loading JAR files for task Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (2/2) (c365017ac85c61dc4f885a5155f06f1e) [DEPLOYING].
03/06/2020 13:13:33.612 DEBUG [org.apache.flink.runtime.taskmanager.Task] Getting user code class loader for task c365017ac85c61dc4f885a5155f06f1e at library cache manager took 0 milliseconds
03/06/2020 13:13:33.613  INFO [org.apache.flink.runtime.taskmanager.Task] Registering task at network: Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (2/2) (c365017ac85c61dc4f885a5155f06f1e) [DEPLOYING].
03/06/2020 13:13:33.614 DEBUG [org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager] Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[/tmp/localState/aid_25d44a59926bde802cdf946b4a6b94f9], jobID=cf350677de1d99f7f7ea8e79709c5624, jobVertexID=db7de5d6d7db9354bd8e4698740f442c, subtaskIndex=1}} for cf350677de1d99f7f7ea8e79709c5624 - db7de5d6d7db9354bd8e4698740f442c - 1 under allocation id 25d44a59926bde802cdf946b4a6b94f9.
03/06/2020 13:13:33.614 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionFactory] GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (2/2) (1ff6ef243e2fa7b8aa3f13605b545e75): Initialized org.apache.flink.runtime.io.network.partition.ResultPartitionFactory@6439c9d7
03/06/2020 13:13:33.614 DEBUG [org.apache.flink.runtime.io.network.partition.consumer.SingleInputGateFactory] GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (2/2) (1ff6ef243e2fa7b8aa3f13605b545e75): Created 2 input channels (local: 2, remote: 0, unknown: 0).
03/06/2020 13:13:33.614  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutor] Received task GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (2/2).
03/06/2020 13:13:33.615  INFO [org.apache.flink.runtime.taskmanager.Task] GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (1/2) (02de6f076d7957e472f6eb0edbd38dbf) switched from CREATED to DEPLOYING.
03/06/2020 13:13:33.615  INFO [org.apache.flink.runtime.taskmanager.Task] Creating FileSystem stream leak safety net for task GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (1/2) (02de6f076d7957e472f6eb0edbd38dbf) [DEPLOYING]
03/06/2020 13:13:33.615  INFO [org.apache.flink.runtime.taskmanager.Task] Loading JAR files for task GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (1/2) (02de6f076d7957e472f6eb0edbd38dbf) [DEPLOYING].
03/06/2020 13:13:33.615 DEBUG [org.apache.flink.runtime.taskmanager.Task] Getting user code class loader for task 02de6f076d7957e472f6eb0edbd38dbf at library cache manager took 0 milliseconds
03/06/2020 13:13:33.616  INFO [org.apache.flink.runtime.taskmanager.Task] Registering task at network: GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (1/2) (02de6f076d7957e472f6eb0edbd38dbf) [DEPLOYING].
03/06/2020 13:13:33.616  INFO [org.apache.flink.runtime.taskmanager.Task] Source: Collection Source -> SourceConversion(table=[Unregistered_DataStream_9], fields=[f0, f1, f2, f3, f4]) -> Calc(select=[f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y]) (1/1) (d74648705093b5c72e78e2c360e29713) switched from CREATED to DEPLOYING.
03/06/2020 13:13:33.617  INFO [org.apache.flink.runtime.taskmanager.Task] Creating FileSystem stream leak safety net for task Source: Collection Source -> SourceConversion(table=[Unregistered_DataStream_9], fields=[f0, f1, f2, f3, f4]) -> Calc(select=[f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y]) (1/1) (d74648705093b5c72e78e2c360e29713) [DEPLOYING]
03/06/2020 13:13:33.620 DEBUG [org.apache.flink.runtime.io.network.buffer.LocalBufferPool] Using a local buffer pool with 3-12 buffers
03/06/2020 13:13:33.618 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionManager] Registered ReleaseOnConsumptionResultPartition 161687556e7759506bc9efabc0bcde87@db3aa1938ec63c4d326136e01fb698e5 [PIPELINED_BOUNDED, 1 subpartitions, 1 pending consumptions].
03/06/2020 13:13:33.618 DEBUG [org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager] Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[/tmp/localState/aid_72c915e615c4f2f98aedf5eb10885367], jobID=cf350677de1d99f7f7ea8e79709c5624, jobVertexID=2da5af51bbd1dbb7a2c205b96fe7a428, subtaskIndex=0}} for cf350677de1d99f7f7ea8e79709c5624 - 2da5af51bbd1dbb7a2c205b96fe7a428 - 0 under allocation id 72c915e615c4f2f98aedf5eb10885367.
03/06/2020 13:13:33.626 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionManager] Registered ReleaseOnConsumptionResultPartition f45f0539b91a35f8f33f7e0d2d64813c@02de6f076d7957e472f6eb0edbd38dbf [PIPELINED_BOUNDED, 2 subpartitions, 2 pending consumptions].
03/06/2020 13:13:33.626  INFO [org.apache.flink.runtime.taskmanager.Task] GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (2/2) (1ff6ef243e2fa7b8aa3f13605b545e75) switched from CREATED to DEPLOYING.
03/06/2020 13:13:33.626 DEBUG [org.apache.flink.runtime.io.network.TaskEventDispatcher] registering 161687556e7759506bc9efabc0bcde87@db3aa1938ec63c4d326136e01fb698e5
03/06/2020 13:13:33.625 DEBUG [org.apache.flink.runtime.io.network.buffer.LocalBufferPool] Using a local buffer pool with 3-12 buffers
03/06/2020 13:13:33.620  INFO [org.apache.flink.runtime.taskmanager.Task] Loading JAR files for task Source: Collection Source -> SourceConversion(table=[Unregistered_DataStream_9], fields=[f0, f1, f2, f3, f4]) -> Calc(select=[f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y]) (1/1) (d74648705093b5c72e78e2c360e29713) [DEPLOYING].
03/06/2020 13:13:33.629 DEBUG [org.apache.flink.runtime.taskmanager.Task] Getting user code class loader for task d74648705093b5c72e78e2c360e29713 at library cache manager took 0 milliseconds
03/06/2020 13:13:33.629  INFO [org.apache.flink.runtime.taskmanager.Task] Registering task at network: Source: Collection Source -> SourceConversion(table=[Unregistered_DataStream_9], fields=[f0, f1, f2, f3, f4]) -> Calc(select=[f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y]) (1/1) (d74648705093b5c72e78e2c360e29713) [DEPLOYING].
03/06/2020 13:13:33.629  INFO [org.apache.flink.runtime.taskmanager.Task] Creating FileSystem stream leak safety net for task GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (2/2) (1ff6ef243e2fa7b8aa3f13605b545e75) [DEPLOYING]
03/06/2020 13:13:33.629 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionManager] Registered ReleaseOnConsumptionResultPartition 0ba5902cc0427ce26c3f0693bdc93d05@c365017ac85c61dc4f885a5155f06f1e [PIPELINED_BOUNDED, 2 subpartitions, 2 pending consumptions].
03/06/2020 13:13:33.629 DEBUG [org.apache.flink.runtime.io.network.buffer.LocalBufferPool] Using a local buffer pool with 3-12 buffers
03/06/2020 13:13:33.626 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionFactory] Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (1/2) (6dfb6ce5559aca85d7e81c96224f4864): Initialized org.apache.flink.runtime.io.network.partition.ResultPartitionFactory@6439c9d7
03/06/2020 13:13:33.631 DEBUG [org.apache.flink.runtime.io.network.buffer.LocalBufferPool] Using a local buffer pool with 3-12 buffers
03/06/2020 13:13:33.630 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionManager] Registered ReleaseOnConsumptionResultPartition 4bd09e894d9b0e6c6119f756bfe2ba7c@4d7a1b8b380293c90670ee95c08224e0 [PIPELINED_BOUNDED, 2 subpartitions, 2 pending consumptions].
03/06/2020 13:13:33.631 DEBUG [org.apache.flink.runtime.io.network.partition.consumer.SingleInputGateFactory] Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (1/2) (6dfb6ce5559aca85d7e81c96224f4864): Created 2 input channels (local: 2, remote: 0, unknown: 0).
03/06/2020 13:13:33.636 DEBUG [org.apache.flink.runtime.io.network.partition.consumer.SingleInputGateFactory] Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (1/2) (6dfb6ce5559aca85d7e81c96224f4864): Created 1 input channels (local: 1, remote: 0, unknown: 0).
03/06/2020 13:13:33.636  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutor] Received task Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (1/2).
03/06/2020 13:13:33.630  INFO [org.apache.flink.runtime.taskmanager.Task] Loading JAR files for task GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (2/2) (1ff6ef243e2fa7b8aa3f13605b545e75) [DEPLOYING].
03/06/2020 13:13:33.632 DEBUG [org.apache.flink.runtime.io.network.buffer.LocalBufferPool] Using a local buffer pool with 0-8 buffers
03/06/2020 13:13:33.631 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionManager] Registered ReleaseOnConsumptionResultPartition 657d9fa3c3c42c8c21b0407ee1e3a770@876cc1eabe833ca7f87c8793f251f04a [PIPELINED_BOUNDED, 2 subpartitions, 2 pending consumptions].
03/06/2020 13:13:33.641 DEBUG [org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel] LocalInputChannel [657d9fa3c3c42c8c21b0407ee1e3a770@876cc1eabe833ca7f87c8793f251f04a]: Requesting LOCAL subpartition 0 of partition 657d9fa3c3c42c8c21b0407ee1e3a770@876cc1eabe833ca7f87c8793f251f04a.
03/06/2020 13:13:33.641 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionManager] Requesting subpartition 0 of ReleaseOnConsumptionResultPartition 657d9fa3c3c42c8c21b0407ee1e3a770@876cc1eabe833ca7f87c8793f251f04a [PIPELINED_BOUNDED, 2 subpartitions, 2 pending consumptions].
03/06/2020 13:13:33.641 DEBUG [org.apache.flink.runtime.io.network.partition.PipelinedSubpartition] SortLimit(orderBy=[degree DESC], offset=[0], fetch=[10]) -> Calc(select=[id, cf]) -> SinkConversionToTuple2 (1/1) (876cc1eabe833ca7f87c8793f251f04a): Creating read view for subpartition 0 of partition 657d9fa3c3c42c8c21b0407ee1e3a770@876cc1eabe833ca7f87c8793f251f04a.
03/06/2020 13:13:33.641 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartition] Created PipelinedSubpartitionView(index: 0) of ResultPartition 657d9fa3c3c42c8c21b0407ee1e3a770@876cc1eabe833ca7f87c8793f251f04a
03/06/2020 13:13:33.641 DEBUG [org.apache.flink.runtime.io.network.TaskEventDispatcher] registering 4bd09e894d9b0e6c6119f756bfe2ba7c@4d7a1b8b380293c90670ee95c08224e0
03/06/2020 13:13:33.642 DEBUG [org.apache.flink.runtime.io.network.buffer.LocalBufferPool] Using a local buffer pool with 0-8 buffers
03/06/2020 13:13:33.643 DEBUG [org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel] LocalInputChannel [657d9fa3c3c42c8c21b0407ee1e3a770@876cc1eabe833ca7f87c8793f251f04a]: Requesting LOCAL subpartition 1 of partition 657d9fa3c3c42c8c21b0407ee1e3a770@876cc1eabe833ca7f87c8793f251f04a.
03/06/2020 13:13:33.643 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionManager] Requesting subpartition 1 of ReleaseOnConsumptionResultPartition 657d9fa3c3c42c8c21b0407ee1e3a770@876cc1eabe833ca7f87c8793f251f04a [PIPELINED_BOUNDED, 2 subpartitions, 2 pending consumptions].
03/06/2020 13:13:33.644 DEBUG [org.apache.flink.runtime.io.network.partition.PipelinedSubpartition] SortLimit(orderBy=[degree DESC], offset=[0], fetch=[10]) -> Calc(select=[id, cf]) -> SinkConversionToTuple2 (1/1) (876cc1eabe833ca7f87c8793f251f04a): Creating read view for subpartition 1 of partition 657d9fa3c3c42c8c21b0407ee1e3a770@876cc1eabe833ca7f87c8793f251f04a.
03/06/2020 13:13:33.643 DEBUG [org.apache.flink.runtime.io.network.buffer.LocalBufferPool] Using a local buffer pool with 3-12 buffers
03/06/2020 13:13:33.644 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartition] Created PipelinedSubpartitionView(index: 1) of ResultPartition 657d9fa3c3c42c8c21b0407ee1e3a770@876cc1eabe833ca7f87c8793f251f04a
03/06/2020 13:13:33.644 DEBUG [org.apache.flink.runtime.io.network.TaskEventDispatcher] registering 0ba5902cc0427ce26c3f0693bdc93d05@c365017ac85c61dc4f885a5155f06f1e
03/06/2020 13:13:33.645 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionManager] Registered ReleaseOnConsumptionResultPartition 152d67b39c04e64fe5971bb597eb96e2@d74648705093b5c72e78e2c360e29713 [PIPELINED_BOUNDED, 2 subpartitions, 2 pending consumptions].
03/06/2020 13:13:33.645 DEBUG [org.apache.flink.runtime.io.network.TaskEventDispatcher] registering 152d67b39c04e64fe5971bb597eb96e2@d74648705093b5c72e78e2c360e29713
03/06/2020 13:13:33.645 DEBUG [org.apache.flink.runtime.io.network.buffer.LocalBufferPool] Using a local buffer pool with 0-8 buffers
03/06/2020 13:13:33.647 DEBUG [org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager] Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[/tmp/localState/aid_25d44a59926bde802cdf946b4a6b94f9], jobID=cf350677de1d99f7f7ea8e79709c5624, jobVertexID=2da5af51bbd1dbb7a2c205b96fe7a428, subtaskIndex=1}} for cf350677de1d99f7f7ea8e79709c5624 - 2da5af51bbd1dbb7a2c205b96fe7a428 - 1 under allocation id 25d44a59926bde802cdf946b4a6b94f9.
03/06/2020 13:13:33.648 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionFactory] Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (2/2) (27eb9406de3597496fd0bb48c5e876a5): Initialized org.apache.flink.runtime.io.network.partition.ResultPartitionFactory@6439c9d7
03/06/2020 13:13:33.648 DEBUG [org.apache.flink.runtime.io.network.partition.consumer.SingleInputGateFactory] Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (2/2) (27eb9406de3597496fd0bb48c5e876a5): Created 2 input channels (local: 2, remote: 0, unknown: 0).
03/06/2020 13:13:33.648 DEBUG [org.apache.flink.runtime.io.network.partition.consumer.SingleInputGateFactory] Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (2/2) (27eb9406de3597496fd0bb48c5e876a5): Created 1 input channels (local: 1, remote: 0, unknown: 0).
03/06/2020 13:13:33.648  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutor] Received task Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (2/2).
03/06/2020 13:13:33.649  INFO [org.apache.flink.runtime.taskmanager.Task] Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (2/2) (27eb9406de3597496fd0bb48c5e876a5) switched from CREATED to DEPLOYING.
03/06/2020 13:13:33.656 DEBUG [org.apache.flink.streaming.runtime.tasks.StreamTask] Using partitioner HASH for output 0 of task Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree])
03/06/2020 13:13:33.655 DEBUG [org.apache.flink.streaming.runtime.tasks.StreamTask] Using partitioner HASH for output 0 of task Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree])
03/06/2020 13:13:33.653 DEBUG [org.apache.flink.streaming.runtime.tasks.StreamTask] Using partitioner GLOBAL for output 0 of task Source: HBaseTableSource[schema=[id, cf], projectFields=null] -> SourceConversion(table=[default_catalog.default_database.loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]], fields=[id, cf]) -> Calc(select=[id, cf, cf.degree AS degree])
03/06/2020 13:13:33.652 DEBUG [org.apache.flink.streaming.runtime.tasks.StreamTask] Using partitioner HASH for output 0 of task Source: Collection Source -> SourceConversion(table=[Unregistered_DataStream_9], fields=[f0, f1, f2, f3, f4]) -> Calc(select=[f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y])
03/06/2020 13:13:33.652 DEBUG [org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager] Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[/tmp/localState/aid_25d44a59926bde802cdf946b4a6b94f9], jobID=cf350677de1d99f7f7ea8e79709c5624, jobVertexID=97062323b8add791924e501dd08b481e, subtaskIndex=0}} for cf350677de1d99f7f7ea8e79709c5624 - 97062323b8add791924e501dd08b481e - 0 under allocation id 25d44a59926bde802cdf946b4a6b94f9.
03/06/2020 13:13:33.664 DEBUG [org.apache.flink.runtime.io.network.partition.consumer.SingleInputGateFactory] Sink: Print to Std. Out (1/1) (26e0302ddaecd3150ec5345d3906b102): Created 2 input channels (local: 2, remote: 0, unknown: 0).
03/06/2020 13:13:33.651 DEBUG [org.apache.flink.runtime.io.network.buffer.LocalBufferPool] Using a local buffer pool with 0-8 buffers
03/06/2020 13:13:33.651 DEBUG [org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel] LocalInputChannel [0ba5902cc0427ce26c3f0693bdc93d05@c365017ac85c61dc4f885a5155f06f1e]: Requesting LOCAL subpartition 0 of partition 0ba5902cc0427ce26c3f0693bdc93d05@c365017ac85c61dc4f885a5155f06f1e.
03/06/2020 13:13:33.665 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionManager] Requesting subpartition 0 of ReleaseOnConsumptionResultPartition 0ba5902cc0427ce26c3f0693bdc93d05@c365017ac85c61dc4f885a5155f06f1e [PIPELINED_BOUNDED, 2 subpartitions, 2 pending consumptions].
03/06/2020 13:13:33.666 DEBUG [org.apache.flink.runtime.io.network.partition.PipelinedSubpartition] Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (2/2) (c365017ac85c61dc4f885a5155f06f1e): Creating read view for subpartition 0 of partition 0ba5902cc0427ce26c3f0693bdc93d05@c365017ac85c61dc4f885a5155f06f1e.
03/06/2020 13:13:33.666 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartition] Created PipelinedSubpartitionView(index: 0) of ResultPartition 0ba5902cc0427ce26c3f0693bdc93d05@c365017ac85c61dc4f885a5155f06f1e
03/06/2020 13:13:33.666 DEBUG [org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel] LocalInputChannel [4bd09e894d9b0e6c6119f756bfe2ba7c@4d7a1b8b380293c90670ee95c08224e0]: Requesting LOCAL subpartition 0 of partition 4bd09e894d9b0e6c6119f756bfe2ba7c@4d7a1b8b380293c90670ee95c08224e0.
03/06/2020 13:13:33.666 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionManager] Requesting subpartition 0 of ReleaseOnConsumptionResultPartition 4bd09e894d9b0e6c6119f756bfe2ba7c@4d7a1b8b380293c90670ee95c08224e0 [PIPELINED_BOUNDED, 2 subpartitions, 2 pending consumptions].
03/06/2020 13:13:33.666 DEBUG [org.apache.flink.runtime.io.network.partition.PipelinedSubpartition] Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (1/2) (4d7a1b8b380293c90670ee95c08224e0): Creating read view for subpartition 0 of partition 4bd09e894d9b0e6c6119f756bfe2ba7c@4d7a1b8b380293c90670ee95c08224e0.
03/06/2020 13:13:33.666 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartition] Created PipelinedSubpartitionView(index: 0) of ResultPartition 4bd09e894d9b0e6c6119f756bfe2ba7c@4d7a1b8b380293c90670ee95c08224e0
03/06/2020 13:13:33.666 DEBUG [org.apache.flink.runtime.io.network.TaskEventDispatcher] registering f45f0539b91a35f8f33f7e0d2d64813c@02de6f076d7957e472f6eb0edbd38dbf
03/06/2020 13:13:33.668 DEBUG [org.apache.flink.streaming.runtime.tasks.StreamTask] Using partitioner HASH for output 0 of task GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')])
03/06/2020 13:13:33.650 DEBUG [org.apache.flink.streaming.runtime.tasks.StreamTask] Using partitioner GLOBAL for output 0 of task Source: HBaseTableSource[schema=[id, cf], projectFields=null] -> SourceConversion(table=[default_catalog.default_database.loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]], fields=[id, cf]) -> Calc(select=[id, cf, cf.degree AS degree])
03/06/2020 13:13:33.650  INFO [org.apache.flink.runtime.taskmanager.Task] Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (1/2) (6dfb6ce5559aca85d7e81c96224f4864) switched from CREATED to DEPLOYING.
03/06/2020 13:13:33.668  INFO [org.apache.flink.runtime.taskmanager.Task] Creating FileSystem stream leak safety net for task Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (1/2) (6dfb6ce5559aca85d7e81c96224f4864) [DEPLOYING]
03/06/2020 13:13:33.668  INFO [org.apache.flink.runtime.taskmanager.Task] Loading JAR files for task Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (1/2) (6dfb6ce5559aca85d7e81c96224f4864) [DEPLOYING].
03/06/2020 13:13:33.669 DEBUG [org.apache.flink.runtime.taskmanager.Task] Getting user code class loader for task 6dfb6ce5559aca85d7e81c96224f4864 at library cache manager took 0 milliseconds
03/06/2020 13:13:33.669  INFO [org.apache.flink.runtime.taskmanager.Task] Registering task at network: Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (1/2) (6dfb6ce5559aca85d7e81c96224f4864) [DEPLOYING].
03/06/2020 13:13:33.649 DEBUG [org.apache.flink.runtime.taskmanager.Task] Getting user code class loader for task 1ff6ef243e2fa7b8aa3f13605b545e75 at library cache manager took 5 milliseconds
03/06/2020 13:13:33.660  INFO [org.apache.flink.runtime.taskmanager.Task] Creating FileSystem stream leak safety net for task Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (2/2) (27eb9406de3597496fd0bb48c5e876a5) [DEPLOYING]
03/06/2020 13:13:33.676  INFO [org.apache.flink.runtime.taskmanager.Task] Loading JAR files for task Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (2/2) (27eb9406de3597496fd0bb48c5e876a5) [DEPLOYING].
03/06/2020 13:13:33.676 DEBUG [org.apache.flink.runtime.taskmanager.Task] Getting user code class loader for task 27eb9406de3597496fd0bb48c5e876a5 at library cache manager took 0 milliseconds
03/06/2020 13:13:33.676  INFO [org.apache.flink.runtime.taskmanager.Task] Registering task at network: Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (2/2) (27eb9406de3597496fd0bb48c5e876a5) [DEPLOYING].
03/06/2020 13:13:33.674  INFO [org.apache.flink.runtime.taskmanager.Task] Registering task at network: GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (2/2) (1ff6ef243e2fa7b8aa3f13605b545e75) [DEPLOYING].
03/06/2020 13:13:33.674  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutor] Received task Sink: Print to Std. Out (1/1).
03/06/2020 13:13:33.673 DEBUG [org.apache.flink.runtime.io.network.buffer.LocalBufferPool] Using a local buffer pool with 2-10 buffers
03/06/2020 13:13:33.671 DEBUG [org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel] LocalInputChannel [7e12330857e44344bfe04391907a4449@b84c3df4861d1ab2874fdf6c2c4b34e1]: Requesting LOCAL subpartition 0 of partition 7e12330857e44344bfe04391907a4449@b84c3df4861d1ab2874fdf6c2c4b34e1.
03/06/2020 13:13:33.677 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionManager] Requesting subpartition 0 of ReleaseOnConsumptionResultPartition 7e12330857e44344bfe04391907a4449@b84c3df4861d1ab2874fdf6c2c4b34e1 [PIPELINED_BOUNDED, 1 subpartitions, 1 pending consumptions].
03/06/2020 13:13:33.677 DEBUG [org.apache.flink.runtime.io.network.partition.PipelinedSubpartition] Source: HBaseTableSource[schema=[id, cf], projectFields=null] -> SourceConversion(table=[default_catalog.default_database.loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]], fields=[id, cf]) -> Calc(select=[id, cf, cf.degree AS degree]) (1/2) (b84c3df4861d1ab2874fdf6c2c4b34e1): Creating read view for subpartition 0 of partition 7e12330857e44344bfe04391907a4449@b84c3df4861d1ab2874fdf6c2c4b34e1.
03/06/2020 13:13:33.677 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartition] Created PipelinedSubpartitionView(index: 0) of ResultPartition 7e12330857e44344bfe04391907a4449@b84c3df4861d1ab2874fdf6c2c4b34e1
03/06/2020 13:13:33.677 DEBUG [org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel] LocalInputChannel [161687556e7759506bc9efabc0bcde87@db3aa1938ec63c4d326136e01fb698e5]: Requesting LOCAL subpartition 0 of partition 161687556e7759506bc9efabc0bcde87@db3aa1938ec63c4d326136e01fb698e5.
03/06/2020 13:13:33.677 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionManager] Requesting subpartition 0 of ReleaseOnConsumptionResultPartition 161687556e7759506bc9efabc0bcde87@db3aa1938ec63c4d326136e01fb698e5 [PIPELINED_BOUNDED, 1 subpartitions, 1 pending consumptions].
03/06/2020 13:13:33.678 DEBUG [org.apache.flink.runtime.io.network.partition.PipelinedSubpartition] Source: HBaseTableSource[schema=[id, cf], projectFields=null] -> SourceConversion(table=[default_catalog.default_database.loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]], fields=[id, cf]) -> Calc(select=[id, cf, cf.degree AS degree]) (2/2) (db3aa1938ec63c4d326136e01fb698e5): Creating read view for subpartition 0 of partition 161687556e7759506bc9efabc0bcde87@db3aa1938ec63c4d326136e01fb698e5.
03/06/2020 13:13:33.678 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartition] Created PipelinedSubpartitionView(index: 0) of ResultPartition 161687556e7759506bc9efabc0bcde87@db3aa1938ec63c4d326136e01fb698e5
03/06/2020 13:13:33.678 DEBUG [org.apache.flink.runtime.io.network.TaskEventDispatcher] registering 657d9fa3c3c42c8c21b0407ee1e3a770@876cc1eabe833ca7f87c8793f251f04a
03/06/2020 13:13:33.679 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionManager] Registered ReleaseOnConsumptionResultPartition 549697b480ed2892912b6fb269129087@6dfb6ce5559aca85d7e81c96224f4864 [PIPELINED_BOUNDED, 1 subpartitions, 1 pending consumptions].
03/06/2020 13:13:33.679 DEBUG [org.apache.flink.runtime.io.network.buffer.LocalBufferPool] Using a local buffer pool with 0-8 buffers
03/06/2020 13:13:33.679 DEBUG [org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel] LocalInputChannel [4a4d2bc06a45d34db956e3a272eab10a@1ff6ef243e2fa7b8aa3f13605b545e75]: Requesting LOCAL subpartition 0 of partition 4a4d2bc06a45d34db956e3a272eab10a@1ff6ef243e2fa7b8aa3f13605b545e75.
03/06/2020 13:13:33.679 DEBUG [org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate] Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (1/2) (6dfb6ce5559aca85d7e81c96224f4864): Retriggering partition request 4a4d2bc06a45d34db956e3a272eab10a@1ff6ef243e2fa7b8aa3f13605b545e75:0.
03/06/2020 13:13:33.680 DEBUG [org.apache.flink.runtime.io.network.buffer.LocalBufferPool] Using a local buffer pool with 3-12 buffers
03/06/2020 13:13:33.680 DEBUG [org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel] LocalInputChannel [f45f0539b91a35f8f33f7e0d2d64813c@02de6f076d7957e472f6eb0edbd38dbf]: Requesting LOCAL subpartition 0 of partition f45f0539b91a35f8f33f7e0d2d64813c@02de6f076d7957e472f6eb0edbd38dbf.
03/06/2020 13:13:33.680 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionManager] Requesting subpartition 0 of ReleaseOnConsumptionResultPartition f45f0539b91a35f8f33f7e0d2d64813c@02de6f076d7957e472f6eb0edbd38dbf [PIPELINED_BOUNDED, 2 subpartitions, 2 pending consumptions].
03/06/2020 13:13:33.680 DEBUG [org.apache.flink.runtime.io.network.partition.PipelinedSubpartition] GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (1/2) (02de6f076d7957e472f6eb0edbd38dbf): Creating read view for subpartition 0 of partition f45f0539b91a35f8f33f7e0d2d64813c@02de6f076d7957e472f6eb0edbd38dbf.
03/06/2020 13:13:33.680 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartition] Created PipelinedSubpartitionView(index: 0) of ResultPartition f45f0539b91a35f8f33f7e0d2d64813c@02de6f076d7957e472f6eb0edbd38dbf
03/06/2020 13:13:33.681  INFO [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl] Activate slot 25d44a59926bde802cdf946b4a6b94f9.
03/06/2020 13:13:33.681  INFO [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl] Activate slot 72c915e615c4f2f98aedf5eb10885367.
03/06/2020 13:13:33.681 DEBUG [org.apache.flink.streaming.runtime.tasks.StreamTask] Using partitioner REBALANCE for output 0 of task SortLimit(orderBy=[degree DESC], offset=[0], fetch=[10]) -> Calc(select=[id, cf]) -> SinkConversionToTuple2
03/06/2020 13:13:33.681  INFO [org.apache.flink.runtime.taskmanager.Task] Sink: Print to Std. Out (1/1) (26e0302ddaecd3150ec5345d3906b102) switched from CREATED to DEPLOYING.
03/06/2020 13:13:33.681  INFO [org.apache.flink.runtime.taskmanager.Task] Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (1/1) (26e0302ddaecd3150ec5345d3906b102) [DEPLOYING]
03/06/2020 13:13:33.682  INFO [org.apache.flink.runtime.taskmanager.Task] Loading JAR files for task Sink: Print to Std. Out (1/1) (26e0302ddaecd3150ec5345d3906b102) [DEPLOYING].
03/06/2020 13:13:33.682 DEBUG [org.apache.flink.runtime.taskmanager.Task] Getting user code class loader for task 26e0302ddaecd3150ec5345d3906b102 at library cache manager took 0 milliseconds
03/06/2020 13:13:33.682  INFO [org.apache.flink.runtime.taskmanager.Task] Registering task at network: Sink: Print to Std. Out (1/1) (26e0302ddaecd3150ec5345d3906b102) [DEPLOYING].
03/06/2020 13:13:33.683  INFO [org.apache.flink.runtime.taskmanager.Task] Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (1/2) (4d7a1b8b380293c90670ee95c08224e0) switched from DEPLOYING to RUNNING.
03/06/2020 13:13:33.684  INFO [org.apache.flink.runtime.taskmanager.Task] Source: HBaseTableSource[schema=[id, cf], projectFields=null] -> SourceConversion(table=[default_catalog.default_database.loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]], fields=[id, cf]) -> Calc(select=[id, cf, cf.degree AS degree]) (2/2) (db3aa1938ec63c4d326136e01fb698e5) switched from DEPLOYING to RUNNING.
03/06/2020 13:13:33.683  INFO [org.apache.flink.runtime.taskmanager.Task] Source: HBaseTableSource[schema=[id, cf], projectFields=null] -> SourceConversion(table=[default_catalog.default_database.loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]], fields=[id, cf]) -> Calc(select=[id, cf, cf.degree AS degree]) (1/2) (b84c3df4861d1ab2874fdf6c2c4b34e1) switched from DEPLOYING to RUNNING.
03/06/2020 13:13:33.684 DEBUG [org.apache.flink.streaming.runtime.tasks.StreamTask] Initializing Source: HBaseTableSource[schema=[id, cf], projectFields=null] -> SourceConversion(table=[default_catalog.default_database.loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]], fields=[id, cf]) -> Calc(select=[id, cf, cf.degree AS degree]) (2/2).
03/06/2020 13:13:33.684 DEBUG [org.apache.flink.streaming.runtime.tasks.StreamTask] Initializing Source: HBaseTableSource[schema=[id, cf], projectFields=null] -> SourceConversion(table=[default_catalog.default_database.loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]], fields=[id, cf]) -> Calc(select=[id, cf, cf.degree AS degree]) (1/2).
03/06/2020 13:13:33.684  INFO [org.apache.flink.runtime.taskmanager.Task] Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (2/2) (c365017ac85c61dc4f885a5155f06f1e) switched from DEPLOYING to RUNNING.
03/06/2020 13:13:33.684  INFO [org.apache.flink.runtime.taskmanager.Task] Source: Collection Source -> SourceConversion(table=[Unregistered_DataStream_9], fields=[f0, f1, f2, f3, f4]) -> Calc(select=[f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y]) (1/1) (d74648705093b5c72e78e2c360e29713) switched from DEPLOYING to RUNNING.
03/06/2020 13:13:33.685 DEBUG [org.apache.flink.streaming.runtime.tasks.StreamTask] Initializing Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (2/2).
03/06/2020 13:13:33.688  INFO [org.apache.flink.streaming.runtime.tasks.StreamTask] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
03/06/2020 13:13:33.689  INFO [org.apache.flink.runtime.taskmanager.Task] SortLimit(orderBy=[degree DESC], offset=[0], fetch=[10]) -> Calc(select=[id, cf]) -> SinkConversionToTuple2 (1/1) (876cc1eabe833ca7f87c8793f251f04a) switched from DEPLOYING to RUNNING.
03/06/2020 13:13:33.689 DEBUG [org.apache.flink.streaming.runtime.tasks.StreamTask] Initializing SortLimit(orderBy=[degree DESC], offset=[0], fetch=[10]) -> Calc(select=[id, cf]) -> SinkConversionToTuple2 (1/1).
03/06/2020 13:13:33.689  INFO [org.apache.flink.streaming.runtime.tasks.StreamTask] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
03/06/2020 13:13:33.689  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] Source: HBaseTableSource[schema=[id, cf], projectFields=null] -> SourceConversion(table=[default_catalog.default_database.loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]], fields=[id, cf]) -> Calc(select=[id, cf, cf.degree AS degree]) (2/2) (db3aa1938ec63c4d326136e01fb698e5) switched from DEPLOYING to RUNNING.
03/06/2020 13:13:33.690  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] Source: HBaseTableSource[schema=[id, cf], projectFields=null] -> SourceConversion(table=[default_catalog.default_database.loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]], fields=[id, cf]) -> Calc(select=[id, cf, cf.degree AS degree]) (1/2) (b84c3df4861d1ab2874fdf6c2c4b34e1) switched from DEPLOYING to RUNNING.
03/06/2020 13:13:33.690  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (2/2) (c365017ac85c61dc4f885a5155f06f1e) switched from DEPLOYING to RUNNING.
03/06/2020 13:13:33.690  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] Source: Collection Source -> SourceConversion(table=[Unregistered_DataStream_9], fields=[f0, f1, f2, f3, f4]) -> Calc(select=[f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y]) (1/1) (d74648705093b5c72e78e2c360e29713) switched from DEPLOYING to RUNNING.
03/06/2020 13:13:33.690  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (1/2) (4d7a1b8b380293c90670ee95c08224e0) switched from DEPLOYING to RUNNING.
03/06/2020 13:13:33.691  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] SortLimit(orderBy=[degree DESC], offset=[0], fetch=[10]) -> Calc(select=[id, cf]) -> SinkConversionToTuple2 (1/1) (876cc1eabe833ca7f87c8793f251f04a) switched from DEPLOYING to RUNNING.
03/06/2020 13:13:33.688 DEBUG [org.apache.flink.streaming.runtime.tasks.StreamTask] Initializing Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (1/2).
03/06/2020 13:13:33.692  INFO [org.apache.flink.streaming.runtime.tasks.StreamTask] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
03/06/2020 13:13:33.688 DEBUG [org.apache.flink.streaming.runtime.tasks.StreamTask] Initializing Source: Collection Source -> SourceConversion(table=[Unregistered_DataStream_9], fields=[f0, f1, f2, f3, f4]) -> Calc(select=[f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y]) (1/1).
03/06/2020 13:13:33.688 DEBUG [org.apache.flink.runtime.io.network.buffer.LocalBufferPool] Using a local buffer pool with 2-10 buffers
03/06/2020 13:13:33.687 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionManager] Registered ReleaseOnConsumptionResultPartition 4a4d2bc06a45d34db956e3a272eab10a@1ff6ef243e2fa7b8aa3f13605b545e75 [PIPELINED_BOUNDED, 2 subpartitions, 2 pending consumptions].
03/06/2020 13:13:33.687  INFO [org.apache.flink.streaming.runtime.tasks.StreamTask] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
03/06/2020 13:13:33.687  INFO [org.apache.flink.streaming.runtime.tasks.StreamTask] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
03/06/2020 13:13:33.692  INFO [org.apache.flink.streaming.runtime.tasks.StreamTask] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
03/06/2020 13:13:33.689  INFO [org.apache.flink.runtime.taskmanager.Task] GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (1/2) (02de6f076d7957e472f6eb0edbd38dbf) switched from DEPLOYING to RUNNING.
03/06/2020 13:13:33.705 DEBUG [org.apache.flink.streaming.runtime.tasks.StreamTask] Initializing GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (1/2).
03/06/2020 13:13:33.706  INFO [org.apache.flink.streaming.runtime.tasks.StreamTask] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
03/06/2020 13:13:33.696 DEBUG [org.apache.flink.runtime.io.network.buffer.LocalBufferPool] Using a local buffer pool with 0-8 buffers
03/06/2020 13:13:33.696 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionManager] Registered ReleaseOnConsumptionResultPartition 37419b70f6b9f20c581859a2a6711084@27eb9406de3597496fd0bb48c5e876a5 [PIPELINED_BOUNDED, 1 subpartitions, 1 pending consumptions].
03/06/2020 13:13:33.707  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (1/2) (02de6f076d7957e472f6eb0edbd38dbf) switched from DEPLOYING to RUNNING.
03/06/2020 13:13:33.711 DEBUG [org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel] LocalInputChannel [0ba5902cc0427ce26c3f0693bdc93d05@c365017ac85c61dc4f885a5155f06f1e]: Requesting LOCAL subpartition 1 of partition 0ba5902cc0427ce26c3f0693bdc93d05@c365017ac85c61dc4f885a5155f06f1e.
03/06/2020 13:13:33.711 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionManager] Requesting subpartition 1 of ReleaseOnConsumptionResultPartition 0ba5902cc0427ce26c3f0693bdc93d05@c365017ac85c61dc4f885a5155f06f1e [PIPELINED_BOUNDED, 2 subpartitions, 2 pending consumptions].
03/06/2020 13:13:33.711 DEBUG [org.apache.flink.runtime.io.network.partition.PipelinedSubpartition] Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (2/2) (c365017ac85c61dc4f885a5155f06f1e): Creating read view for subpartition 1 of partition 0ba5902cc0427ce26c3f0693bdc93d05@c365017ac85c61dc4f885a5155f06f1e.
03/06/2020 13:13:33.711 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartition] Created PipelinedSubpartitionView(index: 1) of ResultPartition 0ba5902cc0427ce26c3f0693bdc93d05@c365017ac85c61dc4f885a5155f06f1e
03/06/2020 13:13:33.711 DEBUG [org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel] LocalInputChannel [4bd09e894d9b0e6c6119f756bfe2ba7c@4d7a1b8b380293c90670ee95c08224e0]: Requesting LOCAL subpartition 1 of partition 4bd09e894d9b0e6c6119f756bfe2ba7c@4d7a1b8b380293c90670ee95c08224e0.
03/06/2020 13:13:33.711 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionManager] Requesting subpartition 1 of ReleaseOnConsumptionResultPartition 4bd09e894d9b0e6c6119f756bfe2ba7c@4d7a1b8b380293c90670ee95c08224e0 [PIPELINED_BOUNDED, 2 subpartitions, 2 pending consumptions].
03/06/2020 13:13:33.711 DEBUG [org.apache.flink.runtime.io.network.partition.PipelinedSubpartition] Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (1/2) (4d7a1b8b380293c90670ee95c08224e0): Creating read view for subpartition 1 of partition 4bd09e894d9b0e6c6119f756bfe2ba7c@4d7a1b8b380293c90670ee95c08224e0.
03/06/2020 13:13:33.711 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartition] Created PipelinedSubpartitionView(index: 1) of ResultPartition 4bd09e894d9b0e6c6119f756bfe2ba7c@4d7a1b8b380293c90670ee95c08224e0
03/06/2020 13:13:33.711 DEBUG [org.apache.flink.runtime.io.network.TaskEventDispatcher] registering 4a4d2bc06a45d34db956e3a272eab10a@1ff6ef243e2fa7b8aa3f13605b545e75
03/06/2020 13:13:33.712 DEBUG [org.apache.flink.streaming.runtime.tasks.StreamTask] Using partitioner HASH for output 0 of task GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')])
03/06/2020 13:13:33.712 DEBUG [org.apache.flink.runtime.io.network.buffer.LocalBufferPool] Using a local buffer pool with 0-8 buffers
03/06/2020 13:13:33.712  INFO [org.apache.flink.runtime.taskmanager.Task] GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (2/2) (1ff6ef243e2fa7b8aa3f13605b545e75) switched from DEPLOYING to RUNNING.
03/06/2020 13:13:33.713 DEBUG [org.apache.flink.streaming.runtime.tasks.StreamTask] Initializing GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (2/2).
03/06/2020 13:13:33.713  INFO [org.apache.flink.streaming.runtime.tasks.StreamTask] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
03/06/2020 13:13:33.717  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (2/2) (1ff6ef243e2fa7b8aa3f13605b545e75) switched from DEPLOYING to RUNNING.
03/06/2020 13:13:33.721 DEBUG [org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel] LocalInputChannel [549697b480ed2892912b6fb269129087@6dfb6ce5559aca85d7e81c96224f4864]: Requesting LOCAL subpartition 0 of partition 549697b480ed2892912b6fb269129087@6dfb6ce5559aca85d7e81c96224f4864.
03/06/2020 13:13:33.721 DEBUG [org.apache.flink.runtime.io.network.buffer.LocalBufferPool] Using a local buffer pool with 0-8 buffers
03/06/2020 13:13:33.721 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionManager] Requesting subpartition 0 of ReleaseOnConsumptionResultPartition 549697b480ed2892912b6fb269129087@6dfb6ce5559aca85d7e81c96224f4864 [PIPELINED_BOUNDED, 1 subpartitions, 1 pending consumptions].
03/06/2020 13:13:33.723 DEBUG [org.apache.flink.table.runtime.generated.CompileUtils] Compiling: StreamExecCalc$144 

 Code:

      public class StreamExecCalc$144 extends org.apache.flink.table.runtime.operators.AbstractProcessStreamOperator
          implements org.apache.flink.streaming.api.operators.OneInputStreamOperator {

        private final Object[] references;
        private transient org.apache.flink.table.runtime.typeutils.BinaryStringSerializer typeSerializer$130;
        
        private final org.apache.flink.table.dataformat.BinaryString str$132 = org.apache.flink.table.dataformat.BinaryString.fromString("v_id_2");
                   
        
        private final org.apache.flink.table.dataformat.BinaryString str$135 = org.apache.flink.table.dataformat.BinaryString.fromString("v_label");
                   
        
        private final org.apache.flink.table.dataformat.BinaryString str$137 = org.apache.flink.table.dataformat.BinaryString.fromString("v_id_layout");
                   
        
        private final org.apache.flink.table.dataformat.BinaryString str$140 = org.apache.flink.table.dataformat.BinaryString.fromString("X");
                   
        
        private final org.apache.flink.table.dataformat.BinaryString str$143 = org.apache.flink.table.dataformat.BinaryString.fromString("Y");
                   
        final org.apache.flink.table.dataformat.BoxedWrapperRow out = new org.apache.flink.table.dataformat.BoxedWrapperRow(5);
        private final org.apache.flink.streaming.runtime.streamrecord.StreamRecord outElement = new org.apache.flink.streaming.runtime.streamrecord.StreamRecord(null);

        public StreamExecCalc$144(
            Object[] references,
            org.apache.flink.streaming.runtime.tasks.StreamTask task,
            org.apache.flink.streaming.api.graph.StreamConfig config,
            org.apache.flink.streaming.api.operators.Output output) throws Exception {
          this.references = references;
          typeSerializer$130 = (((org.apache.flink.table.runtime.typeutils.BinaryStringSerializer) references[0]));
          this.setup(task, config, output);
        }

        @Override
        public void open() throws Exception {
          super.open();
          
        }

        @Override
        public void processElement(org.apache.flink.streaming.runtime.streamrecord.StreamRecord element) throws Exception {
          org.apache.flink.table.dataformat.BaseRow in1 = (org.apache.flink.table.dataformat.BaseRow) element.getValue();
          
          org.apache.flink.table.dataformat.BinaryString field$129;
          boolean isNull$129;
          org.apache.flink.table.dataformat.BinaryString field$131;
          org.apache.flink.table.dataformat.BinaryString field$133;
          boolean isNull$133;
          org.apache.flink.table.dataformat.BinaryString field$134;
          int field$136;
          boolean isNull$136;
          org.apache.flink.table.dataformat.BinaryString field$138;
          boolean isNull$138;
          org.apache.flink.table.dataformat.BinaryString field$139;
          org.apache.flink.table.dataformat.BinaryString field$141;
          boolean isNull$141;
          org.apache.flink.table.dataformat.BinaryString field$142;
          
          
          isNull$136 = in1.isNullAt(2);
          field$136 = -1;
          if (!isNull$136) {
            field$136 = in1.getInt(2);
          }
          
          isNull$129 = in1.isNullAt(0);
          field$129 = org.apache.flink.table.dataformat.BinaryString.EMPTY_UTF8;
          if (!isNull$129) {
            field$129 = in1.getString(0);
          }
          field$131 = field$129;
          if (!isNull$129) {
            field$131 = (org.apache.flink.table.dataformat.BinaryString) (typeSerializer$130.copy(field$131));
          }
                  
          
          isNull$141 = in1.isNullAt(4);
          field$141 = org.apache.flink.table.dataformat.BinaryString.EMPTY_UTF8;
          if (!isNull$141) {
            field$141 = in1.getString(4);
          }
          field$142 = field$141;
          if (!isNull$141) {
            field$142 = (org.apache.flink.table.dataformat.BinaryString) (typeSerializer$130.copy(field$142));
          }
                  
          
          isNull$133 = in1.isNullAt(1);
          field$133 = org.apache.flink.table.dataformat.BinaryString.EMPTY_UTF8;
          if (!isNull$133) {
            field$133 = in1.getString(1);
          }
          field$134 = field$133;
          if (!isNull$133) {
            field$134 = (org.apache.flink.table.dataformat.BinaryString) (typeSerializer$130.copy(field$134));
          }
                  
          
          isNull$138 = in1.isNullAt(3);
          field$138 = org.apache.flink.table.dataformat.BinaryString.EMPTY_UTF8;
          if (!isNull$138) {
            field$138 = in1.getString(3);
          }
          field$139 = field$138;
          if (!isNull$138) {
            field$139 = (org.apache.flink.table.dataformat.BinaryString) (typeSerializer$130.copy(field$139));
          }
                  
          
          out.setHeader(in1.getHeader());
          
          
          
          
          if (isNull$129) {
            out.setNullAt(0);
          } else {
            out.setNonPrimitiveValue(0, field$131);
          }
                    
          
          
          if (isNull$133) {
            out.setNullAt(1);
          } else {
            out.setNonPrimitiveValue(1, field$134);
          }
                    
          
          
          if (isNull$136) {
            out.setNullAt(2);
          } else {
            out.setInt(2, field$136);
          }
                    
          
          
          if (isNull$138) {
            out.setNullAt(3);
          } else {
            out.setNonPrimitiveValue(3, field$139);
          }
                    
          
          
          if (isNull$141) {
            out.setNullAt(4);
          } else {
            out.setNonPrimitiveValue(4, field$142);
          }
                    
                  
          output.collect(outElement.replace(out));
          
          
        }

        

        @Override
        public void close() throws Exception {
           super.close();
          
        }

        
      }
    
03/06/2020 13:13:33.723 DEBUG [org.apache.flink.table.runtime.generated.CompileUtils] Compiling: StreamExecCalc$125 

 Code:

      public class StreamExecCalc$125 extends org.apache.flink.table.runtime.operators.AbstractProcessStreamOperator
          implements org.apache.flink.streaming.api.operators.OneInputStreamOperator {

        private final Object[] references;
        private transient org.apache.flink.table.runtime.typeutils.BaseRowSerializer typeSerializer$110;
        
        private final org.apache.flink.table.dataformat.BinaryString str$114 = org.apache.flink.table.dataformat.BinaryString.fromString("bool");
                   
        
        private final org.apache.flink.table.dataformat.BinaryString str$115 = org.apache.flink.table.dataformat.BinaryString.fromString("true");
                   
        private transient org.apache.flink.table.runtime.typeutils.BinaryStringSerializer typeSerializer$119;
        
        private final org.apache.flink.table.dataformat.BinaryString str$121 = org.apache.flink.table.dataformat.BinaryString.fromString("v_id");
                   
        
        private final org.apache.flink.table.dataformat.BinaryString str$124 = org.apache.flink.table.dataformat.BinaryString.fromString("degree");
                   
        final org.apache.flink.table.dataformat.BoxedWrapperRow out = new org.apache.flink.table.dataformat.BoxedWrapperRow(2);
        private final org.apache.flink.streaming.runtime.streamrecord.StreamRecord outElement = new org.apache.flink.streaming.runtime.streamrecord.StreamRecord(null);

        public StreamExecCalc$125(
            Object[] references,
            org.apache.flink.streaming.runtime.tasks.StreamTask task,
            org.apache.flink.streaming.api.graph.StreamConfig config,
            org.apache.flink.streaming.api.operators.Output output) throws Exception {
          this.references = references;
          typeSerializer$110 = (((org.apache.flink.table.runtime.typeutils.BaseRowSerializer) references[0]));
          typeSerializer$119 = (((org.apache.flink.table.runtime.typeutils.BinaryStringSerializer) references[1]));
          this.setup(task, config, output);
        }

        @Override
        public void open() throws Exception {
          super.open();
          
        }

        @Override
        public void processElement(org.apache.flink.streaming.runtime.streamrecord.StreamRecord element) throws Exception {
          org.apache.flink.table.dataformat.BaseRow in1 = (org.apache.flink.table.dataformat.BaseRow) element.getValue();
          
          org.apache.flink.table.dataformat.BaseRow field$109;
          boolean isNull$109;
          org.apache.flink.table.dataformat.BaseRow field$111;
          org.apache.flink.table.dataformat.BinaryString field$112;
          boolean isNull$112;
          org.apache.flink.table.dataformat.BinaryString result$113;
          boolean isNull$113;
          boolean isNull$116;
          boolean result$117;
          org.apache.flink.table.dataformat.BinaryString field$118;
          boolean isNull$118;
          org.apache.flink.table.dataformat.BinaryString field$120;
          org.apache.flink.table.dataformat.BinaryString field$122;
          boolean isNull$122;
          org.apache.flink.table.dataformat.BinaryString result$123;
          boolean isNull$123;
          
          
          
          isNull$109 = in1.isNullAt(1);
          field$109 = null;
          if (!isNull$109) {
            field$109 = in1.getRow(1, 2);
          }
          field$111 = field$109;
          if (!isNull$109) {
            field$111 = (org.apache.flink.table.dataformat.BaseRow) (typeSerializer$110.copy(field$111));
          }
                  
          
          
          
          if (isNull$109) {
            result$113 = org.apache.flink.table.dataformat.BinaryString.EMPTY_UTF8;
            isNull$113 = true;
          }
          else {
            isNull$112 = field$111.isNullAt(0);
          field$112 = org.apache.flink.table.dataformat.BinaryString.EMPTY_UTF8;
          if (!isNull$112) {
            field$112 = field$111.getString(0);
          }
            result$113 = field$112;
            isNull$113 = isNull$112;
          }
          
          
          isNull$116 = isNull$113 || false;
          result$117 = false;
          if (!isNull$116) {
            
            result$117 = result$113.equals(((org.apache.flink.table.dataformat.BinaryString) str$115));
            
          }
          
          if (result$117) {
            
          isNull$118 = in1.isNullAt(0);
          field$118 = org.apache.flink.table.dataformat.BinaryString.EMPTY_UTF8;
          if (!isNull$118) {
            field$118 = in1.getString(0);
          }
          field$120 = field$118;
          if (!isNull$118) {
            field$120 = (org.apache.flink.table.dataformat.BinaryString) (typeSerializer$119.copy(field$120));
          }
                  
            
          out.setHeader(in1.getHeader());
          
          
          
          
          if (isNull$118) {
            out.setNullAt(0);
          } else {
            out.setNonPrimitiveValue(0, field$120);
          }
                    
          
          
          
          if (isNull$109) {
            result$123 = org.apache.flink.table.dataformat.BinaryString.EMPTY_UTF8;
            isNull$123 = true;
          }
          else {
            isNull$122 = field$111.isNullAt(1);
          field$122 = org.apache.flink.table.dataformat.BinaryString.EMPTY_UTF8;
          if (!isNull$122) {
            field$122 = field$111.getString(1);
          }
            result$123 = field$122;
            isNull$123 = isNull$122;
          }
          
          if (isNull$123) {
            out.setNullAt(1);
          } else {
            out.setNonPrimitiveValue(1, result$123);
          }
                    
                  
          output.collect(outElement.replace(out));
          
          }
          
        }

        

        @Override
        public void close() throws Exception {
           super.close();
          
        }

        
      }
    
03/06/2020 13:13:33.723 DEBUG [org.apache.flink.table.runtime.generated.CompileUtils] Compiling: StreamExecCalc$71 

 Code:

      public class StreamExecCalc$71 extends org.apache.flink.table.runtime.operators.AbstractProcessStreamOperator
          implements org.apache.flink.streaming.api.operators.OneInputStreamOperator {

        private final Object[] references;
        private transient org.apache.flink.table.runtime.typeutils.BinaryStringSerializer typeSerializer$62;
        
        private final org.apache.flink.table.dataformat.BinaryString str$64 = org.apache.flink.table.dataformat.BinaryString.fromString("bool");
                   
        
        private final org.apache.flink.table.dataformat.BinaryString str$67 = org.apache.flink.table.dataformat.BinaryString.fromString("v_id");
                   
        
        private final org.apache.flink.table.dataformat.BinaryString str$70 = org.apache.flink.table.dataformat.BinaryString.fromString("degree");
                   
        final org.apache.flink.table.dataformat.BoxedWrapperRow out = new org.apache.flink.table.dataformat.BoxedWrapperRow(3);
        private final org.apache.flink.streaming.runtime.streamrecord.StreamRecord outElement = new org.apache.flink.streaming.runtime.streamrecord.StreamRecord(null);

        public StreamExecCalc$71(
            Object[] references,
            org.apache.flink.streaming.runtime.tasks.StreamTask task,
            org.apache.flink.streaming.api.graph.StreamConfig config,
            org.apache.flink.streaming.api.operators.Output output) throws Exception {
          this.references = references;
          typeSerializer$62 = (((org.apache.flink.table.runtime.typeutils.BinaryStringSerializer) references[0]));
          this.setup(task, config, output);
        }

        @Override
        public void open() throws Exception {
          super.open();
          
        }

        @Override
        public void processElement(org.apache.flink.streaming.runtime.streamrecord.StreamRecord element) throws Exception {
          org.apache.flink.table.dataformat.BaseRow in1 = (org.apache.flink.table.dataformat.BaseRow) element.getValue();
          
          org.apache.flink.table.dataformat.BinaryString field$61;
          boolean isNull$61;
          org.apache.flink.table.dataformat.BinaryString field$63;
          org.apache.flink.table.dataformat.BinaryString field$65;
          boolean isNull$65;
          org.apache.flink.table.dataformat.BinaryString field$66;
          org.apache.flink.table.dataformat.BinaryString field$68;
          boolean isNull$68;
          org.apache.flink.table.dataformat.BinaryString field$69;
          
          
          
          isNull$68 = in1.isNullAt(2);
          field$68 = org.apache.flink.table.dataformat.BinaryString.EMPTY_UTF8;
          if (!isNull$68) {
            field$68 = in1.getString(2);
          }
          field$69 = field$68;
          if (!isNull$68) {
            field$69 = (org.apache.flink.table.dataformat.BinaryString) (typeSerializer$62.copy(field$69));
          }
                  
          
          isNull$61 = in1.isNullAt(0);
          field$61 = org.apache.flink.table.dataformat.BinaryString.EMPTY_UTF8;
          if (!isNull$61) {
            field$61 = in1.getString(0);
          }
          field$63 = field$61;
          if (!isNull$61) {
            field$63 = (org.apache.flink.table.dataformat.BinaryString) (typeSerializer$62.copy(field$63));
          }
                  
          
          isNull$65 = in1.isNullAt(1);
          field$65 = org.apache.flink.table.dataformat.BinaryString.EMPTY_UTF8;
          if (!isNull$65) {
            field$65 = in1.getString(1);
          }
          field$66 = field$65;
          if (!isNull$65) {
            field$66 = (org.apache.flink.table.dataformat.BinaryString) (typeSerializer$62.copy(field$66));
          }
                  
          
          out.setHeader(in1.getHeader());
          
          
          
          
          if (isNull$61) {
            out.setNullAt(0);
          } else {
            out.setNonPrimitiveValue(0, field$63);
          }
                    
          
          
          if (isNull$65) {
            out.setNullAt(1);
          } else {
            out.setNonPrimitiveValue(1, field$66);
          }
                    
          
          
          if (isNull$68) {
            out.setNullAt(2);
          } else {
            out.setNonPrimitiveValue(2, field$69);
          }
                    
                  
          output.collect(outElement.replace(out));
          
          
        }

        

        @Override
        public void close() throws Exception {
           super.close();
          
        }

        
      }
    
03/06/2020 13:13:33.723 DEBUG [org.apache.flink.table.runtime.generated.CompileUtils] Compiling: SinkConversion$21 

 Code:

      public class SinkConversion$21 extends org.apache.flink.table.runtime.operators.TableStreamOperator
          implements org.apache.flink.streaming.api.operators.OneInputStreamOperator {

        private final Object[] references;
        private transient org.apache.flink.table.dataformat.DataFormatConverters.RowConverter converter$19;
        private final org.apache.flink.streaming.runtime.streamrecord.StreamRecord outElement = new org.apache.flink.streaming.runtime.streamrecord.StreamRecord(null);

        public SinkConversion$21(
            Object[] references,
            org.apache.flink.streaming.runtime.tasks.StreamTask task,
            org.apache.flink.streaming.api.graph.StreamConfig config,
            org.apache.flink.streaming.api.operators.Output output) throws Exception {
          this.references = references;
          converter$19 = (((org.apache.flink.table.dataformat.DataFormatConverters.RowConverter) references[0]));
          this.setup(task, config, output);
        }

        @Override
        public void open() throws Exception {
          super.open();
          
        }

        @Override
        public void processElement(org.apache.flink.streaming.runtime.streamrecord.StreamRecord element) throws Exception {
          org.apache.flink.table.dataformat.BaseRow in1 = (org.apache.flink.table.dataformat.BaseRow) element.getValue();
          
          
          
          
          
          
          org.apache.flink.api.java.tuple.Tuple2 result$20 = new org.apache.flink.api.java.tuple.Tuple2();
          result$20.setField(org.apache.flink.table.dataformat.util.BaseRowUtil.isAccumulateMsg(in1), 0);
          result$20.setField((org.apache.flink.types.Row) converter$19.toExternal((org.apache.flink.table.dataformat.BaseRow) in1), 1);
          output.collect(outElement.replace(result$20));
                   
          
        }

        

        @Override
        public void close() throws Exception {
           super.close();
          
        }

        
      }
    
03/06/2020 13:13:33.722 DEBUG [org.apache.flink.runtime.io.network.buffer.LocalBufferPool] Using a local buffer pool with 0-8 buffers
03/06/2020 13:13:33.722 DEBUG [org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel] LocalInputChannel [152d67b39c04e64fe5971bb597eb96e2@d74648705093b5c72e78e2c360e29713]: Requesting LOCAL subpartition 0 of partition 152d67b39c04e64fe5971bb597eb96e2@d74648705093b5c72e78e2c360e29713.
03/06/2020 13:13:33.729 DEBUG [org.apache.flink.table.runtime.generated.CompileUtils] Compiling: StreamExecCalc$10 

 Code:

      public class StreamExecCalc$10 extends org.apache.flink.table.runtime.operators.AbstractProcessStreamOperator
          implements org.apache.flink.streaming.api.operators.OneInputStreamOperator {

        private final Object[] references;
        private transient org.apache.flink.table.runtime.typeutils.BinaryStringSerializer typeSerializer$3;
        private transient org.apache.flink.table.runtime.typeutils.BaseRowSerializer typeSerializer$6;
        final org.apache.flink.table.dataformat.BoxedWrapperRow out = new org.apache.flink.table.dataformat.BoxedWrapperRow(3);
        private final org.apache.flink.streaming.runtime.streamrecord.StreamRecord outElement = new org.apache.flink.streaming.runtime.streamrecord.StreamRecord(null);

        public StreamExecCalc$10(
            Object[] references,
            org.apache.flink.streaming.runtime.tasks.StreamTask task,
            org.apache.flink.streaming.api.graph.StreamConfig config,
            org.apache.flink.streaming.api.operators.Output output) throws Exception {
          this.references = references;
          typeSerializer$3 = (((org.apache.flink.table.runtime.typeutils.BinaryStringSerializer) references[0]));
          typeSerializer$6 = (((org.apache.flink.table.runtime.typeutils.BaseRowSerializer) references[1]));
          this.setup(task, config, output);
        }

        @Override
        public void open() throws Exception {
          super.open();
          
        }

        @Override
        public void processElement(org.apache.flink.streaming.runtime.streamrecord.StreamRecord element) throws Exception {
          org.apache.flink.table.dataformat.BaseRow in1 = (org.apache.flink.table.dataformat.BaseRow) element.getValue();
          
          org.apache.flink.table.dataformat.BinaryString field$2;
          boolean isNull$2;
          org.apache.flink.table.dataformat.BinaryString field$4;
          org.apache.flink.table.dataformat.BaseRow field$5;
          boolean isNull$5;
          org.apache.flink.table.dataformat.BaseRow field$7;
          int field$8;
          boolean isNull$8;
          int result$9;
          boolean isNull$9;
          
          
          
          isNull$2 = in1.isNullAt(0);
          field$2 = org.apache.flink.table.dataformat.BinaryString.EMPTY_UTF8;
          if (!isNull$2) {
            field$2 = in1.getString(0);
          }
          field$4 = field$2;
          if (!isNull$2) {
            field$4 = (org.apache.flink.table.dataformat.BinaryString) (typeSerializer$3.copy(field$4));
          }
                  
          
          isNull$5 = in1.isNullAt(1);
          field$5 = null;
          if (!isNull$5) {
            field$5 = in1.getRow(1, 1);
          }
          field$7 = field$5;
          if (!isNull$5) {
            field$7 = (org.apache.flink.table.dataformat.BaseRow) (typeSerializer$6.copy(field$7));
          }
                  
          
          out.setHeader(in1.getHeader());
          
          
          
          
          if (isNull$2) {
            out.setNullAt(0);
          } else {
            out.setNonPrimitiveValue(0, field$4);
          }
                    
          
          
          if (isNull$5) {
            out.setNullAt(1);
          } else {
            out.setNonPrimitiveValue(1, field$7);
          }
                    
          
          
          
          if (isNull$5) {
            result$9 = -1;
            isNull$9 = true;
          }
          else {
            isNull$8 = field$7.isNullAt(0);
          field$8 = -1;
          if (!isNull$8) {
            field$8 = field$7.getInt(0);
          }
            result$9 = field$8;
            isNull$9 = isNull$8;
          }
          
          if (isNull$9) {
            out.setNullAt(2);
          } else {
            out.setInt(2, result$9);
          }
                    
                  
          output.collect(outElement.replace(out));
          
          
        }

        

        @Override
        public void close() throws Exception {
           super.close();
          
        }

        
      }
    
03/06/2020 13:13:33.730 DEBUG [org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel] LocalInputChannel [4a4d2bc06a45d34db956e3a272eab10a@1ff6ef243e2fa7b8aa3f13605b545e75]: Requesting LOCAL subpartition 1 of partition 4a4d2bc06a45d34db956e3a272eab10a@1ff6ef243e2fa7b8aa3f13605b545e75.
03/06/2020 13:13:33.734 DEBUG [org.apache.flink.runtime.io.network.partition.PipelinedSubpartition] Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (1/2) (6dfb6ce5559aca85d7e81c96224f4864): Creating read view for subpartition 0 of partition 549697b480ed2892912b6fb269129087@6dfb6ce5559aca85d7e81c96224f4864.
03/06/2020 13:13:33.734 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartition] Created PipelinedSubpartitionView(index: 0) of ResultPartition 549697b480ed2892912b6fb269129087@6dfb6ce5559aca85d7e81c96224f4864
03/06/2020 13:13:33.734 DEBUG [org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel] LocalInputChannel [37419b70f6b9f20c581859a2a6711084@27eb9406de3597496fd0bb48c5e876a5]: Requesting LOCAL subpartition 0 of partition 37419b70f6b9f20c581859a2a6711084@27eb9406de3597496fd0bb48c5e876a5.
03/06/2020 13:13:33.734 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionManager] Requesting subpartition 1 of ReleaseOnConsumptionResultPartition 4a4d2bc06a45d34db956e3a272eab10a@1ff6ef243e2fa7b8aa3f13605b545e75 [PIPELINED_BOUNDED, 2 subpartitions, 2 pending consumptions].
03/06/2020 13:13:33.735 DEBUG [org.apache.flink.runtime.io.network.partition.PipelinedSubpartition] GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (2/2) (1ff6ef243e2fa7b8aa3f13605b545e75): Creating read view for subpartition 1 of partition 4a4d2bc06a45d34db956e3a272eab10a@1ff6ef243e2fa7b8aa3f13605b545e75.
03/06/2020 13:13:33.735 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartition] Created PipelinedSubpartitionView(index: 1) of ResultPartition 4a4d2bc06a45d34db956e3a272eab10a@1ff6ef243e2fa7b8aa3f13605b545e75
03/06/2020 13:13:33.735 DEBUG [org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel] LocalInputChannel [f45f0539b91a35f8f33f7e0d2d64813c@02de6f076d7957e472f6eb0edbd38dbf]: Requesting LOCAL subpartition 1 of partition f45f0539b91a35f8f33f7e0d2d64813c@02de6f076d7957e472f6eb0edbd38dbf.
03/06/2020 13:13:33.735 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionManager] Requesting subpartition 1 of ReleaseOnConsumptionResultPartition f45f0539b91a35f8f33f7e0d2d64813c@02de6f076d7957e472f6eb0edbd38dbf [PIPELINED_BOUNDED, 2 subpartitions, 2 pending consumptions].
03/06/2020 13:13:33.735 DEBUG [org.apache.flink.runtime.io.network.partition.PipelinedSubpartition] GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (1/2) (02de6f076d7957e472f6eb0edbd38dbf): Creating read view for subpartition 1 of partition f45f0539b91a35f8f33f7e0d2d64813c@02de6f076d7957e472f6eb0edbd38dbf.
03/06/2020 13:13:33.735 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartition] Created PipelinedSubpartitionView(index: 1) of ResultPartition f45f0539b91a35f8f33f7e0d2d64813c@02de6f076d7957e472f6eb0edbd38dbf
03/06/2020 13:13:33.735 DEBUG [org.apache.flink.runtime.io.network.buffer.LocalBufferPool] Using a local buffer pool with 0-8 buffers
03/06/2020 13:13:33.735 DEBUG [org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel] LocalInputChannel [152d67b39c04e64fe5971bb597eb96e2@d74648705093b5c72e78e2c360e29713]: Requesting LOCAL subpartition 1 of partition 152d67b39c04e64fe5971bb597eb96e2@d74648705093b5c72e78e2c360e29713.
03/06/2020 13:13:33.735 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionManager] Requesting subpartition 1 of ReleaseOnConsumptionResultPartition 152d67b39c04e64fe5971bb597eb96e2@d74648705093b5c72e78e2c360e29713 [PIPELINED_BOUNDED, 2 subpartitions, 2 pending consumptions].
03/06/2020 13:13:33.735 DEBUG [org.apache.flink.runtime.io.network.partition.PipelinedSubpartition] Source: Collection Source -> SourceConversion(table=[Unregistered_DataStream_9], fields=[f0, f1, f2, f3, f4]) -> Calc(select=[f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y]) (1/1) (d74648705093b5c72e78e2c360e29713): Creating read view for subpartition 1 of partition 152d67b39c04e64fe5971bb597eb96e2@d74648705093b5c72e78e2c360e29713.
03/06/2020 13:13:33.735 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartition] Created PipelinedSubpartitionView(index: 1) of ResultPartition 152d67b39c04e64fe5971bb597eb96e2@d74648705093b5c72e78e2c360e29713
03/06/2020 13:13:33.736 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionManager] Requesting subpartition 0 of ReleaseOnConsumptionResultPartition 152d67b39c04e64fe5971bb597eb96e2@d74648705093b5c72e78e2c360e29713 [PIPELINED_BOUNDED, 2 subpartitions, 2 pending consumptions].
03/06/2020 13:13:33.736 DEBUG [org.apache.flink.runtime.io.network.partition.PipelinedSubpartition] Source: Collection Source -> SourceConversion(table=[Unregistered_DataStream_9], fields=[f0, f1, f2, f3, f4]) -> Calc(select=[f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y]) (1/1) (d74648705093b5c72e78e2c360e29713): Creating read view for subpartition 0 of partition 152d67b39c04e64fe5971bb597eb96e2@d74648705093b5c72e78e2c360e29713.
03/06/2020 13:13:33.736 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartition] Created PipelinedSubpartitionView(index: 0) of ResultPartition 152d67b39c04e64fe5971bb597eb96e2@d74648705093b5c72e78e2c360e29713
03/06/2020 13:13:33.736 DEBUG [org.apache.flink.runtime.io.network.TaskEventDispatcher] registering 37419b70f6b9f20c581859a2a6711084@27eb9406de3597496fd0bb48c5e876a5
03/06/2020 13:13:33.736 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionManager] Requesting subpartition 0 of ReleaseOnConsumptionResultPartition 37419b70f6b9f20c581859a2a6711084@27eb9406de3597496fd0bb48c5e876a5 [PIPELINED_BOUNDED, 1 subpartitions, 1 pending consumptions].
03/06/2020 13:13:33.736 DEBUG [org.apache.flink.runtime.io.network.partition.PipelinedSubpartition] Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (2/2) (27eb9406de3597496fd0bb48c5e876a5): Creating read view for subpartition 0 of partition 37419b70f6b9f20c581859a2a6711084@27eb9406de3597496fd0bb48c5e876a5.
03/06/2020 13:13:33.736 DEBUG [org.apache.flink.runtime.io.network.TaskEventDispatcher] registering 549697b480ed2892912b6fb269129087@6dfb6ce5559aca85d7e81c96224f4864
03/06/2020 13:13:33.736 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartition] Created PipelinedSubpartitionView(index: 0) of ResultPartition 37419b70f6b9f20c581859a2a6711084@27eb9406de3597496fd0bb48c5e876a5
03/06/2020 13:13:33.737  INFO [org.apache.flink.runtime.taskmanager.Task] Sink: Print to Std. Out (1/1) (26e0302ddaecd3150ec5345d3906b102) switched from DEPLOYING to RUNNING.
03/06/2020 13:13:33.737  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] Sink: Print to Std. Out (1/1) (26e0302ddaecd3150ec5345d3906b102) switched from DEPLOYING to RUNNING.
03/06/2020 13:13:33.738 DEBUG [org.apache.flink.streaming.runtime.tasks.StreamTask] Initializing Sink: Print to Std. Out (1/1).
03/06/2020 13:13:33.738  INFO [org.apache.flink.streaming.runtime.tasks.StreamTask] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
03/06/2020 13:13:33.744 DEBUG [org.apache.flink.streaming.runtime.tasks.StreamTask] Using partitioner REBALANCE for output 0 of task Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed
03/06/2020 13:13:33.745 DEBUG [org.apache.flink.streaming.runtime.tasks.StreamTask] Using partitioner REBALANCE for output 0 of task Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed
03/06/2020 13:13:33.754  INFO [org.apache.flink.runtime.taskmanager.Task] Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (2/2) (27eb9406de3597496fd0bb48c5e876a5) switched from DEPLOYING to RUNNING.
03/06/2020 13:13:33.755 DEBUG [org.apache.flink.streaming.runtime.tasks.StreamTask] Initializing Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (2/2).
03/06/2020 13:13:33.755  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (2/2) (27eb9406de3597496fd0bb48c5e876a5) switched from DEPLOYING to RUNNING.
03/06/2020 13:13:33.755  INFO [org.apache.flink.streaming.runtime.tasks.StreamTask] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
03/06/2020 13:13:33.757  INFO [org.apache.flink.runtime.taskmanager.Task] Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (1/2) (6dfb6ce5559aca85d7e81c96224f4864) switched from DEPLOYING to RUNNING.
03/06/2020 13:13:33.758 DEBUG [org.apache.flink.streaming.runtime.tasks.StreamTask] Initializing Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (1/2).
03/06/2020 13:13:33.758  INFO [org.apache.flink.streaming.runtime.tasks.StreamTask] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
03/06/2020 13:13:33.758  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (1/2) (6dfb6ce5559aca85d7e81c96224f4864) switched from DEPLOYING to RUNNING.
03/06/2020 13:13:33.780 DEBUG [org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel] LocalInputChannel [4a4d2bc06a45d34db956e3a272eab10a@1ff6ef243e2fa7b8aa3f13605b545e75]: Requesting LOCAL subpartition 0 of partition 4a4d2bc06a45d34db956e3a272eab10a@1ff6ef243e2fa7b8aa3f13605b545e75.
03/06/2020 13:13:33.781 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionManager] Requesting subpartition 0 of ReleaseOnConsumptionResultPartition 4a4d2bc06a45d34db956e3a272eab10a@1ff6ef243e2fa7b8aa3f13605b545e75 [PIPELINED_BOUNDED, 2 subpartitions, 2 pending consumptions].
03/06/2020 13:13:33.781 DEBUG [org.apache.flink.runtime.io.network.partition.PipelinedSubpartition] GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (2/2) (1ff6ef243e2fa7b8aa3f13605b545e75): Creating read view for subpartition 0 of partition 4a4d2bc06a45d34db956e3a272eab10a@1ff6ef243e2fa7b8aa3f13605b545e75.
03/06/2020 13:13:33.781 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartition] Created PipelinedSubpartitionView(index: 0) of ResultPartition 4a4d2bc06a45d34db956e3a272eab10a@1ff6ef243e2fa7b8aa3f13605b545e75
03/06/2020 13:13:33.789  WARN [org.apache.flink.metrics.MetricGroup] The operator name GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) exceeded the 80 characters length limit and was truncated.
03/06/2020 13:13:33.791 DEBUG [org.apache.flink.table.runtime.generated.CompileUtils] Compiling: SinkConversion$154 

 Code:

      public class SinkConversion$154 extends org.apache.flink.table.runtime.operators.TableStreamOperator
          implements org.apache.flink.streaming.api.operators.OneInputStreamOperator {

        private final Object[] references;
        private transient org.apache.flink.table.dataformat.DataFormatConverters.RowConverter converter$152;
        private final org.apache.flink.streaming.runtime.streamrecord.StreamRecord outElement = new org.apache.flink.streaming.runtime.streamrecord.StreamRecord(null);

        public SinkConversion$154(
            Object[] references,
            org.apache.flink.streaming.runtime.tasks.StreamTask task,
            org.apache.flink.streaming.api.graph.StreamConfig config,
            org.apache.flink.streaming.api.operators.Output output) throws Exception {
          this.references = references;
          converter$152 = (((org.apache.flink.table.dataformat.DataFormatConverters.RowConverter) references[0]));
          this.setup(task, config, output);
        }

        @Override
        public void open() throws Exception {
          super.open();
          
        }

        @Override
        public void processElement(org.apache.flink.streaming.runtime.streamrecord.StreamRecord element) throws Exception {
          org.apache.flink.table.dataformat.BaseRow in1 = (org.apache.flink.table.dataformat.BaseRow) element.getValue();
          
          
          
          
          
          
          org.apache.flink.api.java.tuple.Tuple2 result$153 = new org.apache.flink.api.java.tuple.Tuple2();
          result$153.setField(org.apache.flink.table.dataformat.util.BaseRowUtil.isAccumulateMsg(in1), 0);
          result$153.setField((org.apache.flink.types.Row) converter$152.toExternal((org.apache.flink.table.dataformat.BaseRow) in1), 1);
          output.collect(outElement.replace(result$153));
                   
          
        }

        

        @Override
        public void close() throws Exception {
           super.close();
          
        }

        
      }
    
03/06/2020 13:13:33.789  WARN [org.apache.flink.metrics.MetricGroup] The operator name GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) exceeded the 80 characters length limit and was truncated.
03/06/2020 13:13:33.793 DEBUG [org.apache.flink.table.runtime.generated.CompileUtils] Compiling: SourceConversion$60 

 Code:

      public class SourceConversion$60 extends org.apache.flink.table.runtime.operators.AbstractProcessStreamOperator
          implements org.apache.flink.streaming.api.operators.OneInputStreamOperator {

        private final Object[] references;
        private transient org.apache.flink.table.dataformat.DataFormatConverters.TupleConverter converter$59;
        private final org.apache.flink.streaming.runtime.streamrecord.StreamRecord outElement = new org.apache.flink.streaming.runtime.streamrecord.StreamRecord(null);

        public SourceConversion$60(
            Object[] references,
            org.apache.flink.streaming.runtime.tasks.StreamTask task,
            org.apache.flink.streaming.api.graph.StreamConfig config,
            org.apache.flink.streaming.api.operators.Output output) throws Exception {
          this.references = references;
          converter$59 = (((org.apache.flink.table.dataformat.DataFormatConverters.TupleConverter) references[0]));
          this.setup(task, config, output);
        }

        @Override
        public void open() throws Exception {
          super.open();
          
        }

        @Override
        public void processElement(org.apache.flink.streaming.runtime.streamrecord.StreamRecord element) throws Exception {
          org.apache.flink.table.dataformat.BaseRow in1 = (org.apache.flink.table.dataformat.BaseRow) (org.apache.flink.table.dataformat.BaseRow) converter$59.toInternal((org.apache.flink.api.java.tuple.Tuple3) element.getValue());
          
          
          
          output.collect(outElement.replace(in1));
        }

        

        @Override
        public void close() throws Exception {
           super.close();
          
        }

        
      }
    
03/06/2020 13:13:33.800 DEBUG [org.apache.flink.table.runtime.generated.CompileUtils] Compiling: StreamExecCalc$18 

 Code:

      public class StreamExecCalc$18 extends org.apache.flink.table.runtime.operators.AbstractProcessStreamOperator
          implements org.apache.flink.streaming.api.operators.OneInputStreamOperator {

        private final Object[] references;
        final org.apache.flink.table.dataformat.BoxedWrapperRow out = new org.apache.flink.table.dataformat.BoxedWrapperRow(2);
        private final org.apache.flink.streaming.runtime.streamrecord.StreamRecord outElement = new org.apache.flink.streaming.runtime.streamrecord.StreamRecord(null);

        public StreamExecCalc$18(
            Object[] references,
            org.apache.flink.streaming.runtime.tasks.StreamTask task,
            org.apache.flink.streaming.api.graph.StreamConfig config,
            org.apache.flink.streaming.api.operators.Output output) throws Exception {
          this.references = references;
          
          this.setup(task, config, output);
        }

        @Override
        public void open() throws Exception {
          super.open();
          
        }

        @Override
        public void processElement(org.apache.flink.streaming.runtime.streamrecord.StreamRecord element) throws Exception {
          org.apache.flink.table.dataformat.BaseRow in1 = (org.apache.flink.table.dataformat.BaseRow) element.getValue();
          
          
          
          
          
          
          out.setHeader(in1.getHeader());
          
          
          
          
          if (in1.isNullAt(1)) {
            out.setNullAt(1);
          } else {
            out.setNonPrimitiveValue(1, in1.getRow(1, 1));
          }
                    
          
          
          if (in1.isNullAt(0)) {
            out.setNullAt(0);
          } else {
            out.setNonPrimitiveValue(0, in1.getString(0));
          }
                    
                  
          output.collect(outElement.replace(out));
          
          
        }

        

        @Override
        public void close() throws Exception {
           super.close();
          
        }

        
      }
    
03/06/2020 13:13:33.801 DEBUG [org.apache.flink.table.runtime.generated.CompileUtils] Compiling: SourceConversion$1 

 Code:

      public class SourceConversion$1 extends org.apache.flink.table.runtime.operators.AbstractProcessStreamOperator
          implements org.apache.flink.streaming.api.operators.OneInputStreamOperator {

        private final Object[] references;
        private transient org.apache.flink.table.dataformat.DataFormatConverters.RowConverter converter$0;
        private final org.apache.flink.streaming.runtime.streamrecord.StreamRecord outElement = new org.apache.flink.streaming.runtime.streamrecord.StreamRecord(null);

        public SourceConversion$1(
            Object[] references,
            org.apache.flink.streaming.runtime.tasks.StreamTask task,
            org.apache.flink.streaming.api.graph.StreamConfig config,
            org.apache.flink.streaming.api.operators.Output output) throws Exception {
          this.references = references;
          converter$0 = (((org.apache.flink.table.dataformat.DataFormatConverters.RowConverter) references[0]));
          this.setup(task, config, output);
        }

        @Override
        public void open() throws Exception {
          super.open();
          
        }

        @Override
        public void processElement(org.apache.flink.streaming.runtime.streamrecord.StreamRecord element) throws Exception {
          org.apache.flink.table.dataformat.BaseRow in1 = (org.apache.flink.table.dataformat.BaseRow) (org.apache.flink.table.dataformat.BaseRow) converter$0.toInternal((org.apache.flink.types.Row) element.getValue());
          
          
          
          output.collect(outElement.replace(in1));
        }

        

        @Override
        public void close() throws Exception {
           super.close();
          
        }

        
      }
    
03/06/2020 13:13:33.821 DEBUG [org.apache.flink.table.runtime.generated.CompileUtils] Compiling: SourceConversion$128 

 Code:

      public class SourceConversion$128 extends org.apache.flink.table.runtime.operators.AbstractProcessStreamOperator
          implements org.apache.flink.streaming.api.operators.OneInputStreamOperator {

        private final Object[] references;
        private transient org.apache.flink.table.dataformat.DataFormatConverters.TupleConverter converter$127;
        private final org.apache.flink.streaming.runtime.streamrecord.StreamRecord outElement = new org.apache.flink.streaming.runtime.streamrecord.StreamRecord(null);

        public SourceConversion$128(
            Object[] references,
            org.apache.flink.streaming.runtime.tasks.StreamTask task,
            org.apache.flink.streaming.api.graph.StreamConfig config,
            org.apache.flink.streaming.api.operators.Output output) throws Exception {
          this.references = references;
          converter$127 = (((org.apache.flink.table.dataformat.DataFormatConverters.TupleConverter) references[0]));
          this.setup(task, config, output);
        }

        @Override
        public void open() throws Exception {
          super.open();
          
        }

        @Override
        public void processElement(org.apache.flink.streaming.runtime.streamrecord.StreamRecord element) throws Exception {
          org.apache.flink.table.dataformat.BaseRow in1 = (org.apache.flink.table.dataformat.BaseRow) (org.apache.flink.table.dataformat.BaseRow) converter$127.toInternal((org.apache.flink.api.java.tuple.Tuple5) element.getValue());
          
          
          
          output.collect(outElement.replace(in1));
        }

        

        @Override
        public void close() throws Exception {
           super.close();
          
        }

        
      }
    
03/06/2020 13:13:33.822 DEBUG [org.apache.flink.table.runtime.generated.CompileUtils] Compiling: StreamExecCalc$151 

 Code:

      public class StreamExecCalc$151 extends org.apache.flink.table.runtime.operators.AbstractProcessStreamOperator
          implements org.apache.flink.streaming.api.operators.OneInputStreamOperator {

        private final Object[] references;
        final org.apache.flink.table.dataformat.BoxedWrapperRow out = new org.apache.flink.table.dataformat.BoxedWrapperRow(6);
        private final org.apache.flink.streaming.runtime.streamrecord.StreamRecord outElement = new org.apache.flink.streaming.runtime.streamrecord.StreamRecord(null);

        public StreamExecCalc$151(
            Object[] references,
            org.apache.flink.streaming.runtime.tasks.StreamTask task,
            org.apache.flink.streaming.api.graph.StreamConfig config,
            org.apache.flink.streaming.api.operators.Output output) throws Exception {
          this.references = references;
          
          this.setup(task, config, output);
        }

        @Override
        public void open() throws Exception {
          super.open();
          
        }

        @Override
        public void processElement(org.apache.flink.streaming.runtime.streamrecord.StreamRecord element) throws Exception {
          org.apache.flink.table.dataformat.BaseRow in1 = (org.apache.flink.table.dataformat.BaseRow) element.getValue();
          
          
          
          
          
          
          out.setHeader(in1.getHeader());
          
          
          
          
          if (in1.isNullAt(3)) {
            out.setNullAt(0);
          } else {
            out.setNonPrimitiveValue(0, in1.getString(3));
          }
                    
          
          
          if (in1.isNullAt(5)) {
            out.setNullAt(1);
          } else {
            out.setNonPrimitiveValue(1, in1.getString(5));
          }
                    
          
          
          if (in1.isNullAt(6)) {
            out.setNullAt(2);
          } else {
            out.setNonPrimitiveValue(2, in1.getString(6));
          }
                    
          
          
          if (in1.isNullAt(1)) {
            out.setNullAt(4);
          } else {
            out.setNonPrimitiveValue(4, in1.getString(1));
          }
                    
          
          
          if (in1.isNullAt(0)) {
            out.setNullAt(5);
          } else {
            out.setNonPrimitiveValue(5, in1.getString(0));
          }
                    
          
          
          if (in1.isNullAt(4)) {
            out.setNullAt(3);
          } else {
            out.setInt(3, in1.getInt(4));
          }
                    
                  
          output.collect(outElement.replace(out));
          
          
        }

        

        @Override
        public void close() throws Exception {
           super.close();
          
        }

        
      }
    
03/06/2020 13:13:33.826 DEBUG [org.apache.flink.streaming.runtime.tasks.StreamTask] Invoking GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (1/2)
03/06/2020 13:13:33.826 DEBUG [org.apache.flink.streaming.runtime.tasks.StreamTask] Invoking Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (2/2)
03/06/2020 13:13:33.827 DEBUG [org.apache.flink.streaming.runtime.tasks.StreamTask] Invoking GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (2/2)
03/06/2020 13:13:33.828 DEBUG [org.apache.flink.streaming.runtime.tasks.StreamTask] Invoking Sink: Print to Std. Out (1/1)
03/06/2020 13:13:33.829 DEBUG [org.apache.flink.streaming.runtime.tasks.StreamTask] Invoking Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (1/2)
03/06/2020 13:13:33.832 DEBUG [org.apache.flink.streaming.runtime.tasks.StreamTask] Invoking SortLimit(orderBy=[degree DESC], offset=[0], fetch=[10]) -> Calc(select=[id, cf]) -> SinkConversionToTuple2 (1/1)
03/06/2020 13:13:33.834 DEBUG [org.apache.flink.streaming.runtime.tasks.StreamTask] Invoking Source: Collection Source -> SourceConversion(table=[Unregistered_DataStream_9], fields=[f0, f1, f2, f3, f4]) -> Calc(select=[f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y]) (1/1)
03/06/2020 13:13:33.840  WARN [org.apache.flink.metrics.MetricGroup] The operator name SourceConversion(table=[default_catalog.default_database.loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]], fields=[id, cf]) exceeded the 80 characters length limit and was truncated.
03/06/2020 13:13:33.841  WARN [org.apache.flink.metrics.MetricGroup] The operator name SourceConversion(table=[default_catalog.default_database.loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]], fields=[id, cf]) exceeded the 80 characters length limit and was truncated.
03/06/2020 13:13:33.842 DEBUG [org.apache.flink.streaming.runtime.tasks.StreamTask] Invoking Source: HBaseTableSource[schema=[id, cf], projectFields=null] -> SourceConversion(table=[default_catalog.default_database.loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]], fields=[id, cf]) -> Calc(select=[id, cf, cf.degree AS degree]) (2/2)
03/06/2020 13:13:33.843 DEBUG [org.apache.flink.streaming.runtime.tasks.StreamTask] Invoking Source: HBaseTableSource[schema=[id, cf], projectFields=null] -> SourceConversion(table=[default_catalog.default_database.loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]], fields=[id, cf]) -> Calc(select=[id, cf, cf.degree AS degree]) (1/2)
03/06/2020 13:13:33.844  WARN [org.apache.flink.metrics.MetricGroup] The operator name Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) exceeded the 80 characters length limit and was truncated.
03/06/2020 13:13:33.847  WARN [org.apache.flink.metrics.MetricGroup] The operator name Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) exceeded the 80 characters length limit and was truncated.
03/06/2020 13:13:33.850 DEBUG [org.apache.flink.streaming.api.operators.BackendRestorerProcedure] Creating operator state backend for StreamSink_97062323b8add791924e501dd08b481e_(1/1) with empty state.
03/06/2020 13:13:33.851 DEBUG [org.apache.flink.streaming.api.operators.BackendRestorerProcedure] Creating operator state backend for StreamExecCalc$10_961f812b71e0974941c334fd7d5c8da9_(2/2) with empty state.
03/06/2020 13:13:33.851 DEBUG [org.apache.flink.streaming.api.operators.BackendRestorerProcedure] Creating operator state backend for StreamExecCalc$125_5971f78eebd3a74273268ccf78e1350c_(2/2) with empty state.
03/06/2020 13:13:33.852 DEBUG [org.apache.flink.streaming.api.operators.BackendRestorerProcedure] Creating operator state backend for StreamExecCalc$125_5971f78eebd3a74273268ccf78e1350c_(1/2) with empty state.
03/06/2020 13:13:33.852 DEBUG [org.apache.flink.streaming.api.operators.BackendRestorerProcedure] Creating operator state backend for StreamExecCalc$10_961f812b71e0974941c334fd7d5c8da9_(1/2) with empty state.
03/06/2020 13:13:33.854 DEBUG [org.apache.flink.streaming.api.operators.BackendRestorerProcedure] Creating operator state backend for SinkConversion$21_36762bf1d2ec1b7aa259957f5c1fbec3_(1/1) with empty state.
03/06/2020 13:13:33.855 DEBUG [org.apache.flink.streaming.api.operators.BackendRestorerProcedure] Creating operator state backend for StreamExecCalc$71_9df84b442478cb434a0b4172c7682204_(1/2) with empty state.
03/06/2020 13:13:33.856 DEBUG [org.apache.flink.streaming.api.operators.BackendRestorerProcedure] Creating operator state backend for StreamExecCalc$71_9df84b442478cb434a0b4172c7682204_(2/2) with empty state.
03/06/2020 13:13:33.856 DEBUG [org.apache.flink.streaming.api.operators.BackendRestorerProcedure] Creating operator state backend for StreamExecCalc$144_82c4a6eead942893d0c01a3775161323_(1/1) with empty state.
03/06/2020 13:13:33.871 DEBUG [org.apache.flink.streaming.runtime.tasks.StreamTask] Invoking Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (2/2)
03/06/2020 13:13:33.871 DEBUG [org.apache.flink.streaming.api.operators.BackendRestorerProcedure] Creating operator state backend for StreamSink_578e2203407d7922d27ba52d4fe96b11_(2/2) with empty state.
03/06/2020 13:13:33.873 DEBUG [org.apache.flink.streaming.runtime.tasks.StreamTask] Invoking Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (1/2)
03/06/2020 13:13:33.873 DEBUG [org.apache.flink.streaming.api.operators.BackendRestorerProcedure] Creating operator state backend for StreamSink_578e2203407d7922d27ba52d4fe96b11_(1/2) with empty state.
03/06/2020 13:13:33.874 DEBUG [org.apache.flink.streaming.api.operators.BackendRestorerProcedure] Creating operator state backend for SourceConversion$128_19894d47902564dfbf88a679e52ed49e_(1/1) with empty state.
03/06/2020 13:13:33.875 DEBUG [org.apache.flink.streaming.api.operators.BackendRestorerProcedure] Creating operator state backend for StreamSource_6cdc5bb954874d922eaee11a8e7b5dd5_(1/1) with empty state.
03/06/2020 13:13:33.876 DEBUG [org.apache.flink.streaming.api.operators.BackendRestorerProcedure] Creating keyed state backend for KeyedProcessOperator_db7de5d6d7db9354bd8e4698740f442c_(1/2) with empty state.
03/06/2020 13:13:33.876 DEBUG [org.apache.flink.streaming.api.operators.BackendRestorerProcedure] Creating keyed state backend for KeyedProcessOperator_db7de5d6d7db9354bd8e4698740f442c_(2/2) with empty state.
03/06/2020 13:13:33.885 DEBUG [org.apache.flink.streaming.api.operators.BackendRestorerProcedure] Creating operator state backend for SourceConversion$1_268c6e26884db845b34fbed5b355f2be_(1/2) with empty state.
03/06/2020 13:13:33.886 DEBUG [org.apache.flink.streaming.api.operators.BackendRestorerProcedure] Creating operator state backend for SourceConversion$60_cea40dfef71ba11303db8931523861e0_(2/2) with empty state.
03/06/2020 13:13:33.887 DEBUG [org.apache.flink.streaming.api.operators.BackendRestorerProcedure] Creating operator state backend for StreamMap_730748a2d3477923527d4df19c1115d3_(2/2) with empty state.
03/06/2020 13:13:33.886 DEBUG [org.apache.flink.streaming.api.operators.BackendRestorerProcedure] Creating operator state backend for StreamSource_cbc357ccb763df2852fee8c4fc7d55f2_(1/2) with empty state.
03/06/2020 13:13:33.887 DEBUG [org.apache.flink.streaming.api.operators.BackendRestorerProcedure] Creating operator state backend for SourceConversion$60_cea40dfef71ba11303db8931523861e0_(1/2) with empty state.
03/06/2020 13:13:33.887 DEBUG [org.apache.flink.streaming.api.operators.BackendRestorerProcedure] Creating operator state backend for SourceConversion$1_268c6e26884db845b34fbed5b355f2be_(2/2) with empty state.
03/06/2020 13:13:33.891 DEBUG [org.apache.flink.streaming.api.operators.BackendRestorerProcedure] Creating operator state backend for StreamMap_730748a2d3477923527d4df19c1115d3_(1/2) with empty state.
03/06/2020 13:13:33.891 DEBUG [org.apache.flink.streaming.api.operators.BackendRestorerProcedure] Creating operator state backend for StreamSource_cbc357ccb763df2852fee8c4fc7d55f2_(2/2) with empty state.
03/06/2020 13:13:33.891  INFO [org.apache.flink.addons.hbase.HBaseRowInputFormat] Initializing HBase configuration.
03/06/2020 13:13:33.887 DEBUG [org.apache.flink.streaming.api.operators.BackendRestorerProcedure] Creating operator state backend for StreamExecCalc$18_c2b501861aaae10089171c0c9a4cc810_(1/1) with empty state.
03/06/2020 13:13:33.891  INFO [org.apache.flink.addons.hbase.HBaseRowInputFormat] Initializing HBase configuration.
03/06/2020 13:13:33.893 DEBUG [org.apache.flink.streaming.api.operators.BackendRestorerProcedure] Creating keyed state backend for KeyedProcessOperator_57df6b5c78b46bc5e7b8e2b883e729a9_(1/1) with empty state.
03/06/2020 13:13:33.931 DEBUG [org.apache.flink.core.fs.FileSystem] Loading extension file systems via services
03/06/2020 13:13:33.951 DEBUG [org.apache.flink.table.runtime.generated.CompileUtils] Compiling: KeyProjection$145 

 Code:

public class KeyProjection$145 implements org.apache.flink.table.runtime.generated.Projection<org.apache.flink.table.dataformat.BaseRow, org.apache.flink.table.dataformat.BinaryRow> {

  final org.apache.flink.table.dataformat.BinaryRow out = new org.apache.flink.table.dataformat.BinaryRow(1);
final org.apache.flink.table.dataformat.BinaryRowWriter outWriter = new org.apache.flink.table.dataformat.BinaryRowWriter(out);

  public KeyProjection$145(Object[] references) throws Exception {
    
  }

  @Override
  public org.apache.flink.table.dataformat.BinaryRow apply(org.apache.flink.table.dataformat.BaseRow in1) {
    
    

outWriter.reset();


if (in1.isNullAt(0)) {
  outWriter.setNullAt(0);
} else {
  outWriter.writeString(0, in1.getString(0));
}
             
outWriter.complete();
        
    return out;
  }
}
        
03/06/2020 13:13:33.954  INFO [org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper] Process identifier=hconnection-0x5349142 connecting to ZooKeeper ensemble=localhost:2181
03/06/2020 13:13:33.954  INFO [org.apache.zookeeper.ZooKeeper] Initiating client connection, connectString=localhost:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.PendingWatcher@51235b3e
03/06/2020 13:13:33.965 DEBUG [org.apache.flink.streaming.api.operators.BackendRestorerProcedure] Creating operator state backend for StreamMap_db0ae7f16fcd52af04330fcbb25ead52_(2/2) with empty state.
03/06/2020 13:13:33.966 DEBUG [org.apache.flink.streaming.api.operators.BackendRestorerProcedure] Creating operator state backend for SinkConversion$154_4a29f77aa6210388e24ffaa2e359aff7_(2/2) with empty state.
03/06/2020 13:13:33.966 DEBUG [org.apache.flink.streaming.api.operators.BackendRestorerProcedure] Creating operator state backend for StreamExecCalc$151_851ae0001e60ebfeff9a92d797f0e8a5_(2/2) with empty state.
03/06/2020 13:13:33.966 DEBUG [org.apache.flink.streaming.api.operators.BackendRestorerProcedure] Creating keyed state backend for StreamingJoinOperator_2da5af51bbd1dbb7a2c205b96fe7a428_(2/2) with empty state.
03/06/2020 13:13:33.969  INFO [org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper] Process identifier=hconnection-0x31475611 connecting to ZooKeeper ensemble=localhost:2181
03/06/2020 13:13:33.969  INFO [org.apache.zookeeper.ZooKeeper] Initiating client connection, connectString=localhost:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.PendingWatcher@6915bfa7
03/06/2020 13:13:33.969  INFO [org.apache.flink.runtime.state.heap.HeapKeyedStateBackend] Initializing heap keyed state backend with stream factory.
03/06/2020 13:13:33.969 DEBUG [org.apache.flink.streaming.api.operators.BackendRestorerProcedure] Creating operator state backend for KeyedProcessOperator_57df6b5c78b46bc5e7b8e2b883e729a9_(1/1) with empty state.
03/06/2020 13:13:33.969  INFO [org.apache.flink.runtime.state.heap.HeapKeyedStateBackend] Initializing heap keyed state backend with stream factory.
03/06/2020 13:13:33.970 DEBUG [org.apache.flink.streaming.api.operators.BackendRestorerProcedure] Creating operator state backend for StreamingJoinOperator_2da5af51bbd1dbb7a2c205b96fe7a428_(2/2) with empty state.
03/06/2020 13:13:33.970  INFO [org.apache.flink.runtime.state.heap.HeapKeyedStateBackend] Initializing heap keyed state backend with stream factory.
03/06/2020 13:13:33.970 DEBUG [org.apache.flink.streaming.api.operators.BackendRestorerProcedure] Creating operator state backend for KeyedProcessOperator_db7de5d6d7db9354bd8e4698740f442c_(1/2) with empty state.
03/06/2020 13:13:33.970  INFO [org.apache.flink.runtime.state.heap.HeapKeyedStateBackend] Initializing heap keyed state backend with stream factory.
03/06/2020 13:13:33.970 DEBUG [org.apache.flink.streaming.api.operators.BackendRestorerProcedure] Creating operator state backend for KeyedProcessOperator_db7de5d6d7db9354bd8e4698740f442c_(2/2) with empty state.
03/06/2020 13:13:33.971 DEBUG [org.apache.flink.streaming.api.operators.BackendRestorerProcedure] Creating operator state backend for StreamMap_db0ae7f16fcd52af04330fcbb25ead52_(1/2) with empty state.
03/06/2020 13:13:33.971 DEBUG [org.apache.flink.streaming.api.operators.BackendRestorerProcedure] Creating operator state backend for SinkConversion$154_4a29f77aa6210388e24ffaa2e359aff7_(1/2) with empty state.
03/06/2020 13:13:33.971 DEBUG [org.apache.flink.streaming.api.operators.BackendRestorerProcedure] Creating operator state backend for StreamExecCalc$151_851ae0001e60ebfeff9a92d797f0e8a5_(1/2) with empty state.
03/06/2020 13:13:33.971 DEBUG [org.apache.flink.streaming.api.operators.BackendRestorerProcedure] Creating keyed state backend for StreamingJoinOperator_2da5af51bbd1dbb7a2c205b96fe7a428_(1/2) with empty state.
03/06/2020 13:13:33.971  INFO [org.apache.flink.runtime.state.heap.HeapKeyedStateBackend] Initializing heap keyed state backend with stream factory.
03/06/2020 13:13:33.972 DEBUG [org.apache.flink.streaming.api.operators.BackendRestorerProcedure] Creating operator state backend for StreamingJoinOperator_2da5af51bbd1dbb7a2c205b96fe7a428_(1/2) with empty state.
03/06/2020 13:13:33.976 DEBUG [org.apache.flink.table.runtime.generated.CompileUtils] Compiling: ConditionFunction$149 

 Code:

      public class ConditionFunction$149 extends org.apache.flink.api.common.functions.AbstractRichFunction
          implements org.apache.flink.table.runtime.generated.JoinCondition {

        

        public ConditionFunction$149(Object[] references) throws Exception {
          
        }

        

        @Override
        public void open(org.apache.flink.configuration.Configuration parameters) throws Exception {
          
        }

        @Override
        public boolean apply(org.apache.flink.table.dataformat.BaseRow in1, org.apache.flink.table.dataformat.BaseRow in2) throws Exception {
          
          
          
          return true;
        }

        @Override
        public void close() throws Exception {
          super.close();
          
        }
      }
     
03/06/2020 13:13:33.977 DEBUG [org.apache.flink.table.runtime.generated.CompileUtils] Compiling: StreamExecSortComparator$12 

 Code:

      public class StreamExecSortComparator$12 implements org.apache.flink.table.runtime.generated.RecordComparator {

        private final Object[] references;
        

        public StreamExecSortComparator$12(Object[] references) {
          this.references = references;
          
          
        }

        @Override
        public int compare(org.apache.flink.table.dataformat.BaseRow o1, org.apache.flink.table.dataformat.BaseRow o2) {
          
          boolean isNullA$14 = o1.isNullAt(0);
          boolean isNullB$16 = o2.isNullAt(0);
          if (isNullA$14 && isNullB$16) {
            // Continue to compare the next element
          } else if (isNullA$14) {
            return 1;
          } else if (isNullB$16) {
            return -1;
          } else {
            int fieldA$13 = o1.getInt(0);
            int fieldB$15 = o2.getInt(0);
            int comp$17 = (fieldA$13 > fieldB$15 ? 1 : fieldA$13 < fieldB$15 ? -1 : 0);
            if (comp$17 != 0) {
              return -comp$17;
            }
          }
                   
          return 0;
        }

      }
      
03/06/2020 13:13:33.976 DEBUG [org.apache.flink.table.runtime.generated.CompileUtils] Compiling: GroupAggsHandler$99 

 Code:

        public final class GroupAggsHandler$99 implements org.apache.flink.table.runtime.generated.AggsHandleFunction {

          private transient aljoschaRydzyk.Gradoop_Flink_Prototype.MatchDegreeChoice$CurrentVertex function_aljoschaRydzyk$Gradoop_Flink_Prototype$MatchDegreeChoice$CurrentVertex$3d0463f5434850ea9bb43ad6f64954bb;
          private transient org.apache.flink.table.dataformat.DataFormatConverters.GenericConverter converter$73;
          private transient org.apache.flink.table.dataformat.DataFormatConverters.GenericConverter converter$76;
          private org.apache.flink.table.dataformat.BinaryGeneric agg0_acc_internal;
          private aljoschaRydzyk.Gradoop_Flink_Prototype.MatchDegreeChoice.VertexAccum agg0_acc_external;
          private transient org.apache.flink.table.dataformat.DataFormatConverters.GenericConverter converter$79;
          private transient org.apache.flink.table.dataformat.DataFormatConverters.GenericConverter converter$80;
          private transient org.apache.flink.table.runtime.typeutils.BinaryStringSerializer typeSerializer$82;
          private transient org.apache.flink.table.dataformat.DataFormatConverters.StringConverter converter$85;
          private transient org.apache.flink.table.dataformat.DataFormatConverters.StringConverter converter$89;
          private transient org.apache.flink.table.dataformat.DataFormatConverters.StringConverter converter$93;
          private transient org.apache.flink.table.dataformat.DataFormatConverters.TupleConverter converter$97;

          public GroupAggsHandler$99(java.lang.Object[] references) throws Exception {
            function_aljoschaRydzyk$Gradoop_Flink_Prototype$MatchDegreeChoice$CurrentVertex$3d0463f5434850ea9bb43ad6f64954bb = (((aljoschaRydzyk.Gradoop_Flink_Prototype.MatchDegreeChoice$CurrentVertex) references[0]));
            converter$73 = (((org.apache.flink.table.dataformat.DataFormatConverters.GenericConverter) references[1]));
            converter$76 = (((org.apache.flink.table.dataformat.DataFormatConverters.GenericConverter) references[2]));
            converter$79 = (((org.apache.flink.table.dataformat.DataFormatConverters.GenericConverter) references[3]));
            converter$80 = (((org.apache.flink.table.dataformat.DataFormatConverters.GenericConverter) references[4]));
            typeSerializer$82 = (((org.apache.flink.table.runtime.typeutils.BinaryStringSerializer) references[5]));
            converter$85 = (((org.apache.flink.table.dataformat.DataFormatConverters.StringConverter) references[6]));
            converter$89 = (((org.apache.flink.table.dataformat.DataFormatConverters.StringConverter) references[7]));
            converter$93 = (((org.apache.flink.table.dataformat.DataFormatConverters.StringConverter) references[8]));
            converter$97 = (((org.apache.flink.table.dataformat.DataFormatConverters.TupleConverter) references[9]));
          }

          @Override
          public void open(org.apache.flink.table.runtime.dataview.StateDataViewStore store) throws Exception {
            
            function_aljoschaRydzyk$Gradoop_Flink_Prototype$MatchDegreeChoice$CurrentVertex$3d0463f5434850ea9bb43ad6f64954bb.open(new org.apache.flink.table.functions.FunctionContext(store.getRuntimeContext()));
                   
          }

          @Override
          public void accumulate(org.apache.flink.table.dataformat.BaseRow accInput) throws Exception {
            
            org.apache.flink.table.dataformat.BinaryString field$81;
            boolean isNull$81;
            org.apache.flink.table.dataformat.BinaryString field$83;
            org.apache.flink.table.dataformat.BinaryString field$84;
            org.apache.flink.table.dataformat.BinaryString field$86;
            boolean isNull$86;
            org.apache.flink.table.dataformat.BinaryString field$87;
            org.apache.flink.table.dataformat.BinaryString field$88;
            org.apache.flink.table.dataformat.BinaryString field$90;
            boolean isNull$90;
            org.apache.flink.table.dataformat.BinaryString field$91;
            org.apache.flink.table.dataformat.BinaryString field$92;
            isNull$90 = accInput.isNullAt(2);
            field$90 = org.apache.flink.table.dataformat.BinaryString.EMPTY_UTF8;
            if (!isNull$90) {
              field$90 = accInput.getString(2);
            }
            field$91 = field$90;
            if (!isNull$90) {
              field$91 = (org.apache.flink.table.dataformat.BinaryString) (typeSerializer$82.copy(field$91));
            }
                    
            
            isNull$81 = accInput.isNullAt(0);
            field$81 = org.apache.flink.table.dataformat.BinaryString.EMPTY_UTF8;
            if (!isNull$81) {
              field$81 = accInput.getString(0);
            }
            field$83 = field$81;
            if (!isNull$81) {
              field$83 = (org.apache.flink.table.dataformat.BinaryString) (typeSerializer$82.copy(field$83));
            }
                    
            
            isNull$86 = accInput.isNullAt(1);
            field$86 = org.apache.flink.table.dataformat.BinaryString.EMPTY_UTF8;
            if (!isNull$86) {
              field$86 = accInput.getString(1);
            }
            field$87 = field$86;
            if (!isNull$86) {
              field$87 = (org.apache.flink.table.dataformat.BinaryString) (typeSerializer$82.copy(field$87));
            }
            
            
            
            field$84 = field$83;
            if (!isNull$81) {
              field$84 = (org.apache.flink.table.dataformat.BinaryString) (typeSerializer$82.copy(field$84));
            }
                    
            
            
            field$88 = field$87;
            if (!isNull$86) {
              field$88 = (org.apache.flink.table.dataformat.BinaryString) (typeSerializer$82.copy(field$88));
            }
                    
            
            
            field$92 = field$91;
            if (!isNull$90) {
              field$92 = (org.apache.flink.table.dataformat.BinaryString) (typeSerializer$82.copy(field$92));
            }
                    
            function_aljoschaRydzyk$Gradoop_Flink_Prototype$MatchDegreeChoice$CurrentVertex$3d0463f5434850ea9bb43ad6f64954bb.accumulate(agg0_acc_external, isNull$81 ? null : (java.lang.String) converter$85.toExternal((org.apache.flink.table.dataformat.BinaryString) field$84), isNull$86 ? null : (java.lang.String) converter$89.toExternal((org.apache.flink.table.dataformat.BinaryString) field$88), isNull$90 ? null : (java.lang.String) converter$93.toExternal((org.apache.flink.table.dataformat.BinaryString) field$92));
                     
            
          }

          @Override
          public void retract(org.apache.flink.table.dataformat.BaseRow retractInput) throws Exception {
            
            throw new java.lang.RuntimeException("This function not require retract method, but the retract method is called.");
                 
          }

          @Override
          public void merge(org.apache.flink.table.dataformat.BaseRow otherAcc) throws Exception {
            
            throw new java.lang.RuntimeException("This function not require merge method, but the merge method is called.");
                 
          }

          @Override
          public void setAccumulators(org.apache.flink.table.dataformat.BaseRow acc) throws Exception {
            
            org.apache.flink.table.dataformat.BinaryGeneric field$78;
            boolean isNull$78;
            isNull$78 = acc.isNullAt(0);
            field$78 = null;
            if (!isNull$78) {
              field$78 = acc.getGeneric(0);
            }
            
            agg0_acc_internal = field$78;
            agg0_acc_external = (aljoschaRydzyk.Gradoop_Flink_Prototype.MatchDegreeChoice.VertexAccum) converter$79.toExternal((org.apache.flink.table.dataformat.BinaryGeneric) agg0_acc_internal);
                  
                
          }

          @Override
          public void resetAccumulators() throws Exception {
            
            
            
            agg0_acc_external = (aljoschaRydzyk.Gradoop_Flink_Prototype.MatchDegreeChoice.VertexAccum) function_aljoschaRydzyk$Gradoop_Flink_Prototype$MatchDegreeChoice$CurrentVertex$3d0463f5434850ea9bb43ad6f64954bb.createAccumulator();
            agg0_acc_internal = (org.apache.flink.table.dataformat.BinaryGeneric) converter$80.toInternal((aljoschaRydzyk.Gradoop_Flink_Prototype.MatchDegreeChoice.VertexAccum) agg0_acc_external);
                   
                
          }

          @Override
          public org.apache.flink.table.dataformat.BaseRow getAccumulators() throws Exception {
            
            
            
            final org.apache.flink.table.dataformat.GenericRow acc$77 = new org.apache.flink.table.dataformat.GenericRow(1);
            
            agg0_acc_internal = (org.apache.flink.table.dataformat.BinaryGeneric) converter$76.toInternal((aljoschaRydzyk.Gradoop_Flink_Prototype.MatchDegreeChoice.VertexAccum) agg0_acc_external);
            if (false) {
              acc$77.setNullAt(0);
            } else {
              acc$77.setField(0, agg0_acc_internal);;
            }
                      
                    
            return acc$77;
                
          }

          @Override
          public org.apache.flink.table.dataformat.BaseRow createAccumulators() throws Exception {
            
            
            
            final org.apache.flink.table.dataformat.GenericRow acc$75 = new org.apache.flink.table.dataformat.GenericRow(1);
            
            org.apache.flink.table.dataformat.BinaryGeneric acc_internal$74 = (org.apache.flink.table.dataformat.BinaryGeneric) (org.apache.flink.table.dataformat.BinaryGeneric) converter$73.toInternal((aljoschaRydzyk.Gradoop_Flink_Prototype.MatchDegreeChoice.VertexAccum) function_aljoschaRydzyk$Gradoop_Flink_Prototype$MatchDegreeChoice$CurrentVertex$3d0463f5434850ea9bb43ad6f64954bb.createAccumulator());
            if (false) {
              acc$75.setNullAt(0);
            } else {
              acc$75.setField(0, acc_internal$74);;
            }
                      
                    
            return acc$75;
                
          }

          @Override
          public org.apache.flink.table.dataformat.BaseRow getValue() throws Exception {
            
            
            
            final org.apache.flink.table.dataformat.GenericRow aggValue$98 = new org.apache.flink.table.dataformat.GenericRow(1);
            
            
            org.apache.flink.api.java.tuple.Tuple2 value_external$94 = (org.apache.flink.api.java.tuple.Tuple2)
              function_aljoschaRydzyk$Gradoop_Flink_Prototype$MatchDegreeChoice$CurrentVertex$3d0463f5434850ea9bb43ad6f64954bb.getValue(agg0_acc_external);
            org.apache.flink.table.dataformat.BaseRow value_internal$95 =
              (org.apache.flink.table.dataformat.BaseRow) converter$97.toInternal((org.apache.flink.api.java.tuple.Tuple2) value_external$94);
            boolean valueIsNull$96 = value_internal$95 == null;
                  
            if (valueIsNull$96) {
              aggValue$98.setNullAt(0);
            } else {
              aggValue$98.setField(0, value_internal$95);;
            }
                      
                    
            return aggValue$98;
                
          }

          @Override
          public void cleanup() throws Exception {
            
            
          }

          @Override
          public void close() throws Exception {
            
            function_aljoschaRydzyk$Gradoop_Flink_Prototype$MatchDegreeChoice$CurrentVertex$3d0463f5434850ea9bb43ad6f64954bb.close();
                   
          }
        }
      
03/06/2020 13:13:33.994  INFO [org.apache.zookeeper.ClientCnxn] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
03/06/2020 13:13:34.006  INFO [org.apache.zookeeper.ClientCnxn] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
03/06/2020 13:13:34.006  INFO [org.apache.zookeeper.ClientCnxn] Socket connection established to localhost/127.0.0.1:2181, initiating session
03/06/2020 13:13:34.011 DEBUG [org.apache.zookeeper.ClientCnxn] Session establishment request sent on localhost/127.0.0.1:2181
03/06/2020 13:13:34.014  INFO [org.apache.zookeeper.ClientCnxn] Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x172799b82f20031, negotiated timeout = 90000
03/06/2020 13:13:34.014 DEBUG [org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher] hconnection-0x53491420x0, quorum=localhost:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
03/06/2020 13:13:34.017  INFO [org.apache.zookeeper.ClientCnxn] Socket connection established to localhost/127.0.0.1:2181, initiating session
03/06/2020 13:13:34.015 DEBUG [org.apache.zookeeper.ClientCnxn] Reading reply sessionid:0x172799b82f20031, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,1046,0  request:: '/hbase/hbaseid,F  response:: s{36,897,1589975516652,1591178147927,3,0,0,0,67,0,36} 
03/06/2020 13:13:34.018 DEBUG [org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher] hconnection-0x5349142-0x172799b82f20031 connected
03/06/2020 13:13:34.039 DEBUG [org.apache.zookeeper.ClientCnxn] Reading reply sessionid:0x172799b82f20031, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,1046,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a31363030302affffff9f4357ffffffbf5875150425546a2434306339306330662d663833372d343664652d626233622d363436353332383637336261,s{36,897,1589975516652,1591178147927,3,0,0,0,67,0,36} 
03/06/2020 13:13:34.040 DEBUG [org.apache.hadoop.hbase.ipc.AbstractRpcClient] Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@735bc57c, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
03/06/2020 13:13:34.041 DEBUG [org.apache.flink.table.runtime.generated.CompileUtils] Compiling: KeyProjection$147 

 Code:

public class KeyProjection$147 implements org.apache.flink.table.runtime.generated.Projection<org.apache.flink.table.dataformat.BaseRow, org.apache.flink.table.dataformat.BinaryRow> {

  final org.apache.flink.table.dataformat.BinaryRow out = new org.apache.flink.table.dataformat.BinaryRow(1);
final org.apache.flink.table.dataformat.BinaryRowWriter outWriter = new org.apache.flink.table.dataformat.BinaryRowWriter(out);

  public KeyProjection$147(Object[] references) throws Exception {
    
  }

  @Override
  public org.apache.flink.table.dataformat.BinaryRow apply(org.apache.flink.table.dataformat.BaseRow in1) {
    
    

outWriter.reset();


if (in1.isNullAt(0)) {
  outWriter.setNullAt(0);
} else {
  outWriter.writeString(0, in1.getString(0));
}
             
outWriter.complete();
        
    return out;
  }
}
        
03/06/2020 13:13:34.038 DEBUG [org.apache.zookeeper.ClientCnxn] Session establishment request sent on localhost/127.0.0.1:2181
03/06/2020 13:13:34.042  INFO [org.apache.flink.api.common.io.LocatableInputSplitAssigner] Assigning remote split to host localhost
03/06/2020 13:13:34.044 DEBUG [org.apache.flink.runtime.jobmaster.JobMaster] Send next input split Locatable Split (0) at [ubuntu:16201].
03/06/2020 13:13:34.044  INFO [org.apache.zookeeper.ClientCnxn] Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x172799b82f20032, negotiated timeout = 90000
03/06/2020 13:13:34.045 DEBUG [org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher] hconnection-0x314756110x0, quorum=localhost:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
03/06/2020 13:13:34.047 DEBUG [org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher] hconnection-0x31475611-0x172799b82f20032 connected
03/06/2020 13:13:34.050 DEBUG [org.apache.zookeeper.ClientCnxn] Reading reply sessionid:0x172799b82f20032, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,1047,0  request:: '/hbase/hbaseid,F  response:: s{36,897,1589975516652,1591178147927,3,0,0,0,67,0,36} 
03/06/2020 13:13:34.051 DEBUG [org.apache.zookeeper.ClientCnxn] Reading reply sessionid:0x172799b82f20032, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,1047,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a31363030302affffff9f4357ffffffbf5875150425546a2434306339306330662d663833372d343664652d626233622d363436353332383637336261,s{36,897,1589975516652,1591178147927,3,0,0,0,67,0,36} 
03/06/2020 13:13:34.052 DEBUG [org.apache.hadoop.hbase.ipc.AbstractRpcClient] Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@1622f481, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
03/06/2020 13:13:34.061 DEBUG [org.apache.flink.table.runtime.generated.CompileUtils] Compiling: GroupAggValueEqualiser$100 

 Code:

        public final class GroupAggValueEqualiser$100 implements org.apache.flink.table.runtime.generated.RecordEqualiser {

          private transient org.apache.flink.table.runtime.generated.GeneratedRecordEqualiser field$0GeneratedEqualiser$106;
          private org.apache.flink.table.runtime.generated.RecordEqualiser equaliser$107 = null;

          public GroupAggValueEqualiser$100(Object[] references) throws Exception {
            field$0GeneratedEqualiser$106 = (((org.apache.flink.table.runtime.generated.GeneratedRecordEqualiser) references[0]));
            
            equaliser$107 = (org.apache.flink.table.runtime.generated.RecordEqualiser)
              field$0GeneratedEqualiser$106.newInstance(Thread.currentThread().getContextClassLoader());
            
          }

          @Override
          public boolean equals(org.apache.flink.table.dataformat.BaseRow left, org.apache.flink.table.dataformat.BaseRow right) {
            if (left instanceof org.apache.flink.table.dataformat.BinaryRow && right instanceof org.apache.flink.table.dataformat.BinaryRow) {
              return left.equals(right);
            } else {
              
              if (left.getHeader() != right.getHeader()) {
                return false;
              }
                     
              
              
              boolean leftIsNull$0 = left.isNullAt(0);
              boolean rightIsNull$0 = right.isNullAt(0);
              boolean cmp0;
              if (leftIsNull$0 && rightIsNull$0) {
                cmp0 = true;
              } else if (leftIsNull$0|| rightIsNull$0) {
                cmp0 = false;
              } else {
                org.apache.flink.table.dataformat.BaseRow leftField$0 = left.getRow(0, 2);
                org.apache.flink.table.dataformat.BaseRow rightField$0 = right.getRow(0, 2);
                
                cmp0 = equaliser$107.equalsWithoutHeader(leftField$0, rightField$0);
              }
              if (!cmp0) {
                return false;
              }
                    
              return true;
            }
          }

          @Override
          public boolean equalsWithoutHeader(org.apache.flink.table.dataformat.BaseRow left, org.apache.flink.table.dataformat.BaseRow right) {
            if (left instanceof org.apache.flink.table.dataformat.BinaryRow && right instanceof org.apache.flink.table.dataformat.BinaryRow) {
              return ((org.apache.flink.table.dataformat.BinaryRow)left).equalsWithoutHeader(((org.apache.flink.table.dataformat.BinaryRow)right));
            } else {
              
              
              boolean leftIsNull$0 = left.isNullAt(0);
              boolean rightIsNull$0 = right.isNullAt(0);
              boolean cmp0;
              if (leftIsNull$0 && rightIsNull$0) {
                cmp0 = true;
              } else if (leftIsNull$0|| rightIsNull$0) {
                cmp0 = false;
              } else {
                org.apache.flink.table.dataformat.BaseRow leftField$0 = left.getRow(0, 2);
                org.apache.flink.table.dataformat.BaseRow rightField$0 = right.getRow(0, 2);
                
                cmp0 = equaliser$107.equalsWithoutHeader(leftField$0, rightField$0);
              }
              if (!cmp0) {
                return false;
              }
                    
              return true;
            }
          }
        }
      
03/06/2020 13:13:34.066  INFO [org.apache.flink.table.runtime.operators.rank.AppendOnlyTopNFunction] Top10 operator is using LRU caches key-size: 1000
03/06/2020 13:13:34.071  INFO [org.apache.flink.addons.hbase.AbstractTableInputFormat] opening split (this=org.apache.flink.addons.hbase.HBaseRowInputFormat@23ba981a)[0|[ubuntu:16201]|-|-]
03/06/2020 13:13:34.073 DEBUG [org.apache.flink.api.common.io.LocatableInputSplitAssigner] No more input splits remaining.
03/06/2020 13:13:34.074 DEBUG [org.apache.flink.runtime.jobmaster.JobMaster] Send next input split null.
03/06/2020 13:13:34.075 DEBUG [org.apache.zookeeper.ClientCnxn] Reading reply sessionid:0x172799b82f20031, packet:: clientPath:null serverPath:null finished:false header:: 3,4  replyHeader:: 3,1047,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a31363230317245ffffff8ffffffff46c10ffffffddffffffc050425546a12a67562756e747510ffffffc97e18ffffffa8ffffffa8ffffffeeffffffccffffffa72e100183,s{911,911,1591178156577,1591178156577,0,0,0,0,59,0,911} 
03/06/2020 13:13:34.079 DEBUG [org.apache.zookeeper.ClientCnxn] Reading reply sessionid:0x172799b82f20031, packet:: clientPath:null serverPath:null finished:false header:: 4,8  replyHeader:: 4,1047,0  request:: '/hbase,F  response:: v{'replication,'meta-region-server,'rs,'splitWAL,'backup-masters,'table-lock,'flush-table-proc,'master-maintenance,'region-in-transition,'online-snapshot,'switch,'master,'running,'recovering-regions,'draining,'namespace,'hbaseid,'table} 
03/06/2020 13:13:34.086 DEBUG [org.apache.flink.table.runtime.generated.CompileUtils] Compiling: field$0GeneratedEqualiser$101 

 Code:

        public final class field$0GeneratedEqualiser$101 implements org.apache.flink.table.runtime.generated.RecordEqualiser {

          

          public field$0GeneratedEqualiser$101(Object[] references) throws Exception {
            
          }

          @Override
          public boolean equals(org.apache.flink.table.dataformat.BaseRow left, org.apache.flink.table.dataformat.BaseRow right) {
            if (left instanceof org.apache.flink.table.dataformat.BinaryRow && right instanceof org.apache.flink.table.dataformat.BinaryRow) {
              return left.equals(right);
            } else {
              
              if (left.getHeader() != right.getHeader()) {
                return false;
              }
                     
              boolean isNull$102;
              boolean result$103;
              boolean isNull$104;
              boolean result$105;
              
              boolean leftIsNull$0 = left.isNullAt(0);
              boolean rightIsNull$0 = right.isNullAt(0);
              boolean cmp0;
              if (leftIsNull$0 && rightIsNull$0) {
                cmp0 = true;
              } else if (leftIsNull$0|| rightIsNull$0) {
                cmp0 = false;
              } else {
                org.apache.flink.table.dataformat.BinaryString leftField$0 = left.getString(0);
                org.apache.flink.table.dataformat.BinaryString rightField$0 = right.getString(0);
                
              
              
              isNull$102 = leftIsNull$0 || rightIsNull$0;
              result$103 = false;
              if (!isNull$102) {
                
                result$103 = leftField$0.equals(rightField$0);
                
              }
              
                cmp0 = result$103;
              }
              if (!cmp0) {
                return false;
              }
                    
              
              boolean leftIsNull$1 = left.isNullAt(1);
              boolean rightIsNull$1 = right.isNullAt(1);
              boolean cmp1;
              if (leftIsNull$1 && rightIsNull$1) {
                cmp1 = true;
              } else if (leftIsNull$1|| rightIsNull$1) {
                cmp1 = false;
              } else {
                org.apache.flink.table.dataformat.BinaryString leftField$1 = left.getString(1);
                org.apache.flink.table.dataformat.BinaryString rightField$1 = right.getString(1);
                
              
              
              isNull$104 = leftIsNull$1 || rightIsNull$1;
              result$105 = false;
              if (!isNull$104) {
                
                result$105 = leftField$1.equals(rightField$1);
                
              }
              
                cmp1 = result$105;
              }
              if (!cmp1) {
                return false;
              }
                    
              return true;
            }
          }

          @Override
          public boolean equalsWithoutHeader(org.apache.flink.table.dataformat.BaseRow left, org.apache.flink.table.dataformat.BaseRow right) {
            if (left instanceof org.apache.flink.table.dataformat.BinaryRow && right instanceof org.apache.flink.table.dataformat.BinaryRow) {
              return ((org.apache.flink.table.dataformat.BinaryRow)left).equalsWithoutHeader(((org.apache.flink.table.dataformat.BinaryRow)right));
            } else {
              boolean isNull$102;
              boolean result$103;
              boolean isNull$104;
              boolean result$105;
              
              boolean leftIsNull$0 = left.isNullAt(0);
              boolean rightIsNull$0 = right.isNullAt(0);
              boolean cmp0;
              if (leftIsNull$0 && rightIsNull$0) {
                cmp0 = true;
              } else if (leftIsNull$0|| rightIsNull$0) {
                cmp0 = false;
              } else {
                org.apache.flink.table.dataformat.BinaryString leftField$0 = left.getString(0);
                org.apache.flink.table.dataformat.BinaryString rightField$0 = right.getString(0);
                
              
              
              isNull$102 = leftIsNull$0 || rightIsNull$0;
              result$103 = false;
              if (!isNull$102) {
                
                result$103 = leftField$0.equals(rightField$0);
                
              }
              
                cmp0 = result$103;
              }
              if (!cmp0) {
                return false;
              }
                    
              
              boolean leftIsNull$1 = left.isNullAt(1);
              boolean rightIsNull$1 = right.isNullAt(1);
              boolean cmp1;
              if (leftIsNull$1 && rightIsNull$1) {
                cmp1 = true;
              } else if (leftIsNull$1|| rightIsNull$1) {
                cmp1 = false;
              } else {
                org.apache.flink.table.dataformat.BinaryString leftField$1 = left.getString(1);
                org.apache.flink.table.dataformat.BinaryString rightField$1 = right.getString(1);
                
              
              
              isNull$104 = leftIsNull$1 || rightIsNull$1;
              result$105 = false;
              if (!isNull$104) {
                
                result$105 = leftField$1.equals(rightField$1);
                
              }
              
                cmp1 = result$105;
              }
              if (!cmp1) {
                return false;
              }
                    
              return true;
            }
          }
        }
      
03/06/2020 13:13:34.106 DEBUG [org.apache.hadoop.hbase.ipc.RpcConnection] Use SIMPLE authentication for service ClientService, sasl=false
03/06/2020 13:13:34.107 DEBUG [org.apache.hadoop.hbase.ipc.BlockingRpcConnection] Connecting to ubuntu/127.0.1.1:16201
03/06/2020 13:13:34.121  INFO [org.apache.flink.addons.hbase.AbstractTableInputFormat] Closing split (scanned 0 rows)
03/06/2020 13:13:34.123 DEBUG [org.apache.flink.streaming.runtime.tasks.StreamTask] Finished task Source: HBaseTableSource[schema=[id, cf], projectFields=null] -> SourceConversion(table=[default_catalog.default_database.loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]], fields=[id, cf]) -> Calc(select=[id, cf, cf.degree AS degree]) (1/2)
03/06/2020 13:13:34.124  INFO [org.apache.flink.addons.hbase.AbstractTableInputFormat] Closing split (scanned 0 rows)
03/06/2020 13:13:34.124 DEBUG [org.apache.flink.streaming.runtime.tasks.StreamTask] Closed operators for task Source: HBaseTableSource[schema=[id, cf], projectFields=null] -> SourceConversion(table=[default_catalog.default_database.loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]], fields=[id, cf]) -> Calc(select=[id, cf, cf.degree AS degree]) (1/2)
03/06/2020 13:13:34.127 DEBUG [org.apache.flink.runtime.io.network.partition.PipelinedSubpartition] Source: HBaseTableSource[schema=[id, cf], projectFields=null] -> SourceConversion(table=[default_catalog.default_database.loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]], fields=[id, cf]) -> Calc(select=[id, cf, cf.degree AS degree]) (1/2) (b84c3df4861d1ab2874fdf6c2c4b34e1): Finished PipelinedSubpartition#0 [number of buffers: 1 (0 bytes), number of buffers in backlog: 0, finished? true, read view? true].
03/06/2020 13:13:34.127  INFO [org.apache.flink.runtime.taskmanager.Task] Source: HBaseTableSource[schema=[id, cf], projectFields=null] -> SourceConversion(table=[default_catalog.default_database.loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]], fields=[id, cf]) -> Calc(select=[id, cf, cf.degree AS degree]) (1/2) (b84c3df4861d1ab2874fdf6c2c4b34e1) switched from RUNNING to FINISHED.
03/06/2020 13:13:34.127  INFO [org.apache.flink.runtime.taskmanager.Task] Freeing task resources for Source: HBaseTableSource[schema=[id, cf], projectFields=null] -> SourceConversion(table=[default_catalog.default_database.loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]], fields=[id, cf]) -> Calc(select=[id, cf, cf.degree AS degree]) (1/2) (b84c3df4861d1ab2874fdf6c2c4b34e1).
03/06/2020 13:13:34.128 DEBUG [org.apache.flink.runtime.taskmanager.Task] Release task Source: HBaseTableSource[schema=[id, cf], projectFields=null] -> SourceConversion(table=[default_catalog.default_database.loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]], fields=[id, cf]) -> Calc(select=[id, cf, cf.degree AS degree]) (1/2) network resources (state: FINISHED).
03/06/2020 13:13:34.128 DEBUG [org.apache.flink.runtime.io.network.TaskEventDispatcher] unregistering 7e12330857e44344bfe04391907a4449@b84c3df4861d1ab2874fdf6c2c4b34e1
03/06/2020 13:13:34.129  INFO [org.apache.flink.runtime.taskmanager.Task] Ensuring all FileSystem streams are closed for task Source: HBaseTableSource[schema=[id, cf], projectFields=null] -> SourceConversion(table=[default_catalog.default_database.loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]], fields=[id, cf]) -> Calc(select=[id, cf, cf.degree AS degree]) (1/2) (b84c3df4861d1ab2874fdf6c2c4b34e1) [FINISHED]
03/06/2020 13:13:34.129  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutor] Un-registering task and sending final execution state FINISHED to JobManager for task Source: HBaseTableSource[schema=[id, cf], projectFields=null] -> SourceConversion(table=[default_catalog.default_database.loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]], fields=[id, cf]) -> Calc(select=[id, cf, cf.degree AS degree]) (1/2) b84c3df4861d1ab2874fdf6c2c4b34e1.
03/06/2020 13:13:34.132 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartition] ReleaseOnConsumptionResultPartition 7e12330857e44344bfe04391907a4449@b84c3df4861d1ab2874fdf6c2c4b34e1 [PIPELINED_BOUNDED, 1 subpartitions, 0 pending consumptions]: Received consumed notification for subpartition 0.
03/06/2020 13:13:34.133 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionManager] Received consume notification from ReleaseOnConsumptionResultPartition 7e12330857e44344bfe04391907a4449@b84c3df4861d1ab2874fdf6c2c4b34e1 [PIPELINED_BOUNDED, 1 subpartitions, 0 pending consumptions].
03/06/2020 13:13:34.133 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartition] Source: HBaseTableSource[schema=[id, cf], projectFields=null] -> SourceConversion(table=[default_catalog.default_database.loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]], fields=[id, cf]) -> Calc(select=[id, cf, cf.degree AS degree]) (1/2) (b84c3df4861d1ab2874fdf6c2c4b34e1): Releasing ReleaseOnConsumptionResultPartition 7e12330857e44344bfe04391907a4449@b84c3df4861d1ab2874fdf6c2c4b34e1 [PIPELINED_BOUNDED, 1 subpartitions, 0 pending consumptions].
03/06/2020 13:13:34.133 DEBUG [org.apache.flink.runtime.io.network.partition.PipelinedSubpartition] Source: HBaseTableSource[schema=[id, cf], projectFields=null] -> SourceConversion(table=[default_catalog.default_database.loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]], fields=[id, cf]) -> Calc(select=[id, cf, cf.degree AS degree]) (1/2) (b84c3df4861d1ab2874fdf6c2c4b34e1): Released PipelinedSubpartition#0 [number of buffers: 1 (4 bytes), number of buffers in backlog: 0, finished? true, read view? false].
03/06/2020 13:13:34.133 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionManager] Released partition 7e12330857e44344bfe04391907a4449 produced by b84c3df4861d1ab2874fdf6c2c4b34e1.
03/06/2020 13:13:34.134  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] Source: HBaseTableSource[schema=[id, cf], projectFields=null] -> SourceConversion(table=[default_catalog.default_database.loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]], fields=[id, cf]) -> Calc(select=[id, cf, cf.degree AS degree]) (1/2) (b84c3df4861d1ab2874fdf6c2c4b34e1) switched from RUNNING to FINISHED.
03/06/2020 13:13:34.134 DEBUG [org.apache.flink.runtime.executiongraph.ExecutionGraph] Ignoring transition of vertex Source: HBaseTableSource[schema=[id, cf], projectFields=null] -> SourceConversion(table=[default_catalog.default_database.loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]], fields=[id, cf]) -> Calc(select=[id, cf, cf.degree AS degree]) (1/2) - execution #0 to FAILED while being FINISHED.
03/06/2020 13:13:34.173 DEBUG [org.apache.flink.table.runtime.generated.CompileUtils] Compiling: KeyProjection$11 

 Code:

public class KeyProjection$11 implements org.apache.flink.table.runtime.generated.Projection<org.apache.flink.table.dataformat.BaseRow, org.apache.flink.table.dataformat.BinaryRow> {

  final org.apache.flink.table.dataformat.BinaryRow out = new org.apache.flink.table.dataformat.BinaryRow(1);
final org.apache.flink.table.dataformat.BinaryRowWriter outWriter = new org.apache.flink.table.dataformat.BinaryRowWriter(out);

  public KeyProjection$11(Object[] references) throws Exception {
    
  }

  @Override
  public org.apache.flink.table.dataformat.BinaryRow apply(org.apache.flink.table.dataformat.BaseRow in1) {
    
    

outWriter.reset();


if (in1.isNullAt(2)) {
  outWriter.setNullAt(0);
} else {
  outWriter.writeInt(0, in1.getInt(2));
}
             
outWriter.complete();
        
    return out;
  }
}
        
03/06/2020 13:13:34.187  INFO [org.apache.flink.addons.hbase.AbstractTableInputFormat] Closing split (scanned 1033 rows)
03/06/2020 13:13:34.191 DEBUG [org.apache.flink.api.common.io.LocatableInputSplitAssigner] No more input splits remaining.
03/06/2020 13:13:34.191 DEBUG [org.apache.flink.runtime.jobmaster.JobMaster] Send next input split null.
03/06/2020 13:13:34.192  INFO [org.apache.flink.addons.hbase.AbstractTableInputFormat] Closing split (scanned 1033 rows)
03/06/2020 13:13:34.192 DEBUG [org.apache.flink.streaming.runtime.tasks.StreamTask] Finished task Source: HBaseTableSource[schema=[id, cf], projectFields=null] -> SourceConversion(table=[default_catalog.default_database.loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]], fields=[id, cf]) -> Calc(select=[id, cf, cf.degree AS degree]) (2/2)
03/06/2020 13:13:34.192  INFO [org.apache.flink.addons.hbase.AbstractTableInputFormat] Closing split (scanned 1033 rows)
03/06/2020 13:13:34.192 DEBUG [org.apache.flink.streaming.runtime.tasks.StreamTask] Closed operators for task Source: HBaseTableSource[schema=[id, cf], projectFields=null] -> SourceConversion(table=[default_catalog.default_database.loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]], fields=[id, cf]) -> Calc(select=[id, cf, cf.degree AS degree]) (2/2)
03/06/2020 13:13:34.192 DEBUG [org.apache.flink.runtime.io.network.partition.PipelinedSubpartition] Source: HBaseTableSource[schema=[id, cf], projectFields=null] -> SourceConversion(table=[default_catalog.default_database.loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]], fields=[id, cf]) -> Calc(select=[id, cf, cf.degree AS degree]) (2/2) (db3aa1938ec63c4d326136e01fb698e5): Finished PipelinedSubpartition#0 [number of buffers: 4 (32768 bytes), number of buffers in backlog: 2, finished? true, read view? true].
03/06/2020 13:13:34.193  INFO [org.apache.flink.runtime.taskmanager.Task] Source: HBaseTableSource[schema=[id, cf], projectFields=null] -> SourceConversion(table=[default_catalog.default_database.loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]], fields=[id, cf]) -> Calc(select=[id, cf, cf.degree AS degree]) (2/2) (db3aa1938ec63c4d326136e01fb698e5) switched from RUNNING to FINISHED.
03/06/2020 13:13:34.193  INFO [org.apache.flink.runtime.taskmanager.Task] Freeing task resources for Source: HBaseTableSource[schema=[id, cf], projectFields=null] -> SourceConversion(table=[default_catalog.default_database.loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]], fields=[id, cf]) -> Calc(select=[id, cf, cf.degree AS degree]) (2/2) (db3aa1938ec63c4d326136e01fb698e5).
03/06/2020 13:13:34.193 DEBUG [org.apache.flink.runtime.taskmanager.Task] Release task Source: HBaseTableSource[schema=[id, cf], projectFields=null] -> SourceConversion(table=[default_catalog.default_database.loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]], fields=[id, cf]) -> Calc(select=[id, cf, cf.degree AS degree]) (2/2) network resources (state: FINISHED).
03/06/2020 13:13:34.193 DEBUG [org.apache.flink.runtime.io.network.TaskEventDispatcher] unregistering 161687556e7759506bc9efabc0bcde87@db3aa1938ec63c4d326136e01fb698e5
03/06/2020 13:13:34.193  INFO [org.apache.flink.runtime.taskmanager.Task] Ensuring all FileSystem streams are closed for task Source: HBaseTableSource[schema=[id, cf], projectFields=null] -> SourceConversion(table=[default_catalog.default_database.loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]], fields=[id, cf]) -> Calc(select=[id, cf, cf.degree AS degree]) (2/2) (db3aa1938ec63c4d326136e01fb698e5) [FINISHED]
03/06/2020 13:13:34.202  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutor] Un-registering task and sending final execution state FINISHED to JobManager for task Source: HBaseTableSource[schema=[id, cf], projectFields=null] -> SourceConversion(table=[default_catalog.default_database.loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]], fields=[id, cf]) -> Calc(select=[id, cf, cf.degree AS degree]) (2/2) db3aa1938ec63c4d326136e01fb698e5.
03/06/2020 13:13:34.203  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] Source: HBaseTableSource[schema=[id, cf], projectFields=null] -> SourceConversion(table=[default_catalog.default_database.loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]], fields=[id, cf]) -> Calc(select=[id, cf, cf.degree AS degree]) (2/2) (db3aa1938ec63c4d326136e01fb698e5) switched from RUNNING to FINISHED.
03/06/2020 13:13:34.203 DEBUG [org.apache.flink.runtime.executiongraph.ExecutionGraph] Ignoring transition of vertex Source: HBaseTableSource[schema=[id, cf], projectFields=null] -> SourceConversion(table=[default_catalog.default_database.loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]], fields=[id, cf]) -> Calc(select=[id, cf, cf.degree AS degree]) (2/2) - execution #0 to FAILED while being FINISHED.
03/06/2020 13:13:34.208 DEBUG [org.apache.flink.streaming.runtime.tasks.StreamTask] Finished task Source: Collection Source -> SourceConversion(table=[Unregistered_DataStream_9], fields=[f0, f1, f2, f3, f4]) -> Calc(select=[f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y]) (1/1)
03/06/2020 13:13:34.209 DEBUG [org.apache.flink.streaming.runtime.tasks.StreamTask] Closed operators for task Source: Collection Source -> SourceConversion(table=[Unregistered_DataStream_9], fields=[f0, f1, f2, f3, f4]) -> Calc(select=[f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y]) (1/1)
03/06/2020 13:13:34.212 DEBUG [org.apache.flink.runtime.io.network.partition.PipelinedSubpartition] Source: Collection Source -> SourceConversion(table=[Unregistered_DataStream_9], fields=[f0, f1, f2, f3, f4]) -> Calc(select=[f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y]) (1/1) (d74648705093b5c72e78e2c360e29713): Finished PipelinedSubpartition#0 [number of buffers: 3 (41067 bytes), number of buffers in backlog: 1, finished? true, read view? true].
03/06/2020 13:13:34.212 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartition] ReleaseOnConsumptionResultPartition 152d67b39c04e64fe5971bb597eb96e2@d74648705093b5c72e78e2c360e29713 [PIPELINED_BOUNDED, 2 subpartitions, 1 pending consumptions]: Received consumed notification for subpartition 0.
03/06/2020 13:13:34.212 DEBUG [org.apache.flink.runtime.io.network.partition.PipelinedSubpartition] Source: Collection Source -> SourceConversion(table=[Unregistered_DataStream_9], fields=[f0, f1, f2, f3, f4]) -> Calc(select=[f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y]) (1/1) (d74648705093b5c72e78e2c360e29713): Finished PipelinedSubpartition#1 [number of buffers: 3 (42606 bytes), number of buffers in backlog: 0, finished? true, read view? true].
03/06/2020 13:13:34.214  INFO [org.apache.flink.runtime.taskmanager.Task] Source: Collection Source -> SourceConversion(table=[Unregistered_DataStream_9], fields=[f0, f1, f2, f3, f4]) -> Calc(select=[f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y]) (1/1) (d74648705093b5c72e78e2c360e29713) switched from RUNNING to FINISHED.
03/06/2020 13:13:34.215  INFO [org.apache.flink.runtime.taskmanager.Task] Freeing task resources for Source: Collection Source -> SourceConversion(table=[Unregistered_DataStream_9], fields=[f0, f1, f2, f3, f4]) -> Calc(select=[f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y]) (1/1) (d74648705093b5c72e78e2c360e29713).
03/06/2020 13:13:34.215 DEBUG [org.apache.flink.runtime.taskmanager.Task] Release task Source: Collection Source -> SourceConversion(table=[Unregistered_DataStream_9], fields=[f0, f1, f2, f3, f4]) -> Calc(select=[f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y]) (1/1) network resources (state: FINISHED).
03/06/2020 13:13:34.215 DEBUG [org.apache.flink.runtime.io.network.TaskEventDispatcher] unregistering 152d67b39c04e64fe5971bb597eb96e2@d74648705093b5c72e78e2c360e29713
03/06/2020 13:13:34.215  INFO [org.apache.flink.runtime.taskmanager.Task] Ensuring all FileSystem streams are closed for task Source: Collection Source -> SourceConversion(table=[Unregistered_DataStream_9], fields=[f0, f1, f2, f3, f4]) -> Calc(select=[f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y]) (1/1) (d74648705093b5c72e78e2c360e29713) [FINISHED]
03/06/2020 13:13:34.215  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutor] Un-registering task and sending final execution state FINISHED to JobManager for task Source: Collection Source -> SourceConversion(table=[Unregistered_DataStream_9], fields=[f0, f1, f2, f3, f4]) -> Calc(select=[f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y]) (1/1) d74648705093b5c72e78e2c360e29713.
03/06/2020 13:13:34.215 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartition] ReleaseOnConsumptionResultPartition 152d67b39c04e64fe5971bb597eb96e2@d74648705093b5c72e78e2c360e29713 [PIPELINED_BOUNDED, 2 subpartitions, 0 pending consumptions]: Received consumed notification for subpartition 1.
03/06/2020 13:13:34.215 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionManager] Received consume notification from ReleaseOnConsumptionResultPartition 152d67b39c04e64fe5971bb597eb96e2@d74648705093b5c72e78e2c360e29713 [PIPELINED_BOUNDED, 2 subpartitions, 0 pending consumptions].
03/06/2020 13:13:34.215 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartition] Source: Collection Source -> SourceConversion(table=[Unregistered_DataStream_9], fields=[f0, f1, f2, f3, f4]) -> Calc(select=[f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y]) (1/1) (d74648705093b5c72e78e2c360e29713): Releasing ReleaseOnConsumptionResultPartition 152d67b39c04e64fe5971bb597eb96e2@d74648705093b5c72e78e2c360e29713 [PIPELINED_BOUNDED, 2 subpartitions, 0 pending consumptions].
03/06/2020 13:13:34.216 DEBUG [org.apache.flink.runtime.io.network.partition.PipelinedSubpartition] Source: Collection Source -> SourceConversion(table=[Unregistered_DataStream_9], fields=[f0, f1, f2, f3, f4]) -> Calc(select=[f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y]) (1/1) (d74648705093b5c72e78e2c360e29713): Released PipelinedSubpartition#0 [number of buffers: 3 (41071 bytes), number of buffers in backlog: 0, finished? true, read view? false].
03/06/2020 13:13:34.216 DEBUG [org.apache.flink.runtime.io.network.partition.PipelinedSubpartition] Source: Collection Source -> SourceConversion(table=[Unregistered_DataStream_9], fields=[f0, f1, f2, f3, f4]) -> Calc(select=[f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y]) (1/1) (d74648705093b5c72e78e2c360e29713): Released PipelinedSubpartition#1 [number of buffers: 3 (42610 bytes), number of buffers in backlog: 0, finished? true, read view? false].
03/06/2020 13:13:34.216  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] Source: Collection Source -> SourceConversion(table=[Unregistered_DataStream_9], fields=[f0, f1, f2, f3, f4]) -> Calc(select=[f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y]) (1/1) (d74648705093b5c72e78e2c360e29713) switched from RUNNING to FINISHED.
03/06/2020 13:13:34.216 DEBUG [org.apache.flink.runtime.executiongraph.ExecutionGraph] Ignoring transition of vertex Source: Collection Source -> SourceConversion(table=[Unregistered_DataStream_9], fields=[f0, f1, f2, f3, f4]) -> Calc(select=[f0 AS v_id_2, f1 AS v_label, f2 AS v_id_layout, f3 AS X, f4 AS Y]) (1/1) - execution #0 to FAILED while being FINISHED.
03/06/2020 13:13:34.212 DEBUG [org.apache.flink.streaming.runtime.io.CheckpointBarrierAligner] Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (1/2) (6dfb6ce5559aca85d7e81c96224f4864): End of stream alignment, feeding buffered data back.
03/06/2020 13:13:34.217 DEBUG [org.apache.flink.streaming.runtime.io.CachedBufferStorage] Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (1/2) (6dfb6ce5559aca85d7e81c96224f4864): Size of buffered data: 0 bytes
03/06/2020 13:13:34.217 DEBUG [org.apache.flink.streaming.runtime.io.CachedBufferStorage] Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (1/2) (6dfb6ce5559aca85d7e81c96224f4864): Size of buffered data: 0 bytes
03/06/2020 13:13:34.216 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionManager] Released partition 152d67b39c04e64fe5971bb597eb96e2 produced by d74648705093b5c72e78e2c360e29713.
03/06/2020 13:13:34.221 DEBUG [org.apache.flink.streaming.runtime.io.CheckpointBarrierAligner] Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (2/2) (27eb9406de3597496fd0bb48c5e876a5): End of stream alignment, feeding buffered data back.
03/06/2020 13:13:34.221 DEBUG [org.apache.flink.streaming.runtime.io.CachedBufferStorage] Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (2/2) (27eb9406de3597496fd0bb48c5e876a5): Size of buffered data: 0 bytes
03/06/2020 13:13:34.221 DEBUG [org.apache.flink.streaming.runtime.io.CachedBufferStorage] Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (2/2) (27eb9406de3597496fd0bb48c5e876a5): Size of buffered data: 0 bytes
03/06/2020 13:13:34.247 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartition] ReleaseOnConsumptionResultPartition 161687556e7759506bc9efabc0bcde87@db3aa1938ec63c4d326136e01fb698e5 [PIPELINED_BOUNDED, 1 subpartitions, 0 pending consumptions]: Received consumed notification for subpartition 0.
03/06/2020 13:13:34.247 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionManager] Received consume notification from ReleaseOnConsumptionResultPartition 161687556e7759506bc9efabc0bcde87@db3aa1938ec63c4d326136e01fb698e5 [PIPELINED_BOUNDED, 1 subpartitions, 0 pending consumptions].
03/06/2020 13:13:34.247 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartition] Source: HBaseTableSource[schema=[id, cf], projectFields=null] -> SourceConversion(table=[default_catalog.default_database.loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]], fields=[id, cf]) -> Calc(select=[id, cf, cf.degree AS degree]) (2/2) (db3aa1938ec63c4d326136e01fb698e5): Releasing ReleaseOnConsumptionResultPartition 161687556e7759506bc9efabc0bcde87@db3aa1938ec63c4d326136e01fb698e5 [PIPELINED_BOUNDED, 1 subpartitions, 0 pending consumptions].
03/06/2020 13:13:34.247 DEBUG [org.apache.flink.runtime.io.network.partition.PipelinedSubpartition] Source: HBaseTableSource[schema=[id, cf], projectFields=null] -> SourceConversion(table=[default_catalog.default_database.loadTempTable, source: [HBaseTableSource[schema=[id, cf], projectFields=null]]], fields=[id, cf]) -> Calc(select=[id, cf, cf.degree AS degree]) (2/2) (db3aa1938ec63c4d326136e01fb698e5): Released PipelinedSubpartition#0 [number of buffers: 4 (83677 bytes), number of buffers in backlog: 0, finished? true, read view? false].
03/06/2020 13:13:34.247 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionManager] Released partition 161687556e7759506bc9efabc0bcde87 produced by db3aa1938ec63c4d326136e01fb698e5.
03/06/2020 13:13:34.248 DEBUG [org.apache.flink.streaming.runtime.io.CheckpointBarrierAligner] SortLimit(orderBy=[degree DESC], offset=[0], fetch=[10]) -> Calc(select=[id, cf]) -> SinkConversionToTuple2 (1/1) (876cc1eabe833ca7f87c8793f251f04a): End of stream alignment, feeding buffered data back.
03/06/2020 13:13:34.248 DEBUG [org.apache.flink.streaming.runtime.io.CachedBufferStorage] SortLimit(orderBy=[degree DESC], offset=[0], fetch=[10]) -> Calc(select=[id, cf]) -> SinkConversionToTuple2 (1/1) (876cc1eabe833ca7f87c8793f251f04a): Size of buffered data: 0 bytes
03/06/2020 13:13:34.248 DEBUG [org.apache.flink.streaming.runtime.tasks.StreamTask] Finished task SortLimit(orderBy=[degree DESC], offset=[0], fetch=[10]) -> Calc(select=[id, cf]) -> SinkConversionToTuple2 (1/1)
03/06/2020 13:13:34.248 DEBUG [org.apache.flink.streaming.runtime.tasks.StreamTask] Closed operators for task SortLimit(orderBy=[degree DESC], offset=[0], fetch=[10]) -> Calc(select=[id, cf]) -> SinkConversionToTuple2 (1/1)
03/06/2020 13:13:34.249 DEBUG [org.apache.flink.table.runtime.generated.CompileUtils] Compiling: KeyProjection$72 

 Code:

public class KeyProjection$72 implements org.apache.flink.table.runtime.generated.Projection<org.apache.flink.table.dataformat.BaseRow, org.apache.flink.table.dataformat.BinaryRow> {

  final org.apache.flink.table.dataformat.BinaryRow out = new org.apache.flink.table.dataformat.BinaryRow(1);
final org.apache.flink.table.dataformat.BinaryRowWriter outWriter = new org.apache.flink.table.dataformat.BinaryRowWriter(out);

  public KeyProjection$72(Object[] references) throws Exception {
    
  }

  @Override
  public org.apache.flink.table.dataformat.BinaryRow apply(org.apache.flink.table.dataformat.BaseRow in1) {
    
    

outWriter.reset();


if (in1.isNullAt(1)) {
  outWriter.setNullAt(0);
} else {
  outWriter.writeString(0, in1.getString(1));
}
             
outWriter.complete();
        
    return out;
  }
}
        
03/06/2020 13:13:34.252 DEBUG [org.apache.flink.runtime.io.network.partition.PipelinedSubpartition] SortLimit(orderBy=[degree DESC], offset=[0], fetch=[10]) -> Calc(select=[id, cf]) -> SinkConversionToTuple2 (1/1) (876cc1eabe833ca7f87c8793f251f04a): Finished PipelinedSubpartition#0 [number of buffers: 2 (1665 bytes), number of buffers in backlog: 1, finished? true, read view? true].
03/06/2020 13:13:34.252 DEBUG [org.apache.flink.runtime.io.network.partition.PipelinedSubpartition] SortLimit(orderBy=[degree DESC], offset=[0], fetch=[10]) -> Calc(select=[id, cf]) -> SinkConversionToTuple2 (1/1) (876cc1eabe833ca7f87c8793f251f04a): Finished PipelinedSubpartition#1 [number of buffers: 2 (1665 bytes), number of buffers in backlog: 1, finished? true, read view? true].
03/06/2020 13:13:34.252  INFO [org.apache.flink.runtime.taskmanager.Task] SortLimit(orderBy=[degree DESC], offset=[0], fetch=[10]) -> Calc(select=[id, cf]) -> SinkConversionToTuple2 (1/1) (876cc1eabe833ca7f87c8793f251f04a) switched from RUNNING to FINISHED.
03/06/2020 13:13:34.253  INFO [org.apache.flink.runtime.taskmanager.Task] Freeing task resources for SortLimit(orderBy=[degree DESC], offset=[0], fetch=[10]) -> Calc(select=[id, cf]) -> SinkConversionToTuple2 (1/1) (876cc1eabe833ca7f87c8793f251f04a).
03/06/2020 13:13:34.253 DEBUG [org.apache.flink.runtime.taskmanager.Task] Release task SortLimit(orderBy=[degree DESC], offset=[0], fetch=[10]) -> Calc(select=[id, cf]) -> SinkConversionToTuple2 (1/1) network resources (state: FINISHED).
03/06/2020 13:13:34.253 DEBUG [org.apache.flink.runtime.io.network.TaskEventDispatcher] unregistering 657d9fa3c3c42c8c21b0407ee1e3a770@876cc1eabe833ca7f87c8793f251f04a
03/06/2020 13:13:34.253 DEBUG [org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate] SortLimit(orderBy=[degree DESC], offset=[0], fetch=[10]) -> Calc(select=[id, cf]) -> SinkConversionToTuple2 (1/1) (876cc1eabe833ca7f87c8793f251f04a): Releasing org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate@17644094.
03/06/2020 13:13:34.253  INFO [org.apache.flink.runtime.taskmanager.Task] Ensuring all FileSystem streams are closed for task SortLimit(orderBy=[degree DESC], offset=[0], fetch=[10]) -> Calc(select=[id, cf]) -> SinkConversionToTuple2 (1/1) (876cc1eabe833ca7f87c8793f251f04a) [FINISHED]
03/06/2020 13:13:34.255 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartition] ReleaseOnConsumptionResultPartition 657d9fa3c3c42c8c21b0407ee1e3a770@876cc1eabe833ca7f87c8793f251f04a [PIPELINED_BOUNDED, 2 subpartitions, 0 pending consumptions]: Received consumed notification for subpartition 0.
03/06/2020 13:13:34.255 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartition] ReleaseOnConsumptionResultPartition 657d9fa3c3c42c8c21b0407ee1e3a770@876cc1eabe833ca7f87c8793f251f04a [PIPELINED_BOUNDED, 2 subpartitions, 0 pending consumptions]: Received consumed notification for subpartition 1.
03/06/2020 13:13:34.257 DEBUG [org.apache.flink.streaming.runtime.io.CheckpointBarrierAligner] Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (2/2) (c365017ac85c61dc4f885a5155f06f1e): End of stream alignment, feeding buffered data back.
03/06/2020 13:13:34.257 DEBUG [org.apache.flink.streaming.runtime.io.CachedBufferStorage] Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (2/2) (c365017ac85c61dc4f885a5155f06f1e): Size of buffered data: 0 bytes
03/06/2020 13:13:34.257 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionManager] Received consume notification from ReleaseOnConsumptionResultPartition 657d9fa3c3c42c8c21b0407ee1e3a770@876cc1eabe833ca7f87c8793f251f04a [PIPELINED_BOUNDED, 2 subpartitions, 0 pending consumptions].
03/06/2020 13:13:34.257  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutor] Un-registering task and sending final execution state FINISHED to JobManager for task SortLimit(orderBy=[degree DESC], offset=[0], fetch=[10]) -> Calc(select=[id, cf]) -> SinkConversionToTuple2 (1/1) 876cc1eabe833ca7f87c8793f251f04a.
03/06/2020 13:13:34.258 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartition] SortLimit(orderBy=[degree DESC], offset=[0], fetch=[10]) -> Calc(select=[id, cf]) -> SinkConversionToTuple2 (1/1) (876cc1eabe833ca7f87c8793f251f04a): Releasing ReleaseOnConsumptionResultPartition 657d9fa3c3c42c8c21b0407ee1e3a770@876cc1eabe833ca7f87c8793f251f04a [PIPELINED_BOUNDED, 2 subpartitions, 0 pending consumptions].
03/06/2020 13:13:34.259 DEBUG [org.apache.flink.runtime.io.network.partition.PipelinedSubpartition] SortLimit(orderBy=[degree DESC], offset=[0], fetch=[10]) -> Calc(select=[id, cf]) -> SinkConversionToTuple2 (1/1) (876cc1eabe833ca7f87c8793f251f04a): Released PipelinedSubpartition#0 [number of buffers: 2 (1669 bytes), number of buffers in backlog: 0, finished? true, read view? false].
03/06/2020 13:13:34.258 DEBUG [org.apache.flink.streaming.runtime.tasks.StreamTask] Finished task Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (2/2)
03/06/2020 13:13:34.259 DEBUG [org.apache.flink.streaming.runtime.tasks.StreamTask] Closed operators for task Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (2/2)
03/06/2020 13:13:34.259 DEBUG [org.apache.flink.runtime.io.network.partition.PipelinedSubpartition] SortLimit(orderBy=[degree DESC], offset=[0], fetch=[10]) -> Calc(select=[id, cf]) -> SinkConversionToTuple2 (1/1) (876cc1eabe833ca7f87c8793f251f04a): Released PipelinedSubpartition#1 [number of buffers: 2 (1669 bytes), number of buffers in backlog: 0, finished? true, read view? false].
03/06/2020 13:13:34.259  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] SortLimit(orderBy=[degree DESC], offset=[0], fetch=[10]) -> Calc(select=[id, cf]) -> SinkConversionToTuple2 (1/1) (876cc1eabe833ca7f87c8793f251f04a) switched from RUNNING to FINISHED.
03/06/2020 13:13:34.260 DEBUG [org.apache.flink.runtime.io.network.partition.PipelinedSubpartition] Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (2/2) (c365017ac85c61dc4f885a5155f06f1e): Finished PipelinedSubpartition#0 [number of buffers: 2 (1625 bytes), number of buffers in backlog: 1, finished? true, read view? true].
03/06/2020 13:13:34.260 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionManager] Released partition 657d9fa3c3c42c8c21b0407ee1e3a770 produced by 876cc1eabe833ca7f87c8793f251f04a.
03/06/2020 13:13:34.260 DEBUG [org.apache.flink.runtime.executiongraph.ExecutionGraph] Ignoring transition of vertex SortLimit(orderBy=[degree DESC], offset=[0], fetch=[10]) -> Calc(select=[id, cf]) -> SinkConversionToTuple2 (1/1) - execution #0 to FAILED while being FINISHED.
03/06/2020 13:13:34.260 DEBUG [org.apache.flink.table.runtime.generated.CompileUtils] Compiling: KeyProjection$108 

 Code:

public class KeyProjection$108 implements org.apache.flink.table.runtime.generated.Projection<org.apache.flink.table.dataformat.BaseRow, org.apache.flink.table.dataformat.BinaryRow> {

  final org.apache.flink.table.dataformat.BinaryRow out = new org.apache.flink.table.dataformat.BinaryRow(1);
final org.apache.flink.table.dataformat.BinaryRowWriter outWriter = new org.apache.flink.table.dataformat.BinaryRowWriter(out);

  public KeyProjection$108(Object[] references) throws Exception {
    
  }

  @Override
  public org.apache.flink.table.dataformat.BinaryRow apply(org.apache.flink.table.dataformat.BaseRow in1) {
    
    

outWriter.reset();


if (in1.isNullAt(1)) {
  outWriter.setNullAt(0);
} else {
  outWriter.writeString(0, in1.getString(1));
}
             
outWriter.complete();
        
    return out;
  }
}
        
03/06/2020 13:13:34.261 DEBUG [org.apache.flink.streaming.runtime.io.CheckpointBarrierAligner] Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (1/2) (4d7a1b8b380293c90670ee95c08224e0): End of stream alignment, feeding buffered data back.
03/06/2020 13:13:34.261 DEBUG [org.apache.flink.streaming.runtime.io.CachedBufferStorage] Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (1/2) (4d7a1b8b380293c90670ee95c08224e0): Size of buffered data: 0 bytes
03/06/2020 13:13:34.261 DEBUG [org.apache.flink.streaming.runtime.tasks.StreamTask] Finished task Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (1/2)
03/06/2020 13:13:34.261 DEBUG [org.apache.flink.streaming.runtime.tasks.StreamTask] Closed operators for task Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (1/2)
03/06/2020 13:13:34.260 DEBUG [org.apache.flink.runtime.io.network.partition.PipelinedSubpartition] Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (2/2) (c365017ac85c61dc4f885a5155f06f1e): Finished PipelinedSubpartition#1 [number of buffers: 2 (1300 bytes), number of buffers in backlog: 0, finished? true, read view? true].
03/06/2020 13:13:34.263 DEBUG [org.apache.flink.runtime.io.network.partition.PipelinedSubpartition] Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (1/2) (4d7a1b8b380293c90670ee95c08224e0): Finished PipelinedSubpartition#0 [number of buffers: 2 (0 bytes), number of buffers in backlog: 1, finished? true, read view? true].
03/06/2020 13:13:34.263 DEBUG [org.apache.flink.runtime.io.network.partition.PipelinedSubpartition] Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (1/2) (4d7a1b8b380293c90670ee95c08224e0): Finished PipelinedSubpartition#1 [number of buffers: 2 (0 bytes), number of buffers in backlog: 1, finished? true, read view? true].
03/06/2020 13:13:34.263  INFO [org.apache.flink.runtime.taskmanager.Task] Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (1/2) (4d7a1b8b380293c90670ee95c08224e0) switched from RUNNING to FINISHED.
03/06/2020 13:13:34.263  INFO [org.apache.flink.runtime.taskmanager.Task] Freeing task resources for Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (1/2) (4d7a1b8b380293c90670ee95c08224e0).
03/06/2020 13:13:34.264 DEBUG [org.apache.flink.runtime.taskmanager.Task] Release task Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (1/2) network resources (state: FINISHED).
03/06/2020 13:13:34.264 DEBUG [org.apache.flink.runtime.io.network.TaskEventDispatcher] unregistering 4bd09e894d9b0e6c6119f756bfe2ba7c@4d7a1b8b380293c90670ee95c08224e0
03/06/2020 13:13:34.264 DEBUG [org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate] Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (1/2) (4d7a1b8b380293c90670ee95c08224e0): Releasing org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate@43e3b98a.
03/06/2020 13:13:34.264  INFO [org.apache.flink.runtime.taskmanager.Task] Ensuring all FileSystem streams are closed for task Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (1/2) (4d7a1b8b380293c90670ee95c08224e0) [FINISHED]
03/06/2020 13:13:34.264  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutor] Un-registering task and sending final execution state FINISHED to JobManager for task Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (1/2) 4d7a1b8b380293c90670ee95c08224e0.
03/06/2020 13:13:34.265  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (1/2) (4d7a1b8b380293c90670ee95c08224e0) switched from RUNNING to FINISHED.
03/06/2020 13:13:34.265 DEBUG [org.apache.flink.runtime.executiongraph.ExecutionGraph] Ignoring transition of vertex Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (1/2) - execution #0 to FAILED while being FINISHED.
03/06/2020 13:13:34.263  INFO [org.apache.flink.runtime.taskmanager.Task] Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (2/2) (c365017ac85c61dc4f885a5155f06f1e) switched from RUNNING to FINISHED.
03/06/2020 13:13:34.266  INFO [org.apache.flink.runtime.taskmanager.Task] Freeing task resources for Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (2/2) (c365017ac85c61dc4f885a5155f06f1e).
03/06/2020 13:13:34.266 DEBUG [org.apache.flink.runtime.taskmanager.Task] Release task Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (2/2) network resources (state: FINISHED).
03/06/2020 13:13:34.266 DEBUG [org.apache.flink.runtime.io.network.TaskEventDispatcher] unregistering 0ba5902cc0427ce26c3f0693bdc93d05@c365017ac85c61dc4f885a5155f06f1e
03/06/2020 13:13:34.266 DEBUG [org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate] Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (2/2) (c365017ac85c61dc4f885a5155f06f1e): Releasing org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate@3dadb270.
03/06/2020 13:13:34.267  INFO [org.apache.flink.runtime.taskmanager.Task] Ensuring all FileSystem streams are closed for task Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (2/2) (c365017ac85c61dc4f885a5155f06f1e) [FINISHED]
03/06/2020 13:13:34.269 DEBUG [org.apache.flink.table.runtime.generated.CompileUtils] Compiling: KeyProjection$126 

 Code:

public class KeyProjection$126 implements org.apache.flink.table.runtime.generated.Projection<org.apache.flink.table.dataformat.BaseRow, org.apache.flink.table.dataformat.BinaryRow> {

  final org.apache.flink.table.dataformat.BinaryRow out = new org.apache.flink.table.dataformat.BinaryRow(1);
final org.apache.flink.table.dataformat.BinaryRowWriter outWriter = new org.apache.flink.table.dataformat.BinaryRowWriter(out);

  public KeyProjection$126(Object[] references) throws Exception {
    
  }

  @Override
  public org.apache.flink.table.dataformat.BinaryRow apply(org.apache.flink.table.dataformat.BaseRow in1) {
    
    

outWriter.reset();


if (in1.isNullAt(0)) {
  outWriter.setNullAt(0);
} else {
  outWriter.writeString(0, in1.getString(0));
}
             
outWriter.complete();
        
    return out;
  }
}
        
03/06/2020 13:13:34.269  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutor] Un-registering task and sending final execution state FINISHED to JobManager for task Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (2/2) c365017ac85c61dc4f885a5155f06f1e.
03/06/2020 13:13:34.271  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (2/2) (c365017ac85c61dc4f885a5155f06f1e) switched from RUNNING to FINISHED.
03/06/2020 13:13:34.271 DEBUG [org.apache.flink.runtime.executiongraph.ExecutionGraph] Ignoring transition of vertex Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (2/2) - execution #0 to FAILED while being FINISHED.
03/06/2020 13:13:34.277 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartition] ReleaseOnConsumptionResultPartition 0ba5902cc0427ce26c3f0693bdc93d05@c365017ac85c61dc4f885a5155f06f1e [PIPELINED_BOUNDED, 2 subpartitions, 1 pending consumptions]: Received consumed notification for subpartition 1.
03/06/2020 13:13:34.277 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartition] ReleaseOnConsumptionResultPartition 0ba5902cc0427ce26c3f0693bdc93d05@c365017ac85c61dc4f885a5155f06f1e [PIPELINED_BOUNDED, 2 subpartitions, 0 pending consumptions]: Received consumed notification for subpartition 0.
03/06/2020 13:13:34.277 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionManager] Received consume notification from ReleaseOnConsumptionResultPartition 0ba5902cc0427ce26c3f0693bdc93d05@c365017ac85c61dc4f885a5155f06f1e [PIPELINED_BOUNDED, 2 subpartitions, 0 pending consumptions].
03/06/2020 13:13:34.277 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartition] Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (2/2) (c365017ac85c61dc4f885a5155f06f1e): Releasing ReleaseOnConsumptionResultPartition 0ba5902cc0427ce26c3f0693bdc93d05@c365017ac85c61dc4f885a5155f06f1e [PIPELINED_BOUNDED, 2 subpartitions, 0 pending consumptions].
03/06/2020 13:13:34.277 DEBUG [org.apache.flink.runtime.io.network.partition.PipelinedSubpartition] Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (2/2) (c365017ac85c61dc4f885a5155f06f1e): Released PipelinedSubpartition#0 [number of buffers: 2 (1629 bytes), number of buffers in backlog: 0, finished? true, read view? false].
03/06/2020 13:13:34.277 DEBUG [org.apache.flink.runtime.io.network.partition.PipelinedSubpartition] Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (2/2) (c365017ac85c61dc4f885a5155f06f1e): Released PipelinedSubpartition#1 [number of buffers: 2 (1304 bytes), number of buffers in backlog: 0, finished? true, read view? false].
03/06/2020 13:13:34.277 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionManager] Released partition 0ba5902cc0427ce26c3f0693bdc93d05 produced by c365017ac85c61dc4f885a5155f06f1e.
03/06/2020 13:13:34.278 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartition] ReleaseOnConsumptionResultPartition 4bd09e894d9b0e6c6119f756bfe2ba7c@4d7a1b8b380293c90670ee95c08224e0 [PIPELINED_BOUNDED, 2 subpartitions, 1 pending consumptions]: Received consumed notification for subpartition 1.
03/06/2020 13:13:34.278 DEBUG [org.apache.flink.streaming.runtime.io.CheckpointBarrierAligner] GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (2/2) (1ff6ef243e2fa7b8aa3f13605b545e75): End of stream alignment, feeding buffered data back.
03/06/2020 13:13:34.279 DEBUG [org.apache.flink.streaming.runtime.io.CachedBufferStorage] GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (2/2) (1ff6ef243e2fa7b8aa3f13605b545e75): Size of buffered data: 0 bytes
03/06/2020 13:13:34.279 DEBUG [org.apache.flink.streaming.runtime.tasks.StreamTask] Finished task GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (2/2)
03/06/2020 13:13:34.279 DEBUG [org.apache.flink.streaming.runtime.tasks.StreamTask] Closed operators for task GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (2/2)
03/06/2020 13:13:34.279 DEBUG [org.apache.flink.table.runtime.generated.CompileUtils] Compiling: KeyProjection$146 

 Code:

public class KeyProjection$146 implements org.apache.flink.table.runtime.generated.Projection<org.apache.flink.table.dataformat.BaseRow, org.apache.flink.table.dataformat.BinaryRow> {

  final org.apache.flink.table.dataformat.BinaryRow out = new org.apache.flink.table.dataformat.BinaryRow(1);
final org.apache.flink.table.dataformat.BinaryRowWriter outWriter = new org.apache.flink.table.dataformat.BinaryRowWriter(out);

  public KeyProjection$146(Object[] references) throws Exception {
    
  }

  @Override
  public org.apache.flink.table.dataformat.BinaryRow apply(org.apache.flink.table.dataformat.BaseRow in1) {
    
    

outWriter.reset();


if (in1.isNullAt(0)) {
  outWriter.setNullAt(0);
} else {
  outWriter.writeString(0, in1.getString(0));
}
             
outWriter.complete();
        
    return out;
  }
}
        
03/06/2020 13:13:34.293 DEBUG [org.apache.flink.runtime.io.network.partition.PipelinedSubpartition] GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (2/2) (1ff6ef243e2fa7b8aa3f13605b545e75): Finished PipelinedSubpartition#0 [number of buffers: 1 (0 bytes), number of buffers in backlog: 0, finished? true, read view? true].
03/06/2020 13:13:34.293 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartition] ReleaseOnConsumptionResultPartition 4a4d2bc06a45d34db956e3a272eab10a@1ff6ef243e2fa7b8aa3f13605b545e75 [PIPELINED_BOUNDED, 2 subpartitions, 1 pending consumptions]: Received consumed notification for subpartition 0.
03/06/2020 13:13:34.294 DEBUG [org.apache.flink.runtime.io.network.partition.PipelinedSubpartition] GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (2/2) (1ff6ef243e2fa7b8aa3f13605b545e75): Finished PipelinedSubpartition#1 [number of buffers: 2 (2394 bytes), number of buffers in backlog: 1, finished? true, read view? true].
03/06/2020 13:13:34.294  INFO [org.apache.flink.runtime.taskmanager.Task] GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (2/2) (1ff6ef243e2fa7b8aa3f13605b545e75) switched from RUNNING to FINISHED.
03/06/2020 13:13:34.294  INFO [org.apache.flink.runtime.taskmanager.Task] Freeing task resources for GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (2/2) (1ff6ef243e2fa7b8aa3f13605b545e75).
03/06/2020 13:13:34.294 DEBUG [org.apache.flink.runtime.taskmanager.Task] Release task GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (2/2) network resources (state: FINISHED).
03/06/2020 13:13:34.294 DEBUG [org.apache.flink.runtime.io.network.TaskEventDispatcher] unregistering 4a4d2bc06a45d34db956e3a272eab10a@1ff6ef243e2fa7b8aa3f13605b545e75
03/06/2020 13:13:34.294 DEBUG [org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate] GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (2/2) (1ff6ef243e2fa7b8aa3f13605b545e75): Releasing org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate@16e6e8d5.
03/06/2020 13:13:34.294  INFO [org.apache.flink.runtime.taskmanager.Task] Ensuring all FileSystem streams are closed for task GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (2/2) (1ff6ef243e2fa7b8aa3f13605b545e75) [FINISHED]
03/06/2020 13:13:34.295  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutor] Un-registering task and sending final execution state FINISHED to JobManager for task GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (2/2) 1ff6ef243e2fa7b8aa3f13605b545e75.
03/06/2020 13:13:34.295  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (2/2) (1ff6ef243e2fa7b8aa3f13605b545e75) switched from RUNNING to FINISHED.
03/06/2020 13:13:34.296 DEBUG [org.apache.flink.runtime.executiongraph.ExecutionGraph] Ignoring transition of vertex GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (2/2) - execution #0 to FAILED while being FINISHED.
03/06/2020 13:13:34.300 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartition] ReleaseOnConsumptionResultPartition 4bd09e894d9b0e6c6119f756bfe2ba7c@4d7a1b8b380293c90670ee95c08224e0 [PIPELINED_BOUNDED, 2 subpartitions, 0 pending consumptions]: Received consumed notification for subpartition 0.
03/06/2020 13:13:34.300 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionManager] Received consume notification from ReleaseOnConsumptionResultPartition 4bd09e894d9b0e6c6119f756bfe2ba7c@4d7a1b8b380293c90670ee95c08224e0 [PIPELINED_BOUNDED, 2 subpartitions, 0 pending consumptions].
03/06/2020 13:13:34.300 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartition] Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (1/2) (4d7a1b8b380293c90670ee95c08224e0): Releasing ReleaseOnConsumptionResultPartition 4bd09e894d9b0e6c6119f756bfe2ba7c@4d7a1b8b380293c90670ee95c08224e0 [PIPELINED_BOUNDED, 2 subpartitions, 0 pending consumptions].
03/06/2020 13:13:34.300 DEBUG [org.apache.flink.runtime.io.network.partition.PipelinedSubpartition] Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (1/2) (4d7a1b8b380293c90670ee95c08224e0): Released PipelinedSubpartition#0 [number of buffers: 2 (1499 bytes), number of buffers in backlog: 0, finished? true, read view? false].
03/06/2020 13:13:34.300 DEBUG [org.apache.flink.runtime.io.network.partition.PipelinedSubpartition] Map -> SourceConversion(table=[Unregistered_DataStream_8], fields=[f0, f1, f2]) -> Calc(select=[f0 AS bool, f1 AS v_id, f2 AS degree]) (1/2) (4d7a1b8b380293c90670ee95c08224e0): Released PipelinedSubpartition#1 [number of buffers: 2 (1434 bytes), number of buffers in backlog: 0, finished? true, read view? false].
03/06/2020 13:13:34.300 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionManager] Released partition 4bd09e894d9b0e6c6119f756bfe2ba7c produced by 4d7a1b8b380293c90670ee95c08224e0.
03/06/2020 13:13:34.300 DEBUG [org.apache.flink.streaming.runtime.io.CheckpointBarrierAligner] GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (1/2) (02de6f076d7957e472f6eb0edbd38dbf): End of stream alignment, feeding buffered data back.
03/06/2020 13:13:34.300 DEBUG [org.apache.flink.streaming.runtime.io.CachedBufferStorage] GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (1/2) (02de6f076d7957e472f6eb0edbd38dbf): Size of buffered data: 0 bytes
03/06/2020 13:13:34.301 DEBUG [org.apache.flink.streaming.runtime.tasks.StreamTask] Finished task GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (1/2)
03/06/2020 13:13:34.301 DEBUG [org.apache.flink.streaming.runtime.tasks.StreamTask] Closed operators for task GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (1/2)
03/06/2020 13:13:34.303 DEBUG [org.apache.flink.runtime.io.network.partition.PipelinedSubpartition] GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (1/2) (02de6f076d7957e472f6eb0edbd38dbf): Finished PipelinedSubpartition#0 [number of buffers: 2 (2736 bytes), number of buffers in backlog: 1, finished? true, read view? true].
03/06/2020 13:13:34.304 DEBUG [org.apache.flink.runtime.io.network.partition.PipelinedSubpartition] GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (1/2) (02de6f076d7957e472f6eb0edbd38dbf): Finished PipelinedSubpartition#1 [number of buffers: 1 (0 bytes), number of buffers in backlog: 0, finished? true, read view? true].
03/06/2020 13:13:34.304  INFO [org.apache.flink.runtime.taskmanager.Task] GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (1/2) (02de6f076d7957e472f6eb0edbd38dbf) switched from RUNNING to FINISHED.
03/06/2020 13:13:34.304  INFO [org.apache.flink.runtime.taskmanager.Task] Freeing task resources for GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (1/2) (02de6f076d7957e472f6eb0edbd38dbf).
03/06/2020 13:13:34.304 DEBUG [org.apache.flink.runtime.taskmanager.Task] Release task GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (1/2) network resources (state: FINISHED).
03/06/2020 13:13:34.304 DEBUG [org.apache.flink.runtime.io.network.TaskEventDispatcher] unregistering f45f0539b91a35f8f33f7e0d2d64813c@02de6f076d7957e472f6eb0edbd38dbf
03/06/2020 13:13:34.304 DEBUG [org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate] GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (1/2) (02de6f076d7957e472f6eb0edbd38dbf): Releasing org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate@7b6e631b.
03/06/2020 13:13:34.304  INFO [org.apache.flink.runtime.taskmanager.Task] Ensuring all FileSystem streams are closed for task GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (1/2) (02de6f076d7957e472f6eb0edbd38dbf) [FINISHED]
03/06/2020 13:13:34.304  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutor] Un-registering task and sending final execution state FINISHED to JobManager for task GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (1/2) 02de6f076d7957e472f6eb0edbd38dbf.
03/06/2020 13:13:34.305  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (1/2) (02de6f076d7957e472f6eb0edbd38dbf) switched from RUNNING to FINISHED.
03/06/2020 13:13:34.305 DEBUG [org.apache.flink.runtime.executiongraph.ExecutionGraph] Ignoring transition of vertex GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (1/2) - execution #0 to FAILED while being FINISHED.
03/06/2020 13:13:34.307 DEBUG [org.apache.flink.streaming.api.functions.sink.filesystem.Bucket] Subtask 0 closing in-progress part file for bucket id=2020-06-03--13 due to element true 1 tag 1 1202 1970.
03/06/2020 13:13:34.309 DEBUG [org.apache.flink.streaming.api.functions.sink.filesystem.Bucket] Subtask 1 closing in-progress part file for bucket id=2020-06-03--13 due to element true 3 tag 3 2211 2414.
03/06/2020 13:13:34.316 DEBUG [org.apache.flink.streaming.api.functions.sink.filesystem.Bucket] Subtask 0 opening new part file "part-0-0" for bucket id=2020-06-03--13.
03/06/2020 13:13:34.317 DEBUG [org.apache.flink.streaming.api.functions.sink.filesystem.Bucket] Subtask 1 opening new part file "part-1-0" for bucket id=2020-06-03--13.
03/06/2020 13:13:34.323 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartition] ReleaseOnConsumptionResultPartition f45f0539b91a35f8f33f7e0d2d64813c@02de6f076d7957e472f6eb0edbd38dbf [PIPELINED_BOUNDED, 2 subpartitions, 1 pending consumptions]: Received consumed notification for subpartition 0.
03/06/2020 13:13:34.324 DEBUG [org.apache.flink.streaming.runtime.io.CheckpointBarrierAligner] Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (1/2) (6dfb6ce5559aca85d7e81c96224f4864): End of stream alignment, feeding buffered data back.
03/06/2020 13:13:34.324 DEBUG [org.apache.flink.streaming.runtime.io.CachedBufferStorage] Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (1/2) (6dfb6ce5559aca85d7e81c96224f4864): Size of buffered data: 0 bytes
03/06/2020 13:13:34.324 DEBUG [org.apache.flink.streaming.runtime.io.CachedBufferStorage] Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (1/2) (6dfb6ce5559aca85d7e81c96224f4864): Size of buffered data: 0 bytes
03/06/2020 13:13:34.324 DEBUG [org.apache.flink.streaming.runtime.tasks.StreamTask] Finished task Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (1/2)
03/06/2020 13:13:34.329 DEBUG [org.apache.flink.streaming.runtime.tasks.StreamTask] Closed operators for task Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (1/2)
03/06/2020 13:13:34.333 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartition] ReleaseOnConsumptionResultPartition 549697b480ed2892912b6fb269129087@6dfb6ce5559aca85d7e81c96224f4864 [PIPELINED_BOUNDED, 1 subpartitions, 0 pending consumptions]: Received consumed notification for subpartition 0.
03/06/2020 13:13:34.333 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionManager] Received consume notification from ReleaseOnConsumptionResultPartition 549697b480ed2892912b6fb269129087@6dfb6ce5559aca85d7e81c96224f4864 [PIPELINED_BOUNDED, 1 subpartitions, 0 pending consumptions].
03/06/2020 13:13:34.333 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartition] Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (1/2) (6dfb6ce5559aca85d7e81c96224f4864): Releasing ReleaseOnConsumptionResultPartition 549697b480ed2892912b6fb269129087@6dfb6ce5559aca85d7e81c96224f4864 [PIPELINED_BOUNDED, 1 subpartitions, 0 pending consumptions].
03/06/2020 13:13:34.334 DEBUG [org.apache.flink.runtime.io.network.partition.PipelinedSubpartition] Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (1/2) (6dfb6ce5559aca85d7e81c96224f4864): Released PipelinedSubpartition#0 [number of buffers: 2 (1611 bytes), number of buffers in backlog: 0, finished? true, read view? false].
03/06/2020 13:13:34.334 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionManager] Released partition 549697b480ed2892912b6fb269129087 produced by 6dfb6ce5559aca85d7e81c96224f4864.
03/06/2020 13:13:34.333 DEBUG [org.apache.flink.runtime.io.network.partition.PipelinedSubpartition] Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (1/2) (6dfb6ce5559aca85d7e81c96224f4864): Finished PipelinedSubpartition#0 [number of buffers: 2 (1607 bytes), number of buffers in backlog: 1, finished? true, read view? true].
03/06/2020 13:13:34.335  INFO [org.apache.flink.runtime.taskmanager.Task] Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (1/2) (6dfb6ce5559aca85d7e81c96224f4864) switched from RUNNING to FINISHED.
03/06/2020 13:13:34.335  INFO [org.apache.flink.runtime.taskmanager.Task] Freeing task resources for Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (1/2) (6dfb6ce5559aca85d7e81c96224f4864).
03/06/2020 13:13:34.335 DEBUG [org.apache.flink.runtime.taskmanager.Task] Release task Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (1/2) network resources (state: FINISHED).
03/06/2020 13:13:34.335 DEBUG [org.apache.flink.runtime.io.network.TaskEventDispatcher] unregistering 549697b480ed2892912b6fb269129087@6dfb6ce5559aca85d7e81c96224f4864
03/06/2020 13:13:34.335 DEBUG [org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate] Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (1/2) (6dfb6ce5559aca85d7e81c96224f4864): Releasing org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate@41c79021.
03/06/2020 13:13:34.335 DEBUG [org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate] Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (1/2) (6dfb6ce5559aca85d7e81c96224f4864): Releasing org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate@1644ac98.
03/06/2020 13:13:34.337  INFO [org.apache.flink.runtime.taskmanager.Task] Ensuring all FileSystem streams are closed for task Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (1/2) (6dfb6ce5559aca85d7e81c96224f4864) [FINISHED]
03/06/2020 13:13:34.337  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutor] Un-registering task and sending final execution state FINISHED to JobManager for task Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (1/2) 6dfb6ce5559aca85d7e81c96224f4864.
03/06/2020 13:13:34.338  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (1/2) (6dfb6ce5559aca85d7e81c96224f4864) switched from RUNNING to FINISHED.
03/06/2020 13:13:34.338 DEBUG [org.apache.flink.runtime.executiongraph.ExecutionGraph] Ignoring transition of vertex Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (1/2) - execution #0 to FAILED while being FINISHED.
03/06/2020 13:13:34.338 DEBUG [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] Releasing slot [SlotRequestId{2441ab0ac753774db5fa5db436e75215}] because: Release multi task slot because all children have been released.
03/06/2020 13:13:34.338 DEBUG [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] Adding returned slot [72c915e615c4f2f98aedf5eb10885367] to available slots
03/06/2020 13:13:34.339 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartition] ReleaseOnConsumptionResultPartition 4a4d2bc06a45d34db956e3a272eab10a@1ff6ef243e2fa7b8aa3f13605b545e75 [PIPELINED_BOUNDED, 2 subpartitions, 0 pending consumptions]: Received consumed notification for subpartition 1.
03/06/2020 13:13:34.339 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionManager] Received consume notification from ReleaseOnConsumptionResultPartition 4a4d2bc06a45d34db956e3a272eab10a@1ff6ef243e2fa7b8aa3f13605b545e75 [PIPELINED_BOUNDED, 2 subpartitions, 0 pending consumptions].
03/06/2020 13:13:34.339 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartition] GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (2/2) (1ff6ef243e2fa7b8aa3f13605b545e75): Releasing ReleaseOnConsumptionResultPartition 4a4d2bc06a45d34db956e3a272eab10a@1ff6ef243e2fa7b8aa3f13605b545e75 [PIPELINED_BOUNDED, 2 subpartitions, 0 pending consumptions].
03/06/2020 13:13:34.339 DEBUG [org.apache.flink.runtime.io.network.partition.PipelinedSubpartition] GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (2/2) (1ff6ef243e2fa7b8aa3f13605b545e75): Released PipelinedSubpartition#0 [number of buffers: 1 (4 bytes), number of buffers in backlog: 0, finished? true, read view? false].
03/06/2020 13:13:34.339 DEBUG [org.apache.flink.runtime.io.network.partition.PipelinedSubpartition] GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (2/2) (1ff6ef243e2fa7b8aa3f13605b545e75): Released PipelinedSubpartition#1 [number of buffers: 2 (2398 bytes), number of buffers in backlog: 0, finished? true, read view? false].
03/06/2020 13:13:34.339 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionManager] Released partition 4a4d2bc06a45d34db956e3a272eab10a produced by 1ff6ef243e2fa7b8aa3f13605b545e75.
03/06/2020 13:13:34.343 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartition] ReleaseOnConsumptionResultPartition f45f0539b91a35f8f33f7e0d2d64813c@02de6f076d7957e472f6eb0edbd38dbf [PIPELINED_BOUNDED, 2 subpartitions, 0 pending consumptions]: Received consumed notification for subpartition 1.
03/06/2020 13:13:34.343 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionManager] Received consume notification from ReleaseOnConsumptionResultPartition f45f0539b91a35f8f33f7e0d2d64813c@02de6f076d7957e472f6eb0edbd38dbf [PIPELINED_BOUNDED, 2 subpartitions, 0 pending consumptions].
03/06/2020 13:13:34.343 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartition] GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (1/2) (02de6f076d7957e472f6eb0edbd38dbf): Releasing ReleaseOnConsumptionResultPartition f45f0539b91a35f8f33f7e0d2d64813c@02de6f076d7957e472f6eb0edbd38dbf [PIPELINED_BOUNDED, 2 subpartitions, 0 pending consumptions].
03/06/2020 13:13:34.343 DEBUG [org.apache.flink.runtime.io.network.partition.PipelinedSubpartition] GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (1/2) (02de6f076d7957e472f6eb0edbd38dbf): Released PipelinedSubpartition#0 [number of buffers: 2 (2740 bytes), number of buffers in backlog: 0, finished? true, read view? false].
03/06/2020 13:13:34.343 DEBUG [org.apache.flink.runtime.io.network.partition.PipelinedSubpartition] GroupAggregate(groupBy=[v_id], select=[v_id, CurrentVertex(bool, v_id, degree) AS TMP_0]) -> Calc(select=[v_id, TMP_0.f1 AS degree], where=[(TMP_0.f0 = _UTF-16LE'true')]) (1/2) (02de6f076d7957e472f6eb0edbd38dbf): Released PipelinedSubpartition#1 [number of buffers: 1 (4 bytes), number of buffers in backlog: 0, finished? true, read view? false].
03/06/2020 13:13:34.343 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionManager] Released partition f45f0539b91a35f8f33f7e0d2d64813c produced by 02de6f076d7957e472f6eb0edbd38dbf.
03/06/2020 13:13:34.343 DEBUG [org.apache.flink.streaming.runtime.io.CheckpointBarrierAligner] Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (2/2) (27eb9406de3597496fd0bb48c5e876a5): End of stream alignment, feeding buffered data back.
03/06/2020 13:13:34.343 DEBUG [org.apache.flink.streaming.runtime.io.CachedBufferStorage] Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (2/2) (27eb9406de3597496fd0bb48c5e876a5): Size of buffered data: 0 bytes
03/06/2020 13:13:34.343 DEBUG [org.apache.flink.streaming.runtime.io.CachedBufferStorage] Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (2/2) (27eb9406de3597496fd0bb48c5e876a5): Size of buffered data: 0 bytes
03/06/2020 13:13:34.344 DEBUG [org.apache.flink.streaming.runtime.tasks.StreamTask] Finished task Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (2/2)
03/06/2020 13:13:34.344 DEBUG [org.apache.flink.streaming.runtime.tasks.StreamTask] Closed operators for task Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (2/2)
03/06/2020 13:13:34.348 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartition] ReleaseOnConsumptionResultPartition 37419b70f6b9f20c581859a2a6711084@27eb9406de3597496fd0bb48c5e876a5 [PIPELINED_BOUNDED, 1 subpartitions, 0 pending consumptions]: Received consumed notification for subpartition 0.
03/06/2020 13:13:34.348 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionManager] Received consume notification from ReleaseOnConsumptionResultPartition 37419b70f6b9f20c581859a2a6711084@27eb9406de3597496fd0bb48c5e876a5 [PIPELINED_BOUNDED, 1 subpartitions, 0 pending consumptions].
03/06/2020 13:13:34.348 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartition] Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (2/2) (27eb9406de3597496fd0bb48c5e876a5): Releasing ReleaseOnConsumptionResultPartition 37419b70f6b9f20c581859a2a6711084@27eb9406de3597496fd0bb48c5e876a5 [PIPELINED_BOUNDED, 1 subpartitions, 0 pending consumptions].
03/06/2020 13:13:34.348 DEBUG [org.apache.flink.runtime.io.network.partition.PipelinedSubpartition] Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (2/2) (27eb9406de3597496fd0bb48c5e876a5): Released PipelinedSubpartition#0 [number of buffers: 2 (1386 bytes), number of buffers in backlog: 0, finished? true, read view? false].
03/06/2020 13:13:34.348 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionManager] Released partition 37419b70f6b9f20c581859a2a6711084 produced by 27eb9406de3597496fd0bb48c5e876a5.
03/06/2020 13:13:34.349 DEBUG [org.apache.flink.streaming.runtime.io.CheckpointBarrierAligner] Sink: Print to Std. Out (1/1) (26e0302ddaecd3150ec5345d3906b102): End of stream alignment, feeding buffered data back.
03/06/2020 13:13:34.349 DEBUG [org.apache.flink.streaming.runtime.io.CachedBufferStorage] Sink: Print to Std. Out (1/1) (26e0302ddaecd3150ec5345d3906b102): Size of buffered data: 0 bytes
03/06/2020 13:13:34.349 DEBUG [org.apache.flink.streaming.runtime.tasks.StreamTask] Finished task Sink: Print to Std. Out (1/1)
03/06/2020 13:13:34.349 DEBUG [org.apache.flink.streaming.runtime.tasks.StreamTask] Closed operators for task Sink: Print to Std. Out (1/1)
03/06/2020 13:13:34.349  INFO [org.apache.flink.runtime.taskmanager.Task] Sink: Print to Std. Out (1/1) (26e0302ddaecd3150ec5345d3906b102) switched from RUNNING to FINISHED.
03/06/2020 13:13:34.349  INFO [org.apache.flink.runtime.taskmanager.Task] Freeing task resources for Sink: Print to Std. Out (1/1) (26e0302ddaecd3150ec5345d3906b102).
03/06/2020 13:13:34.349 DEBUG [org.apache.flink.runtime.taskmanager.Task] Release task Sink: Print to Std. Out (1/1) network resources (state: FINISHED).
03/06/2020 13:13:34.349 DEBUG [org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate] Sink: Print to Std. Out (1/1) (26e0302ddaecd3150ec5345d3906b102): Releasing org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate@257881c7.
03/06/2020 13:13:34.349  INFO [org.apache.flink.runtime.taskmanager.Task] Ensuring all FileSystem streams are closed for task Sink: Print to Std. Out (1/1) (26e0302ddaecd3150ec5345d3906b102) [FINISHED]
03/06/2020 13:13:34.350  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutor] Un-registering task and sending final execution state FINISHED to JobManager for task Sink: Print to Std. Out (1/1) 26e0302ddaecd3150ec5345d3906b102.
03/06/2020 13:13:34.351  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] Sink: Print to Std. Out (1/1) (26e0302ddaecd3150ec5345d3906b102) switched from RUNNING to FINISHED.
03/06/2020 13:13:34.351 DEBUG [org.apache.flink.runtime.io.network.partition.PipelinedSubpartition] Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (2/2) (27eb9406de3597496fd0bb48c5e876a5): Finished PipelinedSubpartition#0 [number of buffers: 2 (1386 bytes), number of buffers in backlog: 0, finished? true, read view? false].
03/06/2020 13:13:34.351  INFO [org.apache.flink.runtime.taskmanager.Task] Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (2/2) (27eb9406de3597496fd0bb48c5e876a5) switched from RUNNING to FINISHED.
03/06/2020 13:13:34.351  INFO [org.apache.flink.runtime.taskmanager.Task] Freeing task resources for Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (2/2) (27eb9406de3597496fd0bb48c5e876a5).
03/06/2020 13:13:34.351 DEBUG [org.apache.flink.runtime.taskmanager.Task] Release task Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (2/2) network resources (state: FINISHED).
03/06/2020 13:13:34.351 DEBUG [org.apache.flink.runtime.executiongraph.ExecutionGraph] Ignoring transition of vertex Sink: Print to Std. Out (1/1) - execution #0 to FAILED while being FINISHED.
03/06/2020 13:13:34.351 DEBUG [org.apache.flink.runtime.io.network.TaskEventDispatcher] unregistering 37419b70f6b9f20c581859a2a6711084@27eb9406de3597496fd0bb48c5e876a5
03/06/2020 13:13:34.352 DEBUG [org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate] Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (2/2) (27eb9406de3597496fd0bb48c5e876a5): Releasing org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate@1dffdb7d.
03/06/2020 13:13:34.352 DEBUG [org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate] Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (2/2) (27eb9406de3597496fd0bb48c5e876a5): Releasing org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate@47dc3fcb.
03/06/2020 13:13:34.352  INFO [org.apache.flink.runtime.taskmanager.Task] Ensuring all FileSystem streams are closed for task Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (2/2) (27eb9406de3597496fd0bb48c5e876a5) [FINISHED]
03/06/2020 13:13:34.354  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutor] Un-registering task and sending final execution state FINISHED to JobManager for task Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (2/2) 27eb9406de3597496fd0bb48c5e876a5.
03/06/2020 13:13:34.355  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (2/2) (27eb9406de3597496fd0bb48c5e876a5) switched from RUNNING to FINISHED.
03/06/2020 13:13:34.356 DEBUG [org.apache.flink.runtime.executiongraph.ExecutionGraph] Ignoring transition of vertex Join(joinType=[InnerJoin], where=[(v_id = v_id_2)], select=[v_id, degree, v_id_2, v_label, v_id_layout, X, Y], leftInputSpec=[JoinKeyContainsUniqueKey], rightInputSpec=[NoUniqueKey]) -> Calc(select=[v_label, X, Y, v_id_layout, degree, v_id]) -> SinkConversionToTuple2 -> Map -> Sink: Unnamed (2/2) - execution #0 to FAILED while being FINISHED.
03/06/2020 13:13:34.356 DEBUG [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] Releasing slot [SlotRequestId{f1a06e8d90a3a49be59c5acf6026b3b9}] because: Release multi task slot because all children have been released.
03/06/2020 13:13:34.356 DEBUG [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] Adding returned slot [25d44a59926bde802cdf946b4a6b94f9] to available slots
03/06/2020 13:13:34.356  INFO [org.apache.flink.runtime.executiongraph.ExecutionGraph] Job test (cf350677de1d99f7f7ea8e79709c5624) switched from state RUNNING to FINISHED.
03/06/2020 13:13:34.356  INFO [org.apache.flink.runtime.checkpoint.CheckpointCoordinator] Stopping checkpoint coordinator for job cf350677de1d99f7f7ea8e79709c5624.
03/06/2020 13:13:34.357  INFO [org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore] Shutting down
03/06/2020 13:13:34.360  INFO [org.apache.flink.runtime.minicluster.MiniCluster] Shutting down Flink Mini Cluster
03/06/2020 13:13:34.360  INFO [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Shutting down rest endpoint.
03/06/2020 13:13:34.368  INFO [org.apache.flink.runtime.dispatcher.StandaloneDispatcher] Job cf350677de1d99f7f7ea8e79709c5624 reached globally terminal state FINISHED.
03/06/2020 13:13:34.368  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutor] Stopping TaskExecutor akka://flink/user/taskmanager_2.
03/06/2020 13:13:34.368 DEBUG [org.apache.flink.runtime.taskexecutor.TaskExecutor] Close ResourceManager connection bc49a6984ea2749b4609c8a8d254c617.
org.apache.flink.util.FlinkException: The TaskExecutor is shutting down.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.onStop(TaskExecutor.java:359)
	at org.apache.flink.runtime.rpc.RpcEndpoint.internalCallOnStop(RpcEndpoint.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor$StartedState.terminate(AkkaRpcActor.java:509)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleControlMessage(AkkaRpcActor.java:175)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction$class.applyOrElse(PartialFunction.scala:123)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at akka.actor.Actor$class.aroundReceive(Actor.scala:517)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
03/06/2020 13:13:34.369 DEBUG [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl] Free slot TaskSlot(index:0, state:ACTIVE, resource profile: ResourceProfile{managedMemory=64,000mb (67108864 bytes), networkMemory=32,000mb (33554432 bytes)}, allocationId: 25d44a59926bde802cdf946b4a6b94f9, jobId: cf350677de1d99f7f7ea8e79709c5624).
org.apache.flink.util.FlinkException: Closing task slot table
	at org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.closeAsync(TaskSlotTableImpl.java:160)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.onStop(TaskExecutor.java:375)
	at org.apache.flink.runtime.rpc.RpcEndpoint.internalCallOnStop(RpcEndpoint.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor$StartedState.terminate(AkkaRpcActor.java:509)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleControlMessage(AkkaRpcActor.java:175)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction$class.applyOrElse(PartialFunction.scala:123)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at akka.actor.Actor$class.aroundReceive(Actor.scala:517)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
03/06/2020 13:13:34.370 DEBUG [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl] Free slot TaskSlot(index:1, state:ACTIVE, resource profile: ResourceProfile{managedMemory=64,000mb (67108864 bytes), networkMemory=32,000mb (33554432 bytes)}, allocationId: 72c915e615c4f2f98aedf5eb10885367, jobId: cf350677de1d99f7f7ea8e79709c5624).
org.apache.flink.util.FlinkException: Closing task slot table
	at org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.closeAsync(TaskSlotTableImpl.java:160)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.onStop(TaskExecutor.java:375)
	at org.apache.flink.runtime.rpc.RpcEndpoint.internalCallOnStop(RpcEndpoint.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor$StartedState.terminate(AkkaRpcActor.java:509)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleControlMessage(AkkaRpcActor.java:175)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction$class.applyOrElse(PartialFunction.scala:123)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at akka.actor.Actor$class.aroundReceive(Actor.scala:517)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
03/06/2020 13:13:34.390  INFO [org.apache.flink.runtime.taskexecutor.JobLeaderService] Stop job leader service.
03/06/2020 13:13:34.391  INFO [org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager] Shutting down TaskExecutorLocalStateStoresManager.
03/06/2020 13:13:34.391 DEBUG [org.apache.flink.runtime.io.disk.iomanager.IOManager] Shutting down I/O manager.
03/06/2020 13:13:34.397  INFO [org.apache.flink.runtime.io.disk.FileChannelManagerImpl] FileChannelManager removed spill file directory /tmp/flink-io-80161287-20ce-471f-9e75-d41564babd95
03/06/2020 13:13:34.398  INFO [org.apache.flink.runtime.io.network.NettyShuffleEnvironment] Shutting down the network environment and its components.
03/06/2020 13:13:34.398 DEBUG [org.apache.flink.runtime.io.network.NettyShuffleEnvironment] Shutting down network connection manager
03/06/2020 13:13:34.398 DEBUG [org.apache.flink.runtime.io.network.NettyShuffleEnvironment] Shutting down intermediate result partition manager
03/06/2020 13:13:34.398 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionManager] Releasing 0 partitions because of shutdown.
03/06/2020 13:13:34.398 DEBUG [org.apache.flink.runtime.io.network.partition.ResultPartitionManager] Successful shutdown.
03/06/2020 13:13:34.399  INFO [org.apache.flink.runtime.io.disk.FileChannelManagerImpl] FileChannelManager removed spill file directory /tmp/flink-netty-shuffle-a1c80bef-0ecb-4cf0-9606-ce437caabafb
03/06/2020 13:13:34.399  INFO [org.apache.flink.runtime.taskexecutor.KvStateService] Shutting down the kvState service and its components.
03/06/2020 13:13:34.399  INFO [org.apache.flink.runtime.taskexecutor.JobLeaderService] Stop job leader service.
03/06/2020 13:13:34.400  INFO [org.apache.flink.runtime.filecache.FileCache] removed file cache directory /tmp/flink-dist-cache-c02a8175-fe8a-45dd-aa04-d39660dd09e3
03/06/2020 13:13:34.400  INFO [org.apache.flink.runtime.taskexecutor.TaskExecutor] Stopped TaskExecutor akka://flink/user/taskmanager_2.
03/06/2020 13:13:34.401  INFO [org.apache.flink.runtime.jobmaster.JobMaster] Stopping the JobMaster for job test(cf350677de1d99f7f7ea8e79709c5624).
03/06/2020 13:13:34.401 DEBUG [org.apache.flink.runtime.jobmaster.JobMaster] Disconnect TaskExecutor c6dad6c4-5aed-483e-a3f5-af04f31f7b7e because: Stopping JobMaster for job test(cf350677de1d99f7f7ea8e79709c5624).
03/06/2020 13:13:34.402  INFO [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Removing cache directory /tmp/flink-web-ui
03/06/2020 13:13:34.402  INFO [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] Shut down complete.
03/06/2020 13:13:34.405  INFO [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] Suspending SlotPool.
03/06/2020 13:13:34.405 DEBUG [org.apache.flink.runtime.jobmaster.JobMaster] Close ResourceManager connection bc49a6984ea2749b4609c8a8d254c617.
org.apache.flink.util.FlinkException: JobManager is shutting down.
	at org.apache.flink.runtime.jobmaster.JobMaster.onStop(JobMaster.java:350)
	at org.apache.flink.runtime.rpc.RpcEndpoint.internalCallOnStop(RpcEndpoint.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor$StartedState.terminate(AkkaRpcActor.java:509)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleControlMessage(AkkaRpcActor.java:175)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction$class.applyOrElse(PartialFunction.scala:123)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at akka.actor.Actor$class.aroundReceive(Actor.scala:517)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
03/06/2020 13:13:34.406  INFO [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] Stopping SlotPool.
03/06/2020 13:13:34.406 DEBUG [org.apache.flink.runtime.resourcemanager.JobLeaderIdService] Found a new job leader null@null.
03/06/2020 13:13:34.406  INFO [org.apache.flink.runtime.resourcemanager.StandaloneResourceManager] Closing TaskExecutor connection c6dad6c4-5aed-483e-a3f5-af04f31f7b7e because: The TaskExecutor is shutting down.
03/06/2020 13:13:34.406 DEBUG [org.apache.flink.runtime.resourcemanager.slotmanager.SlotManagerImpl] Unregister TaskManager 54817bd444f822416fc4182c5a3e3f1a from the SlotManager.
03/06/2020 13:13:34.407  INFO [org.apache.flink.runtime.resourcemanager.StandaloneResourceManager] Shut down cluster because application is in CANCELED, diagnostics DispatcherResourceManagerComponent has been closed..
03/06/2020 13:13:34.407  INFO [org.apache.flink.runtime.resourcemanager.StandaloneResourceManager] Disconnect job manager 93203913567134c500f8b882c0a54ed1@akka://flink/user/jobmanager_3 for job cf350677de1d99f7f7ea8e79709c5624 from the resource manager.
03/06/2020 13:13:34.407 DEBUG [org.apache.flink.runtime.resourcemanager.StandaloneResourceManager] Discard job leader lost leadership for outdated leader 93203913567134c500f8b882c0a54ed1 for job cf350677de1d99f7f7ea8e79709c5624.
03/06/2020 13:13:34.408  INFO [org.apache.flink.runtime.entrypoint.component.DispatcherResourceManagerComponent] Closing components.
03/06/2020 13:13:34.409  INFO [org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess] Stopping SessionDispatcherLeaderProcess.
03/06/2020 13:13:34.409  INFO [org.apache.flink.runtime.dispatcher.StandaloneDispatcher] Stopping dispatcher akka://flink/user/dispatcher.
03/06/2020 13:13:34.410  INFO [org.apache.flink.runtime.dispatcher.StandaloneDispatcher] Stopping all currently running jobs of dispatcher akka://flink/user/dispatcher.
03/06/2020 13:13:34.410  INFO [org.apache.flink.runtime.rest.handler.legacy.backpressure.BackPressureRequestCoordinator] Shutting down back pressure request coordinator.
03/06/2020 13:13:34.410  INFO [org.apache.flink.runtime.dispatcher.StandaloneDispatcher] Stopped dispatcher akka://flink/user/dispatcher.
03/06/2020 13:13:34.411  INFO [org.apache.flink.runtime.resourcemanager.slotmanager.SlotManagerImpl] Closing the SlotManager.
03/06/2020 13:13:34.411  INFO [org.apache.flink.runtime.resourcemanager.slotmanager.SlotManagerImpl] Suspending the SlotManager.
03/06/2020 13:13:34.412  INFO [org.apache.flink.runtime.rpc.akka.AkkaRpcService] Stopping Akka RPC service.
03/06/2020 13:13:34.416  INFO [akka.remote.RemoteActorRefProvider$RemotingTerminator] Shutting down remote daemon.
03/06/2020 13:13:34.418  INFO [akka.remote.RemoteActorRefProvider$RemotingTerminator] Remote daemon shut down; proceeding with flushing remote transports.
03/06/2020 13:13:34.423  INFO [akka.remote.RemoteActorRefProvider$RemotingTerminator] Remoting shut down.
03/06/2020 13:13:34.439  INFO [org.apache.flink.runtime.rpc.akka.AkkaRpcService] Stopping Akka RPC service.
03/06/2020 13:13:34.439  INFO [org.apache.flink.runtime.rpc.akka.AkkaRpcService] Stopped Akka RPC service.
03/06/2020 13:13:34.444  INFO [org.apache.flink.runtime.blob.PermanentBlobCache] Shutting down BLOB cache
03/06/2020 13:13:34.445  INFO [org.apache.flink.runtime.blob.TransientBlobCache] Shutting down BLOB cache
03/06/2020 13:13:34.447  INFO [org.apache.flink.runtime.blob.BlobServer] Stopped BLOB server at 0.0.0.0:43109
03/06/2020 13:13:34.447  INFO [org.apache.flink.runtime.rpc.akka.AkkaRpcService] Stopped Akka RPC service.
